{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn import model_selection,ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "# from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, LabelBinarizer, MultiLabelBinarizer,LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats.mstats import gmean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "train_df=pd.read_json('../input/train.json').reset_index(drop = True)\n",
    "test_df=pd.read_json('../input/test.json').reset_index(drop = True)\n",
    "\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 322)\n",
      "(74659, 322)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X_0322 = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X_0322 = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "\n",
    "print train_X_0322.shape\n",
    "print test_X_0322.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_num_map = {'high':2, 'medium':1, 'low':0}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 222)\n",
      "(74659, 222)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_CV_MS_52571.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_CV_MS_52571.csv')\n",
    "print train_X.shape\n",
    "print test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 223)\n",
      "(74659, 223)\n"
     ]
    }
   ],
   "source": [
    "time_feature = pd.read_csv(data_path + 'listing_image_time.csv')\n",
    "time_feature.columns = ['listing_id','time_stamp']\n",
    "train_X = train_X.merge(time_feature,on='listing_id',how='left')\n",
    "test_X = test_X.merge(time_feature,on='listing_id',how='left')\n",
    "\n",
    "print train_X.shape\n",
    "print test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgb_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,random_state=1234)\n",
    "    N_class = len(set(train_y))\n",
    "        \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(objective = 'binary:logistic')\n",
    "        est.set_params(silent = False)\n",
    "        est.set_params(learning_rate = 0.03)\n",
    "        est.set_params(n_estimators=1000000)\n",
    "        \n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "    \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]      \n",
    "\n",
    "            est.fit(train_x_fold,train_y_fold,\n",
    "                    eval_set = [(val_x_fold, val_y_fold)],\n",
    "                    eval_metric = 'logloss',\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose=False)\n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,ntree_limit=best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score\n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,ntree_limit=best_round)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34284\n"
     ]
    }
   ],
   "source": [
    "y_low =[]\n",
    "for i in range(train_X.shape[0]):\n",
    "    y_low.append(1 if train_y[i] == 0 else 0)\n",
    "    \n",
    "y_low = np.array(y_low)  \n",
    "print np.sum(y_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 5 folds\n",
      "Model 1: XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.290381,\n",
      "       gamma=0.075128, learning_rate=0.03, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=6, missing=None, n_estimators=1000000, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=False, subsample=0.988734)\n",
      "Model 1 fold 1\n",
      "best round 2558\n",
      "('Score: ', 0.38437436864385305)\n",
      "Model 1 fold 1 fitting finished in 58.124s\n",
      "Model 1 fold 2\n",
      "best round 2164\n",
      "('Score: ', 0.34849309257339706)\n",
      "Model 1 fold 2 fitting finished in 49.444s\n",
      "Model 1 fold 3\n",
      "best round 2468\n",
      "('Score: ', 0.34681978626416798)\n",
      "Model 1 fold 3 fitting finished in 55.462s\n",
      "Model 1 fold 4\n",
      "best round 2581\n",
      "('Score: ', 0.36662480416383131)\n",
      "Model 1 fold 4 fitting finished in 56.222s\n",
      "Model 1 fold 5\n",
      "best round 1959\n",
      "('Score: ', 0.38789336896971094)\n",
      "Model 1 fold 5 fitting finished in 45.294s\n",
      "Score for model 1 is 0.366841\n",
      "Score for blended models is 0.366841\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "            xgb.XGBClassifier(max_depth = 4,\n",
    "                              min_child_weight = 6,\n",
    "                              colsample_bytree = 0.290381 ,\n",
    "                              subsample = 0.988734 ,\n",
    "                              gamma = 0.075128)          \n",
    "             ]\n",
    "#  \t \tmax_depth \tmin_child_weight \tcolsample_bytree \tsubsample \tgamma \t \tscore\n",
    "# 12 \t4.697965 \t6.439472 \t \t \t0.290381 \t \t \t0.988734 \t0.075128 \t-0.386062\n",
    "# 5 \t4.361961 \t8.354384 \t \t \t0.768667 \t \t \t0.986623 \t0.003024 \t-0.386068\n",
    "# 28 \t5.020978 \t19.866215 \t \t \t0.883846 \t \t \t0.984659 \t0.135751 \t-0.386150\n",
    "\n",
    "\n",
    "(train_blend_x_xgb_low,\n",
    " test_blend_x_xgb_mean_low,\n",
    " test_blend_x_xgb_gmean_low,\n",
    " blend_scores_xgb_low,\n",
    " best_rounds_xgb_low) = xgb_blend(estimators,\n",
    "                              train_X,y_low,\n",
    "                              test_X,\n",
    "                              5,\n",
    "                              200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36684108]\n",
      "[ 2346.]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_xgb_low_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_low_mean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../output/test_blend_xgb_low_gmean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb_low,axis=0))\n",
    "print (np.mean(best_rounds_xgb_low,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_xgb_low, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_xgb_mean_low, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_xgb_gmean_low, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11229\n"
     ]
    }
   ],
   "source": [
    "y_medium =[]\n",
    "for i in range(train_X.shape[0]):\n",
    "    y_medium.append(1 if train_y[i] == 1 else 0)\n",
    "    \n",
    "y_medium = np.array(y_medium)  \n",
    "print np.sum(y_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 5 folds\n",
      "Model 1: XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.986761,\n",
      "       gamma=0.034931, learning_rate=0.03, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=16, missing=None, n_estimators=1000000, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=False, subsample=0.986039)\n",
      "Model 1 fold 1\n",
      "best round 992\n",
      "('Score: ', 0.42220802852188838)\n",
      "Model 1 fold 1 fitting finished in 62.282s\n",
      "Model 1 fold 2\n",
      "best round 848\n",
      "('Score: ', 0.40444656485414893)\n",
      "Model 1 fold 2 fitting finished in 55.550s\n",
      "Model 1 fold 3\n",
      "best round 1423\n",
      "('Score: ', 0.40104374546981869)\n",
      "Model 1 fold 3 fitting finished in 84.455s\n",
      "Model 1 fold 4\n",
      "best round 1080\n",
      "('Score: ', 0.41120174265612414)\n",
      "Model 1 fold 4 fitting finished in 66.330s\n",
      "Model 1 fold 5\n",
      "best round 1055\n",
      "('Score: ', 0.42669308882738127)\n",
      "Model 1 fold 5 fitting finished in 64.727s\n",
      "Score for model 1 is 0.413119\n",
      "Score for blended models is 0.413119\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "            xgb.XGBClassifier(max_depth = 5,\n",
    "                              min_child_weight = 16,\n",
    "                              colsample_bytree = 0.986761 ,\n",
    "                              subsample = 0.986039 ,\n",
    "                              gamma = 0.034931)          \n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "(train_blend_x_xgb_medium,\n",
    " test_blend_x_xgb_mean_medium,\n",
    " test_blend_x_xgb_gmean_medium,\n",
    " blend_scores_xgb_medium,\n",
    " best_rounds_xgb_medium) = xgb_blend(estimators,\n",
    "                              train_X,y_medium,\n",
    "                              test_X,\n",
    "                              5,\n",
    "                              200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.41311863]\n",
      "[ 1079.6]\n"
     ]
    }
   ],
   "source": [
    "name_train_blend = '../output/train_blend_xgb_medium_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_medium_mean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../output/test_blend_xgb_medium_gmean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb_medium,axis=0))\n",
    "print (np.mean(best_rounds_xgb_medium,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_xgb_medium, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_xgb_mean_medium, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_xgb_gmean_medium, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3839\n"
     ]
    }
   ],
   "source": [
    "y_high =[]\n",
    "for i in range(train_X.shape[0]):\n",
    "    y_high.append(1 if train_y[i] == 2 else 0)\n",
    "    \n",
    "y_high = np.array(y_high)  \n",
    "print np.sum(y_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 5 folds\n",
      "Model 1: XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.254931,\n",
      "       gamma=1.52802, learning_rate=0.03, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=6, missing=None, n_estimators=1000000, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=False, subsample=0.99869)\n",
      "Model 1 fold 1\n",
      "best round 837\n",
      "('Score: ', 0.17048693307556323)\n",
      "Model 1 fold 1 fitting finished in 30.681s\n",
      "Model 1 fold 2\n",
      "best round 775\n",
      "('Score: ', 0.16771294040236134)\n",
      "Model 1 fold 2 fitting finished in 29.559s\n",
      "Model 1 fold 3\n",
      "best round 634\n",
      "('Score: ', 0.16826319966689912)\n",
      "Model 1 fold 3 fitting finished in 25.273s\n",
      "Model 1 fold 4\n",
      "best round 674\n",
      "('Score: ', 0.16382289716470466)\n",
      "Model 1 fold 4 fitting finished in 26.635s\n",
      "Model 1 fold 5\n",
      "best round 933\n",
      "('Score: ', 0.17342380741860161)\n",
      "Model 1 fold 5 fitting finished in 33.723s\n",
      "Score for model 1 is 0.168742\n",
      "Score for blended models is 0.168742\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "            xgb.XGBClassifier(max_depth = 6,\n",
    "                              min_child_weight = 6,\n",
    "                              colsample_bytree = 0.254931 ,\n",
    "                              subsample = 0.998690 ,\n",
    "                              gamma = 1.528020)          \n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "(train_blend_x_xgb_high,\n",
    " test_blend_x_xgb_mean_high,\n",
    " test_blend_x_xgb_gmean_high,\n",
    " blend_scores_xgb_high,\n",
    " best_rounds_xgb_high) = xgb_blend(estimators,\n",
    "                              train_X,y_high,\n",
    "                              test_X,\n",
    "                              5,\n",
    "                              200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16874196]\n",
      "[ 770.6]\n"
     ]
    }
   ],
   "source": [
    "name_train_blend = '../output/train_blend_xgb_high_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_high_mean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../output/test_blend_xgb_high_gmean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb_high,axis=0))\n",
    "print (np.mean(best_rounds_xgb_high,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_xgb_high, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_xgb_mean_high, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_xgb_gmean_high, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352L, 3L)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_blend_x_xgb = np.vstack([train_blend_x_xgb_low[:,1],train_blend_x_xgb_medium[:,1],train_blend_x_xgb_high[:,1]]).T\n",
    "train_blend_x_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659L, 3L)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_mean = np.vstack([test_blend_x_xgb_mean_low[:,1],test_blend_x_xgb_mean_medium[:,1],test_blend_x_xgb_mean_high[:,1]]).T\n",
    "test_blend_x_xgb_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659L, 3L)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_gmean = np.vstack([test_blend_x_xgb_gmean_low[:,1],test_blend_x_xgb_gmean_medium[:,1],test_blend_x_xgb_gmean_high[:,1]]).T\n",
    "test_blend_x_xgb_gmean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_blend_x_xgb = pd.DataFrame(train_blend_x_xgb)\n",
    "train_blend_x_xgb.columns = [\"low\", \"medium\", \"high\"]\n",
    "train_blend_x_xgb[\"listing_id\"] = train_X.listing_id.values\n",
    "\n",
    "test_blend_x_xgb_mean = pd.DataFrame(test_blend_x_xgb_mean)\n",
    "test_blend_x_xgb_mean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_blend_x_xgb_mean[\"listing_id\"] = test_X.listing_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_train = train_X_0322[['listing_id']].merge(train_blend_x_xgb,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_mean = test_X_0322[['listing_id']].merge(test_blend_x_xgb_mean,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_train_blend = '../output/train_blend_xgb_ovr_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_ovr_mean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "# print (np.mean(blend_scores_xgb,axis=0))\n",
    "# print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,tmp_train, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,tmp_test_mean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_XGB_2bagging_CV_MS_52571_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(tmp_test_mean[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X_0322.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.47930203e-01,   5.71099824e-01,   1.64883459e-01],\n",
       "       [  9.77132773e-01,   1.00000978e-02,   8.71934639e-03],\n",
       "       [  9.54789793e-01,   9.35790062e-02,   4.79983645e-03],\n",
       "       [  1.54439420e-01,   5.56799817e-01,   2.12952900e-01],\n",
       "       [  6.97897673e-01,   2.67950007e-01,   8.85903025e-03],\n",
       "       [  7.56280649e-01,   2.96792227e-01,   5.74759413e-03],\n",
       "       [  9.99139762e-01,   1.95185969e-03,   1.24549634e-04],\n",
       "       [  2.58878088e-01,   4.86703187e-01,   1.73916987e-01],\n",
       "       [  9.26443124e-01,   3.78795039e-02,   1.36201400e-02],\n",
       "       [  9.85897434e-01,   1.59702195e-02,   1.36567574e-03]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_test_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
