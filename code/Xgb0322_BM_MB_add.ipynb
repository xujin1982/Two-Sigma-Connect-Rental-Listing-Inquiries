{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.stats.mstats import gmean\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import skew, boxcox,boxcox_normmax\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 322) (74659, 322) (49352,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "sub_id = test_X.listing_id.astype('int32').values\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 322)\n",
      "(9871, 322)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "# xgtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.03729\n",
      "Will train until validation_0-mlogloss hasn't improved in 50 rounds.\n",
      "[25]\tvalidation_0-mlogloss:0.639405\n",
      "[50]\tvalidation_0-mlogloss:0.599529\n",
      "[75]\tvalidation_0-mlogloss:0.584213\n",
      "[100]\tvalidation_0-mlogloss:0.574866\n",
      "[125]\tvalidation_0-mlogloss:0.568737\n",
      "[150]\tvalidation_0-mlogloss:0.563895\n",
      "[175]\tvalidation_0-mlogloss:0.560445\n",
      "[200]\tvalidation_0-mlogloss:0.557579\n",
      "[225]\tvalidation_0-mlogloss:0.555358\n",
      "[250]\tvalidation_0-mlogloss:0.553443\n",
      "[275]\tvalidation_0-mlogloss:0.551671\n",
      "[300]\tvalidation_0-mlogloss:0.550225\n",
      "[325]\tvalidation_0-mlogloss:0.548876\n",
      "[350]\tvalidation_0-mlogloss:0.547644\n",
      "[375]\tvalidation_0-mlogloss:0.546672\n",
      "[400]\tvalidation_0-mlogloss:0.545659\n",
      "[425]\tvalidation_0-mlogloss:0.545018\n",
      "[450]\tvalidation_0-mlogloss:0.544299\n",
      "[475]\tvalidation_0-mlogloss:0.543861\n",
      "[500]\tvalidation_0-mlogloss:0.543206\n",
      "[525]\tvalidation_0-mlogloss:0.542953\n",
      "[550]\tvalidation_0-mlogloss:0.542268\n",
      "[575]\tvalidation_0-mlogloss:0.541983\n",
      "[600]\tvalidation_0-mlogloss:0.541475\n",
      "[625]\tvalidation_0-mlogloss:0.541075\n",
      "[650]\tvalidation_0-mlogloss:0.540843\n",
      "[675]\tvalidation_0-mlogloss:0.540564\n",
      "[700]\tvalidation_0-mlogloss:0.540464\n",
      "[725]\tvalidation_0-mlogloss:0.540027\n",
      "[750]\tvalidation_0-mlogloss:0.539665\n",
      "[775]\tvalidation_0-mlogloss:0.53961\n",
      "[800]\tvalidation_0-mlogloss:0.539347\n",
      "[825]\tvalidation_0-mlogloss:0.539155\n",
      "[850]\tvalidation_0-mlogloss:0.539059\n",
      "[875]\tvalidation_0-mlogloss:0.539007\n",
      "[900]\tvalidation_0-mlogloss:0.538696\n",
      "[925]\tvalidation_0-mlogloss:0.538523\n",
      "[950]\tvalidation_0-mlogloss:0.538428\n",
      "[975]\tvalidation_0-mlogloss:0.538212\n",
      "[1000]\tvalidation_0-mlogloss:0.538089\n",
      "[1025]\tvalidation_0-mlogloss:0.538194\n",
      "Stopping. Best iteration:\n",
      "[999]\tvalidation_0-mlogloss:0.538056\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=10000, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgr = xgb.XGBClassifier(objective = 'multi:softprob',\n",
    "                       learning_rate = 0.1,\n",
    "                       n_estimators = 10000,\n",
    "                       nthread = -1)\n",
    "\n",
    "rgr.fit(X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "#         num_class = 3,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=25\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y = rgr.predict_proba(test_X, ntree_limit = rgr.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "sub_name = '../output/sub_xgb_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(pred_y[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = sub_id\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tune XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t0.538056 999\n",
      "4 \t0.535551 682\n",
      "5 \t0.535388 504\n",
      "6 \t0.537389 281\n",
      "7 \t0.53739 228\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "best_score = 1000\n",
    "train_param = 0\n",
    "for x in [3,4,5,6,7]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= x,\n",
    "        nthread = -1,\n",
    "        silent = False\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \t0.539197 171\n",
      "9 \t0.544561 123\n"
     ]
    }
   ],
   "source": [
    "for x in [8,9]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= x,\n",
    "        nthread = -1,\n",
    "        silent = False\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "max_depth = train_param\n",
    "print max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t0.535875 451\n",
      "4 \t0.53768 468\n",
      "8 \t0.535414 541\n",
      "12 \t0.535852 382\n",
      "16 \t0.534811 502\n",
      "20 \t0.535808 417\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [2,4,8,12,16,20]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 \t0.534658 465\n",
      "28 \t0.535242 387\n",
      "32 \t0.535742 501\n"
     ]
    }
   ],
   "source": [
    "for x in [24,28,32]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "min_child_weight = train_param\n",
    "print min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 \t0.543347 1102\n",
      "0.1 \t0.537411 558\n",
      "0.2 \t0.532129 548\n",
      "0.3 \t0.530955 594\n",
      "0.4 \t0.532481 472\n",
      "0.5 \t0.533489 439\n",
      "0.6 \t0.53406 442\n",
      "0.7 \t0.533872 533\n",
      "0.8 \t0.535258 458\n",
      "0.9 \t0.535175 532\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = train_param\n",
    "print colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 \t0.53808 445\n",
      "0.6 \t0.53512 453\n",
      "0.7 \t0.534725 432\n",
      "0.8 \t0.534234 482\n",
      "0.9 \t0.531949 483\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        subsample = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "subsample = train_param\n",
    "print subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 \t0.530912 593\n",
      "0.6 \t0.531407 607\n",
      "0.9 \t0.532852 469\n",
      "1.2 \t0.530871 677\n",
      "1.5 \t0.530909 555\n",
      "1.8 \t0.532441 586\n",
      "2.1 \t0.532689 696\n",
      "2.4 \t0.531855 654\n",
      "2.7 \t0.534031 864\n",
      "3.0 \t0.533408 804\n"
     ]
    }
   ],
   "source": [
    "train_param = 0\n",
    "for x in [0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3.0]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        subsample = subsample,\n",
    "        gamma = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2\n"
     ]
    }
   ],
   "source": [
    "gamma = train_param\n",
    "print gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.3 \t0.528756 371\n",
    "# 0.6 \t0.530068 353\n",
    "# 0.9 \t0.530043 275\n",
    "# 1.2 \t0.530065 388\n",
    "# 1.5 \t0.529657 331\n",
    "# 1.8 \t0.529906 328\n",
    "# 2.1 \t0.528338 393\n",
    "# 2.4 \t0.529364 372\n",
    "# 2.7 \t0.527919 456\n",
    "# 3.0 \t0.528962 417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[725]\ttrain-mlogloss:0.400678+0.00155655\ttest-mlogloss:0.529636+0.00537507\n",
      "\n",
      "    1 | 21m34s | \u001b[35m  -0.52964\u001b[0m | \u001b[32m            0.5829\u001b[0m | \u001b[32m   0.5937\u001b[0m | \u001b[32m     4.5959\u001b[0m | \u001b[32m           22.1669\u001b[0m | \u001b[32m     0.9258\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[436]\ttrain-mlogloss:0.329219+0.000572654\ttest-mlogloss:0.529528+0.00450463\n",
      "\n",
      "    2 | 13m13s | \u001b[35m  -0.52953\u001b[0m | \u001b[32m            0.2249\u001b[0m | \u001b[32m   2.0639\u001b[0m | \u001b[32m     9.2559\u001b[0m | \u001b[32m           27.9980\u001b[0m | \u001b[32m     0.9033\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[620]\ttrain-mlogloss:0.382068+0.00175183\ttest-mlogloss:0.529855+0.00489064\n",
      "\n",
      "    3 | 11m23s |   -0.52985 |             0.2260 |    1.1090 |      5.9577 |            20.5135 |      0.8806 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[539]\ttrain-mlogloss:0.378652+0.00153673\ttest-mlogloss:0.528915+0.00471728\n",
      "\n",
      "    4 | 16m09s | \u001b[35m  -0.52892\u001b[0m | \u001b[32m            0.3537\u001b[0m | \u001b[32m   2.2917\u001b[0m | \u001b[32m     6.3368\u001b[0m | \u001b[32m           27.6647\u001b[0m | \u001b[32m     0.8543\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[408]\ttrain-mlogloss:0.352017+0.00078047\ttest-mlogloss:0.527827+0.00393516\n",
      "\n",
      "    5 | 18m39s | \u001b[35m  -0.52783\u001b[0m | \u001b[32m            0.5019\u001b[0m | \u001b[32m   2.0627\u001b[0m | \u001b[32m     7.1299\u001b[0m | \u001b[32m           26.5390\u001b[0m | \u001b[32m     0.9817\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[445]\ttrain-mlogloss:0.353028+0.00176479\ttest-mlogloss:0.528777+0.0045159\n",
      "\n",
      "    6 | 11m35s |   -0.52878 |             0.2910 |    0.2977 |      6.3218 |            19.3892 |      0.9229 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[313]\ttrain-mlogloss:0.347105+0.00178655\ttest-mlogloss:0.528801+0.00432501\n",
      "\n",
      "    7 | 16m42s |   -0.52880 |             0.5807 |    0.9820 |      7.1708 |            27.5953 |      0.9613 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[567]\ttrain-mlogloss:0.398161+0.000843893\ttest-mlogloss:0.529514+0.00530573\n",
      "\n",
      "    8 | 13m29s |   -0.52951 |             0.3189 |    2.0874 |      5.3422 |            16.8676 |      0.8292 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[559]\ttrain-mlogloss:0.376363+0.000870647\ttest-mlogloss:0.528177+0.00523033\n",
      "\n",
      "    9 | 17m03s |   -0.52818 |             0.4524 |    0.5824 |      5.3800 |            25.3427 |      0.9086 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[365]\ttrain-mlogloss:0.344995+0.000931265\ttest-mlogloss:0.527054+0.00451258\n",
      "\n",
      "   10 | 17m41s | \u001b[35m  -0.52705\u001b[0m | \u001b[32m            0.4080\u001b[0m | \u001b[32m   2.5434\u001b[0m | \u001b[32m     9.9217\u001b[0m | \u001b[32m           24.6880\u001b[0m | \u001b[32m     0.9978\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00019102]), 'nit': 5, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[184]\ttrain-mlogloss:0.291984+0.00238293\ttest-mlogloss:0.529962+0.00405876\n",
      "\n",
      "   11 | 14m49s |   -0.52996 |             0.5553 |    0.3280 |      9.9388 |            12.1396 |      0.9189 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[925]\ttrain-mlogloss:0.382127+0.000735958\ttest-mlogloss:0.529125+0.00451081\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 19m22s |   -0.52913 |             0.3726 |    0.2058 |      4.0259 |            12.2460 |      0.9922 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[172]\ttrain-mlogloss:0.32246+0.00132542\ttest-mlogloss:0.529665+0.00446974\n",
      "\n",
      "   13 | 14m17s |   -0.52966 |             0.5996 |    0.1170 |      9.9857 |            19.8379 |      0.9344 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1026]\ttrain-mlogloss:0.375292+0.00130248\ttest-mlogloss:0.527378+0.00533473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.21692541e-05]), 'nit': 7, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 21m56s |   -0.52738 |             0.2040 |    2.9926 |      7.4795 |            12.1574 |      0.9932 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[473]\ttrain-mlogloss:0.350935+0.00143367\ttest-mlogloss:0.526713+0.00522667\n",
      "\n",
      "   15 | 19m10s | \u001b[35m  -0.52671\u001b[0m | \u001b[32m            0.3269\u001b[0m | \u001b[32m   2.9211\u001b[0m | \u001b[32m     9.8785\u001b[0m | \u001b[32m           15.6469\u001b[0m | \u001b[32m     0.9999\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[885]\ttrain-mlogloss:0.406373+0.00130509\ttest-mlogloss:0.530122+0.00552415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00013456]), 'nit': 8, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 12m59s |   -0.53012 |             0.2128 |    0.3522 |      4.0512 |            27.9874 |      0.9984 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[430]\ttrain-mlogloss:0.33863+0.00047786\ttest-mlogloss:0.526687+0.004655\n",
      "\n",
      "   17 | 22m18s | \u001b[35m  -0.52669\u001b[0m | \u001b[32m            0.4301\u001b[0m | \u001b[32m   2.9819\u001b[0m | \u001b[32m     9.9223\u001b[0m | \u001b[32m           12.3224\u001b[0m | \u001b[32m     0.9849\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[342]\ttrain-mlogloss:0.345625+0.00123\ttest-mlogloss:0.527731+0.00503383\n",
      "\n",
      "   18 | 22m57s |   -0.52773 |             0.5676 |    2.9370 |      9.9507 |            18.8677 |      0.9769 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[484]\ttrain-mlogloss:0.345386+0.000440656\ttest-mlogloss:0.52709+0.00411556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.23095919e-05]), 'nit': 6, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 27m45s |   -0.52709 |             0.5698 |    2.9517 |      8.5407 |            14.3097 |      0.9893 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1075]\ttrain-mlogloss:0.408316+0.000779373\ttest-mlogloss:0.529536+0.00573271\n",
      "\n",
      "   20 | 32m21s |   -0.52954 |             0.5745 |    2.9787 |      4.0570 |            12.2167 |      0.8481 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[671]\ttrain-mlogloss:0.34419+0.00122427\ttest-mlogloss:0.526417+0.00519199\n",
      "\n",
      "   21 | 20m21s | \u001b[35m  -0.52642\u001b[0m | \u001b[32m            0.2345\u001b[0m | \u001b[32m   2.9557\u001b[0m | \u001b[32m     9.8936\u001b[0m | \u001b[32m           13.9868\u001b[0m | \u001b[32m     0.9924\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[425]\ttrain-mlogloss:0.367233+0.00141695\ttest-mlogloss:0.528121+0.00458593\n",
      "\n",
      "   22 | 25m05s |   -0.52812 |             0.5857 |    2.9283 |      8.3730 |            24.0534 |      0.9991 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[264]\ttrain-mlogloss:0.301601+0.00214229\ttest-mlogloss:0.529673+0.00545832\n",
      "\n",
      "   23 | 09m14s |   -0.52967 |             0.2270 |    0.1300 |      9.5883 |            24.7780 |      0.9991 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[329]\ttrain-mlogloss:0.33742+0.00105822\ttest-mlogloss:0.527884+0.00549481\n",
      "\n",
      "   24 | 21m40s |   -0.52788 |             0.5245 |    2.9406 |      9.8065 |            14.1761 |      0.8126 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1284]\ttrain-mlogloss:0.452767+0.00216061\ttest-mlogloss:0.531581+0.00570076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00038557]), 'nit': 6, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 24m00s |   -0.53158 |             0.3279 |    2.9467 |      4.0821 |            25.2351 |      0.9964 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[674]\ttrain-mlogloss:0.339162+0.00168842\ttest-mlogloss:0.527123+0.00407488\n",
      "\n",
      "   26 | 27m28s |   -0.52712 |             0.3474 |    2.9096 |      9.8901 |            22.4212 |      0.9922 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[350]\ttrain-mlogloss:0.315887+0.00212657\ttest-mlogloss:0.528965+0.0057493\n",
      "\n",
      "   27 | 09m56s |   -0.52897 |             0.2094 |    1.3550 |      8.1596 |            15.1486 |      0.9990 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[796]\ttrain-mlogloss:0.398342+0.000935813\ttest-mlogloss:0.52962+0.00512416\n",
      "\n",
      "   28 | 18m23s |   -0.52962 |             0.4139 |    0.0550 |      4.1015 |            16.8497 |      0.9874 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[530]\ttrain-mlogloss:0.356918+0.000787767\ttest-mlogloss:0.527206+0.0045221\n",
      "\n",
      "   29 | 20m58s |   -0.52721 |             0.3174 |    2.9903 |      9.8928 |            26.1291 |      0.9768 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[748]\ttrain-mlogloss:0.386239+0.00209232\ttest-mlogloss:0.527638+0.00479446\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  3.03760612e-05]), 'nit': 7, 'funcalls': 64}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 16m39s |   -0.52764 |             0.2059 |    2.9171 |      7.9178 |            16.7649 |      0.9963 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[607]\ttrain-mlogloss:0.34644+0.00153277\ttest-mlogloss:0.527363+0.0058374\n",
      "\n",
      "   31 | 17m39s |   -0.52736 |             0.2147 |    2.9002 |      9.0786 |            13.1329 |      0.9820 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[413]\ttrain-mlogloss:0.345909+0.00148099\ttest-mlogloss:0.526405+0.00424134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  2.73735510e-05]), 'nit': 7, 'funcalls': 62}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00032061]), 'nit': 7, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00066785]), 'nit': 7, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 21m24s | \u001b[35m  -0.52641\u001b[0m | \u001b[32m            0.4333\u001b[0m | \u001b[32m   2.9445\u001b[0m | \u001b[32m     9.8583\u001b[0m | \u001b[32m           13.2500\u001b[0m | \u001b[32m     0.9998\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[691]\ttrain-mlogloss:0.381477+0.00135683\ttest-mlogloss:0.527726+0.00447741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  2.77681684e-05]), 'nit': 7, 'funcalls': 62}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  2.96226208e-05]), 'nit': 7, 'funcalls': 64}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 29m05s |   -0.52773 |             0.5670 |    2.9543 |      6.0514 |            14.7623 |      0.9909 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[412]\ttrain-mlogloss:0.333635+0.00144647\ttest-mlogloss:0.526878+0.00511223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00425353]), 'nit': 2, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00076771]), 'nit': 6, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 23m45s |   -0.52688 |             0.4896 |    2.8750 |      9.9790 |            13.0506 |      0.9895 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[374]\ttrain-mlogloss:0.368002+0.00102855\ttest-mlogloss:0.528896+0.00498313\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00025348]), 'nit': 3, 'funcalls': 59}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 17m14s |   -0.52890 |             0.5711 |    0.0176 |      6.7121 |            23.6963 |      0.9993 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[620]\ttrain-mlogloss:0.374049+0.00316101\ttest-mlogloss:0.527624+0.00446495\n",
      "\n",
      "   36 | 28m54s |   -0.52762 |             0.5291 |    2.9870 |      7.4630 |            19.1157 |      0.9975 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[447]\ttrain-mlogloss:0.342849+0.00109567\ttest-mlogloss:0.528036+0.00503764\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.68942352e-05]), 'nit': 7, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 26m55s |   -0.52804 |             0.5906 |    2.8966 |      8.6491 |            12.0881 |      0.9900 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[484]\ttrain-mlogloss:0.340231+0.000564369\ttest-mlogloss:0.52791+0.0048331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00096295]), 'nit': 6, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.80424205e-05]), 'nit': 7, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   38 | 32m18s |   -0.52791 |             0.5915 |    2.9325 |      9.6668 |            27.3338 |      0.9887 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[644]\ttrain-mlogloss:0.350561+0.000690743\ttest-mlogloss:0.527347+0.00468315\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00173974]), 'nit': 5, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.10275432e-05]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 18m15s |   -0.52735 |             0.2036 |    2.9937 |      9.7210 |            13.6505 |      0.9663 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1647]\ttrain-mlogloss:0.433856+0.00316512\ttest-mlogloss:0.529726+0.00557642\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00248712]), 'nit': 6, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -4.25134356e-05]), 'nit': 6, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 | 28m32s |   -0.52973 |             0.2936 |    2.7764 |      4.0773 |            18.3647 |      0.9934 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[208]\ttrain-mlogloss:0.294488+0.00167102\ttest-mlogloss:0.528641+0.00366348\n",
      "\n",
      "   41 | 14m58s |   -0.52864 |             0.5352 |    0.0016 |      9.4992 |            16.3353 |      0.9942 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1558]\ttrain-mlogloss:0.45136+0.00192101\ttest-mlogloss:0.530909+0.0056377\n",
      "\n",
      "   42 | 24m25s |   -0.53091 |             0.2486 |    2.9264 |      4.0958 |            14.2523 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[366]\ttrain-mlogloss:0.356865+0.00128579\ttest-mlogloss:0.529281+0.00488904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00022167]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 17m41s |   -0.52928 |             0.5938 |    0.0263 |      6.0669 |            12.0085 |      0.9943 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[273]\ttrain-mlogloss:0.351369+0.00163731\ttest-mlogloss:0.528499+0.00402837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00192492]), 'nit': 6, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   44 | 15m46s |   -0.52850 |             0.5737 |    0.7939 |      7.0712 |            17.5950 |      0.9991 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1000]\ttrain-mlogloss:0.400203+0.00356582\ttest-mlogloss:0.528327+0.0052068\n",
      "\n",
      "   45 | 35m34s |   -0.52833 |             0.5396 |    2.9644 |      5.7632 |            12.0119 |      0.9866 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[739]\ttrain-mlogloss:0.411229+0.00135623\ttest-mlogloss:0.529978+0.00485103\n",
      "\n",
      "   46 | 16m34s |   -0.52998 |             0.3732 |    0.0361 |      4.2472 |            24.7241 |      0.9915 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[253]\ttrain-mlogloss:0.302018+0.00207454\ttest-mlogloss:0.528175+0.00447446\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00780927]), 'nit': 3, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   47 | 15m45s |   -0.52817 |             0.4709 |    0.0424 |      9.8735 |            27.6846 |      0.9867 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[983]\ttrain-mlogloss:0.405389+0.00263627\ttest-mlogloss:0.528608+0.00500426\n",
      "\n",
      "   48 | 32m51s |   -0.52861 |             0.5346 |    2.9289 |      5.8091 |            17.3035 |      0.9933 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[411]\ttrain-mlogloss:0.371359+0.000881543\ttest-mlogloss:0.528633+0.00477758\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -4.00427089e-05]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 11m44s |   -0.52863 |             0.2818 |    0.0935 |      6.3628 |            26.3586 |      0.9974 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1691]\ttrain-mlogloss:0.440857+0.00397754\ttest-mlogloss:0.530862+0.00564943\n",
      "\n",
      "   50 | 47m40s |   -0.53086 |             0.5715 |    2.8924 |      4.7404 |            27.7970 |      0.9955 | \n"
     ]
    }
   ],
   "source": [
    "xgtrain = xgb.DMatrix(train_X, label=train_y) \n",
    "\n",
    "def xgb_evaluate(min_child_weight, colsample_bytree, max_depth, subsample, gamma):\n",
    "    params = dict()\n",
    "    params['objective']='multi:softprob'\n",
    "    params['eval_metric']='mlogloss',\n",
    "    params['num_class']=3\n",
    "    params['silent']=1\n",
    "    params['eta'] = 0.1\n",
    "    params['verbose_eval'] = True\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    \n",
    "    cv_result = xgb.cv(\n",
    "        params, xgtrain, \n",
    "        num_boost_round=10000, nfold=5,\n",
    "        metrics = 'mlogloss',\n",
    "        seed=seed,callbacks=[xgb.callback.early_stop(50)]\n",
    "    )\n",
    "    \n",
    "    return -cv_result['test-mlogloss-mean'].values[-1]\n",
    "\n",
    "\n",
    "xgb_BO = BayesianOptimization(\n",
    "    xgb_evaluate, \n",
    "    {\n",
    "        'max_depth': (4,10),\n",
    "        'min_child_weight': (12,28),\n",
    "        'colsample_bytree': (0.2,0.6),\n",
    "        'subsample': (0.8,1),\n",
    "        'gamma': (0,3)\n",
    "    }\n",
    ")\n",
    "\n",
    "xgb_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>gamma</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.858298</td>\n",
       "      <td>13.249991</td>\n",
       "      <td>0.433260</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>2.944467</td>\n",
       "      <td>-0.526405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.893582</td>\n",
       "      <td>13.986790</td>\n",
       "      <td>0.234479</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>2.955693</td>\n",
       "      <td>-0.526417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.922328</td>\n",
       "      <td>12.322410</td>\n",
       "      <td>0.430052</td>\n",
       "      <td>0.984938</td>\n",
       "      <td>2.981919</td>\n",
       "      <td>-0.526687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.878492</td>\n",
       "      <td>15.646924</td>\n",
       "      <td>0.326926</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>2.921145</td>\n",
       "      <td>-0.526713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.979036</td>\n",
       "      <td>13.050578</td>\n",
       "      <td>0.489616</td>\n",
       "      <td>0.989539</td>\n",
       "      <td>2.874991</td>\n",
       "      <td>-0.526878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.540735</td>\n",
       "      <td>14.309724</td>\n",
       "      <td>0.569809</td>\n",
       "      <td>0.989256</td>\n",
       "      <td>2.951742</td>\n",
       "      <td>-0.527090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.890100</td>\n",
       "      <td>22.421182</td>\n",
       "      <td>0.347370</td>\n",
       "      <td>0.992242</td>\n",
       "      <td>2.909582</td>\n",
       "      <td>-0.527123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.892799</td>\n",
       "      <td>26.129075</td>\n",
       "      <td>0.317373</td>\n",
       "      <td>0.976754</td>\n",
       "      <td>2.990347</td>\n",
       "      <td>-0.527206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.721016</td>\n",
       "      <td>13.650527</td>\n",
       "      <td>0.203559</td>\n",
       "      <td>0.966315</td>\n",
       "      <td>2.993670</td>\n",
       "      <td>-0.527347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.078562</td>\n",
       "      <td>13.132861</td>\n",
       "      <td>0.214693</td>\n",
       "      <td>0.981959</td>\n",
       "      <td>2.900196</td>\n",
       "      <td>-0.527363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  colsample_bytree  subsample     gamma  \\\n",
       "21   9.858298         13.249991          0.433260   0.999819  2.944467   \n",
       "10   9.893582         13.986790          0.234479   0.992427  2.955693   \n",
       "6    9.922328         12.322410          0.430052   0.984938  2.981919   \n",
       "4    9.878492         15.646924          0.326926   0.999855  2.921145   \n",
       "23   9.979036         13.050578          0.489616   0.989539  2.874991   \n",
       "8    8.540735         14.309724          0.569809   0.989256  2.951742   \n",
       "15   9.890100         22.421182          0.347370   0.992242  2.909582   \n",
       "18   9.892799         26.129075          0.317373   0.976754  2.990347   \n",
       "28   9.721016         13.650527          0.203559   0.966315  2.993670   \n",
       "20   9.078562         13.132861          0.214693   0.981959  2.900196   \n",
       "\n",
       "       score  \n",
       "21 -0.526405  \n",
       "10 -0.526417  \n",
       "6  -0.526687  \n",
       "4  -0.526713  \n",
       "23 -0.526878  \n",
       "8  -0.527090  \n",
       "15 -0.527123  \n",
       "18 -0.527206  \n",
       "28 -0.527347  \n",
       "20 -0.527363  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bo_scores = pd.DataFrame([[s[0]['max_depth'],\n",
    "                               s[0]['min_child_weight'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[0]['gamma'],\n",
    "                               s[1]] for s in zip(xgb_BO.res['all']['params'],xgb_BO.res['all']['values'])],\n",
    "                            columns = ['max_depth',\n",
    "                                       'min_child_weight',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'gamma',\n",
    "                                       'score'])\n",
    "xgb_bo_scores=xgb_bo_scores.sort_values('score',ascending=False)\n",
    "xgb_bo_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgb_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,random_state=5555)\n",
    "    N_class = len(set(train_y))\n",
    "        \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(objective = 'multi:softprob')\n",
    "        est.set_params(silent = False)\n",
    "        est.set_params(learning_rate = 0.02)\n",
    "        est.set_params(n_estimators=100000)\n",
    "        \n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "    \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]      \n",
    "\n",
    "            est.fit(train_x_fold,train_y_fold,\n",
    "                    eval_set = [(val_x_fold, val_y_fold)],\n",
    "                    eval_metric = 'mlogloss',\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose=False)\n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,ntree_limit=best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score\n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,ntree_limit=best_round)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ede55aceace5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m estimators = [\n\u001b[0;32m----> 2\u001b[0;31m             xgb.XGBClassifier(max_depth = 9,\n\u001b[0m\u001b[1;32m      3\u001b[0m                               \u001b[0mmin_child_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mcolsample_bytree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.433260\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0msubsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.999819\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "            xgb.XGBClassifier(max_depth = 9,\n",
    "                              min_child_weight = 13,\n",
    "                              colsample_bytree = 0.433260 ,\n",
    "                              subsample = 0.999819 ,\n",
    "                              gamma = 2.944467),\n",
    "             xgb.XGBClassifier(max_depth = 9,\n",
    "                              min_child_weight = 13,\n",
    "                              colsample_bytree = 0.234479,\n",
    "                              subsample = 0.992427,\n",
    "                              gamma = 2.955693),\n",
    "             xgb.XGBClassifier(max_depth = 9,\n",
    "                              min_child_weight = 12,\n",
    "                              colsample_bytree = 0.430052,\n",
    "                              subsample = 0.984938,\n",
    "                              gamma = 2.981919),         \n",
    "             xgb.XGBClassifier(max_depth = 9,\n",
    "                              min_child_weight = 15,\n",
    "                              colsample_bytree = 0.326926,\n",
    "                              subsample = 0.999855,\n",
    "                              gamma = 2.921145),  \n",
    "             xgb.XGBClassifier(max_depth = 9,\n",
    "                              min_child_weight = 13,\n",
    "                              colsample_bytree = 0.489616,\n",
    "                              subsample = 0.989539,\n",
    "                              gamma = 2.874991)              \n",
    "             ]\n",
    "\n",
    "#  \t \tmax_depth \tmin_child_weight \tcolsample_bytree \tsubsample \tgamma \t \tscore\n",
    "# 21 \t9.858298 \t13.249991 \t \t \t0.433260 \t \t \t0.999819 \t2.944467 \t-0.526405\n",
    "# 10 \t9.893582 \t13.986790 \t \t \t0.234479 \t \t \t0.992427 \t2.955693 \t-0.526417\n",
    "# 6 \t9.922328 \t12.322410 \t \t \t0.430052 \t \t \t0.984938 \t2.981919 \t-0.526687\n",
    "# 4 \t9.878492 \t15.646924 \t \t \t0.326926 \t \t \t0.999855 \t2.921145 \t-0.526713\n",
    "# 23 \t9.979036 \t13.050578 \t \t \t0.489616 \t \t \t0.989539 \t2.874991 \t-0.526878\n",
    "\n",
    "# 8 \t8.540735 \t14.309724 \t \t \t0.569809 \t \t \t0.989256 \t2.951742 \t-0.527090\n",
    "# 15 \t9.890100 \t22.421182 \t \t \t0.347370 \t \t \t0.992242 \t2.909582 \t-0.527123\n",
    "# 18 \t9.892799 \t26.129075 \t \t \t0.317373 \t \t \t0.976754 \t2.990347 \t-0.527206\n",
    "# 28 \t9.721016 \t13.650527 \t \t \t0.203559 \t \t \t0.966315 \t2.993670 \t-0.527347\n",
    "# 20 \t9.078562 \t13.132861 \t \t \t0.214693 \t \t \t0.981959 \t2.900196 \t-0.527363\n",
    "# 25 \t5.983142 \t15.522353 \t \t \t0.365431 \t \t \t0.894089 \t1.799546 \t-0.527589\n",
    "# 23 \t5.974873 \t16.538875 \t \t \t0.485034 \t \t \t0.938367 \t0.114823 \t-0.527952\n",
    "# 2 \t5.963303 \t12.117000 \t \t \t0.433634 \t \t \t0.978037 \t1.715329 \t-0.528031\n",
    "# 36 \t5.975359 \t18.867714 \t \t \t0.475715 \t \t \t0.976875 \t1.762219 \t-0.528089\n",
    "# 27 \t5.160960 \t15.607619 \t \t \t0.492978 \t \t \t0.913682 \t1.794400 \t-0.528097\n",
    "# 26 \t5.953624 \t15.884306 \t \t \t0.490160 \t \t \t0.931286 \t1.172554 \t-0.528127\n",
    "# 8 \t5.980293 \t12.262870 \t \t \t0.382213 \t \t \t0.985894 \t0.013603 \t-0.528166\n",
    "# 18 \t5.969315 \t27.978419 \t \t \t0.242325 \t \t \t0.972658 \t1.665230 \t-0.528323\n",
    "# 5 \t5.833405 \t27.333782 \t \t \t0.493605 \t \t \t0.988708 \t1.759493 \t-0.528409\n",
    "# 37 \t5.991305 \t12.978177 \t \t \t0.244283 \t \t \t0.907146 \t1.750585 \t-0.528450\n",
    "\n",
    "(train_blend_x_xgb,\n",
    " test_blend_x_xgb_mean,\n",
    " test_blend_x_xgb_gmean,\n",
    " blend_scores_xgb,\n",
    " best_rounds_xgb) = xgb_blend(estimators,\n",
    "                              train_X,train_y,\n",
    "                              test_X,\n",
    "                              10,\n",
    "                              500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52128253  0.52168419  0.52109504  0.52076998  0.52132577]\n",
      "[ 3811.9  3832.7  3687.   4127.2  2683.2]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_xgb_BM_0322_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_mean_BM_0322_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../output/test_blend_xgb_gmean_BM_0322_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb,axis=0))\n",
    "print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_xgb, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_xgb_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_xgb_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [ 0.52385999  0.52420308  0.52429754  0.52366222  0.52450185]\n",
    "# [ 2866.7  3979.7  3102.9  2783.1  4450.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "sub_name = '../output/sub_XGB_mean_BM_MB_add_desc_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_blend_x_xgb_mean[:,9:12])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)\n",
    "\n",
    "\n",
    "# ypreds.columns = cols\n",
    "\n",
    "# df = pd.read_json(open(\"../input/test.json\", \"r\"))\n",
    "# ypreds['listing_id'] = df[\"listing_id\"]\n",
    "\n",
    "# ypreds.to_csv('my_preds.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.20544260e-01,   6.10888687e-01,   6.56750820e-02],\n",
       "       [  9.66028463e-01,   2.30937453e-02,   1.06505838e-02],\n",
       "       [  9.53579737e-01,   4.13955017e-02,   3.97691225e-03],\n",
       "       ..., \n",
       "       [  9.78252564e-01,   2.03241753e-02,   1.01263996e-03],\n",
       "       [  9.71474749e-01,   2.74180665e-02,   5.09567844e-04],\n",
       "       [  5.87161787e-01,   3.92164954e-01,   1.94305868e-02]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_gmean[:,9:12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.20994298e-01,   6.04517100e-01,   7.12524217e-02],\n",
       "       [  9.57150480e-01,   3.01748109e-02,   1.18646473e-02],\n",
       "       [  9.58178383e-01,   3.74607705e-02,   3.46537444e-03],\n",
       "       ..., \n",
       "       [  9.80787885e-01,   1.80516908e-02,   8.23179767e-04],\n",
       "       [  9.70638017e-01,   2.80394743e-02,   5.14503672e-04],\n",
       "       [  5.81934901e-01,   3.95535699e-01,   2.09051621e-02]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_gmean[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
