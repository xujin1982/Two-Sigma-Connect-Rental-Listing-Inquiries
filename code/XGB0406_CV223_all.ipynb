{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn import model_selection,ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import time\n",
    "import random\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, LabelBinarizer, MultiLabelBinarizer,LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats.mstats import gmean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_train(train,y,max_depth = 6,min_child_weight = 1,colsample_bytree = 1, subsample = 1, gamma = 0 , verbose_eval = None,\n",
    "            seed = 0, early_stop = 50, nfold = 5, eta=0.3):\n",
    "    xgtrain = xgb.DMatrix(train, label=y)\n",
    "    params = dict()\n",
    "    params['objective']='multi:softprob'\n",
    "    params['eval_metric']='mlogloss',\n",
    "    params['num_class']=3\n",
    "    params['silent']=0\n",
    "    params['eta'] = eta\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    params['colsample_bytree'] = colsample_bytree\n",
    "    params['subsample'] = subsample\n",
    "    params['gamma'] = gamma\n",
    "#     params['booster'] = 'dart'\n",
    "#     params['rate_drop'] = 0.1\n",
    "#     params['skip_drop'] = 0.5\n",
    "    \n",
    "    cv_result = xgb.cv(\n",
    "        params, xgtrain, \n",
    "        num_boost_round=10000, nfold=nfold,\n",
    "        metrics = 'mlogloss', verbose_eval = verbose_eval,\n",
    "        seed=seed,callbacks=[xgb.callback.early_stop(early_stop)]\n",
    "    )\n",
    "\n",
    "    return cv_result['test-mlogloss-mean'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CV_st(train,test,feature1,feature2):\n",
    "    index=list(range(train.shape[0]))\n",
    "    random.shuffle(index)\n",
    "    kf = KFold(n_splits=5,shuffle=True, random_state=0)\n",
    "    \n",
    "    # median feature names\n",
    "    features_tmp = []\n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_low_median') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_medium_median') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_high_median')\n",
    "    \n",
    "    # train data \n",
    "    f_low=pd.Series([np.nan]*len(train))\n",
    "    f_medium=pd.Series([np.nan]*len(train))\n",
    "    f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "    for train_index, test_index in kf.split(index):\n",
    "        tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].median().\\\n",
    "                reset_index().rename(columns={feature2:'new'})\n",
    "        f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "                                                            on=feature1,how='left')['new'].values\n",
    "        f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                                            on=feature1,how='left')['new'].values\n",
    "        f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "                                                            on=feature1,how='left')['new'].values   \n",
    "    train[features_tmp[0]] = f_low\n",
    "    train[features_tmp[1]] = f_medium\n",
    "    train[features_tmp[2]] = f_high\n",
    "\n",
    "    # test data\n",
    "    tmp = train.groupby(['interest_level',feature1])[feature2].median().\\\n",
    "            reset_index().rename(columns={feature2:'new'})    \n",
    "    test[features_tmp[0]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "                                       on=feature1,how='left')['new'].values\n",
    "    test[features_tmp[1]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                       on=feature1,how='left')['new'].values\n",
    "    test[features_tmp[2]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "                                       on=feature1,how='left')['new'].values \n",
    "    \n",
    "\n",
    "    # mean feature names\n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_low_mean') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_medium_mean') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_high_mean')\n",
    "    \n",
    "    # train data \n",
    "    f_low=pd.Series([np.nan]*len(train))\n",
    "    f_medium=pd.Series([np.nan]*len(train))\n",
    "    f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "    for train_index, test_index in kf.split(index):\n",
    "        tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].mean().\\\n",
    "                reset_index().rename(columns={feature2:'new'})\n",
    "        f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "                                                            on=feature1,how='left')['new'].values\n",
    "        f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                                            on=feature1,how='left')['new'].values\n",
    "        f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "                                                            on=feature1,how='left')['new'].values   \n",
    "    train[features_tmp[3]] = f_low\n",
    "    train[features_tmp[4]] = f_medium\n",
    "    train[features_tmp[5]] = f_high\n",
    "\n",
    "    # test data\n",
    "    tmp = train.groupby(['interest_level',feature1])[feature2].mean().\\\n",
    "            reset_index().rename(columns={feature2:'new'})    \n",
    "    test[features_tmp[3]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "                                       on=feature1,how='left')['new'].values\n",
    "    test[features_tmp[4]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                       on=feature1,how='left')['new'].values\n",
    "    test[features_tmp[5]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "                                       on=feature1,how='left')['new'].values \n",
    "    \n",
    "    # max feature names\n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_low_max') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_medium_max') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_high_max')\n",
    "    \n",
    "    # train data \n",
    "    f_low=pd.Series([np.nan]*len(train))\n",
    "    f_medium=pd.Series([np.nan]*len(train))\n",
    "    f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "    for train_index, test_index in kf.split(index):\n",
    "        tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].max().\\\n",
    "                reset_index().rename(columns={feature2:'new'})\n",
    "        f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "                                                            on=feature1,how='left')['new'].values\n",
    "        f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                                            on=feature1,how='left')['new'].values\n",
    "        f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "                                                            on=feature1,how='left')['new'].values   \n",
    "    train[features_tmp[6]] = f_low\n",
    "    train[features_tmp[7]] = f_medium\n",
    "    train[features_tmp[8]] = f_high\n",
    "\n",
    "    # test data\n",
    "    tmp = train.groupby(['interest_level',feature1])[feature2].max().\\\n",
    "            reset_index().rename(columns={feature2:'new'})    \n",
    "    test[features_tmp[6]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "                                       on=feature1,how='left')['new'].values\n",
    "    test[features_tmp[7]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                       on=feature1,how='left')['new'].values\n",
    "    test[features_tmp[8]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "                                       on=feature1,how='left')['new'].values \n",
    "    \n",
    "    # min feature names\n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_low_min') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_medium_min') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_high_min')\n",
    "    \n",
    "    # train data \n",
    "    f_low=pd.Series([np.nan]*len(train))\n",
    "    f_medium=pd.Series([np.nan]*len(train))\n",
    "    f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "    for train_index, test_index in kf.split(index):\n",
    "        tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].min().\\\n",
    "                reset_index().rename(columns={feature2:'new'})\n",
    "        f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "                                                            on=feature1,how='left')['new'].values\n",
    "        f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                                            on=feature1,how='left')['new'].values\n",
    "        f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "                                                            on=feature1,how='left')['new'].values   \n",
    "    train[features_tmp[9]] = f_low\n",
    "    train[features_tmp[10]] = f_medium\n",
    "    train[features_tmp[11]] = f_high\n",
    "\n",
    "    # test data\n",
    "    tmp = train.groupby(['interest_level',feature1])[feature2].min().\\\n",
    "            reset_index().rename(columns={feature2:'new'})    \n",
    "    test[features_tmp[9]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "                                       on=feature1,how='left')['new'].values\n",
    "    test[features_tmp[10]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                       on=feature1,how='left')['new'].values\n",
    "    test[features_tmp[11]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "                                       on=feature1,how='left')['new'].values \n",
    "\n",
    "#     # std feature names\n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_low_std') \n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_medium_std') \n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_high_std')\n",
    "    \n",
    "#     # train data \n",
    "#     f_low=pd.Series([np.nan]*len(train))\n",
    "#     f_medium=pd.Series([np.nan]*len(train))\n",
    "#     f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "#     for train_index, test_index in kf.split(index):\n",
    "#         tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].std().\\\n",
    "#                 reset_index().rename(columns={feature2:'new'})\n",
    "#         f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "#                                                             on=feature1,how='left')['new'].values\n",
    "#         f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "#                                                             on=feature1,how='left')['new'].values\n",
    "#         f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "#                                                             on=feature1,how='left')['new'].values   \n",
    "#     train[features_tmp[12]] = f_low\n",
    "#     train[features_tmp[13]] = f_medium\n",
    "#     train[features_tmp[14]] = f_high\n",
    "\n",
    "#     # test data\n",
    "#     tmp = train.groupby(['interest_level',feature1])[feature2].std().\\\n",
    "#             reset_index().rename(columns={feature2:'new'})    \n",
    "#     test[features_tmp[12]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "#                                        on=feature1,how='left')['new'].values\n",
    "#     test[features_tmp[13]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "#                                        on=feature1,how='left')['new'].values\n",
    "#     test[features_tmp[14]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "#                                        on=feature1,how='left')['new'].values \n",
    "    \n",
    "#     # var feature names\n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_low_var') \n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_medium_var') \n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_high_var')\n",
    "    \n",
    "#     # train data \n",
    "#     f_low=pd.Series([np.nan]*len(train))\n",
    "#     f_medium=pd.Series([np.nan]*len(train))\n",
    "#     f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "#     for train_index, test_index in kf.split(index):\n",
    "#         tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].var().\\\n",
    "#                 reset_index().rename(columns={feature2:'new'})\n",
    "#         f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "#                                                             on=feature1,how='left')['new'].values\n",
    "#         f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "#                                                             on=feature1,how='left')['new'].values\n",
    "#         f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "#                                                             on=feature1,how='left')['new'].values   \n",
    "#     train[features_tmp[15]] = f_low\n",
    "#     train[features_tmp[16]] = f_medium\n",
    "#     train[features_tmp[17]] = f_high\n",
    "\n",
    "#     # test data\n",
    "#     tmp = train.groupby(['interest_level',feature1])[feature2].var().\\\n",
    "#             reset_index().rename(columns={feature2:'new'})    \n",
    "#     test[features_tmp[15]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "#                                        on=feature1,how='left')['new'].values\n",
    "#     test[features_tmp[16]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "#                                        on=feature1,how='left')['new'].values\n",
    "#     test[features_tmp[17]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "#                                        on=feature1,how='left')['new'].values \n",
    "    \n",
    "#     # ratio/diff feature\n",
    "#     cols = features_tmp[:]\n",
    "# #     features_tmp = []\n",
    "#     for col in cols:\n",
    "#         new_feature = col+'_ratio'\n",
    "#         train[new_feature] = train[col] / train[feature2]\n",
    "#         test[new_feature] = test[col] / test[feature2]\n",
    "#         features_tmp.append(new_feature)\n",
    "        \n",
    "    print feature1,' vs ', feature2,'Done!'\n",
    "    return train,test,features_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "train_df=pd.read_json('../input/train.json').reset_index(drop = True)\n",
    "test_df=pd.read_json('../input/test.json').reset_index(drop = True)\n",
    "test_df.loc[test_df.bathrooms == 112.0,'bathrooms'] = 1.5    \n",
    "test_df.loc[test_df.bathrooms == 20.0,'bathrooms'] = 2.0\n",
    "test_df.loc[test_df.listing_id == 7220763,'bedrooms'] = 3\n",
    "test_df.loc[test_df.listing_id == 7047074,'bedrooms'] = 6\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    fmt = lambda s: s.replace(\"\\u00a0\", \"\").strip().lower()\n",
    "    df[\"num_photo_count\"] = df[\"photos\"].apply(len)\n",
    "    df[\"street_address\"] = df['street_address'].apply(fmt)\n",
    "    df[\"display_address\"] = df[\"display_address\"].apply(fmt)\n",
    "    df[\"num_desc_wordcount\"] = df[\"description\"].apply(len)\n",
    "    df[\"num_pricePerBed\"] = df['price'] / df['bedrooms']\n",
    "    df[\"num_pricePerBath\"] = df['price'] / df['bathrooms']\n",
    "    df[\"num_pricePerRoom\"] = df['price'] / (df['bedrooms'] + df['bathrooms'])\n",
    "    df[\"num_bedPerBath\"] = df['bedrooms'] / df['bathrooms']\n",
    "    df[\"num_bedBathDiff\"] = df['bedrooms'] - df['bathrooms']\n",
    "    df[\"num_bedBathSum\"] = df[\"bedrooms\"] + df['bathrooms']\n",
    "    df[\"num_bedsPerc\"] = df[\"bedrooms\"] / (df['bedrooms'] + df['bathrooms'])\n",
    "\n",
    "    df = df.fillna(-1).replace(np.inf, -1)\n",
    "    return df\n",
    "\n",
    "# Add common features\n",
    "train_df = add_features(train_df)\n",
    "test_df = add_features(test_df) \n",
    "\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "train_df['num_desc_length_null'] = (train_df.description.str.len()==0).astype(float)\n",
    "test_df['num_desc_length_null'] = (test_df.description.str.len()==0).astype(float)\n",
    "    \n",
    "features_to_use=[\n",
    "    \"latitude\", \"longitude\",\"num_pricePerBed\",\n",
    "    'num_bedBathSum','num_pricePerBath','num_pricePerRoom','num_bedPerBath',\n",
    "    'num_bedBathDiff','num_bedsPerc',\n",
    "    \"num_photo_count\", \"num_features\", \"num_desc_wordcount\",'num_desc_length_null',\n",
    "    \"listing_id\"]\n",
    "\n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Location features: Latitude, longitude\n",
    "precision = 3\n",
    "x = np.sqrt(((train_df.latitude - train_df.latitude.median())**2) + (train_df.longitude - train_df.longitude.median())**2)\n",
    "train_df['num_dist_from_center'] = x.values\n",
    "x = np.sqrt(((test_df.latitude - train_df.latitude.median())**2) + (test_df.longitude - train_df.longitude.median())**2)\n",
    "test_df['num_dist_from_center'] = x.values\n",
    "train_df['position'] = train_df.longitude.round(precision).astype(str) + '_' + train_df.latitude.round(precision).astype(str)\n",
    "test_df['position'] = test_df.longitude.round(precision).astype(str) + '_' + test_df.latitude.round(precision).astype(str)\n",
    "\n",
    "new_feature = ['num_dist_from_center']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Degree of \"outlierness\"\n",
    "OutlierAggregated = (train_df.bedrooms > 4).astype(float)\n",
    "OutlierAggregated2 = (test_df.bedrooms > 4).astype(float)\n",
    "OutlierAggregated += (train_df.bathrooms > 3).astype(float)\n",
    "OutlierAggregated2 += (test_df.bathrooms > 3).astype(float)\n",
    "OutlierAggregated += (train_df.bathrooms < 1).astype(float)\n",
    "OutlierAggregated2 += (test_df.bathrooms < 1).astype(float)\n",
    "x = np.abs((train_df.price - train_df.price.median())/train_df.price.std()) > 0.30\n",
    "OutlierAggregated += x.astype(float)\n",
    "x2 = np.abs((test_df.price - train_df.price.median())/train_df.price.std()) > 0.30\n",
    "OutlierAggregated2 += x2.astype(float)\n",
    "x = np.log1p(train_df.price/(train_df.bedrooms.clip(1,3) + train_df.bathrooms.clip(1,2))) > 8.2\n",
    "OutlierAggregated += x.astype(float)\n",
    "x2 = np.log1p(test_df.price/(test_df.bedrooms.clip(1,3) + test_df.bathrooms.clip(1,2))) > 8.2\n",
    "OutlierAggregated2 += x2.astype(float)\n",
    "x = np.sqrt(((train_df.latitude - train_df.latitude.median())**2) + (train_df.longitude - train_df.longitude.median())**2) > 0.30\n",
    "OutlierAggregated += x.astype(float)\n",
    "x2 = np.sqrt(((test_df.latitude - train_df.latitude.median())**2) + (test_df.longitude - train_df.longitude.median())**2) > 0.30\n",
    "OutlierAggregated2 += x2.astype(float)\n",
    "train_df['num_OutlierAggregated'] = OutlierAggregated.values\n",
    "test_df['num_OutlierAggregated'] = OutlierAggregated2.values\n",
    "\n",
    "\n",
    "new_feature = ['num_OutlierAggregated']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Density in unique locations at given precision\n",
    "vals = train_df['position'].value_counts()\n",
    "dvals = vals.to_dict()\n",
    "train_df['num_pos_density'] = train_df['position'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "test_df['num_pos_density'] = test_df['position'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "\n",
    "# Building null\n",
    "train_df['num_building_null'] = (train_df.building_id=='0').astype(float)\n",
    "test_df['num_building_null'] = (test_df.building_id=='0').astype(float)\n",
    "\n",
    "\n",
    "new_feature = ['num_pos_density','num_building_null']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Creation time features\n",
    "train_df['created'] = pd.to_datetime(train_df.created)\n",
    "train_df['num_created_weekday'] = train_df.created.dt.dayofweek.astype(float)\n",
    "train_df['num_created_weekofyear'] = train_df.created.dt.weekofyear\n",
    "train_df['num_created_day'] = train_df.created.dt.day\n",
    "train_df['num_created_month'] = train_df.created.dt.month\n",
    "train_df['num_created_hour'] = train_df.created.dt.hour\n",
    "  \n",
    "test_df['created'] = pd.to_datetime(test_df.created)\n",
    "test_df['num_created_weekday'] = test_df.created.dt.dayofweek\n",
    "test_df['num_created_weekofyear'] = test_df.created.dt.weekofyear\n",
    "test_df['num_created_day'] = test_df.created.dt.day\n",
    "test_df['num_created_month'] = test_df.created.dt.month\n",
    "test_df['num_created_hour'] = test_df.created.dt.hour\n",
    "\n",
    "\n",
    "new_feature = ['num_created_weekday','num_created_weekofyear','num_created_day','num_created_month','num_created_hour']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Bedrooms/Bathrooms/Price\n",
    "train_df['num_bathrooms'] = train_df.bathrooms.clip_upper(4)\n",
    "test_df['num_bathrooms'] = test_df.bathrooms.clip_upper(4)\n",
    "\n",
    "train_df['num_bedrooms'] = train_df.bedrooms.clip_upper(5)\n",
    "test_df['num_bedrooms'] = test_df.bedrooms.clip_upper(5)\n",
    "\n",
    "train_df['num_price'] = train_df.price.clip_upper(10000)\n",
    "test_df['num_price'] = test_df.price.clip_upper(10000)\n",
    "\n",
    "bins = train_df.price.quantile(np.arange(0.05, 1, 0.05))\n",
    "train_df['num_price_q'] = np.digitize(train_df.price, bins)\n",
    "test_df['num_price_q'] = np.digitize(test_df.price, bins)\n",
    "\n",
    "\n",
    "new_feature = ['num_bathrooms','num_bedrooms','num_price','num_price_q']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Composite features based on: \n",
    "# https://www.kaggle.com/arnaldcat/two-sigma-connect-rental-listing-inquiries/a-proxy-for-sqft-and-the-interest-on-1-2-baths\n",
    "train_df['num_priceXroom'] = (train_df.price / (1 + train_df.bedrooms.clip(1, 4) + 0.5*train_df.bathrooms.clip(0, 2))).values\n",
    "test_df['num_priceXroom'] = (test_df.price / (1 + test_df.bedrooms.clip(1, 4) + 0.5*test_df.bathrooms.clip(0, 2))).values\n",
    "\n",
    "train_df['num_even_bathrooms'] = ((np.round(train_df.bathrooms) - train_df.bathrooms)==0).astype(float)\n",
    "test_df['num_even_bathrooms'] = ((np.round(test_df.bathrooms) - test_df.bathrooms)==0).astype(float)\n",
    "\n",
    "new_feature = ['num_priceXroom','num_even_bathrooms']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "\n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\",'position']\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            if f not in features_to_use:\n",
    "                features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dftemp = train_df.copy()\n",
    "for i in ['latitude', 'longitude']:\n",
    "    while(1):\n",
    "        x = dftemp[i].median()\n",
    "        ix = abs(dftemp[i] - x) > 3*dftemp[i].std()\n",
    "        if ix.sum()==0:\n",
    "            break\n",
    "        dftemp.loc[ix, i] = np.nan\n",
    "dftemp = dftemp.loc[dftemp[['latitude', 'longitude']].isnull().sum(1) == 0, :]\n",
    "\n",
    "dfm = DataFrameMapper([(['latitude'], [StandardScaler()]), (['longitude'], [StandardScaler()])])\n",
    "\n",
    "for i in [6]:\n",
    "    pipe_location = make_pipeline(dfm, KMeans(n_clusters=i, random_state=1))\n",
    "    pipe_location.fit(dftemp);\n",
    "    train_df['location_'+str(i)] = pipe_location.predict(train_df).astype(str)\n",
    "    test_df['location_'+str(i)] = pipe_location.predict(test_df).astype(str)\n",
    "for i in train_df.location_6.unique():\n",
    "    f = 'num_location_6_'+str(i)\n",
    "    train_df[f] = (train_df.location_6==i).astype(float)\n",
    "    test_df[f] = (test_df.location_6==i).astype(float)\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "    \n",
    "    \n",
    "train_df['tmp_bathrooms'] = train_df.bathrooms.clip_upper(2)\n",
    "test_df['tmp_bathrooms'] = test_df.bathrooms.clip_upper(2)\n",
    "train_df['tmp_bedrooms'] = train_df.bedrooms.clip_upper(4)\n",
    "test_df['tmp_bedrooms'] = test_df.bedrooms.clip_upper(4)\n",
    "train_df['roomcal'] = train_df.tmp_bedrooms.astype(str) + '_' + train_df.tmp_bathrooms.astype(str)    \n",
    "test_df['roomcal'] = test_df.tmp_bedrooms.astype(str) + '_' + test_df.tmp_bathrooms.astype(str)    \n",
    "\n",
    "room_lb = LabelBinarizer()\n",
    "room_lb.fit(train_df['roomcal'])\n",
    "room_col = ['num_room_type_' + str(x) for x in range(len(train_df['roomcal'].unique()))]\n",
    "for f in room_col:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "\n",
    "train_df = train_df.join(pd.DataFrame(room_lb.transform(train_df['roomcal']),columns=room_col,index=train_df.index))\n",
    "test_df = test_df.join(pd.DataFrame(room_lb.transform(test_df['roomcal']),columns=room_col,index=test_df.index))\n",
    "\n",
    "tmp = train_df.groupby(['roomcal','location_6'])['num_price'].median().\\\n",
    "            reset_index().rename(columns={'num_price':'num_6_median_price'})\n",
    "    \n",
    "train_df = train_df.merge(tmp,on=['roomcal','location_6'],how='left')\n",
    "test_df = test_df.merge(tmp,on=['roomcal','location_6'],how='left')\n",
    "\n",
    "test_df.loc[27462,'num_6_median_price'] =  7200.0\n",
    "\n",
    "train_df['num_6_price_ratio'] = train_df['num_price'] / train_df['num_6_median_price']\n",
    "train_df['num_6_price_diff'] = train_df['num_price'] - train_df['num_6_median_price']\n",
    "test_df['num_6_price_ratio'] = test_df['num_price'] / test_df['num_6_median_price']\n",
    "test_df['num_6_price_diff'] = test_df['num_price'] - test_df['num_6_median_price']\n",
    "\n",
    "\n",
    "for f in ['num_6_median_price','num_6_price_ratio','num_6_price_diff']:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = train_df.groupby(['num_bedrooms','location_6'])['num_price'].median().\\\n",
    "            reset_index().rename(columns={'num_price':'num_6_median_price_bedroom'})\n",
    "    \n",
    "train_df = train_df.merge(tmp,on=['num_bedrooms','location_6'],how='left')\n",
    "test_df = test_df.merge(tmp,on=['num_bedrooms','location_6'],how='left')\n",
    "\n",
    "train_df['num_6_price_ratio_bedroom'] = train_df['num_price'] / train_df['num_6_median_price_bedroom']\n",
    "train_df['num_6_price_diff_bedroom'] = train_df['num_price'] - train_df['num_6_median_price_bedroom']\n",
    "test_df['num_6_price_ratio_bedroom'] = test_df['num_price'] / test_df['num_6_median_price_bedroom']\n",
    "test_df['num_6_price_diff_bedroom'] = test_df['num_price'] - test_df['num_6_median_price_bedroom']\n",
    "\n",
    "\n",
    "for f in ['num_6_median_price_bedroom','num_6_price_ratio_bedroom','num_6_price_diff_bedroom']:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_binary_features(df):\n",
    "    bows = {\n",
    "        \"dogs\": (\"dogs\", \"dog\",'pet friendly','pets'),\n",
    "        \"cats\": (\"cats\",'pet friendly','pets'),\n",
    "        \"nofee\": (\"no fee\", \"no-fee\", \"no  fee\", \"nofee\", \"no_fee\"),\n",
    "        \"lowfee\": (\"reduced_fee\", \"low_fee\", \"reduced fee\", \"low fee\"),\n",
    "        \"furnished\": (\"furnished\",'equipped'),\n",
    "        \"parquet\": (\"parquet\", \"hardwood\"),\n",
    "        \"concierge\": (\"concierge\", \"doorman\", \"housekeep\", \"in_super\"),\n",
    "        \"prewar\": (\"prewar\", \"pre_war\", \"pre war\", \"pre-war\"),\n",
    "        \"laundry\": (\"laundry\", \"lndry\"),\n",
    "        \"health\": (\"health\", \"gym\", \"fitness\", \"training\"),\n",
    "        \"transport\": (\"train\", \"subway\", \"transport\"),\n",
    "        \"parking\": (\"parking\",),\n",
    "        \"utilities\": (\"utilities\", \"heat water\", \"water included\"),\n",
    "        'fireplace': ('fireplace','fireplaces'),\n",
    "        'elevator': ('elevator'),\n",
    "        'pool':('pool'),\n",
    "        'loft':('loft'),\n",
    "        'luxury':('luxury','valet'),\n",
    "        'marble':('marble'),\n",
    "        'onemounthfree': ('1 month free','one month free'),\n",
    "        'washer':('washer','dryer')\n",
    "    }\n",
    "\n",
    "    def indicator(bow):\n",
    "        return lambda s: int(any([x in s for x in bow]))\n",
    "\n",
    "    features = df[\"features\"].apply(lambda f: \" \".join(f).lower())   # convert features to string\n",
    "    for key in bows:\n",
    "        tmp_key = \"feature_\" + key\n",
    "        df[tmp_key] = features.apply(indicator(bows[key]))\n",
    "        if tmp_key not in features_to_use:\n",
    "            features_to_use.append(tmp_key)\n",
    "    return df\n",
    "\n",
    "# Create binarized features\n",
    "train_df = create_binary_features(train_df)\n",
    "test_df = create_binary_features(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 322)\n",
      "(74659, 322)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X_0322 = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X_0322 = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "\n",
    "print train_X_0322.shape\n",
    "print test_X_0322.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment = [\n",
    "    'building_id_mean_med','building_id_mean_high', \n",
    "    'manager_id_mean_med','manager_id_mean_high',\n",
    "    'median_price_bed', 'ratio_bed',\n",
    "       'compound', 'neg', 'neu', 'pos', 'street',\n",
    "       'avenue', 'east', 'west', 'north', 'south', 'other_address',\n",
    "       'Zero_building_id', 'top_10_building', 'top_25_building',\n",
    "       'top_5_building', 'top_50_building', 'top_1_building',\n",
    "       'top_2_building', 'top_15_building', 'top_20_building',\n",
    "       'top_30_building','listing_id'\n",
    "]\n",
    "\n",
    "train_df = train_df.merge(train_X_0322[sentiment],on='listing_id', how='left')\n",
    "test_df = test_df.merge(test_X_0322[sentiment],on='listing_id', how='left')\n",
    "\n",
    "for f in sentiment:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CV statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  price Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','price')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id  vs  price Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'building_id','price')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_dist_from_center Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_dist_from_center')\n",
    "\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_created_hour Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_created_hour')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id  vs  num_created_hour Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'building_id','num_created_hour')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_desc_wordcount Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_desc_wordcount')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_6_price_diff_bedroom Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_6_price_diff_bedroom')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id  vs  num_6_price_diff_bedroom Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'building_id','num_6_price_diff_bedroom')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_bedrooms Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_bedrooms')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in new_feature:\n",
    "    features_to_use.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_6_price_diff Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_6_price_diff')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id  vs  num_bedrooms Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'building_id','num_bedrooms')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  building_id_mean_med Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','building_id_mean_med')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  building_id_mean_high Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','building_id_mean_high')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id  vs  manager_id_mean_med Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'building_id','manager_id_mean_med')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id  vs  manager_id_mean_high Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'building_id','manager_id_mean_high')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_nofee  vs  num_price Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'feature_nofee','num_price')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_price_q  vs  num_priceXroom Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'num_price_q','num_priceXroom')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'num_building_null','num_priceXroom')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id  vs  num_priceXroom Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'building_id','num_priceXroom')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  feature_nofee Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','feature_nofee')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  manager_id_mean_med Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','manager_id_mean_med')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position  vs  price Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'position','price')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  pos Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','pos')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  median_price_bed Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','median_price_bed')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_pricePerBed Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_pricePerBed')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_pos_density Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_pos_density')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  longitude Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','longitude')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  latitude Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','latitude')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_6_price_ratio Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_6_price_ratio')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_features Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_features')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  ratio_bed Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','ratio_bed')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_6_price_diff_bedroom Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_6_price_diff_bedroom')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_photo_count Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_photo_count')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_priceXroom Done!\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_priceXroom')\n",
    "# for f in new_feature:\n",
    "#     if f not in features_to_use:\n",
    "#         features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_pricePerBath Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_pricePerBath')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager_id  vs  num_pricePerRoom Done!\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','num_pricePerRoom')\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manager_id_num_bedrooms_medium_max',\n",
       " 'manager_id_num_bedrooms_high_max',\n",
       " 'manager_id_num_bedrooms_low_min',\n",
       " 'manager_id_num_bedrooms_medium_min',\n",
       " 'manager_id_num_bedrooms_high_min']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_use[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 223) (74659, 223)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_df[features_to_use]\n",
    "test_X = test_df[features_to_use]\n",
    "\n",
    "train_X.replace(np.inf, np.nan)\n",
    "test_X.replace(np.inf, np.nan)\n",
    "\n",
    "train_X.loc[:,'num_nan'] = train_X.isnull().sum(axis=1)\n",
    "test_X.loc[:,'num_nan'] = test_X.isnull().sum(axis=1)\n",
    "\n",
    "target_num_map = {'high':2, 'medium':1, 'low':0}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "print train_X.shape, test_X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manager_id_num_6_price_diff_low_median</th>\n",
       "      <th>manager_id_num_6_price_diff_medium_median</th>\n",
       "      <th>manager_id_num_6_price_diff_high_median</th>\n",
       "      <th>manager_id_num_6_price_diff_low_mean</th>\n",
       "      <th>manager_id_num_6_price_diff_medium_mean</th>\n",
       "      <th>manager_id_num_6_price_diff_high_mean</th>\n",
       "      <th>manager_id_num_6_price_diff_low_max</th>\n",
       "      <th>manager_id_num_6_price_diff_medium_max</th>\n",
       "      <th>manager_id_num_6_price_diff_high_max</th>\n",
       "      <th>manager_id_num_6_price_diff_low_min</th>\n",
       "      <th>manager_id_num_6_price_diff_medium_min</th>\n",
       "      <th>manager_id_num_6_price_diff_high_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-75.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.735849</td>\n",
       "      <td>30.277778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>875.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1700.0</td>\n",
       "      <td>-700.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1052.5</td>\n",
       "      <td>-3121.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1197.735714</td>\n",
       "      <td>-3121.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>-3121.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1150.0</td>\n",
       "      <td>-3121.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-50.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-322.5</td>\n",
       "      <td>223.050847</td>\n",
       "      <td>-43.225000</td>\n",
       "      <td>-327.500</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>-1505.0</td>\n",
       "      <td>-2510.0</td>\n",
       "      <td>-1340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>-550.0</td>\n",
       "      <td>255.252066</td>\n",
       "      <td>-207.264706</td>\n",
       "      <td>-69.375</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>-2100.0</td>\n",
       "      <td>-2516.5</td>\n",
       "      <td>-965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   manager_id_num_6_price_diff_low_median  \\\n",
       "0                                   -75.0   \n",
       "1                                  1052.5   \n",
       "2                                   -50.0   \n",
       "3                                   135.0   \n",
       "4                                   -55.0   \n",
       "\n",
       "   manager_id_num_6_price_diff_medium_median  \\\n",
       "0                                      -25.0   \n",
       "1                                    -3121.5   \n",
       "2                                     -125.0   \n",
       "3                                     -300.0   \n",
       "4                                        NaN   \n",
       "\n",
       "   manager_id_num_6_price_diff_high_median  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                   -322.5   \n",
       "3                                   -550.0   \n",
       "4                                      NaN   \n",
       "\n",
       "   manager_id_num_6_price_diff_low_mean  \\\n",
       "0                             -7.735849   \n",
       "1                           1197.735714   \n",
       "2                            223.050847   \n",
       "3                            255.252066   \n",
       "4                             15.000000   \n",
       "\n",
       "   manager_id_num_6_price_diff_medium_mean  \\\n",
       "0                                30.277778   \n",
       "1                             -3121.500000   \n",
       "2                               -43.225000   \n",
       "3                              -207.264706   \n",
       "4                                      NaN   \n",
       "\n",
       "   manager_id_num_6_price_diff_high_mean  manager_id_num_6_price_diff_low_max  \\\n",
       "0                                    NaN                                875.0   \n",
       "1                                    NaN                               4300.0   \n",
       "2                               -327.500                               3300.0   \n",
       "3                                -69.375                               4100.0   \n",
       "4                                    NaN                               1000.0   \n",
       "\n",
       "   manager_id_num_6_price_diff_medium_max  \\\n",
       "0                                   900.0   \n",
       "1                                 -3121.5   \n",
       "2                                  3025.0   \n",
       "3                                  1100.0   \n",
       "4                                     NaN   \n",
       "\n",
       "   manager_id_num_6_price_diff_high_max  manager_id_num_6_price_diff_low_min  \\\n",
       "0                                   NaN                              -1700.0   \n",
       "1                                   NaN                              -1150.0   \n",
       "2                                 495.0                              -1505.0   \n",
       "3                                2950.0                              -2100.0   \n",
       "4                                   NaN                               -300.0   \n",
       "\n",
       "   manager_id_num_6_price_diff_medium_min  \\\n",
       "0                                  -700.0   \n",
       "1                                 -3121.5   \n",
       "2                                 -2510.0   \n",
       "3                                 -2516.5   \n",
       "4                                     NaN   \n",
       "\n",
       "   manager_id_num_6_price_diff_high_min  \n",
       "0                                   NaN  \n",
       "1                                   NaN  \n",
       "2                               -1340.0  \n",
       "3                                -965.0  \n",
       "4                                   NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[new_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[0]\ttrain-mlogloss:0.9081+0.000439152\ttest-mlogloss:0.914806+0.00097818\n",
      "[5]\ttrain-mlogloss:0.600289+0.000821237\ttest-mlogloss:0.631917+0.00300072\n",
      "[10]\ttrain-mlogloss:0.526073+0.000777907\ttest-mlogloss:0.575912+0.00432575\n",
      "[15]\ttrain-mlogloss:0.489517+0.00182507\ttest-mlogloss:0.556177+0.00400821\n",
      "[20]\ttrain-mlogloss:0.464523+0.00310209\ttest-mlogloss:0.546892+0.00445571\n",
      "[25]\ttrain-mlogloss:0.443435+0.00276597\ttest-mlogloss:0.541393+0.00449292\n",
      "[30]\ttrain-mlogloss:0.425666+0.00255616\ttest-mlogloss:0.537842+0.00496247\n",
      "[35]\ttrain-mlogloss:0.410124+0.00238644\ttest-mlogloss:0.535211+0.00466594\n",
      "[40]\ttrain-mlogloss:0.396522+0.0016213\ttest-mlogloss:0.533484+0.00509716\n",
      "[45]\ttrain-mlogloss:0.382935+0.00242961\ttest-mlogloss:0.532501+0.00489936\n",
      "[50]\ttrain-mlogloss:0.371589+0.00210863\ttest-mlogloss:0.531685+0.00502912\n",
      "[55]\ttrain-mlogloss:0.360453+0.00267513\ttest-mlogloss:0.531231+0.00522328\n",
      "[60]\ttrain-mlogloss:0.349661+0.00169442\ttest-mlogloss:0.530647+0.0053908\n",
      "[65]\ttrain-mlogloss:0.339191+0.00225167\ttest-mlogloss:0.530363+0.00548772\n",
      "[70]\ttrain-mlogloss:0.329766+0.0025686\ttest-mlogloss:0.530272+0.00538056\n",
      "[75]\ttrain-mlogloss:0.320544+0.00252402\ttest-mlogloss:0.530326+0.00547542\n",
      "[80]\ttrain-mlogloss:0.311336+0.00318315\ttest-mlogloss:0.530211+0.00570428\n",
      "[85]\ttrain-mlogloss:0.303211+0.00278038\ttest-mlogloss:0.530465+0.00572945\n",
      "[90]\ttrain-mlogloss:0.294969+0.00232601\ttest-mlogloss:0.530828+0.0058243\n",
      "[95]\ttrain-mlogloss:0.286858+0.00298929\ttest-mlogloss:0.531275+0.00580822\n",
      "Stopping. Best iteration:\n",
      "[80]\ttrain-mlogloss:0.311336+0.00318315\ttest-mlogloss:0.530211+0.00570428\n",
      "\n",
      "0.5302112\n",
      "\n",
      "Training :439.08s\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "print cv_train(train_X,train_y,verbose_eval = 5, early_stop = 20)\n",
    "print '\\nTraining :{:0.2f}s'.format(time.time() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [81]\ttrain-mlogloss:0.354253+0.00211099\ttest-mlogloss:0.536977+0.00608719 no cv feature\n",
    "# [65]\ttrain-mlogloss:0.367155+0.00211633\ttest-mlogloss:0.534893+0.0062382 price\n",
    "# [72]\ttrain-mlogloss:0.346812+0.00328497\ttest-mlogloss:0.53305+0.00688662 building_id  vs  price\n",
    "# [64]\ttrain-mlogloss:0.357396+0.00288563\ttest-mlogloss:0.531704+0.00625184 num_dist_from_center\n",
    "# [76]\ttrain-mlogloss:0.331548+0.00150892\ttest-mlogloss:0.530707+0.00719767 num_created_hour\n",
    "# [78]\ttrain-mlogloss:0.327187+0.00326905\ttest-mlogloss:0.530522+0.00662889 building_id  vs  num_created_hour\n",
    "# [69]\ttrain-mlogloss:0.341823+0.0009883\ttest-mlogloss:0.530539+0.00755474 num_desc_wordcount\n",
    "# del [64]\ttrain-mlogloss:0.348393+0.00437276\ttest-mlogloss:0.532399+0.00560396 building_id  vs  num_desc_wordcount\n",
    "# [78]\ttrain-mlogloss:0.322085+0.00255577\ttest-mlogloss:0.530573+0.00706681 num_6_price_diff_bedroom\n",
    "# [76]\ttrain-mlogloss:0.322108+0.00188804\ttest-mlogloss:0.53018+0.00868863 building_id  vs  num_6_price_diff_bedroom\n",
    "# [57]\ttrain-mlogloss:0.35853+0.0039214\ttest-mlogloss:0.530243+0.00654921 bedroom\n",
    "# del [80]\ttrain-mlogloss:0.313073+0.00177185\ttest-mlogloss:0.530923+0.00642305 building_id  vs  bedroom\n",
    "# [80]\ttrain-mlogloss:0.311336+0.00318315\ttest-mlogloss:0.530211+0.00570428 num_6_price_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [82]\ttrain-mlogloss:0.373255+0.00424222\ttest-mlogloss:0.551611+0.00772184 no cv feature\n",
    "# [69]\ttrain-mlogloss:0.364704+0.00323687\ttest-mlogloss:0.536954+0.00792152 price \n",
    "# [67]\ttrain-mlogloss:0.363512+0.0026217\ttest-mlogloss:0.536145+0.0072402 num_dist_from_center\n",
    "# [81]\ttrain-mlogloss:0.335269+0.00262769\ttest-mlogloss:0.534375+0.00789059 num_created_hour\n",
    "# [71]\ttrain-mlogloss:0.349284+0.00352997\ttest-mlogloss:0.534292+0.00880248 num_desc_wordcount\n",
    "# [68]\ttrain-mlogloss:0.349212+0.00212014\ttest-mlogloss:0.532903+0.00747242 num_6_price_ratio_bedroom\n",
    "# [74]\ttrain-mlogloss:0.337387+0.00425913\ttest-mlogloss:0.533063+0.00678103 building_id_mean_med\n",
    "# [83]\ttrain-mlogloss:0.320669+0.00289614\ttest-mlogloss:0.532428+0.00780398 building_id_mean_high\n",
    "# [76]\ttrain-mlogloss:0.330415+0.00167131\ttest-mlogloss:0.531293+0.00759899 'manager_id_mean_med','manager_id_mean_high',\n",
    "# [62]\ttrain-mlogloss:0.348022+0.00308306\ttest-mlogloss:0.5307+0.00586143 building_id  vs  num_6_price_diff_bedroom\n",
    "\n",
    "# del [69]\ttrain-mlogloss:0.331928+0.00270211\ttest-mlogloss:0.531707+0.00621119 building_id  vs  price\n",
    "# del [61]\ttrain-mlogloss:0.349982+0.00391241\ttest-mlogloss:0.537226+0.00635442 feature_nofee  vs  num_price\n",
    "# del [69]\ttrain-mlogloss:0.333043+0.00387723\ttest-mlogloss:0.531759+0.0078066 num_price_q  vs  num_priceXroom\n",
    "# del [64]\ttrain-mlogloss:0.345669+0.00295346\ttest-mlogloss:0.531806+0.00678929 num_building_null  vs  num_priceXroom\n",
    "# del [73]\ttrain-mlogloss:0.326921+0.00344616\ttest-mlogloss:0.532193+0.00673751 building_id  vs  num_priceXroom\n",
    "# del [68]\ttrain-mlogloss:0.342177+0.00136703\ttest-mlogloss:0.531945+0.00650216 feature_nofee\n",
    "# del [78]\ttrain-mlogloss:0.324279+0.00234253\ttest-mlogloss:0.531399+0.00642477 num_bedrooms\n",
    "# del [67]\ttrain-mlogloss:0.343537+0.0019745\ttest-mlogloss:0.533178+0.00505587 pos\n",
    "# del [84]\ttrain-mlogloss:0.323042+0.00215233\ttest-mlogloss:0.533643+0.00763431 median_price_bed\n",
    "# del [66]\ttrain-mlogloss:0.350688+0.00226534\ttest-mlogloss:0.533783+0.00685066 num_pricePerBed\n",
    "# del [76]\ttrain-mlogloss:0.333929+0.00233681\ttest-mlogloss:0.533241+0.00765436 num_pos_density\n",
    "# del  [74]\ttrain-mlogloss:0.336716+0.00472892\ttest-mlogloss:0.533678+0.00700685 longitude\n",
    "# del [70]\ttrain-mlogloss:0.343931+0.00190522\ttest-mlogloss:0.533995+0.00708828 latitude\n",
    "# del [66]\ttrain-mlogloss:0.353195+0.00347634\ttest-mlogloss:0.533698+0.00813442 num_6_price_ratio\n",
    "# del[76]\ttrain-mlogloss:0.335395+0.00269504\ttest-mlogloss:0.534366+0.0072334 num_features\n",
    "# del [70]\ttrain-mlogloss:0.344731+0.0040112\ttest-mlogloss:0.533613+0.00852658 ratio_bed\n",
    "# del [63]\ttrain-mlogloss:0.359234+0.00282059\ttest-mlogloss:0.533871+0.00691217 num_6_price_diff_bedroom\n",
    "# del [84]\ttrain-mlogloss:0.322303+0.00294342\ttest-mlogloss:0.534586+0.0076548 num_priceXroom\n",
    "# del [71]\ttrain-mlogloss:0.347942+0.00429741\ttest-mlogloss:0.535784+0.00840754 num_photo_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:0.976351\n",
      "[20]\tvalidation_0-mlogloss:0.570767\n",
      "[40]\tvalidation_0-mlogloss:0.547269\n",
      "[60]\tvalidation_0-mlogloss:0.539594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
       "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=62, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=1, subsample=0.7)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=2016)\n",
    "rgr = xgb.XGBClassifier(\n",
    "            objective='multi:softprob',\n",
    "            seed = 0, # use a fixed seed during tuning so we can reproduce the results\n",
    "            learning_rate = 0.2,\n",
    "            n_estimators = 62,\n",
    "            max_depth= 6,\n",
    "            nthread = -1,\n",
    "            colsample_bytree = 0.3,\n",
    "            subsample =0.7,\n",
    "            silent = 1\n",
    "        )\n",
    "rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=20,\n",
    "        verbose=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgbfir\n",
    "xgbfir.saveXgbFI(rgr, feature_names=X_train.columns, OutputXlsxFile = '../FE/FI.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 394)\n",
      "(9871, 394)\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)\n",
    "# print X_train.shape\n",
    "# print X_val.shape\n",
    "# # xgtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[312]\ttrain-mlogloss:0.395492+0.00170774\ttest-mlogloss:0.527702+0.00663205\n",
      "\n",
      "3 \t0.5277018\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[141]\ttrain-mlogloss:0.396861+0.00183942\ttest-mlogloss:0.527621+0.00736431\n",
      "\n",
      "4 \t0.5276214\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mlogloss:0.357724+0.00219303\ttest-mlogloss:0.528282+0.00654119\n",
      "\n",
      "5 \t0.5282822\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[57]\ttrain-mlogloss:0.35853+0.0039214\ttest-mlogloss:0.530243+0.00654921\n",
      "\n",
      "6 \t0.530243\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[59]\ttrain-mlogloss:0.283875+0.00317202\ttest-mlogloss:0.535384+0.00751206\n",
      "\n",
      "7 \t0.5353838\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[34]\ttrain-mlogloss:0.291909+0.00288588\ttest-mlogloss:0.538363+0.00620757\n",
      "\n",
      "8 \t0.538363\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[26]\ttrain-mlogloss:0.267564+0.0038825\ttest-mlogloss:0.541642+0.00515766\n",
      "\n",
      "9 \t0.541642\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[20]\ttrain-mlogloss:0.244491+0.00434577\ttest-mlogloss:0.546812+0.0055212\n",
      "\n",
      "10 \t0.5468122\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[20]\ttrain-mlogloss:0.195892+0.00375725\ttest-mlogloss:0.550402+0.00728209\n",
      "\n",
      "11 \t0.5504024\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[17]\ttrain-mlogloss:0.17067+0.00195634\ttest-mlogloss:0.557329+0.00518613\n",
      "\n",
      "12 \t0.557329\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-mlogloss:0.149427+0.00259833\ttest-mlogloss:0.562298+0.00633625\n",
      "\n",
      "13 \t0.5622976\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[14]\ttrain-mlogloss:0.126763+0.00196544\ttest-mlogloss:0.569518+0.00782982\n",
      "\n",
      "14 \t0.5695176\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[14]\ttrain-mlogloss:0.10453+0.00319293\ttest-mlogloss:0.572249+0.00606784\n",
      "\n",
      "15 \t0.5722486\n"
     ]
    }
   ],
   "source": [
    "best_score = 1000\n",
    "for x in [3,4,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= x,\n",
    "#         nthread = -1,\n",
    "#         silent = False\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "    tmp = cv_train(train_X,train_y,max_depth = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# max_depth = train_param\n",
    "max_depth = train_param\n",
    "print max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[186]\ttrain-mlogloss:0.367066+0.00186211\ttest-mlogloss:0.527145+0.0074838\n",
      "\n",
      "2 \t0.5271452\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[213]\ttrain-mlogloss:0.352706+0.00230145\ttest-mlogloss:0.526443+0.00732842\n",
      "\n",
      "4 \t0.5264426\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[159]\ttrain-mlogloss:0.390464+0.00279415\ttest-mlogloss:0.527391+0.00724981\n",
      "\n",
      "8 \t0.5273912\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[177]\ttrain-mlogloss:0.381805+0.00237731\ttest-mlogloss:0.526913+0.00594032\n",
      "\n",
      "12 \t0.5269126\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[231]\ttrain-mlogloss:0.354327+0.00325227\ttest-mlogloss:0.525994+0.00717634\n",
      "\n",
      "16 \t0.5259938\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[159]\ttrain-mlogloss:0.398036+0.00265041\ttest-mlogloss:0.527198+0.00718988\n",
      "\n",
      "20 \t0.5271978\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[167]\ttrain-mlogloss:0.393573+0.00269923\ttest-mlogloss:0.526977+0.00679354\n",
      "\n",
      "24 \t0.5269766\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[179]\ttrain-mlogloss:0.388478+0.00255418\ttest-mlogloss:0.527911+0.00768457\n",
      "\n",
      "28 \t0.527911\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[189]\ttrain-mlogloss:0.385292+0.00262723\ttest-mlogloss:0.527001+0.00775232\n",
      "\n",
      "32 \t0.5270012\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[189]\ttrain-mlogloss:0.389593+0.00185931\ttest-mlogloss:0.527247+0.00665882\n",
      "\n",
      "40 \t0.5272468\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[202]\ttrain-mlogloss:0.387127+0.00289643\ttest-mlogloss:0.526661+0.00611834\n",
      "\n",
      "48 \t0.5266614\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[195]\ttrain-mlogloss:0.396135+0.00319157\ttest-mlogloss:0.526655+0.00698115\n",
      "\n",
      "64 \t0.5266546\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[188]\ttrain-mlogloss:0.404784+0.002127\ttest-mlogloss:0.527635+0.00737379\n",
      "\n",
      "80 \t0.5276348\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[214]\ttrain-mlogloss:0.40653+0.00239865\ttest-mlogloss:0.528011+0.00761088\n",
      "\n",
      "128 \t0.5280108\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [2,4,8,12,16,20,24,28,32,40,48,64,80,128]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= max_depth,\n",
    "#         nthread = -1,\n",
    "#         silent = False,\n",
    "#         min_child_weight = x\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "    \n",
    "    tmp = cv_train(train_X,train_y,max_depth = max_depth,min_child_weight = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "min_child_weight = train_param\n",
    "print min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[262]\ttrain-mlogloss:0.395672+0.00192811\ttest-mlogloss:0.532532+0.00697024\n",
      "\n",
      "0.05 \t0.5325316\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[251]\ttrain-mlogloss:0.38311+0.00308902\ttest-mlogloss:0.529113+0.00529031\n",
      "\n",
      "0.1 \t0.5291126\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[212]\ttrain-mlogloss:0.387354+0.0026151\ttest-mlogloss:0.526019+0.00693851\n",
      "\n",
      "0.2 \t0.5260188\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[205]\ttrain-mlogloss:0.384431+0.00255739\ttest-mlogloss:0.526169+0.00587901\n",
      "\n",
      "0.3 \t0.5261692\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[202]\ttrain-mlogloss:0.381644+0.00252687\ttest-mlogloss:0.526699+0.00705682\n",
      "\n",
      "0.4 \t0.5266986\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[204]\ttrain-mlogloss:0.377252+0.00326099\ttest-mlogloss:0.527301+0.00618384\n",
      "\n",
      "0.5 \t0.5273014\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[218]\ttrain-mlogloss:0.367054+0.00132444\ttest-mlogloss:0.526421+0.00760733\n",
      "\n",
      "0.6 \t0.5264212\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[219]\ttrain-mlogloss:0.364027+0.00250635\ttest-mlogloss:0.526563+0.00715006\n",
      "\n",
      "0.7 \t0.5265626\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[168]\ttrain-mlogloss:0.392891+0.00148548\ttest-mlogloss:0.526076+0.00678444\n",
      "\n",
      "0.8 \t0.5260764\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[192]\ttrain-mlogloss:0.376406+0.00267377\ttest-mlogloss:0.526586+0.00671319\n",
      "\n",
      "0.9 \t0.5265856\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= max_depth,\n",
    "#         nthread = -1,\n",
    "#         silent = False,\n",
    "#         min_child_weight = min_child_weight,\n",
    "#         colsample_bytree = x\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "    tmp = cv_train(train_X,train_y,max_depth = max_depth,min_child_weight = min_child_weight, colsample_bytree = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = train_param\n",
    "print colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[114]\ttrain-mlogloss:0.429981+0.00163237\ttest-mlogloss:0.535683+0.0063162\n",
      "\n",
      "0.5 \t0.5356834\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[127]\ttrain-mlogloss:0.417173+0.00106604\ttest-mlogloss:0.532641+0.0071292\n",
      "\n",
      "0.6 \t0.5326408\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[117]\ttrain-mlogloss:0.422807+0.00248712\ttest-mlogloss:0.530766+0.00658263\n",
      "\n",
      "0.7 \t0.5307656\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[138]\ttrain-mlogloss:0.406591+0.002293\ttest-mlogloss:0.52841+0.00609406\n",
      "\n",
      "0.8 \t0.5284098\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[184]\ttrain-mlogloss:0.378796+0.00269963\ttest-mlogloss:0.528253+0.00591205\n",
      "\n",
      "0.9 \t0.528253\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= max_depth,\n",
    "#         nthread = -1,\n",
    "#         silent = False,\n",
    "#         min_child_weight = min_child_weight,\n",
    "#         colsample_bytree = colsample_bytree,\n",
    "#         subsample = x\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "    tmp = cv_train(train_X,train_y,max_depth = max_depth,min_child_weight = min_child_weight, \n",
    "                   colsample_bytree = colsample_bytree, subsample = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "subsample = train_param\n",
    "print subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[164]\ttrain-mlogloss:0.393296+0.00247187\ttest-mlogloss:0.526782+0.00697394\n",
      "\n",
      "0.3 \t0.5267822\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[186]\ttrain-mlogloss:0.378468+0.00338923\ttest-mlogloss:0.526772+0.00705368\n",
      "\n",
      "0.6 \t0.526772\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[175]\ttrain-mlogloss:0.38681+0.00159871\ttest-mlogloss:0.526846+0.00696989\n",
      "\n",
      "0.9 \t0.526846\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[167]\ttrain-mlogloss:0.390969+0.002374\ttest-mlogloss:0.527127+0.00787015\n",
      "\n",
      "1.2 \t0.527127\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[206]\ttrain-mlogloss:0.370844+0.00353107\ttest-mlogloss:0.526113+0.00799753\n",
      "\n",
      "1.5 \t0.5261126\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[227]\ttrain-mlogloss:0.375197+0.0107539\ttest-mlogloss:0.526744+0.0071078\n",
      "\n",
      "1.8 \t0.5267444\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[193]\ttrain-mlogloss:0.386555+0.00438174\ttest-mlogloss:0.526173+0.00798028\n",
      "\n",
      "2.1 \t0.5261726\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[161]\ttrain-mlogloss:0.411347+0.00406703\ttest-mlogloss:0.526713+0.00664277\n",
      "\n",
      "2.4 \t0.5267126\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[187]\ttrain-mlogloss:0.419464+0.00941197\ttest-mlogloss:0.527696+0.00723329\n",
      "\n",
      "2.7 \t0.527696\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[205]\ttrain-mlogloss:0.425483+0.00607894\ttest-mlogloss:0.52768+0.00621536\n",
      "\n",
      "3.0 \t0.5276796\n"
     ]
    }
   ],
   "source": [
    "train_param = 0\n",
    "for x in [0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3.0]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= max_depth,\n",
    "#         nthread = -1,\n",
    "#         silent = False,\n",
    "#         min_child_weight = min_child_weight,\n",
    "#         colsample_bytree = colsample_bytree,\n",
    "#         subsample = subsample,\n",
    "#         gamma = x\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "    tmp = cv_train(train_X,train_y,max_depth = max_depth,min_child_weight = min_child_weight, \n",
    "                   colsample_bytree = colsample_bytree, subsample = subsample, gamma = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "gamma = train_param\n",
    "print gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1030]\ttrain-mlogloss:0.404719+0.00154409\ttest-mlogloss:0.525766+0.00730057\n",
      "\n",
      "    1 | 36m59s | \u001b[35m  -0.52577\u001b[0m | \u001b[32m            0.9657\u001b[0m | \u001b[32m   0.5937\u001b[0m | \u001b[32m     3.6952\u001b[0m | \u001b[32m           53.7510\u001b[0m | \u001b[32m     0.8887\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[306]\ttrain-mlogloss:0.331036+0.00100352\ttest-mlogloss:0.523922+0.00655783\n",
      "\n",
      "    2 | 11m06s | \u001b[35m  -0.52392\u001b[0m | \u001b[32m            0.2498\u001b[0m | \u001b[32m   2.0639\u001b[0m | \u001b[32m     9.1318\u001b[0m | \u001b[32m           79.9910\u001b[0m | \u001b[32m     0.8549\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[492]\ttrain-mlogloss:0.369798+0.00244995\ttest-mlogloss:0.522661+0.00721979\n",
      "\n",
      "    3 | 10m07s | \u001b[35m  -0.52266\u001b[0m | \u001b[32m            0.2521\u001b[0m | \u001b[32m   1.1090\u001b[0m | \u001b[32m     5.2840\u001b[0m | \u001b[32m           46.3109\u001b[0m | \u001b[32m     0.8209\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[568]\ttrain-mlogloss:0.375003+0.00242683\ttest-mlogloss:0.523358+0.00741672\n",
      "\n",
      "    4 | 19m53s |   -0.52336 |             0.5074 |    2.2917 |      5.7263 |            78.4913 |      0.7814 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[441]\ttrain-mlogloss:0.34618+0.00212326\ttest-mlogloss:0.523767+0.00649373\n",
      "\n",
      "    5 | 28m18s |   -0.52377 |             0.8037 |    2.0627 |      6.6516 |            73.4255 |      0.9725 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[477]\ttrain-mlogloss:0.361901+0.00115809\ttest-mlogloss:0.522582+0.00790332\n",
      "\n",
      "    6 | 13m38s | \u001b[35m  -0.52258\u001b[0m | \u001b[32m            0.3819\u001b[0m | \u001b[32m   0.2977\u001b[0m | \u001b[32m     5.7087\u001b[0m | \u001b[32m           41.2513\u001b[0m | \u001b[32m     0.8843\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[383]\ttrain-mlogloss:0.354484+0.00176575\ttest-mlogloss:0.524447+0.00753368\n",
      "\n",
      "    7 | 29m09s |   -0.52445 |             0.9614 |    0.9820 |      6.6992 |            78.1787 |      0.9419 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[748]\ttrain-mlogloss:0.377889+0.00149642\ttest-mlogloss:0.522743+0.00774583\n",
      "\n",
      "    8 | 18m35s |   -0.52274 |             0.4378 |    2.0874 |      4.5659 |            29.9043 |      0.7439 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[627]\ttrain-mlogloss:0.394458+0.00157602\ttest-mlogloss:0.524122+0.00734611\n",
      "\n",
      "    9 | 23m20s |   -0.52412 |             0.7047 |    0.5824 |      4.6100 |            68.0420 |      0.8630 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[282]\ttrain-mlogloss:0.320211+0.00137317\ttest-mlogloss:0.523535+0.00661574\n",
      "\n",
      "   10 | 22m23s |   -0.52353 |             0.6161 |    2.5434 |      9.9087 |            65.0961 |      0.9966 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[165]\ttrain-mlogloss:0.248977+0.00153038\ttest-mlogloss:0.524667+0.00725594\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00034402]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 09m13s |   -0.52467 |             0.2801 |    1.2652 |      9.9552 |             8.0470 |      0.9948 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[418]\ttrain-mlogloss:0.310456+0.00136334\ttest-mlogloss:0.521622+0.00676404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00029959]), 'nit': 7, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.78618932e-05]), 'nit': 6, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 14m51s | \u001b[35m  -0.52162\u001b[0m | \u001b[32m            0.2312\u001b[0m | \u001b[32m   2.9760\u001b[0m | \u001b[32m     9.9279\u001b[0m | \u001b[32m           32.8581\u001b[0m | \u001b[32m     0.7750\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[527]\ttrain-mlogloss:0.31345+0.00208761\ttest-mlogloss:0.522371+0.00672728\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.0001338]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 16m20s |   -0.52237 |             0.2031 |    2.9745 |      9.5747 |            43.2279 |      0.8012 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[208]\ttrain-mlogloss:0.262656+0.00148398\ttest-mlogloss:0.524278+0.00803445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00030502]), 'nit': 2, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00017021]), 'nit': 5, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 08m15s |   -0.52428 |             0.2114 |    0.1048 |      9.8273 |            22.2451 |      0.7493 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1331]\ttrain-mlogloss:0.435051+0.00326607\ttest-mlogloss:0.52577+0.00659671\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -4.19516962e-05]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 17m57s |   -0.52577 |             0.2675 |    2.8381 |      3.0131 |            40.4910 |      0.9524 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1154]\ttrain-mlogloss:0.394056+0.00124302\ttest-mlogloss:0.52437+0.00779506\n",
      "\n",
      "   16 | 14m31s |   -0.52437 |             0.2299 |    0.4023 |      3.0882 |             8.5025 |      0.8048 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[238]\ttrain-mlogloss:0.305061+0.00163014\ttest-mlogloss:0.52328+0.00618194\n",
      "\n",
      "   17 | 09m07s |   -0.52328 |             0.2208 |    0.0167 |      9.7664 |            50.1199 |      0.7391 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[161]\ttrain-mlogloss:0.309798+0.00112151\ttest-mlogloss:0.524406+0.00633186\n",
      "\n",
      "   18 | 18m13s |   -0.52441 |             0.7556 |    0.0910 |      9.7512 |            35.2942 |      0.7007 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1824]\ttrain-mlogloss:0.422446+0.00311434\ttest-mlogloss:0.524161+0.00667966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00011164]), 'nit': 6, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 21m27s |   -0.52416 |             0.2205 |    2.9564 |      3.3751 |            17.0361 |      0.9441 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1093]\ttrain-mlogloss:0.418861+0.00141002\ttest-mlogloss:0.526003+0.00688117\n",
      "\n",
      "   20 | 13m37s |   -0.52600 |             0.2256 |    0.3522 |      3.0597 |            79.9431 |      0.9976 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[241]\ttrain-mlogloss:0.295872+0.00102268\ttest-mlogloss:0.523703+0.00673072\n",
      "\n",
      "   21 | 29m48s |   -0.52370 |             0.9330 |    2.9849 |      9.1945 |            26.5030 |      0.7375 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[284]\ttrain-mlogloss:0.313244+0.00117791\ttest-mlogloss:0.523573+0.00714569\n",
      "\n",
      "   22 | 10m38s |   -0.52357 |             0.2297 |    0.3247 |      9.0742 |            71.3606 |      0.7012 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[776]\ttrain-mlogloss:0.388069+0.00171412\ttest-mlogloss:0.522928+0.00671597\n",
      "\n",
      "   23 | 14m03s |   -0.52293 |             0.2105 |    2.9432 |      5.6259 |            61.7767 |      0.7005 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[437]\ttrain-mlogloss:0.341984+0.000910511\ttest-mlogloss:0.521371+0.0071039\n",
      "\n",
      "   24 | 11m36s | \u001b[35m  -0.52137\u001b[0m | \u001b[32m            0.2118\u001b[0m | \u001b[32m   2.9171\u001b[0m | \u001b[32m     7.5708\u001b[0m | \u001b[32m           29.4422\u001b[0m | \u001b[32m     0.9944\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2068]\ttrain-mlogloss:0.414223+0.00308619\ttest-mlogloss:0.524115+0.00747179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.62603828e-05]), 'nit': 2, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.99316442e-05]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 27m09s |   -0.52412 |             0.2673 |    2.8450 |      3.8539 |             8.0205 |      0.7101 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[237]\ttrain-mlogloss:0.322747+0.00155381\ttest-mlogloss:0.523257+0.00577917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00021269]), 'nit': 3, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 08m56s |   -0.52326 |             0.2477 |    0.0493 |      8.7521 |            43.1011 |      0.7986 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[446]\ttrain-mlogloss:0.328456+0.00148537\ttest-mlogloss:0.522107+0.00582033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00018671]), 'nit': 6, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 14m12s |   -0.52211 |             0.2036 |    2.9264 |      9.5995 |            55.4239 |      0.8143 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[406]\ttrain-mlogloss:0.344176+0.00172654\ttest-mlogloss:0.522368+0.00626433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -4.59130580e-05]), 'nit': 5, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 11m49s |   -0.52237 |             0.2055 |    2.9293 |      8.4159 |            48.4203 |      0.7171 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[674]\ttrain-mlogloss:0.384479+0.00172066\ttest-mlogloss:0.523107+0.00695791\n",
      "\n",
      "   29 | 10m24s |   -0.52311 |             0.2043 |    0.0990 |      4.0908 |            24.6326 |      0.8489 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[310]\ttrain-mlogloss:0.311127+0.00202267\ttest-mlogloss:0.522195+0.00694825\n",
      "\n",
      "   30 | 09m09s |   -0.52219 |             0.2202 |    0.1870 |      7.3179 |            30.4401 |      0.7319 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[410]\ttrain-mlogloss:0.350179+0.000865348\ttest-mlogloss:0.521795+0.00665957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00021764]), 'nit': 3, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00077468]), 'nit': 2, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 10m42s |   -0.52179 |             0.2039 |    2.9285 |      7.1774 |            32.8201 |      0.7794 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[408]\ttrain-mlogloss:0.311563+0.00109869\ttest-mlogloss:0.521969+0.00699273\n",
      "\n",
      "   32 | 13m42s |   -0.52197 |             0.2065 |    2.9887 |      9.5413 |            29.2594 |      0.7878 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[267]\ttrain-mlogloss:0.309185+0.0020634\ttest-mlogloss:0.523225+0.00591925\n",
      "\n",
      "   33 | 10m06s |   -0.52323 |             0.2160 |    0.0679 |      9.3548 |            61.0663 |      0.9894 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[597]\ttrain-mlogloss:0.351399+0.00141275\ttest-mlogloss:0.521289+0.00697231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00017053]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 13m09s | \u001b[35m  -0.52129\u001b[0m | \u001b[32m            0.2054\u001b[0m | \u001b[32m   2.9595\u001b[0m | \u001b[32m     6.2395\u001b[0m | \u001b[32m           25.6201\u001b[0m | \u001b[32m     0.7927\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[426]\ttrain-mlogloss:0.316246+0.00146418\ttest-mlogloss:0.521847+0.00681168\n",
      "\n",
      "   35 | 14m26s |   -0.52185 |             0.2131 |    2.9618 |      9.5358 |            37.2910 |      0.9113 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[563]\ttrain-mlogloss:0.354285+0.000954589\ttest-mlogloss:0.521773+0.00677928\n",
      "\n",
      "   36 | 12m15s |   -0.52177 |             0.2011 |    2.8887 |      6.5776 |            27.9240 |      0.8063 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[528]\ttrain-mlogloss:0.347553+0.00150869\ttest-mlogloss:0.522038+0.00705934\n",
      "\n",
      "   37 | 11m41s |   -0.52204 |             0.2003 |    2.7412 |      6.3248 |            22.7948 |      0.9822 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[434]\ttrain-mlogloss:0.330924+0.00154661\ttest-mlogloss:0.521392+0.00720838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.50219156e-05]), 'nit': 5, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   38 | 11m31s |   -0.52139 |             0.2058 |    2.7369 |      7.6812 |            25.8403 |      0.9935 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1333]\ttrain-mlogloss:0.433136+0.00270341\ttest-mlogloss:0.525211+0.00717826\n",
      "\n",
      "   39 | 15m50s |   -0.52521 |             0.2040 |    2.8709 |      3.1960 |            26.3924 |      0.9562 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[508]\ttrain-mlogloss:0.288489+0.00166711\ttest-mlogloss:0.521452+0.00681815\n",
      "\n",
      "   40 | 16m43s |   -0.52145 |             0.2071 |    2.9937 |      9.6745 |            15.4274 |      0.9495 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[342]\ttrain-mlogloss:0.326711+0.00145813\ttest-mlogloss:0.522168+0.00792084\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00021937]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00025344]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 08m53s |   -0.52217 |             0.2128 |    0.0419 |      6.8210 |            13.4813 |      0.7043 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[734]\ttrain-mlogloss:0.330029+0.00162452\ttest-mlogloss:0.521386+0.00755979\n",
      "\n",
      "   42 | 16m04s |   -0.52139 |             0.2072 |    2.9495 |      6.9237 |            13.7162 |      0.7173 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[488]\ttrain-mlogloss:0.342518+0.00173216\ttest-mlogloss:0.522851+0.00667372\n",
      "\n",
      "   43 | 15m17s |   -0.52285 |             0.2011 |    2.9888 |      9.9404 |            75.9973 |      0.7020 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[595]\ttrain-mlogloss:0.311152+0.0014244\ttest-mlogloss:0.521585+0.00706818\n",
      "\n",
      "   44 | 16m38s |   -0.52158 |             0.2366 |    2.9043 |      7.5843 |            17.5325 |      0.7247 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[353]\ttrain-mlogloss:0.314423+0.00129815\ttest-mlogloss:0.521943+0.00759633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00159208]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 12m30s |   -0.52194 |             0.2379 |    2.9856 |      8.9818 |            12.2886 |      0.7533 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1876]\ttrain-mlogloss:0.433604+0.00194479\ttest-mlogloss:0.525569+0.00649456\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00155084]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 | 21m53s |   -0.52557 |             0.2134 |    2.8300 |      3.1496 |            73.0748 |      0.8203 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[423]\ttrain-mlogloss:0.290714+0.000595318\ttest-mlogloss:0.521793+0.00672945\n",
      "\n",
      "   47 | 13m01s |   -0.52179 |             0.2074 |    2.6126 |      8.3304 |            15.2826 |      0.9684 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[435]\ttrain-mlogloss:0.288839+0.00196188\ttest-mlogloss:0.522274+0.0069791\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.0003272]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 16m57s |   -0.52227 |             0.2554 |    2.9282 |      9.5541 |            19.1993 |      0.7799 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[441]\ttrain-mlogloss:0.326479+0.00125082\ttest-mlogloss:0.522097+0.0065175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  4.98592854e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 15m53s |   -0.52210 |             0.2347 |    2.8738 |      9.6917 |            60.8899 |      0.7387 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[547]\ttrain-mlogloss:0.353443+0.0018016\ttest-mlogloss:0.522208+0.00722251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -8.18845474e-05]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 10m46s |   -0.52221 |             0.2041 |    0.0582 |      5.2912 |            35.3540 |      0.7538 | \n"
     ]
    }
   ],
   "source": [
    "xgtrain = xgb.DMatrix(train_X, label=train_y) \n",
    "\n",
    "def xgb_evaluate(min_child_weight, colsample_bytree, max_depth, subsample, gamma): #\n",
    "    params = dict()\n",
    "    params['objective']='multi:softprob'\n",
    "    params['eval_metric']='mlogloss',\n",
    "    params['num_class']=3\n",
    "    params['silent']=1\n",
    "    params['eta'] = 0.1\n",
    "    params['verbose_eval'] = True\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = 0.99# max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    \n",
    "    cv_result = xgb.cv(\n",
    "        params, xgtrain, \n",
    "        num_boost_round=10000, nfold=5,\n",
    "        metrics = 'mlogloss',\n",
    "        seed=1234,callbacks=[xgb.callback.early_stop(50)]\n",
    "    )\n",
    "    \n",
    "    return -cv_result['test-mlogloss-mean'].values[-1]\n",
    "\n",
    "\n",
    "xgb_BO = BayesianOptimization(\n",
    "    xgb_evaluate, \n",
    "    {\n",
    "        'max_depth': (3,10),\n",
    "        'min_child_weight': (8,80),\n",
    "        'colsample_bytree': (0.2,1),\n",
    "        'subsample': (0.7,1),\n",
    "        'gamma': (0,3)\n",
    "    }\n",
    ")\n",
    "\n",
    "xgb_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>gamma</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.239472</td>\n",
       "      <td>25.620069</td>\n",
       "      <td>0.205380</td>\n",
       "      <td>0.792672</td>\n",
       "      <td>2.959502</td>\n",
       "      <td>-0.521289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.570794</td>\n",
       "      <td>29.442225</td>\n",
       "      <td>0.211788</td>\n",
       "      <td>0.994441</td>\n",
       "      <td>2.917059</td>\n",
       "      <td>-0.521371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.923701</td>\n",
       "      <td>13.716162</td>\n",
       "      <td>0.207217</td>\n",
       "      <td>0.717320</td>\n",
       "      <td>2.949494</td>\n",
       "      <td>-0.521386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.681158</td>\n",
       "      <td>25.840275</td>\n",
       "      <td>0.205797</td>\n",
       "      <td>0.993480</td>\n",
       "      <td>2.736861</td>\n",
       "      <td>-0.521392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.674519</td>\n",
       "      <td>15.427370</td>\n",
       "      <td>0.207118</td>\n",
       "      <td>0.949473</td>\n",
       "      <td>2.993670</td>\n",
       "      <td>-0.521452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.584293</td>\n",
       "      <td>17.532455</td>\n",
       "      <td>0.236574</td>\n",
       "      <td>0.724688</td>\n",
       "      <td>2.904289</td>\n",
       "      <td>-0.521585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.927876</td>\n",
       "      <td>32.858122</td>\n",
       "      <td>0.231155</td>\n",
       "      <td>0.774997</td>\n",
       "      <td>2.976026</td>\n",
       "      <td>-0.521622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.577559</td>\n",
       "      <td>27.923958</td>\n",
       "      <td>0.201063</td>\n",
       "      <td>0.806311</td>\n",
       "      <td>2.888736</td>\n",
       "      <td>-0.521773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8.330396</td>\n",
       "      <td>15.282628</td>\n",
       "      <td>0.207412</td>\n",
       "      <td>0.968408</td>\n",
       "      <td>2.612650</td>\n",
       "      <td>-0.521793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.177386</td>\n",
       "      <td>32.820085</td>\n",
       "      <td>0.203923</td>\n",
       "      <td>0.779411</td>\n",
       "      <td>2.928484</td>\n",
       "      <td>-0.521795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  colsample_bytree  subsample     gamma  \\\n",
       "23   6.239472         25.620069          0.205380   0.792672  2.959502   \n",
       "13   7.570794         29.442225          0.211788   0.994441  2.917059   \n",
       "31   6.923701         13.716162          0.207217   0.717320  2.949494   \n",
       "27   7.681158         25.840275          0.205797   0.993480  2.736861   \n",
       "29   9.674519         15.427370          0.207118   0.949473  2.993670   \n",
       "33   7.584293         17.532455          0.236574   0.724688  2.904289   \n",
       "1    9.927876         32.858122          0.231155   0.774997  2.976026   \n",
       "25   6.577559         27.923958          0.201063   0.806311  2.888736   \n",
       "36   8.330396         15.282628          0.207412   0.968408  2.612650   \n",
       "20   7.177386         32.820085          0.203923   0.779411  2.928484   \n",
       "\n",
       "       score  \n",
       "23 -0.521289  \n",
       "13 -0.521371  \n",
       "31 -0.521386  \n",
       "27 -0.521392  \n",
       "29 -0.521452  \n",
       "33 -0.521585  \n",
       "1  -0.521622  \n",
       "25 -0.521773  \n",
       "36 -0.521793  \n",
       "20 -0.521795  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bo_scores = pd.DataFrame([[s[0]['max_depth'],\n",
    "                               s[0]['min_child_weight'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[0]['gamma'],\n",
    "                               s[1]] for s in zip(xgb_BO.res['all']['params'],xgb_BO.res['all']['values'])],\n",
    "                            columns = ['max_depth',\n",
    "                                       'min_child_weight',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'gamma',\n",
    "                                       'score'])\n",
    "xgb_bo_scores=xgb_bo_scores.sort_values('score',ascending=False)\n",
    "xgb_bo_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,random_state=1234)\n",
    "    N_class = len(set(train_y))\n",
    "        \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(objective = 'multi:softprob')\n",
    "        est.set_params(silent = False)\n",
    "        est.set_params(learning_rate = 0.02)\n",
    "        est.set_params(n_estimators=100000)\n",
    "        \n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "    \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]      \n",
    "\n",
    "            est.fit(train_x_fold,train_y_fold,\n",
    "                    eval_set = [(val_x_fold, val_y_fold)],\n",
    "                    eval_metric = 'mlogloss',\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose=False)\n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,ntree_limit=best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score\n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,ntree_limit=best_round)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 5 folds\n",
      "Model 1: XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.20538,\n",
      "       gamma=2.959502, learning_rate=0.02, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=25, missing=None, n_estimators=100000, nthread=-1,\n",
      "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=False, subsample=0.792672)\n",
      "Model 1 fold 1\n",
      "best round 3789\n",
      "('Score: ', 0.52623984795218892)\n",
      "Model 1 fold 1 fitting finished in 1048.941s\n",
      "Model 1 fold 2\n",
      "best round 2465\n",
      "('Score: ', 0.51521617151629873)\n",
      "Model 1 fold 2 fitting finished in 724.615s\n",
      "Model 1 fold 3\n",
      "best round 3246\n",
      "('Score: ', 0.50918119850995902)\n",
      "Model 1 fold 3 fitting finished in 918.114s\n",
      "Model 1 fold 4\n",
      "best round 2825\n",
      "('Score: ', 0.51632242760436764)\n",
      "Model 1 fold 4 fitting finished in 822.807s\n",
      "Model 1 fold 5\n",
      "best round 3384\n",
      "('Score: ', 0.53591464058234262)\n",
      "Model 1 fold 5 fitting finished in 949.518s\n",
      "Score for model 1 is 0.520575\n",
      "Score for blended models is 0.520575\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "#     xgb.XGBClassifier(max_depth = 7,\n",
    "#                               min_child_weight = 24,\n",
    "#                               colsample_bytree = 0.309861 ,\n",
    "#                               subsample = 0.998132 ,\n",
    "#                               gamma = 2.211859),\n",
    "#              xgb.XGBClassifier(max_depth = 6,\n",
    "#                               min_child_weight = 19,\n",
    "#                               colsample_bytree = 0.432358,\n",
    "#                               subsample = 0.949350,\n",
    "#                               gamma = 2.976848),\n",
    "#              xgb.XGBClassifier(max_depth = 7,\n",
    "#                               min_child_weight = 23,\n",
    "#                               colsample_bytree = 0.214791,\n",
    "#                               subsample = 0.997197,\n",
    "#                               gamma = 2.163581),         \n",
    "#              xgb.XGBClassifier(max_depth = 8,\n",
    "#                               min_child_weight = 23,\n",
    "#                               colsample_bytree = 0.5,\n",
    "#                               subsample = 0.988002,\n",
    "#                               gamma = 3.0),  \n",
    "             xgb.XGBClassifier(max_depth = 6,\n",
    "                              min_child_weight = 25,\n",
    "                              colsample_bytree = 0.205380,\n",
    "                              subsample = 0.792672,\n",
    "                              gamma = 2.959502)              \n",
    "             ]\n",
    "\n",
    "#  \t \tmax_depth \tmin_child_weight \tcolsample_bytree \tsubsample \tgamma \tscore\n",
    "# 23 \t6.239472 \t25.620069 \t \t \t0.205380 \t \t \t0.792672 \t2.959502 \t-0.521289\n",
    "# 13 \t7.570794 \t29.442225 \t \t \t0.211788 \t \t \t0.994441 \t2.917059 \t-0.521371\n",
    "# 31 \t6.923701 \t13.716162 \t \t \t0.207217 \t \t \t0.717320 \t2.949494 \t-0.521386\n",
    "# 27 \t7.681158 \t25.840275 \t \t \t0.205797 \t \t \t0.993480 \t2.736861 \t-0.521392\n",
    "# 29 \t9.674519 \t15.427370 \t \t \t0.207118 \t \t \t0.949473 \t2.993670 \t-0.521452\n",
    "\n",
    "\n",
    "(train_blend_x_xgb,\n",
    " test_blend_x_xgb_mean,\n",
    " test_blend_x_xgb_gmean,\n",
    " blend_scores_xgb,\n",
    " best_rounds_xgb) = xgb_blend(estimators,\n",
    "                              train_X,train_y,\n",
    "                              test_X,\n",
    "                              5,\n",
    "                              500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_blend_x_xgb = pd.DataFrame(train_blend_x_xgb)\n",
    "train_blend_x_xgb.columns = [\"low\", \"medium\", \"high\"]\n",
    "train_blend_x_xgb[\"listing_id\"] = train_X.listing_id.values\n",
    "\n",
    "test_blend_x_xgb_mean = pd.DataFrame(test_blend_x_xgb_mean)\n",
    "test_blend_x_xgb_mean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_blend_x_xgb_mean[\"listing_id\"] = test_X.listing_id.values\n",
    "\n",
    "test_blend_x_xgb_gmean = pd.DataFrame(test_blend_x_xgb_gmean)\n",
    "test_blend_x_xgb_gmean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_blend_x_xgb_gmean[\"listing_id\"] = test_X.listing_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_train = train_X_0322[['listing_id']].merge(train_blend_x_xgb,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_mean = test_X_0322[['listing_id']].merge(test_blend_x_xgb_mean,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_gmean = test_X_0322[['listing_id']].merge(test_blend_x_xgb_gmean,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52057486]\n",
      "[ 3141.8]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_xgb_cv_price_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_mean_cv_price_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../output/test_blend_xgb_gmean_cv_price_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb,axis=0))\n",
    "print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,tmp_train, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,tmp_test_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,tmp_test_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "sub_name = '../output/sub_XGB_mean_cv223_5blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(tmp_test_mean[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X_0322.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
