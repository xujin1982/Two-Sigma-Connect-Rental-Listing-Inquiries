{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU,LeakyReLU,ELU,ParametricSoftplus,ThresholdedReLU,SReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Nadam\n",
    "from keras.regularizers import WeightRegularizer, ActivityRegularizer,l2, activity_l2\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 222) (74659, 222) (49352, 3)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "\n",
    "train_df=pd.read_json('../input/train.json').reset_index(drop = True)\n",
    "target_num_map = {'high':2, 'medium':1, 'low':0}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "train_y = to_categorical(train_y)\n",
    "\n",
    "train_X = pd.read_csv(data_path + 'train_CV_MS_52571.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_CV_MS_52571.csv')\n",
    "\n",
    "\n",
    "\n",
    "train_X_0322 = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X_0322 = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "\n",
    "\n",
    "ntrain = train_X.shape[0]\n",
    "sub_id = test_X_0322.listing_id.astype('int32').values\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 223)\n",
      "(74659, 223)\n"
     ]
    }
   ],
   "source": [
    "time_feature = pd.read_csv(data_path + 'listing_image_time.csv')\n",
    "time_feature.columns = ['listing_id','time_stamp']\n",
    "train_X = train_X.merge(time_feature,on='listing_id',how='left')\n",
    "test_X = test_X.merge(time_feature,on='listing_id',how='left')\n",
    "\n",
    "print train_X.shape\n",
    "print test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124011, 223)\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.concat([train_X,test_X])\n",
    "print full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['latitude', 'longitude', 'num_pricePerBed', 'num_bedBathSum',\n",
       "       'num_pricePerBath', 'num_pricePerRoom', 'num_bedPerBath',\n",
       "       'num_bedBathDiff', 'num_bedsPerc', 'num_photo_count',\n",
       "       'num_features', 'num_desc_wordcount', 'num_desc_length_null',\n",
       "       'listing_id', 'num_dist_from_center', 'num_OutlierAggregated',\n",
       "       'num_pos_density', 'num_building_null', 'num_created_weekday',\n",
       "       'num_created_weekofyear', 'num_created_day', 'num_created_month',\n",
       "       'num_created_hour', 'num_bathrooms', 'num_bedrooms', 'num_price',\n",
       "       'num_price_q', 'num_priceXroom', 'num_even_bathrooms',\n",
       "       'display_address', 'manager_id', 'building_id', 'street_address',\n",
       "       'position', 'num_location_6_3', 'num_location_6_1',\n",
       "       'num_location_6_0', 'num_location_6_5', 'num_location_6_4',\n",
       "       'num_location_6_2', 'num_room_type_0', 'num_room_type_1',\n",
       "       'num_room_type_2', 'num_room_type_3', 'num_room_type_4',\n",
       "       'num_room_type_5', 'num_room_type_6', 'num_room_type_7',\n",
       "       'num_room_type_8', 'num_room_type_9', 'num_room_type_10',\n",
       "       'num_room_type_11', 'num_room_type_12', 'num_room_type_13',\n",
       "       'num_room_type_14', 'num_room_type_15', 'num_room_type_16',\n",
       "       'num_room_type_17', 'num_room_type_18', 'num_room_type_19',\n",
       "       'num_6_median_price', 'num_6_price_ratio', 'num_6_price_diff',\n",
       "       'num_6_median_price_bedroom', 'num_6_price_ratio_bedroom',\n",
       "       'num_6_price_diff_bedroom', 'feature_washer', 'feature_laundry',\n",
       "       'feature_prewar', 'feature_furnished', 'feature_parking',\n",
       "       'feature_utilities', 'feature_elevator', 'feature_marble',\n",
       "       'feature_concierge', 'feature_cats', 'feature_health',\n",
       "       'feature_pool', 'feature_onemounthfree', 'feature_parquet',\n",
       "       'feature_lowfee', 'feature_luxury', 'feature_nofee',\n",
       "       'feature_fireplace', 'feature_dogs', 'feature_transport',\n",
       "       'feature_loft', 'median_price_bed', 'ratio_bed', 'compound', 'neg',\n",
       "       'neu', 'pos', 'street', 'avenue', 'east', 'west', 'north', 'south',\n",
       "       'other_address', 'Zero_building_id', 'top_10_building',\n",
       "       'top_25_building', 'top_5_building', 'top_50_building',\n",
       "       'top_1_building', 'top_2_building', 'top_15_building',\n",
       "       'top_20_building', 'top_30_building', 'manager_level_low',\n",
       "       'manager_level_medium', 'manager_level_high',\n",
       "       'manager_id_price_low_median', 'manager_id_price_medium_median',\n",
       "       'manager_id_price_high_median', 'manager_id_price_low_mean',\n",
       "       'manager_id_price_medium_mean', 'manager_id_price_high_mean',\n",
       "       'manager_id_price_low_max', 'manager_id_price_medium_max',\n",
       "       'manager_id_price_high_max', 'manager_id_price_low_min',\n",
       "       'manager_id_price_medium_min', 'manager_id_price_high_min',\n",
       "       'manager_id_num_created_hour_low_median',\n",
       "       'manager_id_num_created_hour_medium_median',\n",
       "       'manager_id_num_created_hour_high_median',\n",
       "       'manager_id_num_created_hour_low_mean',\n",
       "       'manager_id_num_created_hour_medium_mean',\n",
       "       'manager_id_num_created_hour_high_mean',\n",
       "       'manager_id_num_created_hour_low_max',\n",
       "       'manager_id_num_created_hour_medium_max',\n",
       "       'manager_id_num_created_hour_high_max',\n",
       "       'manager_id_num_created_hour_low_min',\n",
       "       'manager_id_num_created_hour_medium_min',\n",
       "       'manager_id_num_created_hour_high_min',\n",
       "       'manager_id_num_6_price_diff_bedroom_low_median',\n",
       "       'manager_id_num_6_price_diff_bedroom_medium_median',\n",
       "       'manager_id_num_6_price_diff_bedroom_high_median',\n",
       "       'manager_id_num_6_price_diff_bedroom_low_mean',\n",
       "       'manager_id_num_6_price_diff_bedroom_medium_mean',\n",
       "       'manager_id_num_6_price_diff_bedroom_high_mean',\n",
       "       'manager_id_num_6_price_diff_bedroom_low_max',\n",
       "       'manager_id_num_6_price_diff_bedroom_medium_max',\n",
       "       'manager_id_num_6_price_diff_bedroom_high_max',\n",
       "       'manager_id_num_6_price_diff_bedroom_low_min',\n",
       "       'manager_id_num_6_price_diff_bedroom_medium_min',\n",
       "       'manager_id_num_6_price_diff_bedroom_high_min',\n",
       "       'manager_id_bedrooms_low_median',\n",
       "       'manager_id_bedrooms_medium_median',\n",
       "       'manager_id_bedrooms_high_median', 'manager_id_bedrooms_low_mean',\n",
       "       'manager_id_bedrooms_medium_mean', 'manager_id_bedrooms_high_mean',\n",
       "       'manager_id_bedrooms_low_max', 'manager_id_bedrooms_medium_max',\n",
       "       'manager_id_bedrooms_high_max', 'manager_id_bedrooms_low_min',\n",
       "       'manager_id_bedrooms_medium_min', 'manager_id_bedrooms_high_min',\n",
       "       'manager_id_num_photo_count_low_median',\n",
       "       'manager_id_num_photo_count_medium_median',\n",
       "       'manager_id_num_photo_count_high_median',\n",
       "       'manager_id_num_photo_count_low_mean',\n",
       "       'manager_id_num_photo_count_medium_mean',\n",
       "       'manager_id_num_photo_count_high_mean',\n",
       "       'manager_id_num_photo_count_low_max',\n",
       "       'manager_id_num_photo_count_medium_max',\n",
       "       'manager_id_num_photo_count_high_max',\n",
       "       'manager_id_num_photo_count_low_min',\n",
       "       'manager_id_num_photo_count_medium_min',\n",
       "       'manager_id_num_photo_count_high_min',\n",
       "       'manager_id_Zero_building_id_low_median',\n",
       "       'manager_id_Zero_building_id_medium_median',\n",
       "       'manager_id_Zero_building_id_high_median',\n",
       "       'manager_id_Zero_building_id_low_mean',\n",
       "       'manager_id_Zero_building_id_medium_mean',\n",
       "       'manager_id_Zero_building_id_high_mean',\n",
       "       'manager_id_Zero_building_id_low_max',\n",
       "       'manager_id_Zero_building_id_medium_max',\n",
       "       'manager_id_Zero_building_id_high_max',\n",
       "       'manager_id_Zero_building_id_low_min',\n",
       "       'manager_id_Zero_building_id_medium_min',\n",
       "       'manager_id_Zero_building_id_high_min',\n",
       "       'manager_id_feature_nofee_low_median',\n",
       "       'manager_id_feature_nofee_medium_median',\n",
       "       'manager_id_feature_nofee_high_median',\n",
       "       'manager_id_feature_nofee_low_mean',\n",
       "       'manager_id_feature_nofee_medium_mean',\n",
       "       'manager_id_feature_nofee_high_mean',\n",
       "       'manager_id_feature_nofee_low_max',\n",
       "       'manager_id_feature_nofee_medium_max',\n",
       "       'manager_id_feature_nofee_high_max',\n",
       "       'manager_id_feature_nofee_low_min',\n",
       "       'manager_id_feature_nofee_medium_min',\n",
       "       'manager_id_feature_nofee_high_min',\n",
       "       'manager_id_longitude_low_median',\n",
       "       'manager_id_longitude_medium_median',\n",
       "       'manager_id_longitude_high_median', 'manager_id_longitude_low_mean',\n",
       "       'manager_id_longitude_medium_mean',\n",
       "       'manager_id_longitude_high_mean', 'manager_id_longitude_low_max',\n",
       "       'manager_id_longitude_medium_max', 'manager_id_longitude_high_max',\n",
       "       'manager_id_longitude_low_min', 'manager_id_longitude_medium_min',\n",
       "       'manager_id_longitude_high_min', 'manager_id_latitude_low_median',\n",
       "       'manager_id_latitude_medium_median',\n",
       "       'manager_id_latitude_high_median', 'manager_id_latitude_low_mean',\n",
       "       'manager_id_latitude_medium_mean', 'manager_id_latitude_high_mean',\n",
       "       'manager_id_latitude_low_max', 'manager_id_latitude_medium_max',\n",
       "       'manager_id_latitude_high_max', 'manager_id_latitude_low_min',\n",
       "       'manager_id_latitude_medium_min', 'manager_id_latitude_high_min',\n",
       "       'num_nan', 'time_stamp'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_to_use = ['latitude', 'longitude', 'num_pricePerBed', 'num_bedBathSum',\n",
    "       'num_pricePerBath', 'num_pricePerRoom', 'num_bedPerBath',\n",
    "       'num_bedBathDiff', 'num_bedsPerc', 'num_photo_count',\n",
    "       'num_features', 'num_desc_wordcount', \n",
    "#                'num_desc_length_null',\n",
    "       'listing_id', 'num_dist_from_center', 'num_OutlierAggregated',\n",
    "       'num_pos_density', \n",
    "#                'num_building_null', \n",
    "               'num_created_weekday',\n",
    "       'num_created_weekofyear', 'num_created_day', 'num_created_month',\n",
    "       'num_created_hour', 'num_bathrooms', 'num_bedrooms', 'num_price',\n",
    "       'num_price_q', 'num_priceXroom', \n",
    "#                'num_even_bathrooms',\n",
    "       'display_address', 'manager_id', 'building_id', 'street_address',\n",
    "       'position', \n",
    "#                'num_location_6_3', 'num_location_6_1',\n",
    "#        'num_location_6_0', 'num_location_6_5', 'num_location_6_4',\n",
    "#        'num_location_6_2', 'num_room_type_0', 'num_room_type_1',\n",
    "#        'num_room_type_2', 'num_room_type_3', 'num_room_type_4',\n",
    "#        'num_room_type_5', 'num_room_type_6', 'num_room_type_7',\n",
    "#        'num_room_type_8', 'num_room_type_9', 'num_room_type_10',\n",
    "#        'num_room_type_11', 'num_room_type_12', 'num_room_type_13',\n",
    "#        'num_room_type_14', 'num_room_type_15', 'num_room_type_16',\n",
    "#        'num_room_type_17', 'num_room_type_18', 'num_room_type_19',\n",
    "       'num_6_median_price', 'num_6_price_ratio', 'num_6_price_diff',\n",
    "       'num_6_median_price_bedroom', 'num_6_price_ratio_bedroom',\n",
    "       'num_6_price_diff_bedroom', \n",
    "#                'feature_washer', 'feature_laundry',\n",
    "#        'feature_prewar', 'feature_furnished', 'feature_parking',\n",
    "#        'feature_utilities', 'feature_elevator', 'feature_marble',\n",
    "#        'feature_concierge', 'feature_cats', 'feature_health',\n",
    "#        'feature_pool', 'feature_onemounthfree', 'feature_parquet',\n",
    "#        'feature_lowfee', 'feature_luxury', 'feature_nofee',\n",
    "#        'feature_fireplace', 'feature_dogs', 'feature_transport',\n",
    "#        'feature_loft', \n",
    "               'median_price_bed', 'ratio_bed', 'compound', 'neg',\n",
    "       'neu', 'pos', \n",
    "#                'street', 'avenue', 'east', 'west', 'north', 'south',\n",
    "#        'other_address', 'Zero_building_id', 'top_10_building',\n",
    "#        'top_25_building', 'top_5_building', 'top_50_building',\n",
    "#        'top_1_building', 'top_2_building', 'top_15_building',\n",
    "#        'top_20_building', 'top_30_building', \n",
    "               'manager_level_low',\n",
    "       'manager_level_medium', 'manager_level_high',\n",
    "       'manager_id_price_low_median', 'manager_id_price_medium_median',\n",
    "       'manager_id_price_high_median', 'manager_id_price_low_mean',\n",
    "       'manager_id_price_medium_mean', 'manager_id_price_high_mean',\n",
    "       'manager_id_price_low_max', 'manager_id_price_medium_max',\n",
    "       'manager_id_price_high_max', 'manager_id_price_low_min',\n",
    "       'manager_id_price_medium_min', 'manager_id_price_high_min',\n",
    "       'manager_id_num_created_hour_low_median',\n",
    "       'manager_id_num_created_hour_medium_median',\n",
    "       'manager_id_num_created_hour_high_median',\n",
    "       'manager_id_num_created_hour_low_mean',\n",
    "       'manager_id_num_created_hour_medium_mean',\n",
    "       'manager_id_num_created_hour_high_mean',\n",
    "       'manager_id_num_created_hour_low_max',\n",
    "       'manager_id_num_created_hour_medium_max',\n",
    "       'manager_id_num_created_hour_high_max',\n",
    "       'manager_id_num_created_hour_low_min',\n",
    "       'manager_id_num_created_hour_medium_min',\n",
    "       'manager_id_num_created_hour_high_min',\n",
    "       'manager_id_num_6_price_diff_bedroom_low_median',\n",
    "       'manager_id_num_6_price_diff_bedroom_medium_median',\n",
    "       'manager_id_num_6_price_diff_bedroom_high_median',\n",
    "       'manager_id_num_6_price_diff_bedroom_low_mean',\n",
    "       'manager_id_num_6_price_diff_bedroom_medium_mean',\n",
    "       'manager_id_num_6_price_diff_bedroom_high_mean',\n",
    "       'manager_id_num_6_price_diff_bedroom_low_max',\n",
    "       'manager_id_num_6_price_diff_bedroom_medium_max',\n",
    "       'manager_id_num_6_price_diff_bedroom_high_max',\n",
    "       'manager_id_num_6_price_diff_bedroom_low_min',\n",
    "       'manager_id_num_6_price_diff_bedroom_medium_min',\n",
    "       'manager_id_num_6_price_diff_bedroom_high_min',\n",
    "       'manager_id_bedrooms_low_median',\n",
    "       'manager_id_bedrooms_medium_median',\n",
    "       'manager_id_bedrooms_high_median', 'manager_id_bedrooms_low_mean',\n",
    "       'manager_id_bedrooms_medium_mean', 'manager_id_bedrooms_high_mean',\n",
    "       'manager_id_bedrooms_low_max', 'manager_id_bedrooms_medium_max',\n",
    "       'manager_id_bedrooms_high_max', 'manager_id_bedrooms_low_min',\n",
    "       'manager_id_bedrooms_medium_min', 'manager_id_bedrooms_high_min',\n",
    "       'manager_id_num_photo_count_low_median',\n",
    "       'manager_id_num_photo_count_medium_median',\n",
    "       'manager_id_num_photo_count_high_median',\n",
    "       'manager_id_num_photo_count_low_mean',\n",
    "       'manager_id_num_photo_count_medium_mean',\n",
    "       'manager_id_num_photo_count_high_mean',\n",
    "       'manager_id_num_photo_count_low_max',\n",
    "       'manager_id_num_photo_count_medium_max',\n",
    "       'manager_id_num_photo_count_high_max',\n",
    "       'manager_id_num_photo_count_low_min',\n",
    "       'manager_id_num_photo_count_medium_min',\n",
    "       'manager_id_num_photo_count_high_min',\n",
    "       'manager_id_Zero_building_id_low_median',\n",
    "       'manager_id_Zero_building_id_medium_median',\n",
    "       'manager_id_Zero_building_id_high_median',\n",
    "       'manager_id_Zero_building_id_low_mean',\n",
    "       'manager_id_Zero_building_id_medium_mean',\n",
    "       'manager_id_Zero_building_id_high_mean',\n",
    "       'manager_id_Zero_building_id_low_max',\n",
    "       'manager_id_Zero_building_id_medium_max',\n",
    "       'manager_id_Zero_building_id_high_max',\n",
    "       'manager_id_Zero_building_id_low_min',\n",
    "       'manager_id_Zero_building_id_medium_min',\n",
    "       'manager_id_Zero_building_id_high_min',\n",
    "       'manager_id_feature_nofee_low_median',\n",
    "       'manager_id_feature_nofee_medium_median',\n",
    "       'manager_id_feature_nofee_high_median',\n",
    "       'manager_id_feature_nofee_low_mean',\n",
    "       'manager_id_feature_nofee_medium_mean',\n",
    "       'manager_id_feature_nofee_high_mean',\n",
    "       'manager_id_feature_nofee_low_max',\n",
    "       'manager_id_feature_nofee_medium_max',\n",
    "       'manager_id_feature_nofee_high_max',\n",
    "       'manager_id_feature_nofee_low_min',\n",
    "       'manager_id_feature_nofee_medium_min',\n",
    "       'manager_id_feature_nofee_high_min',\n",
    "       'manager_id_longitude_low_median',\n",
    "       'manager_id_longitude_medium_median',\n",
    "       'manager_id_longitude_high_median', 'manager_id_longitude_low_mean',\n",
    "       'manager_id_longitude_medium_mean',\n",
    "       'manager_id_longitude_high_mean', 'manager_id_longitude_low_max',\n",
    "       'manager_id_longitude_medium_max', 'manager_id_longitude_high_max',\n",
    "       'manager_id_longitude_low_min', 'manager_id_longitude_medium_min',\n",
    "       'manager_id_longitude_high_min', 'manager_id_latitude_low_median',\n",
    "       'manager_id_latitude_medium_median',\n",
    "       'manager_id_latitude_high_median', 'manager_id_latitude_low_mean',\n",
    "       'manager_id_latitude_medium_mean', 'manager_id_latitude_high_mean',\n",
    "       'manager_id_latitude_low_max', 'manager_id_latitude_medium_max',\n",
    "       'manager_id_latitude_high_max', 'manager_id_latitude_low_min',\n",
    "       'manager_id_latitude_medium_min', 'manager_id_latitude_high_min',\n",
    "       'num_nan','time_stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 223)\n",
      "(74659, 223)\n"
     ]
    }
   ],
   "source": [
    "full_data = full_data.fillna(0)\n",
    "\n",
    "for col in feat_to_use:\n",
    "    full_data.loc[:,col] = (full_data[col]-full_data[col].mean())/full_data[col].std()\n",
    "train_df_nn = full_data[:ntrain]\n",
    "test_df_nn = full_data[ntrain:]\n",
    "\n",
    "train_df_nn = sparse.csr_matrix(train_df_nn)\n",
    "test_df_nn = sparse.csr_matrix(test_df_nn)\n",
    "\n",
    "\n",
    "print train_df_nn.shape\n",
    "print test_df_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df_nn, train_y, train_size=.80, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.8298 - val_loss: 0.6027\n",
      "Epoch 2/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.6499 - val_loss: 0.5898\n",
      "Epoch 3/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.6137 - val_loss: 0.5841\n",
      "Epoch 4/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.6028 - val_loss: 0.5781\n",
      "Epoch 5/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5959 - val_loss: 0.5744\n",
      "Epoch 6/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5872 - val_loss: 0.5757\n",
      "Epoch 7/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5875 - val_loss: 0.5730\n",
      "Epoch 8/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5816 - val_loss: 0.5684\n",
      "Epoch 9/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5817 - val_loss: 0.5662\n",
      "Epoch 10/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5764 - val_loss: 0.5649\n",
      "Epoch 11/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5744 - val_loss: 0.5629\n",
      "Epoch 12/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5778 - val_loss: 0.5633\n",
      "Epoch 13/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5722 - val_loss: 0.5603\n",
      "Epoch 14/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5700 - val_loss: 0.5624\n",
      "Epoch 15/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5670 - val_loss: 0.5589\n",
      "Epoch 16/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5642 - val_loss: 0.5565\n",
      "Epoch 17/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5648 - val_loss: 0.5565\n",
      "Epoch 18/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5684 - val_loss: 0.5579\n",
      "Epoch 19/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5615 - val_loss: 0.5537\n",
      "Epoch 20/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5597 - val_loss: 0.5515\n",
      "Epoch 21/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5623 - val_loss: 0.5506\n",
      "Epoch 22/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5575 - val_loss: 0.5514\n",
      "Epoch 23/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5561 - val_loss: 0.5504\n",
      "Epoch 24/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5600 - val_loss: 0.5491\n",
      "Epoch 25/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5567 - val_loss: 0.5484\n",
      "Epoch 26/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5542 - val_loss: 0.5487\n",
      "Epoch 27/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5524 - val_loss: 0.5477\n",
      "Epoch 28/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5533 - val_loss: 0.5467\n",
      "Epoch 29/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5546 - val_loss: 0.5462\n",
      "Epoch 30/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5494 - val_loss: 0.5459\n",
      "Epoch 31/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5506 - val_loss: 0.5468\n",
      "Epoch 32/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5480 - val_loss: 0.5441\n",
      "Epoch 33/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5492 - val_loss: 0.5461\n",
      "Epoch 34/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5469 - val_loss: 0.5447\n",
      "Epoch 35/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5481 - val_loss: 0.5446\n",
      "Epoch 36/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5483 - val_loss: 0.5449\n",
      "Epoch 37/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5476 - val_loss: 0.5439\n",
      "Epoch 38/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5408 - val_loss: 0.5444\n",
      "Epoch 39/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5479 - val_loss: 0.5446\n",
      "Epoch 40/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5444 - val_loss: 0.5439\n",
      "Epoch 41/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5414 - val_loss: 0.5431\n",
      "Epoch 42/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5504 - val_loss: 0.5435\n",
      "Epoch 43/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5358 - val_loss: 0.5429\n",
      "Epoch 44/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5411 - val_loss: 0.5437\n",
      "Epoch 45/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5395 - val_loss: 0.5426\n",
      "Epoch 46/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5366 - val_loss: 0.5429\n",
      "Epoch 47/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5415 - val_loss: 0.5416\n",
      "Epoch 48/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5397 - val_loss: 0.5411\n",
      "Epoch 49/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5384 - val_loss: 0.5430\n",
      "Epoch 50/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5360 - val_loss: 0.5434\n",
      "Epoch 51/1000\n",
      "49408/49352 [==============================] - 5s - loss: 0.5374 - val_loss: 0.5427\n",
      "Epoch 52/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5373 - val_loss: 0.5420\n",
      "Epoch 53/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5326 - val_loss: 0.5427\n",
      "Epoch 54/1000\n",
      "49408/49352 [==============================] - 6s - loss: 0.5370 - val_loss: 0.5422\n",
      "0.541122689609\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', # custom metric\n",
    "                           patience=5, #early stopping for epoch\n",
    "                           verbose=0)\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", \n",
    "                               monitor='val_loss', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    init = 'glorot_uniform'\n",
    "    \n",
    "    \n",
    "    model.add(Dense(100, # number of input units: needs to be tuned\n",
    "                    input_dim = input_dim, # fixed length: number of columns of X\n",
    "                    init=init,\n",
    "                   ))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU()) # activation function\n",
    "    model.add(BatchNormalization()) # normalization\n",
    "    model.add(Dropout(0.4)) #dropout rate. needs to be tuned\n",
    "        \n",
    "    model.add(Dense(30,init=init)) # number of hidden1 units. needs to be tuned.\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.4)) #dropout rate. needs to be tuned\n",
    "    \n",
    "#     model.add(Dense(9,init=init)) # number of hidden2 units. needs to be tuned.\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.add(PReLU())\n",
    "#     model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.4)) #dropout rate. needs to be tuned\n",
    "    \n",
    "    model.add(Dense(3,\n",
    "                   init = init,\n",
    "                   activation = 'softmax')) # 1 for regression \n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "#                   metrics=[mae_log],\n",
    "                  optimizer = 'Adamax' # optimizer. you may want to try different ones\n",
    "                 )\n",
    "    return(model)\n",
    "\n",
    "\n",
    "\n",
    "model = create_model(X_train.shape[1])\n",
    "fit= model.fit_generator(generator=batch_generator(X_train, y_train, 128, True),\n",
    "                         nb_epoch=1000,\n",
    "                         samples_per_epoch=ntrain,\n",
    "                         validation_data=(X_val.todense(), y_val),\n",
    "                         callbacks=[early_stop,checkpointer]\n",
    "                         )\n",
    "\n",
    "print min(fit.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 150 0.4 50 0.4 15 0.4 'glorot_uniform' 'adam' 0.543332518312\n",
    "# 150 0.5 50 0.5 15 0.5 'glorot_uniform' 'adam' 0.544221234441\n",
    "# 100 0.5 25 0.5 9 0.5 'glorot_uniform' 'adam' 0.54719870663\n",
    "# 100 0.4 30 0.4 9 0.4 'glorot_uniform' 'adam' 0.544765821466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 100 0.5 50 0.5 'glorot_uniform' 'adam' 0.54511465921\n",
    "# 100 0.5 25 0.5 'glorot_uniform' 'adam' 0.543118116239\n",
    "# 100 0.4 30 0.4 'glorot_uniform' 'adam' 0.541240284411\n",
    "# 100 0.4 30 0.4 'glorot_uniform' 'Adamax' 0.542234674134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 100 0.5 'glorot_uniform' 'adam' 0.543593994089\n",
    "# 100 0.4 'glorot_uniform' 'adam' 0.542798319778\n",
    "# 100 0.3 'glorot_uniform' 'adam' 0.54412619796\n",
    "# 100 0.2 'glorot_uniform' 'adam' 0.547258452084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 70 0.4 'glorot_uniform' 'adam' 0.544325359686\n",
    "# 100 0.4 'glorot_uniform' 'adam' 0.542798319778\n",
    "# 150 0.4 'glorot_uniform' 'adam' 0.544117797527\n",
    "# 200 0.4 'glorot_uniform' 'adam' 0.545132525568\n",
    "# 300 0.4 'glorot_uniform' 'adam' 0.545077440339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 100 0.4 'glorot_uniform' 'adam' 0.542798319778\n",
    "# 100 0.4 'glorot_uniform' 'RMSprop' 0.547544663425\n",
    "# 100 0.4 'glorot_uniform' 'Adamax' 0.542127071416\n",
    "# 100 0.4 'glorot_uniform' 'Nadam' 0.544927256042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 100 0.4 'he_uniform' 'adam' 0.54419020321\n",
    "# 100 0.4 'he_normal' 'adam' 0.543867479612\n",
    "# 100 0.4 'glorot_uniform' 'adam' 0.542798319778\n",
    "# 100 0.4 'glorot_normal' 'adam' 0.546524272962\n",
    "# 100 0.4 'lecun_uniform' 'adam' 0.544478366113\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 150 0.4 50 0.5 20 0.5 'he_normal'  val 0.543127303723\n",
    "# 150 0.4 50 0.5 20 0.5 'he_uniform'  val 0.542279646729\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<74659x412 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6084908 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights.hdf5\")\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_y = model.predict_proba(x=test_df_nn.toarray(),batch_size = 128,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.98445845e-01,   4.90590602e-01,   1.10963546e-01],\n",
       "       [  9.91283834e-01,   8.24213494e-03,   4.74051310e-04],\n",
       "       [  9.88962233e-01,   1.05425483e-02,   4.95240442e-04],\n",
       "       ..., \n",
       "       [  9.92257774e-01,   7.49900285e-03,   2.43204151e-04],\n",
       "       [  9.84745502e-01,   1.47970403e-02,   4.57483169e-04],\n",
       "       [  6.17200851e-01,   3.49761784e-01,   3.30373496e-02]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "sub_name = '../output/sub_Keras_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(pred_y)\n",
    "out_df.columns = [\"low\", \"medium\",\"high\"]\n",
    "out_df[\"listing_id\"] = sub_id\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def nn_model(params):\n",
    "    model = Sequential()\n",
    "    init = 'glorot_normal'\n",
    "    \n",
    "    model.add(Dense(params['input_size'], # number of input units: needs to be tuned\n",
    "                    input_dim = params['input_dim'], # fixed length: number of columns of X\n",
    "                    init=init,\n",
    "                   ))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU()) # activation function\n",
    "    model.add(BatchNormalization()) # normalization\n",
    "    model.add(Dropout(params['input_drop_out'])) #dropout rate. needs to be tuned\n",
    "        \n",
    "    model.add(Dense(params['hidden_size'],\n",
    "                    init=init)) # number of hidden1 units. needs to be tuned.\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(params['hidden_drop_out'])) #dropout rate. needs to be tuned\n",
    "    \n",
    "#     model.add(Dense(20,init=init)) # number of hidden2 units. needs to be tuned.\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.add(PReLU())\n",
    "#     model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.5)) #dropout rate. needs to be tuned\n",
    "    \n",
    "    model.add(Dense(3,\n",
    "                    init = init,\n",
    "                    activation = 'softmax')) # 1 for regression \n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'adam' # optimizer. you may want to try different ones\n",
    "                 )\n",
    "    return(model)\n",
    "\n",
    "\n",
    "\n",
    "def nn_blend_data(parameters, train_x, train_y, test_x, fold, early_stopping_rounds=0, batch_size=128):\n",
    "    N_params = len(parameters)\n",
    "    print (\"Blend %d estimators for %d folds\" % (len(parameters), fold))\n",
    "    skf = KFold(n_splits=fold,shuffle=True,random_state=5431)\n",
    "    N_class = train_y.shape[1]\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "\n",
    "    \n",
    "    for j, nn_params in enumerate(parameters):\n",
    "        print (\"Model %d: %s\" %(j+1, nn_params))\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "        \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x[val_index]\n",
    "            val_y_fold = train_y[val_index]\n",
    "            \n",
    "\n",
    "            model = nn_model(nn_params)\n",
    "#             print (model)\n",
    "            fit= model.fit_generator(generator=batch_generator(train_x_fold, train_y_fold, 128, True),\n",
    "                                     nb_epoch=50,\n",
    "                                     samples_per_epoch=train_x_fold.shape[0],\n",
    "                                     validation_data=(val_x_fold.todense(), val_y_fold),\n",
    "                                     verbose = 0,\n",
    "                                     callbacks=[ModelCheckpoint(filepath=\"weights.hdf5\", \n",
    "                                                                monitor='val_loss', \n",
    "                                                                verbose=0, save_best_only=True)]\n",
    "                                    )\n",
    "\n",
    "            best_round=len(fit.epoch)-early_stopping_rounds-1\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            \n",
    "            model.load_weights(\"weights.hdf5\")\n",
    "            # Compile model (required to make predictions)\n",
    "            model.compile(loss = 'categorical_crossentropy',optimizer = 'adam' )\n",
    "            \n",
    "            # print (mean_absolute_error(np.exp(y_val)-200, pred_y))\n",
    "            val_y_predict_fold = model.predict_proba(x=val_x_fold.toarray(),verbose=0)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score   \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            model.load_weights(\"weights.hdf5\")\n",
    "            # Compile model (required to make predictions)\n",
    "            model.compile(loss = 'categorical_crossentropy',optimizer = 'adam' )            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = model.predict_proba(x=test_x.toarray(),verbose=0)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "            \n",
    "        test_blend_x[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 30 folds\n",
      "Model 1: {'input_size': 100, 'input_drop_out': 0.4, 'hidden_drop_out': 0.4, 'hidden_size': 30, 'input_dim': 223}\n",
      "Model 1 fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/keras/engine/training.py:1480: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best round 44\n",
      "('Score: ', 0.5357225917811298)\n",
      "Model 1 fold 1 fitting finished in 198.280s\n",
      "Model 1 fold 2\n",
      "best round 44\n",
      "('Score: ', 0.50543688891403482)\n",
      "Model 1 fold 2 fitting finished in 194.243s\n",
      "Model 1 fold 3\n",
      "best round 44\n",
      "('Score: ', 0.52427053517226052)\n",
      "Model 1 fold 3 fitting finished in 193.987s\n",
      "Model 1 fold 4\n",
      "best round 44\n",
      "('Score: ', 0.56031329332225277)\n",
      "Model 1 fold 4 fitting finished in 193.374s\n",
      "Model 1 fold 5\n",
      "best round 44\n",
      "('Score: ', 0.53015795884806782)\n",
      "Model 1 fold 5 fitting finished in 192.948s\n",
      "Model 1 fold 6\n",
      "best round 44\n",
      "('Score: ', 0.52175388566705205)\n",
      "Model 1 fold 6 fitting finished in 193.670s\n",
      "Model 1 fold 7\n",
      "best round 44\n",
      "('Score: ', 0.53318885099574487)\n",
      "Model 1 fold 7 fitting finished in 193.261s\n",
      "Model 1 fold 8\n",
      "best round 44\n",
      "('Score: ', 0.53512762986395312)\n",
      "Model 1 fold 8 fitting finished in 193.761s\n",
      "Model 1 fold 9\n",
      "best round 44\n",
      "('Score: ', 0.5201558202921942)\n",
      "Model 1 fold 9 fitting finished in 191.947s\n",
      "Model 1 fold 10\n",
      "best round 44\n",
      "('Score: ', 0.53526876629047138)\n",
      "Model 1 fold 10 fitting finished in 188.945s\n",
      "Model 1 fold 11\n",
      "best round 44\n",
      "('Score: ', 0.54386288764374191)\n",
      "Model 1 fold 11 fitting finished in 189.364s\n",
      "Model 1 fold 12\n",
      "best round 44\n",
      "('Score: ', 0.53134915130368598)\n",
      "Model 1 fold 12 fitting finished in 187.322s\n",
      "Model 1 fold 13\n",
      "best round 44\n",
      "('Score: ', 0.52790437411732039)\n",
      "Model 1 fold 13 fitting finished in 190.148s\n",
      "Model 1 fold 14\n",
      "best round 44\n",
      "('Score: ', 0.52809100780589369)\n",
      "Model 1 fold 14 fitting finished in 190.660s\n",
      "Model 1 fold 15\n",
      "best round 44\n",
      "('Score: ', 0.5213677465704788)\n",
      "Model 1 fold 15 fitting finished in 190.356s\n",
      "Model 1 fold 16\n",
      "best round 44\n",
      "('Score: ', 0.5094446987317065)\n",
      "Model 1 fold 16 fitting finished in 190.867s\n",
      "Model 1 fold 17\n",
      "best round 44\n",
      "('Score: ', 0.53157216114725203)\n",
      "Model 1 fold 17 fitting finished in 191.156s\n",
      "Model 1 fold 18\n",
      "best round 44\n",
      "('Score: ', 0.54866192162470007)\n",
      "Model 1 fold 18 fitting finished in 189.882s\n",
      "Model 1 fold 19\n",
      "best round 44\n",
      "('Score: ', 0.50956597109395996)\n",
      "Model 1 fold 19 fitting finished in 188.583s\n",
      "Model 1 fold 20\n",
      "best round 44\n",
      "('Score: ', 0.52440143453621091)\n",
      "Model 1 fold 20 fitting finished in 190.108s\n",
      "Model 1 fold 21\n",
      "best round 44\n",
      "('Score: ', 0.52164086386310871)\n",
      "Model 1 fold 21 fitting finished in 189.053s\n",
      "Model 1 fold 22\n",
      "best round 44\n",
      "('Score: ', 0.53306075097762307)\n",
      "Model 1 fold 22 fitting finished in 191.878s\n",
      "Model 1 fold 23\n",
      "best round 44\n",
      "('Score: ', 0.49439099819872157)\n",
      "Model 1 fold 23 fitting finished in 192.521s\n",
      "Model 1 fold 24\n",
      "best round 44\n",
      "('Score: ', 0.53358203479807853)\n",
      "Model 1 fold 24 fitting finished in 192.868s\n",
      "Model 1 fold 25\n",
      "best round 44\n",
      "('Score: ', 0.51880503921361931)\n",
      "Model 1 fold 25 fitting finished in 190.552s\n",
      "Model 1 fold 26\n",
      "best round 44\n",
      "('Score: ', 0.55215559772323353)\n",
      "Model 1 fold 26 fitting finished in 193.385s\n",
      "Model 1 fold 27\n",
      "best round 44\n",
      "('Score: ', 0.53064015127044728)\n",
      "Model 1 fold 27 fitting finished in 190.569s\n",
      "Model 1 fold 28\n",
      "best round 44\n",
      "('Score: ', 0.52639321991834098)\n",
      "Model 1 fold 28 fitting finished in 190.691s\n",
      "Model 1 fold 29\n",
      "best round 44\n",
      "('Score: ', 0.50600087738406241)\n",
      "Model 1 fold 29 fitting finished in 190.306s\n",
      "Model 1 fold 30\n",
      "best round 44\n",
      "('Score: ', 0.52402630184138743)\n",
      "Model 1 fold 30 fitting finished in 190.264s\n",
      "Score for model 1 is 0.527277\n",
      "Score for blended models is 0.527277\n"
     ]
    }
   ],
   "source": [
    "nn_parameters = [\n",
    "    { 'input_size' :100 ,\n",
    "     'input_dim' : train_X.shape[1],\n",
    "     'input_drop_out' : 0.4 ,\n",
    "     'hidden_size' : 30 ,\n",
    "     'hidden_drop_out' :0.4},\n",
    "]\n",
    "\n",
    "(train_blend_x, test_blend_x, blend_scores,best_round) = nn_blend_data(nn_parameters, train_df_nn, train_y, test_df_nn,\n",
    "                                                         30,\n",
    "                                                         5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_blend_x_xgb = pd.DataFrame(train_blend_x)\n",
    "train_blend_x_xgb.columns = [\"low\", \"medium\", \"high\"]\n",
    "train_blend_x_xgb[\"listing_id\"] = train_X.listing_id.values\n",
    "\n",
    "test_blend_x_xgb_mean = pd.DataFrame(test_blend_x)\n",
    "test_blend_x_xgb_mean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_blend_x_xgb_mean[\"listing_id\"] = test_X.listing_id.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_train = train_X_0322[['listing_id']].merge(train_blend_x_xgb,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_mean = test_X_0322[['listing_id']].merge(test_blend_x_xgb_mean,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52727711]\n",
      "[ 44.]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_Keras_last_30fold_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_Keras_mean_last_30fold_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores,axis=0))\n",
    "print (np.mean(best_round,axis=0))\n",
    "np.savetxt(name_train_blend,tmp_train, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,tmp_test_mean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
