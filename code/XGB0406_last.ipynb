{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn import model_selection,ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "# from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, LabelBinarizer, MultiLabelBinarizer,LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats.mstats import gmean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "train_df=pd.read_json('../input/train.json').reset_index(drop = True)\n",
    "test_df=pd.read_json('../input/test.json').reset_index(drop = True)\n",
    "\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 322)\n",
      "(74659, 322)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X_0322 = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X_0322 = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "\n",
    "print train_X_0322.shape\n",
    "print test_X_0322.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_num_map = {'high':2, 'medium':1, 'low':0}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_CV_MS_52571.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_CV_MS_52571.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 223)\n",
      "(74659, 223)\n"
     ]
    }
   ],
   "source": [
    "time_feature = pd.read_csv(data_path + 'listing_image_time.csv')\n",
    "time_feature.columns = ['listing_id','time_stamp']\n",
    "train_X = train_X.merge(time_feature,on='listing_id',how='left')\n",
    "test_X = test_X.merge(time_feature,on='listing_id',how='left')\n",
    "\n",
    "print train_X.shape\n",
    "print test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgb_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0,randomseed=1234):\n",
    "    N_params = len(estimators)\n",
    "#     print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,shuffle=True,random_state=randomseed)\n",
    "    N_class = len(set(train_y))\n",
    "        \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(objective = 'multi:softprob')\n",
    "        est.set_params(silent = False)\n",
    "        est.set_params(learning_rate = 0.03)\n",
    "        est.set_params(n_estimators=1000000)\n",
    "        \n",
    "#         print (\"Model %d: %s\" %(j+1, est))\n",
    "\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "    \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "#             print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]      \n",
    "\n",
    "            est.fit(train_x_fold,train_y_fold,\n",
    "                    eval_set = [(val_x_fold, val_y_fold)],\n",
    "                    eval_metric = 'mlogloss',\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose=False)\n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "#             print (\"best round %d\" % (best_round))\n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,ntree_limit=best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print \"Score: \", score\n",
    "            scores[i,j]=score\n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,ntree_limit=best_round)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fm\" % (j+1,i+1, (time.time() - fold_start)/60))\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "#         print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.498553110278\n",
      "Model 1 fold 1 fitting finished in 6.641m\n",
      "Score:  0.502627093623\n",
      "Model 1 fold 2 fitting finished in 6.933m\n",
      "Score:  0.508047064992\n",
      "Model 1 fold 3 fitting finished in 6.857m\n",
      "Score:  0.494595752931\n",
      "Model 1 fold 4 fitting finished in 5.121m\n",
      "Score:  0.509710265642\n",
      "Model 1 fold 5 fitting finished in 4.193m\n",
      "Score for blended models is 0.502707\n",
      "Score:  0.502516330235\n",
      "Model 1 fold 1 fitting finished in 3.612m\n",
      "Score:  0.509875984197\n",
      "Model 1 fold 2 fitting finished in 3.048m\n",
      "Score:  0.510923068057\n",
      "Model 1 fold 3 fitting finished in 2.872m\n",
      "Score:  0.494845075031\n",
      "Model 1 fold 4 fitting finished in 3.898m\n",
      "Score:  0.501221138037\n",
      "Model 1 fold 5 fitting finished in 4.822m\n",
      "Score for blended models is 0.503876\n",
      "Score:  0.507129901622\n",
      "Model 1 fold 1 fitting finished in 3.552m\n",
      "Score:  0.505789043926\n",
      "Model 1 fold 2 fitting finished in 3.859m\n",
      "Score:  0.501903321156\n",
      "Model 1 fold 3 fitting finished in 4.003m\n",
      "Score:  0.505918580249\n",
      "Model 1 fold 4 fitting finished in 4.666m\n",
      "Score:  0.499743746365\n",
      "Model 1 fold 5 fitting finished in 4.237m\n",
      "Score for blended models is 0.504097\n",
      "Score:  0.49743991807\n",
      "Model 1 fold 1 fitting finished in 4.858m\n",
      "Score:  0.50808589054\n",
      "Model 1 fold 2 fitting finished in 3.363m\n",
      "Score:  0.504384582251\n",
      "Model 1 fold 3 fitting finished in 3.937m\n",
      "Score:  0.506531166199\n",
      "Model 1 fold 4 fitting finished in 2.970m\n",
      "Score:  0.506156850629\n",
      "Model 1 fold 5 fitting finished in 3.058m\n",
      "Score for blended models is 0.504520\n",
      "Score:  0.521149921668\n",
      "Model 1 fold 1 fitting finished in 3.217m\n",
      "Score:  0.503515878829\n",
      "Model 1 fold 2 fitting finished in 4.760m\n",
      "Score:  0.500229525089\n",
      "Model 1 fold 3 fitting finished in 4.410m\n",
      "Score:  0.502497588242\n",
      "Model 1 fold 4 fitting finished in 3.606m\n",
      "Score:  0.494050531603\n",
      "Model 1 fold 5 fitting finished in 4.330m\n",
      "Score for blended models is 0.504289\n",
      "Score:  0.513009696898\n",
      "Model 1 fold 1 fitting finished in 2.448m\n",
      "Score:  0.507526561999\n",
      "Model 1 fold 2 fitting finished in 4.185m\n",
      "Score:  0.503012098609\n",
      "Model 1 fold 3 fitting finished in 4.359m\n",
      "Score:  0.509349207344\n",
      "Model 1 fold 4 fitting finished in 3.598m\n",
      "Score:  0.494563378021\n",
      "Model 1 fold 5 fitting finished in 3.877m\n",
      "Score for blended models is 0.505492\n",
      "Score:  0.51786963472\n",
      "Model 1 fold 1 fitting finished in 3.007m\n",
      "Score:  0.500068224019\n",
      "Model 1 fold 2 fitting finished in 3.448m\n",
      "Score:  0.495892860403\n",
      "Model 1 fold 3 fitting finished in 4.423m\n",
      "Score:  0.501189210006\n",
      "Model 1 fold 4 fitting finished in 4.071m\n",
      "Score:  0.507704727544\n",
      "Model 1 fold 5 fitting finished in 3.330m\n",
      "Score for blended models is 0.504545\n",
      "Score:  0.503182248124\n",
      "Model 1 fold 1 fitting finished in 3.213m\n",
      "Score:  0.502593277079\n",
      "Model 1 fold 2 fitting finished in 4.428m\n",
      "Score:  0.497649613508\n",
      "Model 1 fold 3 fitting finished in 5.131m\n",
      "Score:  0.512037834347\n",
      "Model 1 fold 4 fitting finished in 3.415m\n",
      "Score:  0.509748579596\n",
      "Model 1 fold 5 fitting finished in 2.907m\n",
      "Score for blended models is 0.505042\n",
      "Score:  0.505051788852\n",
      "Model 1 fold 1 fitting finished in 5.410m\n",
      "Score:  0.506754088981\n",
      "Model 1 fold 2 fitting finished in 2.993m\n",
      "Score:  0.496669081238\n",
      "Model 1 fold 3 fitting finished in 3.711m\n",
      "Score:  0.505005370421\n",
      "Model 1 fold 4 fitting finished in 3.806m\n",
      "Score:  0.505574697163\n",
      "Model 1 fold 5 fitting finished in 3.836m\n",
      "Score for blended models is 0.503811\n",
      "Score:  0.49447058321\n",
      "Model 1 fold 1 fitting finished in 3.930m\n",
      "Score:  0.514000618126\n",
      "Model 1 fold 2 fitting finished in 3.273m\n",
      "Score:  0.504766195424\n",
      "Model 1 fold 3 fitting finished in 3.587m\n",
      "Score:  0.498759771513\n",
      "Model 1 fold 4 fitting finished in 3.778m\n",
      "Score:  0.503617677442\n",
      "Model 1 fold 5 fitting finished in 4.468m\n",
      "Score for blended models is 0.503123\n",
      "Score:  0.503641039168\n",
      "Model 1 fold 1 fitting finished in 4.219m\n",
      "Score:  0.515715717163\n",
      "Model 1 fold 2 fitting finished in 5.476m\n",
      "Score:  0.495723549741\n",
      "Model 1 fold 3 fitting finished in 3.781m\n",
      "Score:  0.506031655616\n",
      "Model 1 fold 4 fitting finished in 3.775m\n",
      "Score:  0.501787378704\n",
      "Model 1 fold 5 fitting finished in 3.087m\n",
      "Score for blended models is 0.504580\n",
      "Score:  0.502617417321\n",
      "Model 1 fold 1 fitting finished in 3.702m\n",
      "Score:  0.51501210272\n",
      "Model 1 fold 2 fitting finished in 3.644m\n",
      "Score:  0.497258455143\n",
      "Model 1 fold 3 fitting finished in 3.475m\n",
      "Score:  0.513399059985\n",
      "Model 1 fold 4 fitting finished in 4.179m\n",
      "Score:  0.492468222097\n",
      "Model 1 fold 5 fitting finished in 4.258m\n",
      "Score for blended models is 0.504151\n",
      "Score:  0.513451994359\n",
      "Model 1 fold 1 fitting finished in 3.264m\n",
      "Score:  0.500048879898\n",
      "Model 1 fold 2 fitting finished in 4.066m\n",
      "Score:  0.508415000763\n",
      "Model 1 fold 3 fitting finished in 4.155m\n",
      "Score:  0.496913626011\n",
      "Model 1 fold 4 fitting finished in 4.655m\n",
      "Score:  0.500053295999\n",
      "Model 1 fold 5 fitting finished in 4.548m\n",
      "Score for blended models is 0.503777\n",
      "Score:  0.513575864116\n",
      "Model 1 fold 1 fitting finished in 4.581m\n",
      "Score:  0.509811307723\n",
      "Model 1 fold 2 fitting finished in 4.001m\n",
      "Score:  0.500765291291\n",
      "Model 1 fold 3 fitting finished in 3.808m\n",
      "Score:  0.500988814163\n",
      "Model 1 fold 4 fitting finished in 3.063m\n",
      "Score:  0.497122116752\n",
      "Model 1 fold 5 fitting finished in 4.617m\n",
      "Score for blended models is 0.504453\n",
      "Score:  0.500611504323\n",
      "Model 1 fold 1 fitting finished in 4.450m\n",
      "Score:  0.51045697107\n",
      "Model 1 fold 2 fitting finished in 3.904m\n",
      "Score:  0.503171520637\n",
      "Model 1 fold 3 fitting finished in 2.908m\n",
      "Score:  0.505771019802\n",
      "Model 1 fold 4 fitting finished in 3.906m\n",
      "Score:  0.50306604968\n",
      "Model 1 fold 5 fitting finished in 3.108m\n",
      "Score for blended models is 0.504615\n",
      "Score:  0.515042503133\n",
      "Model 1 fold 1 fitting finished in 3.027m\n",
      "Score:  0.510831507881\n",
      "Model 1 fold 2 fitting finished in 3.172m\n",
      "Score:  0.506125717727\n",
      "Model 1 fold 3 fitting finished in 5.153m\n",
      "Score:  0.501531079988\n",
      "Model 1 fold 4 fitting finished in 3.313m\n",
      "Score:  0.490802571314\n",
      "Model 1 fold 5 fitting finished in 3.993m\n",
      "Score for blended models is 0.504867\n",
      "Score:  0.496094750607\n",
      "Model 1 fold 1 fitting finished in 3.517m\n",
      "Score:  0.501934266078\n",
      "Model 1 fold 2 fitting finished in 3.576m\n",
      "Score:  0.509118189358\n",
      "Model 1 fold 3 fitting finished in 3.570m\n",
      "Score:  0.499894722776\n",
      "Model 1 fold 4 fitting finished in 3.774m\n",
      "Score:  0.513146618375\n",
      "Model 1 fold 5 fitting finished in 3.419m\n",
      "Score for blended models is 0.504038\n",
      "Score:  0.502841459667\n",
      "Model 1 fold 1 fitting finished in 3.157m\n",
      "Score:  0.504024371387\n",
      "Model 1 fold 2 fitting finished in 4.252m\n",
      "Score:  0.505124936061\n",
      "Model 1 fold 3 fitting finished in 3.419m\n",
      "Score:  0.508161172427\n",
      "Model 1 fold 4 fitting finished in 4.148m\n",
      "Score:  0.503748493256\n",
      "Model 1 fold 5 fitting finished in 3.717m\n",
      "Score for blended models is 0.504780\n",
      "Score:  0.510662281527\n",
      "Model 1 fold 1 fitting finished in 2.994m\n",
      "Score:  0.502953040652\n",
      "Model 1 fold 2 fitting finished in 2.914m\n",
      "Score:  0.498491352071\n",
      "Model 1 fold 3 fitting finished in 4.935m\n",
      "Score:  0.513351187807\n",
      "Model 1 fold 4 fitting finished in 2.342m\n",
      "Score:  0.502030105854\n",
      "Model 1 fold 5 fitting finished in 5.279m\n",
      "Score for blended models is 0.505498\n",
      "Score:  0.504858651803\n",
      "Model 1 fold 1 fitting finished in 3.006m\n",
      "Score:  0.512464745398\n",
      "Model 1 fold 2 fitting finished in 3.852m\n",
      "Score:  0.502064022642\n",
      "Model 1 fold 3 fitting finished in 3.056m\n",
      "Score:  0.49808851952\n",
      "Model 1 fold 4 fitting finished in 4.295m\n",
      "Score:  0.508015010598\n",
      "Model 1 fold 5 fitting finished in 3.860m\n",
      "Score for blended models is 0.505098\n"
     ]
    }
   ],
   "source": [
    "train_total = np.zeros((train_X.shape[0], 3))\n",
    "test_total = np.zeros((test_X.shape[0], 3))\n",
    "score_total = 0\n",
    "count = 20\n",
    "\n",
    "for n in range(count):\n",
    "    randomseed = n\n",
    "    estimators = [\n",
    "                 xgb.XGBClassifier(max_depth = 7,\n",
    "                                  min_child_weight = 10,\n",
    "                                  colsample_bytree = 0.208806,\n",
    "                                  subsample = 0.99,\n",
    "                                  gamma = 2.879361),  \n",
    "                 ]\n",
    "\n",
    "    (train_blend_x_xgb,\n",
    "     test_blend_x_xgb_mean,\n",
    "     test_blend_x_xgb_gmean,\n",
    "     blend_scores_xgb,\n",
    "     best_rounds_xgb) = xgb_blend(estimators,\n",
    "                                  train_X,train_y,\n",
    "                                  test_X,\n",
    "                                  5,\n",
    "                                  200,randomseed)\n",
    "    train_total += train_blend_x_xgb\n",
    "    test_total += test_blend_x_xgb_mean\n",
    "    score_total += np.mean(blend_scores_xgb)\n",
    "    \n",
    "train_total = train_total / count\n",
    "test_total = test_total / count\n",
    "score_total = score_total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_xgb = pd.DataFrame(train_total)\n",
    "train_xgb.columns = [\"low\", \"medium\", \"high\"]\n",
    "train_xgb[\"listing_id\"] = train_X.listing_id.values\n",
    "\n",
    "test_xgb_mean = pd.DataFrame(test_total)\n",
    "test_xgb_mean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_xgb_mean[\"listing_id\"] = test_X.listing_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_train = train_X_0322[['listing_id']].merge(train_xgb,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_mean = test_X_0322[['listing_id']].merge(test_xgb_mean,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504367874862\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_XGB_BM_20bagging_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_XGB_BM_20bagging_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print score_total\n",
    "# print (np.mean(best_rounds_RFC,axis=0))\n",
    "np.savetxt(name_train_blend,tmp_train, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,tmp_test_mean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_XGB_20bagging_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(tmp_test_mean)\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X_0322.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
