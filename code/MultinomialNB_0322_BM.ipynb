{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV,StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "from scipy.stats.mstats import gmean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 322) (74659, 322) (49352L,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "ntrain = train_X.shape[0]\n",
    "sub_list = test_X.listing_id.values.copy()\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data=pd.concat([train_X,test_X])\n",
    "features_to_use = train_X.columns.values\n",
    "\n",
    "skewed_cols = full_data[features_to_use].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "SSL = preprocessing.StandardScaler()\n",
    "skewed_cols = skewed_cols[skewed_cols > 0.25].index.values\n",
    "for skewed_col in skewed_cols:\n",
    "    full_data[skewed_col], lam = boxcox(full_data[skewed_col] - full_data[skewed_col].min() + 1)\n",
    "#     print skewed_col, '\\t', lam\n",
    "for col in features_to_use:\n",
    "    full_data[col] = SSL.fit_transform(full_data[col].values.reshape(-1,1))\n",
    "    full_data[col] = full_data[col] - full_data[col].min() + 1\n",
    "    train_X[col] = full_data.iloc[:ntrain][col]\n",
    "    test_X[col] = full_data.iloc[ntrain:][col]\n",
    "\n",
    "    \n",
    "del full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MNB_cv(alpha=1.0):\n",
    "    scores=[]\n",
    "    est=MultinomialNB(alpha=alpha)\n",
    "    est.fit(X_train, y_train)\n",
    "    y_val_pred = est.predict_proba(X_val)\n",
    "    return -1*log_loss(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 600\t -0.679718494035\n",
      "alpha = 650\t -0.672018712462\n",
      "alpha = 700\t -0.666439945279\n",
      "alpha = 750\t -0.662874572552\n",
      "alpha = 800\t -0.661148162779\n",
      "alpha = 850\t -0.661039819444\n",
      "alpha = 900\t -0.662308874992\n",
      "alpha = 950\t -0.664721112317\n"
     ]
    }
   ],
   "source": [
    "cv_score = -1\n",
    "for x in range(600,1000,50):\n",
    "    score = MNB_cv(alpha = x)\n",
    "    if score > cv_score:\n",
    "        alpha = x\n",
    "        cv_score = score\n",
    "    print 'alpha = {0}\\t {1:.12}'.format(x,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MNB_blend(est, train_x, train_y, test_x, fold):\n",
    "    N_params = len(est)\n",
    "    print \"Blend %d estimators for %d folds\" % (N_params, fold)\n",
    "    skf = KFold(n_splits=fold,random_state=seed)\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros((fold,N_params))\n",
    "    best_rounds = np.zeros((fold, N_params))    \n",
    "    \n",
    "    for j, ester in enumerate(est):\n",
    "        print \"Model %d:\" %(j+1)\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "\n",
    "            \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print \"Model %d fold %d\" %(j+1,i+1)\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]            \n",
    "            \n",
    "\n",
    "            ester.fit(train_x_fold,train_y_fold)\n",
    "            \n",
    "            val_y_predict_fold = ester.predict_proba(val_x_fold)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print \"Score: \", score\n",
    "            scores[i,j]=score            \n",
    "            \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = ester.predict_proba(test_x)\n",
    "            \n",
    "            print \"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start)            \n",
    "\n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print \"Score for model %d is %f\" % (j+1,np.mean(scores[:,j]))\n",
    "    print \"Score for blended models is %f\" % (np.mean(scores))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 3 estimators for 10 folds\n",
      "Model 1:\n",
      "Model 1 fold 1\n",
      "Score:  0.66009173939\n",
      "Model 1 fold 1 fitting finished in 0.459s\n",
      "Model 1 fold 2\n",
      "Score:  0.64887552281\n",
      "Model 1 fold 2 fitting finished in 0.282s\n",
      "Model 1 fold 3\n",
      "Score:  0.671858800985\n",
      "Model 1 fold 3 fitting finished in 0.281s\n",
      "Model 1 fold 4\n",
      "Score:  0.654134087524\n",
      "Model 1 fold 4 fitting finished in 0.282s\n",
      "Model 1 fold 5\n",
      "Score:  0.684212532161\n",
      "Model 1 fold 5 fitting finished in 0.284s\n",
      "Model 1 fold 6\n",
      "Score:  0.666321856974\n",
      "Model 1 fold 6 fitting finished in 0.292s\n",
      "Model 1 fold 7\n",
      "Score:  0.668923804782\n",
      "Model 1 fold 7 fitting finished in 0.291s\n",
      "Model 1 fold 8\n",
      "Score:  0.703091526436\n",
      "Model 1 fold 8 fitting finished in 0.288s\n",
      "Model 1 fold 9\n",
      "Score:  0.680281240744\n",
      "Model 1 fold 9 fitting finished in 0.280s\n",
      "Model 1 fold 10\n",
      "Score:  0.682384031063\n",
      "Model 1 fold 10 fitting finished in 0.280s\n",
      "Score for model 1 is 0.672018\n",
      "Model 2:\n",
      "Model 2 fold 1\n",
      "Score:  0.657395274667\n",
      "Model 2 fold 1 fitting finished in 0.287s\n",
      "Model 2 fold 2\n",
      "Score:  0.647395796289\n",
      "Model 2 fold 2 fitting finished in 0.282s\n",
      "Model 2 fold 3\n",
      "Score:  0.667357615098\n",
      "Model 2 fold 3 fitting finished in 0.283s\n",
      "Model 2 fold 4\n",
      "Score:  0.651937792045\n",
      "Model 2 fold 4 fitting finished in 0.281s\n",
      "Model 2 fold 5\n",
      "Score:  0.681256996419\n",
      "Model 2 fold 5 fitting finished in 0.301s\n",
      "Model 2 fold 6\n",
      "Score:  0.663689069589\n",
      "Model 2 fold 6 fitting finished in 0.284s\n",
      "Model 2 fold 7\n",
      "Score:  0.665838296076\n",
      "Model 2 fold 7 fitting finished in 0.282s\n",
      "Model 2 fold 8\n",
      "Score:  0.698806069874\n",
      "Model 2 fold 8 fitting finished in 0.285s\n",
      "Model 2 fold 9\n",
      "Score:  0.677863887546\n",
      "Model 2 fold 9 fitting finished in 0.297s\n",
      "Model 2 fold 10\n",
      "Score:  0.678911683946\n",
      "Model 2 fold 10 fitting finished in 0.282s\n",
      "Score for model 2 is 0.669045\n",
      "Model 3:\n",
      "Model 3 fold 1\n",
      "Score:  0.655992355985\n",
      "Model 3 fold 1 fitting finished in 0.290s\n",
      "Model 3 fold 2\n",
      "Score:  0.647102108048\n",
      "Model 3 fold 2 fitting finished in 0.302s\n",
      "Model 3 fold 3\n",
      "Score:  0.664591980617\n",
      "Model 3 fold 3 fitting finished in 0.334s\n",
      "Model 3 fold 4\n",
      "Score:  0.650993926491\n",
      "Model 3 fold 4 fitting finished in 0.283s\n",
      "Model 3 fold 5\n",
      "Score:  0.679714283968\n",
      "Model 3 fold 5 fitting finished in 0.277s\n",
      "Model 3 fold 6\n",
      "Score:  0.66229585853\n",
      "Model 3 fold 6 fitting finished in 0.282s\n",
      "Model 3 fold 7\n",
      "Score:  0.664359626993\n",
      "Model 3 fold 7 fitting finished in 0.298s\n",
      "Model 3 fold 8\n",
      "Score:  0.696068110439\n",
      "Model 3 fold 8 fitting finished in 0.279s\n",
      "Model 3 fold 9\n",
      "Score:  0.67684529376\n",
      "Model 3 fold 9 fitting finished in 0.279s\n",
      "Model 3 fold 10\n",
      "Score:  0.676815433868\n",
      "Model 3 fold 10 fitting finished in 0.279s\n",
      "Score for model 3 is 0.667478\n",
      "Score for blended models is 0.669514\n"
     ]
    }
   ],
   "source": [
    "est = [MultinomialNB(alpha = 800),\n",
    "      MultinomialNB(alpha = 850),\n",
    "      MultinomialNB(alpha = 900),]\n",
    "\n",
    "(train_blend_x_MNB,\n",
    " test_blend_x_MNB_mean,\n",
    " test_blend_x_MNB_gmean,\n",
    " blend_scores_MNB,\n",
    " best_rounds_MNB) = MNB_blend(est,\n",
    "                             train_X,train_y,\n",
    "                             test_X,\n",
    "                             10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67201751  0.66904525  0.6674779 ]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_MNB_BM_MB_add03052240_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_MNB_mean_BM_MB_add03052240_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../blend/test_blend_MNB_gmean_BM_MB_add03052240_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_MNB,axis=0))\n",
    "# print (np.mean(best_rounds_RFC,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_MNB, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_MNB_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_MNB_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_MNB_mean_BM_MB_add03052240_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_blend_x_MNB_mean[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = sub_list\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
