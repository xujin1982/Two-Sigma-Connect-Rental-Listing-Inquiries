{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV,StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "from scipy.stats.mstats import gmean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 322) (74659, 322) (49352L,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "ntrain = train_X.shape[0]\n",
    "sub_list = test_X.listing_id.values.copy()\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 323)\n",
      "(74659, 323)\n"
     ]
    }
   ],
   "source": [
    "time_feature = pd.read_csv(data_path + 'listing_image_time.csv')\n",
    "time_feature.columns = ['listing_id','time_stamp']\n",
    "train_X = train_X.merge(time_feature,on='listing_id',how='left')\n",
    "test_X = test_X.merge(time_feature,on='listing_id',how='left')\n",
    "\n",
    "print train_X.shape\n",
    "print test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "full_data=pd.concat([train_X,test_X])\n",
    "features_to_use = train_X.columns.values\n",
    "\n",
    "skewed_cols = full_data[features_to_use].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "SSL = preprocessing.StandardScaler()\n",
    "skewed_cols = skewed_cols[skewed_cols > 0.25].index.values\n",
    "for skewed_col in skewed_cols:\n",
    "    full_data[skewed_col], lam = boxcox(full_data[skewed_col] - full_data[skewed_col].min() + 1)\n",
    "#     print skewed_col, '\\t', lam\n",
    "for col in features_to_use:\n",
    "    full_data[col] = SSL.fit_transform(full_data[col].values.reshape(-1,1))\n",
    "    full_data[col] = full_data[col] - full_data[col].min() + 1\n",
    "    train_X[col] = full_data.iloc[:ntrain][col]\n",
    "    test_X[col] = full_data.iloc[ntrain:][col]\n",
    "\n",
    "    \n",
    "del full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MNB_cv(alpha=1.0):\n",
    "    scores=[]\n",
    "    est=MultinomialNB(alpha=alpha)\n",
    "    est.fit(X_train, y_train)\n",
    "    y_val_pred = est.predict_proba(X_val)\n",
    "    return -1*log_loss(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 600\t -0.679718494035\n",
      "alpha = 650\t -0.672018712462\n",
      "alpha = 700\t -0.666439945279\n",
      "alpha = 750\t -0.662874572552\n",
      "alpha = 800\t -0.661148162779\n",
      "alpha = 850\t -0.661039819444\n",
      "alpha = 900\t -0.662308874992\n",
      "alpha = 950\t -0.664721112317\n"
     ]
    }
   ],
   "source": [
    "cv_score = -1\n",
    "for x in range(600,1000,50):\n",
    "    score = MNB_cv(alpha = x)\n",
    "    if score > cv_score:\n",
    "        alpha = x\n",
    "        cv_score = score\n",
    "    print 'alpha = {0}\\t {1:.12}'.format(x,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MNB_blend(est, train_x, train_y, test_x, fold):\n",
    "    N_params = len(est)\n",
    "    print \"Blend %d estimators for %d folds\" % (N_params, fold)\n",
    "    skf = KFold(n_splits=fold,random_state=seed)\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros((fold,N_params))\n",
    "    best_rounds = np.zeros((fold, N_params))    \n",
    "    \n",
    "    for j, ester in enumerate(est):\n",
    "        print \"Model %d:\" %(j+1)\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "\n",
    "            \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print \"Model %d fold %d\" %(j+1,i+1)\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]            \n",
    "            \n",
    "\n",
    "            ester.fit(train_x_fold,train_y_fold)\n",
    "            \n",
    "            val_y_predict_fold = ester.predict_proba(val_x_fold)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print \"Score: \", score\n",
    "            scores[i,j]=score            \n",
    "            \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = ester.predict_proba(test_x)\n",
    "            \n",
    "            print \"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start)            \n",
    "\n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print \"Score for model %d is %f\" % (j+1,np.mean(scores[:,j]))\n",
    "    print \"Score for blended models is %f\" % (np.mean(scores))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 3 estimators for 10 folds\n",
      "Model 1:\n",
      "Model 1 fold 1\n",
      "Score:  0.657799006929\n",
      "Model 1 fold 1 fitting finished in 0.491s\n",
      "Model 1 fold 2\n",
      "Score:  0.647244562324\n",
      "Model 1 fold 2 fitting finished in 0.222s\n",
      "Model 1 fold 3\n",
      "Score:  0.668859608924\n",
      "Model 1 fold 3 fitting finished in 0.217s\n",
      "Model 1 fold 4\n",
      "Score:  0.649992947797\n",
      "Model 1 fold 4 fitting finished in 0.235s\n",
      "Model 1 fold 5\n",
      "Score:  0.678556294249\n",
      "Model 1 fold 5 fitting finished in 0.239s\n",
      "Model 1 fold 6\n",
      "Score:  0.660997757233\n",
      "Model 1 fold 6 fitting finished in 0.212s\n",
      "Model 1 fold 7\n",
      "Score:  0.66465844729\n",
      "Model 1 fold 7 fitting finished in 0.216s\n",
      "Model 1 fold 8\n",
      "Score:  0.700114740492\n",
      "Model 1 fold 8 fitting finished in 0.250s\n",
      "Model 1 fold 9\n",
      "Score:  0.679775728849\n",
      "Model 1 fold 9 fitting finished in 0.233s\n",
      "Model 1 fold 10\n",
      "Score:  0.680781427454\n",
      "Model 1 fold 10 fitting finished in 0.220s\n",
      "Score for model 1 is 0.668878\n",
      "Model 2:\n",
      "Model 2 fold 1\n",
      "Score:  0.655370825808\n",
      "Model 2 fold 1 fitting finished in 0.222s\n",
      "Model 2 fold 2\n",
      "Score:  0.646007824599\n",
      "Model 2 fold 2 fitting finished in 0.227s\n",
      "Model 2 fold 3\n",
      "Score:  0.664709249816\n",
      "Model 2 fold 3 fitting finished in 0.239s\n",
      "Model 2 fold 4\n",
      "Score:  0.648104945205\n",
      "Model 2 fold 4 fitting finished in 0.235s\n",
      "Model 2 fold 5\n",
      "Score:  0.676021156094\n",
      "Model 2 fold 5 fitting finished in 0.218s\n",
      "Model 2 fold 6\n",
      "Score:  0.658772641393\n",
      "Model 2 fold 6 fitting finished in 0.229s\n",
      "Model 2 fold 7\n",
      "Score:  0.662166103436\n",
      "Model 2 fold 7 fitting finished in 0.254s\n",
      "Model 2 fold 8\n",
      "Score:  0.696441918436\n",
      "Model 2 fold 8 fitting finished in 0.223s\n",
      "Model 2 fold 9\n",
      "Score:  0.677994590235\n",
      "Model 2 fold 9 fitting finished in 0.262s\n",
      "Model 2 fold 10\n",
      "Score:  0.678009645209\n",
      "Model 2 fold 10 fitting finished in 0.218s\n",
      "Score for model 2 is 0.666360\n",
      "Model 3:\n",
      "Model 3 fold 1\n",
      "Score:  0.654204267626\n",
      "Model 3 fold 1 fitting finished in 0.241s\n",
      "Model 3 fold 2\n",
      "Score:  0.6459286815\n",
      "Model 3 fold 2 fitting finished in 0.229s\n",
      "Model 3 fold 3\n",
      "Score:  0.662253180441\n",
      "Model 3 fold 3 fitting finished in 0.244s\n",
      "Model 3 fold 4\n",
      "Score:  0.647436818769\n",
      "Model 3 fold 4 fitting finished in 0.238s\n",
      "Model 3 fold 5\n",
      "Score:  0.674863087847\n",
      "Model 3 fold 5 fitting finished in 0.247s\n",
      "Model 3 fold 6\n",
      "Score:  0.657751105074\n",
      "Model 3 fold 6 fitting finished in 0.229s\n",
      "Model 3 fold 7\n",
      "Score:  0.661229209807\n",
      "Model 3 fold 7 fitting finished in 0.225s\n",
      "Model 3 fold 8\n",
      "Score:  0.694276027677\n",
      "Model 3 fold 8 fitting finished in 0.220s\n",
      "Model 3 fold 9\n",
      "Score:  0.677558516919\n",
      "Model 3 fold 9 fitting finished in 0.221s\n",
      "Model 3 fold 10\n",
      "Score:  0.676562559178\n",
      "Model 3 fold 10 fitting finished in 0.240s\n",
      "Score for model 3 is 0.665206\n",
      "Score for blended models is 0.666815\n"
     ]
    }
   ],
   "source": [
    "est = [MultinomialNB(alpha = 800),\n",
    "      MultinomialNB(alpha = 850),\n",
    "      MultinomialNB(alpha = 900),]\n",
    "\n",
    "(train_blend_x_MNB,\n",
    " test_blend_x_MNB_mean,\n",
    " test_blend_x_MNB_gmean,\n",
    " blend_scores_MNB,\n",
    " best_rounds_MNB) = MNB_blend(est,\n",
    "                             train_X,train_y,\n",
    "                             test_X,\n",
    "                             10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352L, 3L)\n",
      "(74659L, 3L)\n"
     ]
    }
   ],
   "source": [
    "train_blend_mean = \\\n",
    "    np.stack([train_blend_x_MNB[:,[0,3,6]].mean(1),\n",
    "              train_blend_x_MNB[:,[1,4,7]].mean(1),\n",
    "              train_blend_x_MNB[:,[2,5,8]].mean(1)]).T\n",
    "\n",
    "test_blend_mean = \\\n",
    "    np.stack([test_blend_x_MNB_mean[:,[0,3,6]].mean(1),\n",
    "              test_blend_x_MNB_mean[:,[1,4,7]].mean(1),\n",
    "              test_blend_x_MNB_mean[:,[2,5,8]].mean(1)]).T\n",
    "    \n",
    "print train_blend_mean.shape\n",
    "print test_blend_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21645468,  0.58974796,  0.19379736,  0.21839745,  0.59150297,\n",
       "        0.19009957,  0.22051678,  0.5934742 ,  0.18600903])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_MNB_mean[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.18456305e-01,   5.91575042e-01,   1.89968654e-01],\n",
       "       [  9.92103070e-01,   7.10231138e-03,   7.94618304e-04],\n",
       "       [  9.71220288e-01,   2.51676691e-02,   3.61204334e-03],\n",
       "       [  5.01988295e-01,   4.11198271e-01,   8.68134335e-02],\n",
       "       [  7.54495603e-01,   2.13157763e-01,   3.23466334e-02],\n",
       "       [  8.19565150e-01,   1.65648588e-01,   1.47862620e-02],\n",
       "       [  7.02088733e-01,   2.35497534e-01,   6.24137327e-02],\n",
       "       [  2.35404183e-01,   5.36602021e-01,   2.27993796e-01],\n",
       "       [  9.46805054e-01,   4.97536075e-02,   3.44133846e-03],\n",
       "       [  9.82396294e-01,   1.65358408e-02,   1.06786507e-03],\n",
       "       [  9.27042402e-01,   4.57476794e-02,   2.72099187e-02],\n",
       "       [  7.62756263e-01,   2.15655243e-01,   2.15884943e-02],\n",
       "       [  7.20956403e-01,   2.43982971e-01,   3.50606261e-02],\n",
       "       [  7.94255406e-01,   1.75504947e-01,   3.02396471e-02],\n",
       "       [  8.86843719e-01,   1.04687033e-01,   8.46924783e-03],\n",
       "       [  8.01747713e-01,   1.81951429e-01,   1.63008579e-02],\n",
       "       [  8.88442048e-01,   7.77466748e-02,   3.38112774e-02],\n",
       "       [  3.82247030e-01,   5.18453727e-01,   9.92992437e-02],\n",
       "       [  5.63648657e-01,   3.38266012e-01,   9.80853303e-02],\n",
       "       [  9.71231056e-01,   2.36874434e-02,   5.08150022e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_mean[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66887805  0.66635989  0.66520635]\n"
     ]
    }
   ],
   "source": [
    "# now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_MNB_BM_MB_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_MNB_mean_BM_MB_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "# name_test_blend_gmean = '../blend/test_blend_MNB_gmean_BM_MB_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_MNB,axis=0))\n",
    "# print (np.mean(best_rounds_RFC,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_mean, delimiter=\",\")\n",
    "# np.savetxt(name_test_blend_gmean,test_blend_x_MNB_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_MNB_mean_BM_MB_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_blend_x_MNB_mean[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = sub_list\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
