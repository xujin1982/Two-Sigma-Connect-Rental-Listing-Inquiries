{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.stats.mstats import gmean\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import skew, boxcox,boxcox_normmax\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 522) (74659, 522) (49352,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_BM_MB_add03052240_desc.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_BM_MB_add03052240_desc.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print (train_X.shape, test_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "train_X_trans = scaler.transform(train_X)\n",
    "test_X_trans = scaler.transform(test_X)\n",
    "\n",
    "# y_low =[]\n",
    "# for i in range(train_X_trans.shape[0]):\n",
    "#     y_low.append(1 if train_y[i] == 2 else 0)\n",
    "    \n",
    "# y_low = np.array(y_low)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Multi_Class_FM(train_x, train_y_binary, test_x, fold = 5):\n",
    "    skf = KFold(n_splits=fold,random_state=seed)\n",
    "    dict_opochs = {0:300,1:500,2:650}\n",
    "#     dict_opochs = {0:40,1:40,2:40}\n",
    "    label = set(train_y_binary)\n",
    "    train_blend_x = np.zeros((train_x.shape[0], 2*len(label)))    \n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], 2*len(label)))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], 2*len(label)))\n",
    "    \n",
    "    for j, (level) in enumerate(label):\n",
    "        vfunc = np.vectorize(lambda x: 1 if x == level else 0)\n",
    "        y_ovr = vfunc(train_y_binary)\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], 2*fold))\n",
    "        \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            train_x_fold = train_x[train_index]\n",
    "            train_y_fold = y_ovr[train_index]\n",
    "            val_x_fold = train_x[val_index]\n",
    "            val_y_fold = y_ovr[val_index]  \n",
    "\n",
    "            model = TFFMClassifier(\n",
    "                order=2, \n",
    "                rank=10, \n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=3e-3,epsilon = 1), \n",
    "                n_epochs=dict_opochs[level], \n",
    "                batch_size=1024,\n",
    "                init_std=0.001,\n",
    "                reg= 0.01,\n",
    "                input_type='dense',\n",
    "                seed=42\n",
    "            )\n",
    "\n",
    "            model.fit(train_x_fold, train_y_fold, show_progress=False)\n",
    "            predictions = model.predict_proba(val_x_fold)\n",
    "            scores = log_loss(val_y_fold, predictions)\n",
    "            print('label:{0}\\tlog_loss: {1:.12f}\\tfold:{2}'.format(level, scores, i+1))\n",
    "            train_blend_x[val_index,j*2:(j+1)*2] = predictions\n",
    "            test_blend_x_j[:,(i*2):(i+1)*2] = model.predict_proba(test_x)\n",
    "            # this will close tf.Session and free resources\n",
    "            model.destroy()\n",
    "        \n",
    "        test_blend_x_mean[:,(j*2):(j+1)*2] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,2*fold,2)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,2*fold,2)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*2):(j+1)*2] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,2*fold,2)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,2*fold,2)], axis=1)]).T            \n",
    "    return train_blend_x, test_blend_x_mean, test_blend_x_gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:0\tlog_loss: 0.454955991229\tfold:1\n",
      "label:0\tlog_loss: 0.443051334661\tfold:2\n",
      "label:0\tlog_loss: 0.456654232249\tfold:3\n",
      "label:0\tlog_loss: 0.447933480535\tfold:4\n",
      "label:0\tlog_loss: 0.462754510770\tfold:5\n",
      "label:0\tlog_loss: 0.452832541395\tfold:6\n",
      "label:0\tlog_loss: 0.458048671167\tfold:7\n",
      "label:0\tlog_loss: 0.470953706975\tfold:8\n",
      "label:0\tlog_loss: 0.464838941301\tfold:9\n",
      "label:0\tlog_loss: 0.473910745417\tfold:10\n",
      "label:1\tlog_loss: 0.459752223000\tfold:1\n",
      "label:1\tlog_loss: 0.441396369827\tfold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tffm/utils.py:196: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:1\tlog_loss: 0.461093828437\tfold:3\n",
      "label:1\tlog_loss: 0.453319550619\tfold:4\n",
      "label:1\tlog_loss: 0.461915840894\tfold:5\n",
      "label:1\tlog_loss: 0.455964289362\tfold:6\n",
      "label:1\tlog_loss: 0.461743115097\tfold:7\n",
      "label:1\tlog_loss: 0.472934473471\tfold:8\n",
      "label:1\tlog_loss: 0.464874394938\tfold:9\n",
      "label:1\tlog_loss: 0.469379874931\tfold:10\n",
      "label:2\tlog_loss: 0.205032050521\tfold:1\n",
      "label:2\tlog_loss: 0.211113717831\tfold:2\n",
      "label:2\tlog_loss: 0.221399331508\tfold:3\n",
      "label:2\tlog_loss: 0.201093951353\tfold:4\n",
      "label:2\tlog_loss: 0.229471282665\tfold:5\n",
      "label:2\tlog_loss: 0.207587482725\tfold:6\n",
      "label:2\tlog_loss: 0.215556345781\tfold:7\n",
      "label:2\tlog_loss: 0.221223705717\tfold:8\n",
      "label:2\tlog_loss: 0.219412965314\tfold:9\n",
      "label:2\tlog_loss: 0.203328123977\tfold:10\n"
     ]
    }
   ],
   "source": [
    "(tmp,\n",
    " test_mean,\n",
    " test_gmean)= Multi_Class_FM(train_X_trans,train_y,test_X_trans, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low0</th>\n",
       "      <th>low1</th>\n",
       "      <th>med0</th>\n",
       "      <th>med1</th>\n",
       "      <th>high0</th>\n",
       "      <th>high1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.475411</td>\n",
       "      <td>0.524589</td>\n",
       "      <td>0.530110</td>\n",
       "      <td>0.469889</td>\n",
       "      <td>0.850573</td>\n",
       "      <td>0.149427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.689422</td>\n",
       "      <td>0.310578</td>\n",
       "      <td>0.493679</td>\n",
       "      <td>0.506321</td>\n",
       "      <td>0.875653</td>\n",
       "      <td>0.124347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.213016</td>\n",
       "      <td>0.786984</td>\n",
       "      <td>0.787976</td>\n",
       "      <td>0.212024</td>\n",
       "      <td>0.973409</td>\n",
       "      <td>0.026591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.593406</td>\n",
       "      <td>0.406594</td>\n",
       "      <td>0.768885</td>\n",
       "      <td>0.231115</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>0.020228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065210</td>\n",
       "      <td>0.934790</td>\n",
       "      <td>0.889295</td>\n",
       "      <td>0.110705</td>\n",
       "      <td>0.980686</td>\n",
       "      <td>0.019314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.626392</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>0.539808</td>\n",
       "      <td>0.460192</td>\n",
       "      <td>0.895199</td>\n",
       "      <td>0.104801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.420211</td>\n",
       "      <td>0.579789</td>\n",
       "      <td>0.707093</td>\n",
       "      <td>0.292907</td>\n",
       "      <td>0.921662</td>\n",
       "      <td>0.078338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.551261</td>\n",
       "      <td>0.448739</td>\n",
       "      <td>0.575914</td>\n",
       "      <td>0.424086</td>\n",
       "      <td>0.925037</td>\n",
       "      <td>0.074963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.484554</td>\n",
       "      <td>0.515446</td>\n",
       "      <td>0.613156</td>\n",
       "      <td>0.386844</td>\n",
       "      <td>0.856716</td>\n",
       "      <td>0.143284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.091716</td>\n",
       "      <td>0.908284</td>\n",
       "      <td>0.721913</td>\n",
       "      <td>0.278087</td>\n",
       "      <td>0.989420</td>\n",
       "      <td>0.010580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       low0      low1      med0      med1     high0     high1\n",
       "0  0.475411  0.524589  0.530110  0.469889  0.850573  0.149427\n",
       "1  0.689422  0.310578  0.493679  0.506321  0.875653  0.124347\n",
       "2  0.213016  0.786984  0.787976  0.212024  0.973409  0.026591\n",
       "3  0.593406  0.406594  0.768885  0.231115  0.979773  0.020228\n",
       "4  0.065210  0.934790  0.889295  0.110705  0.980686  0.019314\n",
       "5  0.626392  0.373608  0.539808  0.460192  0.895199  0.104801\n",
       "6  0.420211  0.579789  0.707093  0.292907  0.921662  0.078338\n",
       "7  0.551261  0.448739  0.575914  0.424086  0.925037  0.074963\n",
       "8  0.484554  0.515446  0.613156  0.386844  0.856716  0.143284\n",
       "9  0.091716  0.908284  0.721913  0.278087  0.989420  0.010580"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data = pd.DataFrame(tmp, columns = ['low0','low1','med0','med1','high0','high1'])\n",
    "tmp_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low0</th>\n",
       "      <th>low1</th>\n",
       "      <th>med0</th>\n",
       "      <th>med1</th>\n",
       "      <th>high0</th>\n",
       "      <th>high1</th>\n",
       "      <th>sum1</th>\n",
       "      <th>low1_1</th>\n",
       "      <th>med1_1</th>\n",
       "      <th>high1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.475411</td>\n",
       "      <td>0.524589</td>\n",
       "      <td>0.530110</td>\n",
       "      <td>0.469889</td>\n",
       "      <td>0.850573</td>\n",
       "      <td>0.149427</td>\n",
       "      <td>1.143906</td>\n",
       "      <td>0.458595</td>\n",
       "      <td>0.410776</td>\n",
       "      <td>0.130629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.689422</td>\n",
       "      <td>0.310578</td>\n",
       "      <td>0.493679</td>\n",
       "      <td>0.506321</td>\n",
       "      <td>0.875653</td>\n",
       "      <td>0.124347</td>\n",
       "      <td>0.941245</td>\n",
       "      <td>0.329965</td>\n",
       "      <td>0.537926</td>\n",
       "      <td>0.132109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.213016</td>\n",
       "      <td>0.786984</td>\n",
       "      <td>0.787976</td>\n",
       "      <td>0.212024</td>\n",
       "      <td>0.973409</td>\n",
       "      <td>0.026591</td>\n",
       "      <td>1.025599</td>\n",
       "      <td>0.767341</td>\n",
       "      <td>0.206732</td>\n",
       "      <td>0.025927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.593406</td>\n",
       "      <td>0.406594</td>\n",
       "      <td>0.768885</td>\n",
       "      <td>0.231115</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>0.657937</td>\n",
       "      <td>0.617983</td>\n",
       "      <td>0.351273</td>\n",
       "      <td>0.030744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065210</td>\n",
       "      <td>0.934790</td>\n",
       "      <td>0.889295</td>\n",
       "      <td>0.110705</td>\n",
       "      <td>0.980686</td>\n",
       "      <td>0.019314</td>\n",
       "      <td>1.064810</td>\n",
       "      <td>0.877894</td>\n",
       "      <td>0.103967</td>\n",
       "      <td>0.018139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       low0      low1      med0      med1     high0     high1      sum1  \\\n",
       "0  0.475411  0.524589  0.530110  0.469889  0.850573  0.149427  1.143906   \n",
       "1  0.689422  0.310578  0.493679  0.506321  0.875653  0.124347  0.941245   \n",
       "2  0.213016  0.786984  0.787976  0.212024  0.973409  0.026591  1.025599   \n",
       "3  0.593406  0.406594  0.768885  0.231115  0.979773  0.020228  0.657937   \n",
       "4  0.065210  0.934790  0.889295  0.110705  0.980686  0.019314  1.064810   \n",
       "\n",
       "     low1_1    med1_1   high1_1  \n",
       "0  0.458595  0.410776  0.130629  \n",
       "1  0.329965  0.537926  0.132109  \n",
       "2  0.767341  0.206732  0.025927  \n",
       "3  0.617983  0.351273  0.030744  \n",
       "4  0.877894  0.103967  0.018139  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data['sum1'] = tmp_data['low1'] + tmp_data['med1']+ tmp_data['high1']\n",
    "tmp_data['low1_1'] = tmp_data['low1'] / tmp_data['sum1']\n",
    "tmp_data['med1_1'] = tmp_data['med1'] / tmp_data['sum1']\n",
    "tmp_data['high1_1'] = tmp_data['high1'] / tmp_data['sum1']\n",
    "tmp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62095057924051367"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_y,tmp_data[['low1_1','med1_1','high1_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 6)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gmean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_mean_sub = pd.DataFrame(test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 3)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_test_mean = test_mean_sub[[1,3,5]]\n",
    "sub_test_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "sub_name = '../../output/sub_FM_mean_BM_MB_add_desc_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = sub_test_mean\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(tmp, columns = ['low0','low1','med0','med1','high0','high1'])\n",
    "train_data['sum1'] = train_data['low1'] + train_data['med1']+ train_data['high1']\n",
    "train_data['low1_1'] = train_data['low1'] / train_data['sum1']\n",
    "train_data['med1_1'] = train_data['med1'] / train_data['sum1']\n",
    "train_data['high1_1'] = train_data['high1'] / train_data['sum1']\n",
    "train_blend = np.array(train_data[['low1_1','med1_1','high1_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_mean_data = pd.DataFrame(test_mean, columns = ['low0','low1','med0','med1','high0','high1'])\n",
    "test_mean_data['sum1'] = test_mean_data['low1'] + test_mean_data['med1']+ test_mean_data['high1']\n",
    "test_mean_data['low1_1'] = test_mean_data['low1'] / test_mean_data['sum1']\n",
    "test_mean_data['med1_1'] = test_mean_data['med1'] / test_mean_data['sum1']\n",
    "test_mean_data['high1_1'] = test_mean_data['high1'] / test_mean_data['sum1']\n",
    "test_mean_blend = np.array(test_mean_data[['low1_1','med1_1','high1_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_gmean_data = pd.DataFrame(test_gmean, columns = ['low0','low1','med0','med1','high0','high1'])\n",
    "test_gmean_data['sum1'] = test_gmean_data['low1'] + test_gmean_data['med1']+ test_gmean_data['high1']\n",
    "test_gmean_data['low1_1'] = test_gmean_data['low1'] / test_gmean_data['sum1']\n",
    "test_gmean_data['med1_1'] = test_gmean_data['med1'] / test_gmean_data['sum1']\n",
    "test_gmean_data['high1_1'] = test_gmean_data['high1'] / test_gmean_data['sum1']\n",
    "test_gmean_blend = np.array(test_gmean_data[['low1_1','med1_1','high1_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 3)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gmean_blend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_train_blend = '../../output/train_blend_FM_BM_MB_add_desc_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../../output/test_blend_FM_mean_BM_MB_add_desc_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../../output/test_blend_FM_gmean_BM_MB_add_desc_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "# print (np.mean(blend_scores_xgb,axis=0))\n",
    "# print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_mean_blend, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_gmean_blend, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.386762</td>\n",
       "      <td>0.378102</td>\n",
       "      <td>0.169965</td>\n",
       "      <td>7142618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.977577</td>\n",
       "      <td>0.044951</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>7210040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.970149</td>\n",
       "      <td>0.075394</td>\n",
       "      <td>0.031292</td>\n",
       "      <td>7174566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716298</td>\n",
       "      <td>0.247062</td>\n",
       "      <td>0.064973</td>\n",
       "      <td>7191391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.628346</td>\n",
       "      <td>0.345032</td>\n",
       "      <td>0.052520</td>\n",
       "      <td>7171695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        low    medium      high  listing_id\n",
       "0  0.386762  0.378102  0.169965     7142618\n",
       "1  0.977577  0.044951  0.010625     7210040\n",
       "2  0.970149  0.075394  0.031292     7174566\n",
       "3  0.716298  0.247062  0.064973     7191391\n",
       "4  0.628346  0.345032  0.052520     7171695"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low0</th>\n",
       "      <th>low1</th>\n",
       "      <th>med0</th>\n",
       "      <th>med1</th>\n",
       "      <th>high0</th>\n",
       "      <th>high1</th>\n",
       "      <th>sum1</th>\n",
       "      <th>low1_1</th>\n",
       "      <th>med1_1</th>\n",
       "      <th>high1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613034</td>\n",
       "      <td>0.386446</td>\n",
       "      <td>0.621443</td>\n",
       "      <td>0.377402</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.169162</td>\n",
       "      <td>0.933010</td>\n",
       "      <td>0.414192</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.181308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022209</td>\n",
       "      <td>0.977572</td>\n",
       "      <td>0.955045</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>0.989374</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>1.033031</td>\n",
       "      <td>0.946315</td>\n",
       "      <td>0.043438</td>\n",
       "      <td>0.010247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029633</td>\n",
       "      <td>0.970142</td>\n",
       "      <td>0.924576</td>\n",
       "      <td>0.075024</td>\n",
       "      <td>0.968706</td>\n",
       "      <td>0.031229</td>\n",
       "      <td>1.076395</td>\n",
       "      <td>0.901288</td>\n",
       "      <td>0.069699</td>\n",
       "      <td>0.029012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.283653</td>\n",
       "      <td>0.716278</td>\n",
       "      <td>0.752922</td>\n",
       "      <td>0.247014</td>\n",
       "      <td>0.935022</td>\n",
       "      <td>0.064908</td>\n",
       "      <td>1.028200</td>\n",
       "      <td>0.696633</td>\n",
       "      <td>0.240240</td>\n",
       "      <td>0.063128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.371513</td>\n",
       "      <td>0.628260</td>\n",
       "      <td>0.654775</td>\n",
       "      <td>0.344658</td>\n",
       "      <td>0.947474</td>\n",
       "      <td>0.052426</td>\n",
       "      <td>1.025344</td>\n",
       "      <td>0.612731</td>\n",
       "      <td>0.336139</td>\n",
       "      <td>0.051130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       low0      low1      med0      med1     high0     high1      sum1  \\\n",
       "0  0.613034  0.386446  0.621443  0.377402  0.829876  0.169162  0.933010   \n",
       "1  0.022209  0.977572  0.955045  0.044873  0.989374  0.010585  1.033031   \n",
       "2  0.029633  0.970142  0.924576  0.075024  0.968706  0.031229  1.076395   \n",
       "3  0.283653  0.716278  0.752922  0.247014  0.935022  0.064908  1.028200   \n",
       "4  0.371513  0.628260  0.654775  0.344658  0.947474  0.052426  1.025344   \n",
       "\n",
       "     low1_1    med1_1   high1_1  \n",
       "0  0.414192  0.404500  0.181308  \n",
       "1  0.946315  0.043438  0.010247  \n",
       "2  0.901288  0.069699  0.029012  \n",
       "3  0.696633  0.240240  0.063128  \n",
       "4  0.612731  0.336139  0.051130  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gmean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41419245,  0.4044996 ,  0.18130795],\n",
       "       [ 0.94631494,  0.04343844,  0.01024663],\n",
       "       [ 0.90128841,  0.06969916,  0.02901243],\n",
       "       ..., \n",
       "       [ 0.89696797,  0.06031721,  0.04271482],\n",
       "       [ 0.94487662,  0.0479009 ,  0.00722248],\n",
       "       [ 0.53974265,  0.40173102,  0.05852633]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gmean_blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.900926325760214"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.970149/1.076835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 522)\n",
      "(9871, 522)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X_trans, y_low, train_size=.80, random_state=2451234)\n",
    "print (X_train.shape)\n",
    "print (X_val.shape)\n",
    "# xgtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low 300\n",
    "# med 500\n",
    "# high 650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:01<00:00,  1.24epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=150] log_loss: 0.238953546445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:40<00:00,  1.25epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=200] log_loss: 0.226145637034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:21<00:00,  1.24epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=250] log_loss: 0.219946944642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:47<00:00,  1.39epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=300] log_loss: 0.216544215726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [04:37<00:00,  1.24epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=350] log_loss: 0.21453853663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tffm import TFFMClassifier\n",
    "\n",
    "for n_epochs in [150,200,250,300,350]:\n",
    "    model = TFFMClassifier(\n",
    "        order=2, \n",
    "        rank=10, \n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=3e-3,epsilon = 1), \n",
    "        n_epochs=n_epochs, \n",
    "        batch_size=1024,\n",
    "        init_std=0.001,\n",
    "        reg=0.1,\n",
    "        input_type='dense',\n",
    "        seed=42\n",
    "    )\n",
    "    model.fit(X_train, y_train, show_progress=True)\n",
    "    predictions = model.predict_proba(X_val)\n",
    "    print('[n_epochs={}] log_loss: {}'.format(n_epochs, log_loss(y_val, predictions)))\n",
    "    # this will close tf.Session and free resources\n",
    "    model.destroy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [05:49<00:00,  1.14epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=400] log_loss: 0.213159294894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [06:29<00:00,  1.34epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=450] log_loss: 0.212318720357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tffm import TFFMClassifier\n",
    "\n",
    "for n_epochs in [400,450]:\n",
    "    model = TFFMClassifier(\n",
    "        order=2, \n",
    "        rank=10, \n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=3e-3,epsilon = 1), \n",
    "        n_epochs=n_epochs, \n",
    "        batch_size=1024,\n",
    "        init_std=0.001,\n",
    "        reg=0.1,\n",
    "        input_type='dense',\n",
    "        seed=42\n",
    "    )\n",
    "    model.fit(X_train, y_train, show_progress=True)\n",
    "    predictions = model.predict_proba(X_val)\n",
    "    print('[n_epochs={}] log_loss: {}'.format(n_epochs, log_loss(y_val, predictions)))\n",
    "    # this will close tf.Session and free resources\n",
    "    model.destroy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [06:13<00:00,  1.33epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=500] log_loss: 0.211527009557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [06:49<00:00,  1.34epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=550] log_loss: 0.211340100337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:26<00:00,  1.34epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=600] log_loss: 0.211545995756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 650/650 [08:04<00:00,  1.35epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=650] log_loss: 0.211279009451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for n_epochs in [500,550,600,650]:\n",
    "    model = TFFMClassifier(\n",
    "        order=2, \n",
    "        rank=10, \n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=3e-3,epsilon = 1), \n",
    "        n_epochs=n_epochs, \n",
    "        batch_size=1024,\n",
    "        init_std=0.001,\n",
    "        reg=0.1,\n",
    "        input_type='dense',\n",
    "        seed=42\n",
    "    )\n",
    "    model.fit(X_train, y_train, show_progress=True)\n",
    "    predictions = model.predict_proba(X_val)\n",
    "    print('[n_epochs={}] log_loss: {}'.format(n_epochs, log_loss(y_val, predictions)))\n",
    "    # this will close tf.Session and free resources\n",
    "    model.destroy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [09:01<00:00,  1.32epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=700] log_loss: 0.211723860883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [09:37<00:00,  1.33epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_epochs=750] log_loss: 0.21151920601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for n_epochs in [700,750]:\n",
    "    model = TFFMClassifier(\n",
    "        order=2, \n",
    "        rank=10, \n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=3e-3,epsilon = 1), \n",
    "        n_epochs=n_epochs, \n",
    "        batch_size=1024,\n",
    "        init_std=0.001,\n",
    "        reg=0.1,\n",
    "        input_type='dense',\n",
    "        seed=42\n",
    "    )\n",
    "    model.fit(X_train, y_train, show_progress=True)\n",
    "    predictions = model.predict_proba(X_val)\n",
    "    print('[n_epochs={}] log_loss: {}'.format(n_epochs, log_loss(y_val, predictions)))\n",
    "    # this will close tf.Session and free resources\n",
    "    model.destroy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reg=1.000]\t log_loss: 0.323255033825\tfold:1\n",
      "[reg=1.000]\t log_loss: 0.293114717140\tfold:2\n",
      "[reg=1.000]\t log_loss: 0.276313674261\tfold:3\n",
      "[reg=1.000]\t log_loss: 0.295404785321\tfold:4\n",
      "[reg=1.000]\t log_loss: 0.333144691132\tfold:5\n",
      "reg:1.000\t score:0.304\n"
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "skf = KFold(n_splits=fold,random_state=seed)\n",
    "\n",
    "for reg in [1]:\n",
    "    scores = np.zeros ((fold))\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(train_X_trans)):\n",
    "#         print ('reg:{0:.3f}\\t fold:{1}'.format(reg, i+1))\n",
    "        train_x_fold = train_X_trans[train_index]\n",
    "        train_y_fold = y_h[train_index]\n",
    "        val_x_fold = train_X_trans[val_index]\n",
    "        val_y_fold = y_h[val_index]  \n",
    "\n",
    "\n",
    "        model = TFFMClassifier(\n",
    "            order=2, \n",
    "            rank=10, \n",
    "            optimizer=tf.train.AdamOptimizer(learning_rate=3e-3,epsilon = 1), \n",
    "            n_epochs=100, \n",
    "            batch_size=1024,\n",
    "            init_std=0.001,\n",
    "            reg= 0.01,\n",
    "            input_type='dense',\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        print \n",
    "        model.fit(train_x_fold, train_y_fold, show_progress=False)\n",
    "        predictions = model.predict_proba(val_x_fold)\n",
    "        scores[i] = log_loss(val_y_fold, predictions)\n",
    "        print('[reg={0:.3f}]\\t log_loss: {1:.12f}\\tfold:{2}'.format(reg, scores[i],i+1))\n",
    "        # this will close tf.Session and free resources\n",
    "        model.destroy()     \n",
    "\n",
    "    print ('reg:{0:.3f}\\t score:{1:.3f}'.format(reg, np.mean(scores)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 39479, 39480, 39481])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
