{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import sparse\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "seed = 1234\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 287) (74659, 287) (49352L,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_BrandenMurray_MedianBedroom.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_BrandenMurray_MedianBedroom.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ET_cv(max_features = 0.5, n_estimators=300, min_samples_leaf  =1):\n",
    "    scores=[]\n",
    "    est=ExtraTreesClassifier(max_features=max_features,\n",
    "                             n_estimators=int(n_estimators),\n",
    "                             min_samples_leaf =int(min_samples_leaf), \n",
    "                             criterion = 'entropy',\n",
    "                             random_state=seed,\n",
    "                             n_jobs = -1\n",
    "                            )\n",
    "    est.fit(X_train, y_train)\n",
    "    y_val_pred = est.predict_proba(X_val)\n",
    "    return -1*log_loss(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 \t-0.603937657957\n",
      "0.4 \t-0.622711911023\n",
      "0.5 \t-0.609805158959\n",
      "0.6 \t-0.620139916576\n",
      "0.7 \t-0.608383714823\n",
      "0.8 \t-0.617317898006\n",
      "0.9 \t-0.612761189877\n",
      "1 \t-0.658023328662\n"
     ]
    }
   ],
   "source": [
    "cv_score = -1\n",
    "for x in [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score = ET_cv(max_features = x)\n",
    "    if score > cv_score:\n",
    "        max_features = x\n",
    "        cv_score = score\n",
    "    print x,'\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 \t-0.638429411457\n",
      "0.2 \t-0.623223152226\n",
      "auto \t-0.631299802673\n",
      "log2 \t-0.650444374764\n"
     ]
    }
   ],
   "source": [
    "for x in [0.1,0.2,'auto','log2']:\n",
    "    score = ET_cv(max_features = x)\n",
    "    if score > cv_score:\n",
    "        max_features = x\n",
    "        cv_score = score\n",
    "    print x,'\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "print max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t-0.603937657957\n",
      "2 \t-0.576007779722\n",
      "4 \t-0.572413065549\n",
      "8 \t-0.576798293478\n",
      "16 \t-0.587354675884\n",
      "32 \t-0.599323294189\n",
      "64 \t-0.611293128098\n",
      "128 \t-0.625450065185\n"
     ]
    }
   ],
   "source": [
    "for x in [1,2,4,8,16,32,64,128]:\n",
    "    score = ET_cv(max_features = max_features,min_samples_leaf = x)\n",
    "    if score > cv_score:\n",
    "        min_samples_leaf = x\n",
    "        cv_score = score    \n",
    "    print x, '\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t-0.572104066681\n",
      "5 \t-0.571667766452\n",
      "6 \t-0.573685250577\n",
      "7 \t-0.57509504389\n",
      "9 \t-0.578505105907\n",
      "10 \t-0.580123730665\n",
      "11 \t-0.581393499063\n",
      "12 \t-0.582830807356\n"
     ]
    }
   ],
   "source": [
    "for x in [3,5,6,7,9,10,11,12]:\n",
    "    score = ET_cv(max_features = max_features,min_samples_leaf = x)\n",
    "    if score > cv_score:\n",
    "        min_samples_leaf = x\n",
    "        cv_score = score    \n",
    "    print x, '\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ET_blend(est, train_x, train_y, test_x, fold):\n",
    "    N_params = len(est)\n",
    "    print \"Blend %d estimators for %d folds\" % (N_params, fold)\n",
    "    skf = KFold(n_splits=fold,random_state=seed)\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros((fold,N_params))\n",
    "    best_rounds = np.zeros((fold, N_params))    \n",
    "    \n",
    "    for j, ester in enumerate(est):\n",
    "        print \"Model %d:\" %(j+1)\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "\n",
    "            \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print \"Model %d fold %d\" %(j+1,i+1)\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]            \n",
    "            \n",
    "\n",
    "            ester.fit(train_x_fold,train_y_fold)\n",
    "            \n",
    "            val_y_predict_fold = ester.predict_proba(val_x_fold)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print \"Score: \", score\n",
    "            scores[i,j]=score            \n",
    "            \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = ester.predict_proba(test_x)\n",
    "            \n",
    "            print \"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start)            \n",
    "\n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print \"Score for model %d is %f\" % (j+1,np.mean(scores[:,j]))\n",
    "    print \"Score for blended models is %f\" % (np.mean(scores))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 10 folds\n",
      "Model 1:\n",
      "Model 1 fold 1\n",
      "('Score: ', 0.55170774316627136)\n",
      "Model 1 fold 1 fitting finished in 167.387s\n",
      "Model 1 fold 2\n",
      "('Score: ', 0.54149776180905385)\n",
      "Model 1 fold 2 fitting finished in 173.202s\n",
      "Model 1 fold 3\n",
      "('Score: ', 0.56723251072059366)\n",
      "Model 1 fold 3 fitting finished in 172.735s\n",
      "Model 1 fold 4\n",
      "('Score: ', 0.54895035176984375)\n",
      "Model 1 fold 4 fitting finished in 170.088s\n",
      "Model 1 fold 5\n",
      "('Score: ', 0.57535589214003824)\n",
      "Model 1 fold 5 fitting finished in 172.863s\n",
      "Model 1 fold 6\n",
      "('Score: ', 0.56204278905622762)\n",
      "Model 1 fold 6 fitting finished in 164.422s\n",
      "Model 1 fold 7\n",
      "('Score: ', 0.57410113258596085)\n",
      "Model 1 fold 7 fitting finished in 163.573s\n",
      "Model 1 fold 8\n",
      "('Score: ', 0.58483274022333875)\n",
      "Model 1 fold 8 fitting finished in 162.785s\n",
      "Model 1 fold 9\n",
      "('Score: ', 0.58288353973543916)\n",
      "Model 1 fold 9 fitting finished in 159.840s\n",
      "Model 1 fold 10\n",
      "('Score: ', 0.56708969088917782)\n",
      "Model 1 fold 10 fitting finished in 165.490s\n",
      "Score for model 1 is 0.565569\n",
      "Score for blended models is 0.565569\n"
     ]
    }
   ],
   "source": [
    "est = [ExtraTreesClassifier(max_features=max_features,\n",
    "                            n_estimators=1000,\n",
    "                            min_samples_leaf = min_samples_leaf,\n",
    "                            random_state=seed,\n",
    "                            criterion = 'entropy',\n",
    "                            n_jobs = -1\n",
    "                           )]\n",
    "\n",
    "(train_blend_x_RFC,\n",
    " test_blend_x_RFC_mean,\n",
    " test_blend_x_RFC_gmean,\n",
    " blend_scores_RFC,\n",
    " best_rounds_RFC) = ET_blend(est,\n",
    "                             train_X,train_y,\n",
    "                             test_X,\n",
    "                             10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.46850370e-01,   3.78710881e-01,   7.44387485e-02],\n",
       "       [  9.93331851e-01,   6.53604642e-03,   1.32102677e-04],\n",
       "       [  9.68425959e-01,   2.73195356e-02,   4.25450540e-03],\n",
       "       ..., \n",
       "       [  9.46063717e-01,   4.39288465e-02,   1.00074361e-02],\n",
       "       [  9.61860896e-01,   3.76029055e-02,   5.36198801e-04],\n",
       "       [  4.98460605e-01,   4.25297371e-01,   7.62420243e-02]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_RFC_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54661768,  0.37837382,  0.07414224],\n",
       "       [ 0.99333094,  0.00640681,  0.        ],\n",
       "       [ 0.96841079,  0.02692635,  0.0041188 ],\n",
       "       ..., \n",
       "       [ 0.9460548 ,  0.04385678,  0.00970935],\n",
       "       [ 0.961815  ,  0.03632114,  0.        ],\n",
       "       [ 0.49788434,  0.42486431,  0.07448173]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_RFC_gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56556942]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_ET_entropy_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_ET_entropy_mean_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../blend/test_blend_ET_entropy_gmean_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_RFC,axis=0))\n",
    "# print (np.mean(best_rounds_RFC,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_RFC, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_RFC_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_RFC_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ET_cv(max_features = 0.5, n_estimators=300, min_samples_leaf  =1):\n",
    "    scores=[]\n",
    "    est=ExtraTreesClassifier(max_features=max_features,\n",
    "                             n_estimators=int(n_estimators),\n",
    "                             min_samples_leaf =int(min_samples_leaf), \n",
    "                             criterion = 'gini',\n",
    "                             random_state=seed,\n",
    "                             n_jobs = -1\n",
    "                            )\n",
    "    est.fit(X_train, y_train)\n",
    "    y_val_pred = est.predict_proba(X_val)\n",
    "    return -1*log_loss(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 \t-0.629294760249\n",
      "0.2 \t-0.631772985001\n",
      "0.3 \t-0.628260934991\n",
      "0.4 \t-0.615957812746\n",
      "0.5 \t-0.614557935106\n",
      "0.6 \t-0.61590186524\n",
      "0.7 \t-0.629413614269\n",
      "0.8 \t-0.625482701518\n",
      "0.9 \t-0.617293433006\n",
      "auto \t-0.646283785577\n",
      "log2 \t-0.644216588865\n"
     ]
    }
   ],
   "source": [
    "cv_score = -1\n",
    "for x in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,'auto','log2']:\n",
    "    score = ET_cv(max_features = x)\n",
    "    if score > cv_score:\n",
    "        max_features = x\n",
    "        cv_score = score\n",
    "    print x,'\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t-0.614557935106\n",
      "2 \t-0.578045843514\n",
      "4 \t-0.572260661543\n",
      "8 \t-0.573923608629\n",
      "12 \t-0.578935544627\n",
      "16 \t-0.582588098236\n",
      "20 \t-0.585643672577\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6ace0a20c16c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mET_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcv_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmin_samples_leaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcv_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-cce4467b7f37>\u001b[0m in \u001b[0;36mET_cv\u001b[0;34m(max_features, n_estimators, min_samples_leaf)\u001b[0m\n\u001b[1;32m      8\u001b[0m                              \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                             )\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_val_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in [1,2,4,8,12,16,20,24]:\n",
    "    score = ET_cv(max_features = max_features,min_samples_leaf = x)\n",
    "    if score > cv_score:\n",
    "        min_samples_leaf = x\n",
    "        cv_score = score    \n",
    "    print x, '\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t-0.573015767467\n",
      "5 \t-0.56995350617\n",
      "6 \t-0.57049588564\n",
      "7 \t-0.571851081208\n"
     ]
    }
   ],
   "source": [
    "for x in [3,5,6,7]:\n",
    "    score = ET_cv(max_features = max_features,min_samples_leaf = x)\n",
    "    if score > cv_score:\n",
    "        min_samples_leaf = x\n",
    "        cv_score = score    \n",
    "    print x, '\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 10 folds\n",
      "Model 1:\n",
      "Model 1 fold 1\n",
      "Score:  0.554186618271\n",
      "Model 1 fold 1 fitting finished in 287.781s\n",
      "Model 1 fold 2\n",
      "Score:  0.539666939708\n",
      "Model 1 fold 2 fitting finished in 310.746s\n",
      "Model 1 fold 3\n",
      "Score:  0.564736300085\n",
      "Model 1 fold 3 fitting finished in 308.157s\n",
      "Model 1 fold 4\n",
      "Score:  0.546048003999\n",
      "Model 1 fold 4 fitting finished in 318.666s\n",
      "Model 1 fold 5\n",
      "Score:  0.572164065849\n",
      "Model 1 fold 5 fitting finished in 325.941s\n",
      "Model 1 fold 6\n",
      "Score:  0.560933121861\n",
      "Model 1 fold 6 fitting finished in 323.094s\n",
      "Model 1 fold 7\n",
      "Score:  0.572334917682\n",
      "Model 1 fold 7 fitting finished in 335.343s\n",
      "Model 1 fold 8\n",
      "Score:  0.583351278786\n",
      "Model 1 fold 8 fitting finished in 341.519s\n",
      "Model 1 fold 9\n",
      "Score:  0.580610602016\n",
      "Model 1 fold 9 fitting finished in 330.280s\n",
      "Model 1 fold 10\n",
      "Score:  0.566026340134\n",
      "Model 1 fold 10 fitting finished in 337.290s\n",
      "Score for model 1 is 0.564006\n",
      "Score for blended models is 0.564006\n"
     ]
    }
   ],
   "source": [
    "est = [ExtraTreesClassifier(max_features=max_features,\n",
    "                              n_estimators=1000,\n",
    "                              min_samples_leaf = min_samples_leaf,\n",
    "                              random_state=seed,\n",
    "                              criterion = 'gini',\n",
    "                              n_jobs = 4\n",
    "                             )]\n",
    "\n",
    "(train_blend_x_RFC,\n",
    " test_blend_x_RFC_mean,\n",
    " test_blend_x_RFC_gmean,\n",
    " blend_scores_RFC,\n",
    " best_rounds_RFC) = ET_blend(est,\n",
    "                              train_X,train_y,\n",
    "                              test_X,\n",
    "                              10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56400582]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_ET_gini_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_ET_gini_mean_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../blend/test_blend_ET_gini_gmean_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_RFC,axis=0))\n",
    "# print (np.mean(best_rounds_RFC,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_RFC, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_RFC_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_RFC_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_ET_gini_gmean_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_blend_x_RFC_gmean[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
