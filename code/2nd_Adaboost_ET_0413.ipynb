{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from scipy import sparse\n",
    "from scipy.stats.mstats import gmean\n",
    "from datetime import datetime\n",
    "# from sklearn import preprocessing\n",
    "# from scipy.stats import skew, boxcox,boxcox_normmax\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = np.ravel(pd.read_csv('../input/' + 'labels_BrandenMurray.csv'))\n",
    "\n",
    "names = ['low_0','medium_0','high_0',\n",
    "        'low_1','medium_1','high_1',\n",
    "        'low_2','medium_2','high_2',\n",
    "        'low_3','medium_3','high_3',\n",
    "        'low_4','medium_4','high_4',\n",
    "        'low_5','medium_5','high_5',\n",
    "        'low_6','medium_6','high_6',\n",
    "        'low_7','medium_7','high_7',\n",
    "        'low_8','medium_8','high_8',\n",
    "        'low_9','medium_9','high_9']\n",
    "\n",
    "data_path = \"../2nd/\"\n",
    "total_col = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rfc_gini: (49352, 3)\t test_rfc_gini_mean:(74659, 3)\t test_rfc_gini_gmean:(74659, 3)\n",
      "\n",
      "train_rfc_entropy: (49352, 3)\t test_rfc_entropy_mean:(74659, 3)\t test_rfc_entropy_gmean:(74659, 3)\n",
      "\n",
      "train_rfc_gini\n",
      "   rfc_gini_low_0  rfc_gini_medium_0  rfc_gini_high_0\n",
      "0        0.543090           0.387824         0.069086\n",
      "1        0.431967           0.501843         0.066191\n",
      "2        0.796826           0.180090         0.023085\n",
      "3        0.671667           0.274519         0.053815\n",
      "4        0.931788           0.064494         0.003718\n",
      "\n",
      "train_rfc_entropy\n",
      "   rfc_entropy_low_0  rfc_entropy_medium_0  rfc_entropy_high_0\n",
      "0           0.542659              0.393322            0.064019\n",
      "1           0.464249              0.477816            0.057935\n",
      "2           0.799674              0.184329            0.015997\n",
      "3           0.686509              0.278618            0.034872\n",
      "4           0.966726              0.029282            0.003992\n"
     ]
    }
   ],
   "source": [
    "# RFC 1st level \n",
    "file_train      = 'train_blend_RFC_gini_BM_MB_add03052240_2017-03-10-22-02' + '.csv'\n",
    "file_test_mean  = 'test_blend_RFC_gini_mean_BM_MB_add03052240_2017-03-10-22-02' + '.csv'\n",
    "file_test_gmean = 'test_blend_RFC_gini_gmean_BM_MB_add03052240_2017-03-10-22-02' + '.csv'\n",
    "\n",
    "train_rfc_gini      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_rfc_gini_mean  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_rfc_gini_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_rfc_gini.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_rfc_gini.columns      = ['rfc_gini_' + x for x in names[:n_column]]\n",
    "test_rfc_gini_mean.columns  = ['rfc_gini_' + x for x in names[:n_column]]\n",
    "test_rfc_gini_gmean.columns = ['rfc_gini_' + x for x in names[:n_column]]\n",
    "\n",
    "file_train      = 'train_blend_RFC_entropy_BM_MB_add03052240_2017-03-10-21-10' + '.csv'\n",
    "file_test_mean  = 'test_blend_RFC_entropy_mean_BM_MB_add03052240_2017-03-10-21-10' + '.csv'\n",
    "file_test_gmean = 'test_blend_RFC_entropy_gmean_BM_MB_add03052240_2017-03-10-21-10' + '.csv'\n",
    "\n",
    "train_rfc_entropy      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_rfc_entropy_mean  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_rfc_entropy_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_rfc_entropy.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_rfc_entropy.columns      = ['rfc_entropy_' + x for x in names[:n_column]]\n",
    "test_rfc_entropy_mean.columns  = ['rfc_entropy_' + x for x in names[:n_column]]\n",
    "test_rfc_entropy_gmean.columns = ['rfc_entropy_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "\n",
    "print 'train_rfc_gini: {}\\t test_rfc_gini_mean:{}\\t test_rfc_gini_gmean:{}'.\\\n",
    "        format(train_rfc_gini.shape,test_rfc_gini_mean.shape,test_rfc_gini_gmean.shape)\n",
    "print '\\ntrain_rfc_entropy: {}\\t test_rfc_entropy_mean:{}\\t test_rfc_entropy_gmean:{}'.\\\n",
    "        format(train_rfc_entropy.shape,test_rfc_entropy_mean.shape,test_rfc_entropy_gmean.shape)\n",
    "\n",
    "    \n",
    "print '\\ntrain_rfc_gini'\n",
    "print train_rfc_gini.iloc[:5,:3]\n",
    "print '\\ntrain_rfc_entropy'\n",
    "print train_rfc_entropy.iloc[:5,:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_rfc_entropy: (49352, 3)\t test_rfc_entropy_mean:(74659, 3)\t test_rfc_entropy_gmean:(74659, 3)\n",
      "\n",
      "train_rfc_entropy: (49352, 3)\t test_rfc_entropy_mean:(74659, 3)\t test_rfc_entropy_gmean:(74659, 3)\n",
      "\n",
      "train_rfc_gini_0322\n",
      "   rfc_gini_0322_low_0  rfc_gini_0322_medium_0  rfc_gini_0322_high_0\n",
      "0             0.529595                0.404298              0.066107\n",
      "1             0.439197                0.489992              0.070812\n",
      "2             0.792970                0.189331              0.017699\n",
      "3             0.675457                0.276198              0.048345\n",
      "4             0.951710                0.043953              0.004337\n",
      "\n",
      "train_rfc_entropy_0322\n",
      "   rfc_entropy_0322_low_0  rfc_entropy_0322_medium_0  rfc_entropy_0322_high_0\n",
      "0                0.551613                   0.396561                 0.051826\n",
      "1                0.430922                   0.511564                 0.057514\n",
      "2                0.788894                   0.201162                 0.009943\n",
      "3                0.675501                   0.288606                 0.035893\n",
      "4                0.960180                   0.035223                 0.004597\n"
     ]
    }
   ],
   "source": [
    "# RFC 1st level 0322\n",
    "file_train      = 'train_blend_RFC_gini_BM_0322_2017-03-22-17-12' + '.csv'\n",
    "file_test_mean  = 'test_blend_RFC_gini_mean_BM_0322_2017-03-22-17-12' + '.csv'\n",
    "file_test_gmean = 'test_blend_RFC_gini_gmean_BM_0322_2017-03-22-17-12' + '.csv'\n",
    "\n",
    "train_rfc_gini_0322      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_rfc_gini_mean_0322  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_rfc_gini_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_rfc_gini_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_rfc_gini_0322.columns      = ['rfc_gini_0322_' + x for x in names[:n_column]]\n",
    "test_rfc_gini_mean_0322.columns  = ['rfc_gini_0322_' + x for x in names[:n_column]]\n",
    "test_rfc_gini_gmean_0322.columns = ['rfc_gini_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "file_train      = 'train_blend_RFC_entropy_BM_0322_2017-03-22-16-02' + '.csv'\n",
    "file_test_mean  = 'test_blend_RFC_entropy_mean_BM_0322_2017-03-22-16-02' + '.csv'\n",
    "file_test_gmean = 'test_blend_RFC_entropy_gmean_BM_0322_2017-03-22-16-02' + '.csv'\n",
    "\n",
    "train_rfc_entropy_0322      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_rfc_entropy_mean_0322  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_rfc_entropy_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_rfc_entropy_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_rfc_entropy_0322.columns      = ['rfc_entropy_0322_' + x for x in names[:n_column]]\n",
    "test_rfc_entropy_mean_0322.columns  = ['rfc_entropy_0322_' + x for x in names[:n_column]]\n",
    "test_rfc_entropy_gmean_0322.columns = ['rfc_entropy_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "print '\\ntrain_rfc_entropy: {}\\t test_rfc_entropy_mean:{}\\t test_rfc_entropy_gmean:{}'.\\\n",
    "        format(train_rfc_gini_0322.shape,test_rfc_gini_mean_0322.shape,test_rfc_gini_gmean_0322.shape)\n",
    "print '\\ntrain_rfc_entropy: {}\\t test_rfc_entropy_mean:{}\\t test_rfc_entropy_gmean:{}'.\\\n",
    "        format(train_rfc_entropy_0322.shape,test_rfc_entropy_mean_0322.shape,test_rfc_entropy_gmean_0322.shape)\n",
    "    \n",
    "    \n",
    "print '\\ntrain_rfc_gini_0322'\n",
    "print train_rfc_gini_0322.iloc[:5,:3]\n",
    "print '\\ntrain_rfc_entropy_0322'\n",
    "print train_rfc_entropy_0322.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_LR: (49352, 21)\t test_LR_mean:(74659, 21)\t test_LR_gmean:(74659, 21)\n",
      "\n",
      "train_LR\n",
      "   LR_low_0  LR_medium_0  LR_high_0\n",
      "0  0.422874     0.486259   0.090867\n",
      "1  0.321009     0.599539   0.079452\n",
      "2  0.655066     0.315023   0.029912\n",
      "3  0.711200     0.252680   0.036120\n",
      "4  0.902499     0.090717   0.006784\n"
     ]
    }
   ],
   "source": [
    "# LR 1st level\n",
    "file_train = 'train_blend_LR_BM_2017-03-09-02-38' + '.csv'\n",
    "file_test_mean = 'test_blend_LR_mean_BM_2017-03-09-02-38' + '.csv'\n",
    "file_test_gmean = 'test_blend_LR_gmean_BM_2017-03-09-02-38' + '.csv'\n",
    "\n",
    "train_LR      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_LR_mean  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_LR_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_LR.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_LR.columns      = ['LR_' + x for x in names[:n_column]]\n",
    "test_LR_mean.columns  = ['LR_' + x for x in names[:n_column]]\n",
    "test_LR_gmean.columns = ['LR_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_LR: {}\\t test_LR_mean:{}\\t test_LR_gmean:{}'.\\\n",
    "        format(train_LR.shape,test_LR_mean.shape,test_LR_gmean.shape)\n",
    "\n",
    "print '\\ntrain_LR'\n",
    "print train_LR.iloc[:5,:3]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_LR_0322: (49352, 21)\t test_LR_mean_0322:(74659, 21)\t test_LR_gmean_0322:(74659, 21)\n",
      "\n",
      "train_LR_0322\n",
      "   LR_0322_low_0  LR_0322_medium_0  LR_0322_high_0\n",
      "0       0.406942          0.518465        0.074592\n",
      "1       0.333177          0.579416        0.087407\n",
      "2       0.636033          0.314385        0.049582\n",
      "3       0.647588          0.313159        0.039253\n",
      "4       0.899655          0.093021        0.007324\n"
     ]
    }
   ],
   "source": [
    "# LR 1st level 0322\n",
    "file_train = 'train_blend_LR_BM_0322_2017-03-22-23-38' + '.csv'\n",
    "file_test_mean = 'test_blend_LR_mean_BM_0322_2017-03-22-23-38' + '.csv'\n",
    "file_test_gmean = 'test_blend_LR_gmean_BM_0322_2017-03-22-23-38' + '.csv'\n",
    "\n",
    "train_LR_0322      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_LR_mean_0322  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_LR_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_LR_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_LR_0322.columns      = ['LR_0322_' + x for x in names[:n_column]]\n",
    "test_LR_mean_0322.columns  = ['LR_0322_' + x for x in names[:n_column]]\n",
    "test_LR_gmean_0322.columns = ['LR_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_LR_0322: {}\\t test_LR_mean_0322:{}\\t test_LR_gmean_0322:{}'.\\\n",
    "        format(train_LR_0322.shape,test_LR_mean_0322.shape,test_LR_gmean_0322.shape)\n",
    "\n",
    "print '\\ntrain_LR_0322'\n",
    "print train_LR_0322.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ET_gini: (49352, 3)\t test_ET_gini_mean:(74659, 3)\t test_ET_gini_gmean:(74659, 3)\n",
      "\n",
      "train_ET_entropy: (49352, 3)\t test_ET_entropy_mean:(74659, 3)\t test_ET_entropy_gmean:(74659, 3)\n",
      "\n",
      "train_ET_gini\n",
      "   ET_gini_low_0  ET_gini_medium_0  ET_gini_high_0\n",
      "0       0.491197          0.458682        0.050121\n",
      "1       0.350925          0.570142        0.078934\n",
      "2       0.834381          0.154016        0.011603\n",
      "3       0.721964          0.239236        0.038800\n",
      "4       0.950719          0.042887        0.006394\n",
      "\n",
      "train_ET_entropy\n",
      "   ET_entropy_low_0  ET_entropy_medium_0  ET_entropy_high_0\n",
      "0          0.520529             0.431357           0.048114\n",
      "1          0.377125             0.551815           0.071060\n",
      "2          0.799234             0.188755           0.012011\n",
      "3          0.716421             0.248984           0.034595\n",
      "4          0.925534             0.066681           0.007785\n"
     ]
    }
   ],
   "source": [
    "# ET 1st level\n",
    "file_train      = 'train_blend_ET_gini_BM_2017-03-10-09-42' + '.csv'\n",
    "file_test_mean  = 'test_blend_ET_gini_mean_BM_2017-03-10-09-42' + '.csv'\n",
    "file_test_gmean = 'test_blend_ET_gini_gmean_BM_2017-03-10-09-42' + '.csv'\n",
    "\n",
    "train_ET_gini      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_ET_gini_mean  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_ET_gini_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_ET_gini.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_ET_gini.columns      = ['ET_gini_' + x for x in names[:n_column]]\n",
    "test_ET_gini_mean.columns  = ['ET_gini_' + x for x in names[:n_column]]\n",
    "test_ET_gini_gmean.columns = ['ET_gini_' + x for x in names[:n_column]]\n",
    "\n",
    "file_train      = 'train_blend_ET_entropy_BM_2017-03-09-20-44' + '.csv'\n",
    "file_test_mean  = 'test_blend_ET_entropy_mean_BM_2017-03-09-20-44' + '.csv'\n",
    "file_test_gmean = 'test_blend_ET_entropy_gmean_BM_2017-03-09-20-44' + '.csv'\n",
    "\n",
    "train_ET_entropy      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_ET_entropy_mean  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_ET_entropy_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_ET_entropy.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_ET_entropy.columns      = ['ET_entropy_' + x for x in names[:n_column]]\n",
    "test_ET_entropy_mean.columns  = ['ET_entropy_' + x for x in names[:n_column]]\n",
    "test_ET_entropy_gmean.columns = ['ET_entropy_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_ET_gini: {}\\t test_ET_gini_mean:{}\\t test_ET_gini_gmean:{}'.\\\n",
    "        format(train_ET_gini.shape,test_ET_gini_mean.shape,test_ET_gini_gmean.shape)\n",
    "print '\\ntrain_ET_entropy: {}\\t test_ET_entropy_mean:{}\\t test_ET_entropy_gmean:{}'.\\\n",
    "        format(train_ET_entropy.shape,test_ET_entropy_mean.shape,test_ET_entropy_gmean.shape)\n",
    "    \n",
    "    \n",
    "print '\\ntrain_ET_gini'\n",
    "print train_ET_gini.iloc[:5,:3]\n",
    "print '\\ntrain_ET_entropy'\n",
    "print train_ET_entropy.iloc[:5,:3]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ET_gini_0322: (49352, 3)\t test_ET_gini_mean_0322:(74659, 3)\t test_ET_gini_gmean_0322:(74659, 3)\n",
      "\n",
      "train_ET_entropy_0322: (49352, 3)\t test_ET_entropy_mean_0322:(74659, 3)\t test_ET_entropy_gmean_0322:(74659, 3)\n",
      "\n",
      "train_ET_gini_0322\n",
      "   ET_gini_0322_low_0  ET_gini_0322_medium_0  ET_gini_0322_high_0\n",
      "0            0.490512               0.448808             0.060680\n",
      "1            0.327548               0.587699             0.084753\n",
      "2            0.836561               0.149571             0.013868\n",
      "3            0.699839               0.255539             0.044622\n",
      "4            0.950047               0.044878             0.005074\n",
      "\n",
      "train_ET_entropy_0322\n",
      "   ET_entropy_0322_low_0  ET_entropy_0322_medium_0  ET_entropy_0322_high_0\n",
      "0               0.530947                  0.423271                0.045782\n",
      "1               0.342346                  0.574514                0.083140\n",
      "2               0.817611                  0.172923                0.009466\n",
      "3               0.709965                  0.264568                0.025467\n",
      "4               0.947331                  0.048021                0.004648\n"
     ]
    }
   ],
   "source": [
    "# ET 1st level 0322\n",
    "file_train      = 'train_blend_ET_gini_BM_0322_2017-03-23-16-04' + '.csv'\n",
    "file_test_mean  = 'test_blend_ET_gini_mean_BM_0322_2017-03-23-16-04' + '.csv'\n",
    "file_test_gmean = 'test_blend_ET_gini_gmean_BM_0322_2017-03-23-16-04' + '.csv'\n",
    "\n",
    "train_ET_gini_0322      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_ET_gini_mean_0322  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_ET_gini_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_ET_gini_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_ET_gini_0322.columns      = ['ET_gini_0322_' + x for x in names[:n_column]]\n",
    "test_ET_gini_mean_0322.columns  = ['ET_gini_0322_' + x for x in names[:n_column]]\n",
    "test_ET_gini_gmean_0322.columns = ['ET_gini_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "file_train      = 'train_blend_ET_entropy_BM_0322_2017-03-23-13-40' + '.csv'\n",
    "file_test_mean  = 'test_blend_ET_entropy_mean_BM_0322_2017-03-23-13-40' + '.csv'\n",
    "file_test_gmean = 'test_blend_ET_entropy_gmean_BM_0322_2017-03-23-13-40' + '.csv'\n",
    "\n",
    "train_ET_entropy_0322      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_ET_entropy_mean_0322  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_ET_entropy_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_ET_entropy_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_ET_entropy_0322.columns      = ['ET_entropy_0322_' + x for x in names[:n_column]]\n",
    "test_ET_entropy_mean_0322.columns  = ['ET_entropy_0322_' + x for x in names[:n_column]]\n",
    "test_ET_entropy_gmean_0322.columns = ['ET_entropy_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_ET_gini_0322: {}\\t test_ET_gini_mean_0322:{}\\t test_ET_gini_gmean_0322:{}'.\\\n",
    "        format(train_ET_gini_0322.shape,test_ET_gini_mean_0322.shape,test_ET_gini_gmean_0322.shape)\n",
    "print '\\ntrain_ET_entropy_0322: {}\\t test_ET_entropy_mean_0322:{}\\t test_ET_entropy_gmean_0322:{}'.\\\n",
    "        format(train_ET_entropy_0322.shape,test_ET_entropy_mean_0322.shape,test_ET_entropy_gmean_0322.shape)\n",
    "    \n",
    "    \n",
    "print '\\ntrain_ET_gini_0322'\n",
    "print train_ET_gini_0322.iloc[:5,:3]\n",
    "print '\\ntrain_ET_entropy_0322'\n",
    "print train_ET_entropy_0322.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_KNN_uniform: (49352, 3)\t test_KNN_uniform_mean:(74659, 3)\t test_KNN_uniform_gmean:(74659, 3)\n",
      "\n",
      "train_KNN_distance: (49352, 3)\t test_KNN_distance_mean:(74659, 3)\t test_KNN_distance_gmean:(74659, 3)\n",
      "\n",
      "train_KNN_uniform\n",
      "   KNN_uniform_low_0  KNN_uniform_medium_0  KNN_uniform_high_0\n",
      "0              0.505                 0.390               0.105\n",
      "1              0.535                 0.355               0.110\n",
      "2              0.675                 0.270               0.055\n",
      "3              0.555                 0.295               0.150\n",
      "4              0.815                 0.155               0.030\n",
      "\n",
      "train_KNN_distance\n",
      "   KNN_distance_low_0  KNN_distance_medium_0  KNN_distance_high_0\n",
      "0            0.540803               0.380577             0.078620\n",
      "1            0.540929               0.347829             0.111242\n",
      "2            0.666872               0.280763             0.052364\n",
      "3            0.575852               0.266448             0.157700\n",
      "4            0.845119               0.142102             0.012778\n"
     ]
    }
   ],
   "source": [
    "# KNN 1st level\n",
    "file_train      = 'train_blend_KNN_uniform_BM_MB_add03052240_2017-03-11-18-31' + '.csv'\n",
    "file_test_mean  = 'test_blend_KNN_uniform_mean_BM_MB_add03052240_2017-03-11-18-31' + '.csv'\n",
    "file_test_gmean = 'test_blend_KNN_uniform_gmean_BM_MB_add03052240_2017-03-11-18-31' + '.csv'\n",
    "\n",
    "train_KNN_uniform      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_KNN_uniform_mean  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_KNN_uniform_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_KNN_uniform.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_KNN_uniform.columns      = ['KNN_uniform_' + x for x in names[:n_column]]\n",
    "test_KNN_uniform_mean.columns  = ['KNN_uniform_' + x for x in names[:n_column]]\n",
    "test_KNN_uniform_gmean.columns = ['KNN_uniform_' + x for x in names[:n_column]]\n",
    "\n",
    "file_train      = 'train_blend_KNN_distance_BM_MB_add_2017-03-11-21-51' + '.csv'\n",
    "file_test_mean  = 'test_blend_KNN_distance_mean_BM_MB_add_2017-03-11-21-51' + '.csv'\n",
    "file_test_gmean = 'test_blend_KNN_distance_gmean_BM_MB_add_2017-03-11-21-51' + '.csv'\n",
    "\n",
    "train_KNN_distance      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_KNN_distance_mean  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_KNN_distance_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_KNN_distance.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_KNN_distance.columns      = ['KNN_distance_' + x for x in names[:n_column]]\n",
    "test_KNN_distance_mean.columns  = ['KNN_distance_' + x for x in names[:n_column]]\n",
    "test_KNN_distance_gmean.columns = ['KNN_distance_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_KNN_uniform: {}\\t test_KNN_uniform_mean:{}\\t test_KNN_uniform_gmean:{}'.\\\n",
    "        format(train_KNN_uniform.shape,test_KNN_uniform_mean.shape,test_KNN_uniform_gmean.shape)\n",
    "print '\\ntrain_KNN_distance: {}\\t test_KNN_distance_mean:{}\\t test_KNN_distance_gmean:{}'.\\\n",
    "        format(train_KNN_distance.shape,test_KNN_distance_mean.shape,test_KNN_distance_gmean.shape)\n",
    "    \n",
    "print '\\ntrain_KNN_uniform'\n",
    "print train_KNN_uniform.iloc[:5,:3]\n",
    "print '\\ntrain_KNN_distance'\n",
    "print train_KNN_distance.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_KNN_uniform_0322: (49352, 15)\t test_KNN_uniform_mean_0322:(74659, 15)\t test_KNN_uniform_gmean_0322:(74659, 15)\n",
      "\n",
      "train_KNN_distance: (49352, 15)\t test_KNN_distance_mean_0322:(74659, 15)\t test_KNN_distance_gmean_0322:(74659, 15)\n",
      "\n",
      "train_KNN_uniform_0322\n",
      "   KNN_uniform_0322_low_0  KNN_uniform_0322_medium_0  KNN_uniform_0322_high_0\n",
      "0                0.531250                   0.359375                 0.109375\n",
      "1                0.500000                   0.406250                 0.093750\n",
      "2                0.718750                   0.250000                 0.031250\n",
      "3                0.609375                   0.281250                 0.109375\n",
      "4                0.890625                   0.109375                 0.000000\n",
      "\n",
      "train_KNN_distance_0322\n",
      "   KNN_distance_0322_low_0  KNN_distance_0322_medium_0  \\\n",
      "0                 0.536089                    0.365949   \n",
      "1                 0.489625                    0.421250   \n",
      "2                 0.712491                    0.256449   \n",
      "3                 0.617141                    0.273793   \n",
      "4                 0.895361                    0.104639   \n",
      "\n",
      "   KNN_distance_0322_high_0  \n",
      "0                  0.097962  \n",
      "1                  0.089125  \n",
      "2                  0.031061  \n",
      "3                  0.109066  \n",
      "4                  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# KNN 1st level 0322\n",
    "file_train      = 'train_blend_KNN_uniform_BM_0322_2017-03-24-07-31' + '.csv'\n",
    "file_test_mean  = 'test_blend_KNN_uniform_mean_BM_0322_2017-03-24-07-31' + '.csv'\n",
    "file_test_gmean = 'test_blend_KNN_uniform_gmean_BM_0322_2017-03-24-07-31' + '.csv'\n",
    "\n",
    "train_KNN_uniform_0322      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_KNN_uniform_mean_0322  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_KNN_uniform_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_KNN_uniform_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_KNN_uniform_0322.columns      = ['KNN_uniform_0322_' + x for x in names[:n_column]]\n",
    "test_KNN_uniform_mean_0322.columns  = ['KNN_uniform_0322_' + x for x in names[:n_column]]\n",
    "test_KNN_uniform_gmean_0322.columns = ['KNN_uniform_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "file_train      = 'train_blend_KNN_distance_BM_0322_2017-03-25-08-17' + '.csv'\n",
    "file_test_mean  = 'test_blend_KNN_distance_mean_BM_0322_2017-03-25-08-17' + '.csv'\n",
    "file_test_gmean = 'test_blend_KNN_distance_gmean_BM_0322_2017-03-25-08-17' + '.csv'\n",
    "\n",
    "train_KNN_distance_0322      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_KNN_distance_mean_0322  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_KNN_distance_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_KNN_distance_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_KNN_distance_0322.columns      = ['KNN_distance_0322_' + x for x in names[:n_column]]\n",
    "test_KNN_distance_mean_0322.columns  = ['KNN_distance_0322_' + x for x in names[:n_column]]\n",
    "test_KNN_distance_gmean_0322.columns = ['KNN_distance_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_KNN_uniform_0322: {}\\t test_KNN_uniform_mean_0322:{}\\t test_KNN_uniform_gmean_0322:{}'.\\\n",
    "        format(train_KNN_uniform_0322.shape,test_KNN_uniform_mean_0322.shape,test_KNN_uniform_gmean_0322.shape)\n",
    "print '\\ntrain_KNN_distance: {}\\t test_KNN_distance_mean_0322:{}\\t test_KNN_distance_gmean_0322:{}'.\\\n",
    "        format(train_KNN_distance_0322.shape,test_KNN_distance_mean_0322.shape,test_KNN_distance_gmean_0322.shape)\n",
    "    \n",
    "print '\\ntrain_KNN_uniform_0322'\n",
    "print train_KNN_uniform_0322.iloc[:5,:3]\n",
    "print '\\ntrain_KNN_distance_0322'\n",
    "print train_KNN_distance_0322.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_FM: (49352, 3)\t test_FM_mean:(74659, 3)\t test_FM_gmean:(74659, 3)\n",
      "\n",
      "train_FM\n",
      "   FM_low_0  FM_medium_0  FM_high_0\n",
      "0  0.458595     0.410776   0.130629\n",
      "1  0.329965     0.537926   0.132109\n",
      "2  0.767341     0.206732   0.025927\n",
      "3  0.617983     0.351273   0.030744\n",
      "4  0.877894     0.103967   0.018139\n",
      "train_FM_0322: (49352, 3)\t test_FM_mean_0322:(74659, 3)\t test_FM_gmean_0322:(74659, 3)\n",
      "\n",
      "train_FM_0322\n",
      "   FM_0322_low_0  FM_0322_medium_0  FM_0322_high_0\n",
      "0       0.460187          0.436036        0.103776\n",
      "1       0.268598          0.571916        0.159486\n",
      "2       0.724799          0.239351        0.035851\n",
      "3       0.669683          0.286716        0.043600\n",
      "4       0.917878          0.073469        0.008653\n"
     ]
    }
   ],
   "source": [
    "# TFFM 1st level\n",
    "file_train      = 'train_blend_FM_BM_MB_add_desc_2017-03-16-09-52' + '.csv'\n",
    "file_test_mean  = 'test_blend_FM_mean_BM_MB_add_desc_2017-03-16-09-52' + '.csv'\n",
    "file_test_gmean = 'test_blend_FM_gmean_BM_MB_add_desc_2017-03-16-09-52' + '.csv'\n",
    "\n",
    "train_FM      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_FM_mean  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_FM_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_FM.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_FM.columns      = ['FM_' + x for x in names[:n_column]]\n",
    "test_FM_mean.columns  = ['FM_' + x for x in names[:n_column]]\n",
    "test_FM_gmean.columns = ['FM_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_FM: {}\\t test_FM_mean:{}\\t test_FM_gmean:{}'.\\\n",
    "        format(train_FM.shape,test_FM_mean.shape,test_FM_gmean.shape)\n",
    "\n",
    "print '\\ntrain_FM'\n",
    "print train_FM.iloc[:5,:3]\n",
    "\n",
    "\n",
    "# TFFM 1st level 0322\n",
    "file_train      = 'train_blend_FM_BM_0322_2017-03-27-04-35' + '.csv'\n",
    "file_test_mean  = 'test_blend_FM_mean_BM_0322_2017-03-27-04-35' + '.csv'\n",
    "file_test_gmean = 'test_blend_FM_gmean_BM_0322_2017-03-27-04-35' + '.csv'\n",
    "\n",
    "train_FM_0322      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_FM_mean_0322  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_FM_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_FM_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_FM_0322.columns      = ['FM_0322_' + x for x in names[:n_column]]\n",
    "test_FM_mean_0322.columns  = ['FM_0322_' + x for x in names[:n_column]]\n",
    "test_FM_gmean_0322.columns = ['FM_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_FM_0322: {}\\t test_FM_mean_0322:{}\\t test_FM_gmean_0322:{}'.\\\n",
    "        format(train_FM_0322.shape,test_FM_mean_0322.shape,test_FM_gmean_0322.shape)\n",
    "\n",
    "print '\\ntrain_FM_0322'\n",
    "print train_FM_0322.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_MNB: (49352, 9)\t test_MNB_mean:(74659, 9)\t test_MNB_gmean:(74659, 9)\n",
      "\n",
      "train_MNB\n",
      "   MNB_low_0  MNB_medium_0  MNB_high_0\n",
      "0   0.250130      0.546075    0.203795\n",
      "1   0.514751      0.424027    0.061222\n",
      "2   0.675745      0.283239    0.041015\n",
      "3   0.238787      0.331607    0.429605\n",
      "4   0.909543      0.082724    0.007733\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes 1st level\n",
    "file_train      = 'train_blend_MNB_BM_MB_add03052240_2017-03-13-20-51' + '.csv'\n",
    "file_test_mean  = 'test_blend_MNB_mean_BM_MB_add03052240_2017-03-13-20-51' + '.csv'\n",
    "file_test_gmean = 'test_blend_MNB_gmean_BM_MB_add03052240_2017-03-13-20-51' + '.csv'\n",
    "\n",
    "train_MNB      = pd.read_csv(data_path + file_train,      header = None)\n",
    "test_MNB_mean  = pd.read_csv(data_path + file_test_mean,  header = None)\n",
    "test_MNB_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_MNB.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_MNB.columns      = ['MNB_' + x for x in names[:n_column]]\n",
    "test_MNB_mean.columns  = ['MNB_' + x for x in names[:n_column]]\n",
    "test_MNB_gmean.columns = ['MNB_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_MNB: {}\\t test_MNB_mean:{}\\t test_MNB_gmean:{}'.\\\n",
    "        format(train_MNB.shape,test_MNB_mean.shape,test_MNB_gmean.shape)\n",
    "    \n",
    "print '\\ntrain_MNB'\n",
    "print train_MNB.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tsne: (49352, 3)\t test_tsne:(74659, 3)\n",
      "\n",
      "train_tsne\n",
      "      tsne_0     tsne_1    tsne_2\n",
      "0  -8.398991  -2.415894 -3.602143\n",
      "1   0.698237   0.335786  8.884257\n",
      "2  -5.811380 -16.669975  7.145837\n",
      "3  -0.371861 -25.894747 -2.076309\n",
      "4 -15.371799   9.656209  5.813590\n",
      "train_tsne_0322: (49352, 3)\t test_tsne_0322:(74659, 3)\n",
      "\n",
      "train_tsne_0322\n",
      "   tsne_0_0322  tsne_1_0322  tsne_2_0322\n",
      "0    -6.649132    13.028168     8.329733\n",
      "1     7.615566     0.067456   -14.932181\n",
      "2     8.333528     8.561174   -13.536297\n",
      "3    12.819587   -20.027314     0.661660\n",
      "4    -5.513088    -5.609218    17.130673\n"
     ]
    }
   ],
   "source": [
    "# TSNE 1st level\n",
    "\n",
    "file_train = 'X_train_tsne_BM_MB_add_desc_2017-03-18-17-14' + '.csv'\n",
    "file_test  = 'X_test_tsne_BM_MB_add_desc_2017-03-18-17-14' + '.csv'\n",
    "\n",
    "train_tsne = pd.read_csv(data_path + file_train, header = None)\n",
    "test_tsne  = pd.read_csv(data_path + file_test, header = None)\n",
    "\n",
    "\n",
    "n_column = train_tsne.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_tsne.columns = ['tsne_0', 'tsne_1', 'tsne_2']\n",
    "test_tsne.columns  = ['tsne_0', 'tsne_1', 'tsne_2']\n",
    "\n",
    "print 'train_tsne: {}\\t test_tsne:{}'.\\\n",
    "        format(train_tsne.shape,test_tsne.shape)\n",
    "    \n",
    "print '\\ntrain_tsne'\n",
    "print train_tsne.iloc[:5,:3]\n",
    "\n",
    "\n",
    "# TSNE 1st level 0322\n",
    "\n",
    "file_train = 'X_train_tsne_BM_0322_2017-03-26-16-33' + '.csv'\n",
    "file_test  = 'X_test_tsne_BM_0322_2017-03-26-16-33' + '.csv'\n",
    "\n",
    "train_tsne_0322 = pd.read_csv(data_path + file_train, header = None)\n",
    "test_tsne_0322  = pd.read_csv(data_path + file_test, header = None)\n",
    "\n",
    "\n",
    "n_column = train_tsne_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_tsne_0322.columns = ['tsne_0_0322', 'tsne_1_0322', 'tsne_2_0322']\n",
    "test_tsne_0322.columns  = ['tsne_0_0322', 'tsne_1_0322', 'tsne_2_0322']\n",
    "\n",
    "print 'train_tsne_0322: {}\\t test_tsne_0322:{}'.\\\n",
    "        format(train_tsne_0322.shape,test_tsne_0322.shape)\n",
    "    \n",
    "print '\\ntrain_tsne_0322'\n",
    "print train_tsne_0322.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb: (49352, 15)\t test_xgb_mean:(74659, 15)\t test_xgb_gmean:(74659, 15)\n",
      "\n",
      "train_xgb\n",
      "   xgb_low_0  xgb_medium_0  xgb_high_0\n",
      "0   0.620867      0.354255    0.024877\n",
      "1   0.430220      0.494481    0.075300\n",
      "2   0.841392      0.146357    0.012251\n",
      "3   0.832960      0.161299    0.005741\n",
      "4   0.976559      0.022998    0.000443\n"
     ]
    }
   ],
   "source": [
    "# XGB 1st level\n",
    "\n",
    "file_train = 'train_blend_xgb_BM_MB_add_desc_2017-03-14-16-54' + '.csv'\n",
    "file_test_mean = 'test_blend_xgb_mean_BM_MB_add_desc_2017-03-14-16-54' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_gmean_BM_MB_add_desc_2017-03-14-16-54' + '.csv'\n",
    "\n",
    "train_xgb      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb.columns = ['xgb_' + x for x in names[:n_column]]\n",
    "test_xgb_mean.columns = ['xgb_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean.columns = ['xgb_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb: {}\\t test_xgb_mean:{}\\t test_xgb_gmean:{}'.\\\n",
    "        format(train_xgb.shape,test_xgb_mean.shape,test_xgb_gmean.shape)\n",
    "    \n",
    "print '\\ntrain_xgb'\n",
    "print train_xgb.iloc[:5,:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb_0322: (49352, 15)\t test_xgb_mean_0322:(74659, 15)\t test_xgb_gmean_0322:(74659, 15)\n",
      "\n",
      "train_xgb_0322\n",
      "   xgb_0322_low_0  xgb_0322_medium_0  xgb_0322_high_0\n",
      "0        0.564117           0.398080         0.037803\n",
      "1        0.374154           0.569733         0.056113\n",
      "2        0.750527           0.229728         0.019746\n",
      "3        0.795827           0.196790         0.007383\n",
      "4        0.976929           0.022567         0.000505\n"
     ]
    }
   ],
   "source": [
    "# XGB 1st level 0322\n",
    "\n",
    "file_train      = 'train_blend_xgb_BM_0322_2017-03-25-19-12' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_mean_BM_0322_2017-03-25-19-12' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_gmean_BM_0322_2017-03-25-19-12' + '.csv'\n",
    "\n",
    "train_xgb_0322      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean_0322  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb_0322.columns      = ['xgb_0322_' + x for x in names[:n_column]]\n",
    "test_xgb_mean_0322.columns  = ['xgb_0322_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean_0322.columns = ['xgb_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb_0322: {}\\t test_xgb_mean_0322:{}\\t test_xgb_gmean_0322:{}'.\\\n",
    "        format(train_xgb_0322.shape,test_xgb_mean_0322.shape,test_xgb_gmean_0322.shape)\n",
    "    \n",
    "print '\\ntrain_xgb_0322'\n",
    "print train_xgb_0322.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb_0331: (49352, 15)\t test_xgb_mean_0331:(74659, 15)\t test_xgb_gmean_0331:(74659, 15)\n",
      "\n",
      "train_xgb_0331\n",
      "   xgb_0331_low_0  xgb_0331_medium_0  xgb_0331_high_0\n",
      "0        0.555217           0.398932         0.045851\n",
      "1        0.510705           0.412666         0.076630\n",
      "2        0.677054           0.303747         0.019199\n",
      "3        0.916544           0.082619         0.000837\n",
      "4        0.983702           0.015835         0.000464\n"
     ]
    }
   ],
   "source": [
    "# XGB 1st level 0331\n",
    "\n",
    "file_train      = 'train_blend_xgb_BM_0331_2017-04-02-17-55' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_mean_BM_0331_2017-04-02-17-55' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_gmean_BM_0331_2017-04-02-17-55' + '.csv'\n",
    "\n",
    "train_xgb_0331      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean_0331  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean_0331 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb_0331.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb_0331.columns      = ['xgb_0331_' + x for x in names[:n_column]]\n",
    "test_xgb_mean_0331.columns  = ['xgb_0331_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean_0331.columns = ['xgb_0331_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb_0331: {}\\t test_xgb_mean_0331:{}\\t test_xgb_gmean_0331:{}'.\\\n",
    "        format(train_xgb_0331.shape,test_xgb_mean_0331.shape,test_xgb_gmean_0331.shape)\n",
    "    \n",
    "print '\\ntrain_xgb_0331'\n",
    "print train_xgb_0331.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb_0331_30fold: (49352, 3)\t test_xgb_mean_0331_30fold:(74659, 3)\t test_xgb_gmean_0331_30fold:(74659, 3)\n",
      "\n",
      "train_xgb_0331_30fold\n",
      "   xgb_0331_30fold_low_0  xgb_0331_30fold_medium_0  xgb_0331_30fold_high_0\n",
      "0               0.514917                  0.443943                0.041140\n",
      "1               0.496656                  0.413782                0.089561\n",
      "2               0.620738                  0.364521                0.014741\n",
      "3               0.952542                  0.046257                0.001200\n",
      "4               0.983427                  0.016238                0.000335\n"
     ]
    }
   ],
   "source": [
    "# XGB 1st level 0331 30fold\n",
    "\n",
    "file_train      = 'train_blend_xgb_BM_0331_30blend_2017-04-04-09-15' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_mean_BM_0331_30blend_2017-04-04-09-15' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_gmean_BM_0331_30blend_2017-04-04-09-15' + '.csv'\n",
    "\n",
    "train_xgb_0331_30fold      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean_0331_30fold  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean_0331_30fold = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb_0331_30fold.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb_0331_30fold.columns      = ['xgb_0331_30fold_' + x for x in names[:n_column]]\n",
    "test_xgb_mean_0331_30fold.columns  = ['xgb_0331_30fold_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean_0331_30fold.columns = ['xgb_0331_30fold_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb_0331_30fold: {}\\t test_xgb_mean_0331_30fold:{}\\t test_xgb_gmean_0331_30fold:{}'.\\\n",
    "        format(train_xgb_0331_30fold.shape,test_xgb_mean_0331_30fold.shape,test_xgb_gmean_0331_30fold.shape)\n",
    "    \n",
    "print '\\ntrain_xgb_0331_30fold'\n",
    "print train_xgb_0331_30fold.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb_cv137: (49352, 3)\t test_xgb_mean_cv137:(74659, 3)\t test_xgb_gmean_cv137:(74659, 3)\n",
      "\n",
      "train_xgb_cv137\n",
      "   xgb_cv137_low_0  xgb_cv137_medium_0  xgb_cv137_high_0\n",
      "0         0.556073            0.426701          0.017226\n",
      "1         0.239747            0.689633          0.070620\n",
      "2         0.754970            0.235080          0.009951\n",
      "3         0.922978            0.073872          0.003150\n",
      "4         0.970618            0.028882          0.000500\n"
     ]
    }
   ],
   "source": [
    "# XGB 1st level cv137\n",
    "\n",
    "file_train      = 'train_blend_xgb_cv137_BM_2017-04-06-11-44' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_mean_cv137_5blend_BM_2017-04-06-11-44' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_gmean_cv137_5blend_BM_2017-04-06-11-44' + '.csv'\n",
    "\n",
    "train_xgb_cv137      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean_cv137  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean_cv137 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb_cv137.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb_cv137.columns      = ['xgb_cv137_' + x for x in names[:n_column]]\n",
    "test_xgb_mean_cv137.columns  = ['xgb_cv137_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean_cv137.columns = ['xgb_cv137_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb_cv137: {}\\t test_xgb_mean_cv137:{}\\t test_xgb_gmean_cv137:{}'.\\\n",
    "        format(train_xgb_cv137.shape,test_xgb_mean_cv137.shape,test_xgb_gmean_cv137.shape)\n",
    "    \n",
    "print '\\ntrain_xgb_cv137'\n",
    "print train_xgb_cv137.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb_cv137_1: (49352, 3)\t test_xgb_mean_cv137_1:(74659, 3)\t test_xgb_gmean_cv137_1:(74659, 3)\n",
      "\n",
      "train_xgb_cv137_1\n",
      "   xgb_cv137_1_low_0  xgb_cv137_1_medium_0  xgb_cv137_1_high_0\n",
      "0           0.545455              0.435613            0.018933\n",
      "1           0.238423              0.703408            0.058170\n",
      "2           0.736379              0.252045            0.011576\n",
      "3           0.938200              0.058592            0.003208\n",
      "4           0.971339              0.028259            0.000402\n"
     ]
    }
   ],
   "source": [
    "# XGB 1st level cv137 2\n",
    "\n",
    "file_train      = 'train_blend_xgb_cv137_BM_2017-04-06-15-28' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_mean_cv137_5blend_BM_2017-04-06-15-28' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_gmean_cv137_5blend_BM_2017-04-06-15-28' + '.csv'\n",
    "\n",
    "train_xgb_cv137_1      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean_cv137_1  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean_cv137_1 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb_cv137_1.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb_cv137_1.columns      = ['xgb_cv137_1_' + x for x in names[:n_column]]\n",
    "test_xgb_mean_cv137_1.columns  = ['xgb_cv137_1_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean_cv137_1.columns = ['xgb_cv137_1_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb_cv137_1: {}\\t test_xgb_mean_cv137_1:{}\\t test_xgb_gmean_cv137_1:{}'.\\\n",
    "        format(train_xgb_cv137_1.shape,test_xgb_mean_cv137_1.shape,test_xgb_gmean_cv137_1.shape)\n",
    "    \n",
    "print '\\ntrain_xgb_cv137_1'\n",
    "print train_xgb_cv137_1.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb_cv_price: (49352, 3)\t test_xgb_mean_cv_price:(74659, 3)\t test_xgb_gmean_cv_price:(74659, 3)\n",
      "\n",
      "train_xgb_cv_price\n",
      "   xgb_cv_price_low_0  xgb_cv_price_medium_0  xgb_cv_price_high_0\n",
      "0            0.515747               0.466206             0.018048\n",
      "1            0.447346               0.496976             0.055678\n",
      "2            0.784029               0.200907             0.015064\n",
      "3            0.943679               0.054516             0.001805\n",
      "4            0.947229               0.052005             0.000765\n"
     ]
    }
   ],
   "source": [
    "# XGB 1st level cv_price\n",
    "\n",
    "file_train      = 'train_blend_xgb_cv_price_BM_2017-04-09-14-06' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_mean_cv_price_BM_2017-04-09-14-06' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_gmean_cv_price_BM_2017-04-09-14-06' + '.csv'\n",
    "\n",
    "train_xgb_cv_price      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean_cv_price  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean_cv_price = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb_cv_price.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb_cv_price.columns      = ['xgb_cv_price_' + x for x in names[:n_column]]\n",
    "test_xgb_mean_cv_price.columns  = ['xgb_cv_price_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean_cv_price.columns = ['xgb_cv_price_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb_cv_price: {}\\t test_xgb_mean_cv_price:{}\\t test_xgb_gmean_cv_price:{}'.\\\n",
    "        format(train_xgb_cv_price.shape,test_xgb_mean_cv_price.shape,test_xgb_gmean_cv_price.shape)\n",
    "    \n",
    "print '\\ntrain_xgb_cv_price'\n",
    "print train_xgb_cv_price.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb_cv_MS_52571: (49352, 15)\t test_xgb_mean_cv_MS_52571:(74659, 15)\t test_xgb_gmean_cv_MS_52571:(74659, 15)\n",
      "\n",
      "train_xgb_cv_MS_52571\n",
      "   xgb_cv_MS_52571_low_0  xgb_cv_MS_52571_medium_0  xgb_cv_MS_52571_high_0\n",
      "0               0.610970                  0.376845                0.012185\n",
      "1               0.381871                  0.523843                0.094286\n",
      "2               0.771936                  0.212986                0.015078\n",
      "3               0.936476                  0.061077                0.002447\n",
      "4               0.940247                  0.058707                0.001046\n"
     ]
    }
   ],
   "source": [
    "# XGB 1st level CV_MS_52571\n",
    "\n",
    "file_train      = 'train_blend_xgb_CV_MS_BM_2017-04-11-09-18' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_mean_CV_MS_BM_2017-04-11-09-18' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_gmean_CV_MS_BM_2017-04-11-09-18' + '.csv'\n",
    "\n",
    "train_xgb_cv_MS_52571      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean_cv_MS_52571  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean_cv_MS_52571 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb_cv_MS_52571.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb_cv_MS_52571.columns      = ['xgb_cv_MS_52571_' + x for x in names[:n_column]]\n",
    "test_xgb_mean_cv_MS_52571.columns  = ['xgb_cv_MS_52571_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean_cv_MS_52571.columns = ['xgb_cv_MS_52571_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb_cv_MS_52571: {}\\t test_xgb_mean_cv_MS_52571:{}\\t test_xgb_gmean_cv_MS_52571:{}'.\\\n",
    "        format(train_xgb_cv_MS_52571.shape,test_xgb_mean_cv_MS_52571.shape,test_xgb_gmean_cv_MS_52571.shape)\n",
    "    \n",
    "print '\\ntrain_xgb_cv_MS_52571'\n",
    "print train_xgb_cv_MS_52571.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb_cv_MS_52571_30fold: (49352, 3)\t test_xgb_mean_cv_MS_52571_30fold:(74659, 3)\t test_xgb_gmean_cv_MS_52571_30fold:(74659, 3)\n",
      "\n",
      "train_xgb_cv_MS_52571_30fold\n",
      "   xgb_cv_MS_52571_30fold_low_0  xgb_cv_MS_52571_30fold_medium_0  \\\n",
      "0                      0.626121                         0.359925   \n",
      "1                      0.389560                         0.532293   \n",
      "2                      0.780193                         0.206190   \n",
      "3                      0.954307                         0.044390   \n",
      "4                      0.942051                         0.056965   \n",
      "\n",
      "   xgb_cv_MS_52571_30fold_high_0  \n",
      "0                       0.013954  \n",
      "1                       0.078147  \n",
      "2                       0.013618  \n",
      "3                       0.001303  \n",
      "4                       0.000984  \n"
     ]
    }
   ],
   "source": [
    "# XGB 1st level CV_MS_52571 30fold\n",
    "\n",
    "file_train      = 'train_blend_xgb_CV_MS_30blend_BM_2017-04-12-08-56' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_mean_CV_MS_30blend_BM_2017-04-12-08-56' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_gmean_CV_MS_30blend_BM_2017-04-12-08-56' + '.csv'\n",
    "\n",
    "train_xgb_cv_MS_52571_30fold      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean_cv_MS_52571_30fold  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean_cv_MS_52571_30fold = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb_cv_MS_52571_30fold.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb_cv_MS_52571_30fold.columns      = ['xgb_cv_MS_52571_30fold_' + x for x in names[:n_column]]\n",
    "test_xgb_mean_cv_MS_52571_30fold.columns  = ['xgb_cv_MS_52571_30fold_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean_cv_MS_52571_30fold.columns = ['xgb_cv_MS_52571_30fold_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb_cv_MS_52571_30fold: {}\\t test_xgb_mean_cv_MS_52571_30fold:{}\\t test_xgb_gmean_cv_MS_52571_30fold:{}'.\\\n",
    "        format(train_xgb_cv_MS_52571_30fold.shape,test_xgb_mean_cv_MS_52571_30fold.shape,test_xgb_gmean_cv_MS_52571_30fold.shape)\n",
    "    \n",
    "print '\\ntrain_xgb_cv_MS_52571_30fold'\n",
    "print train_xgb_cv_MS_52571_30fold.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_xgb_0322: (49352, 3)\t test_xgb_mean_0322:(74659, 3)\t test_xgb_gmean_0322:(74659, 3)\n",
      "\n",
      "train_xgb_ovr_0322\n",
      "   xgb_0322_ovr_low_0  xgb_0322_ovr_medium_0  xgb_0322_ovr_high_0\n",
      "0            0.576382               0.389992             0.032310\n",
      "1            0.405845               0.460087             0.054413\n",
      "2            0.788904               0.204474             0.018300\n",
      "3            0.808683               0.274157             0.003941\n",
      "4            0.970781               0.045735             0.000718\n"
     ]
    }
   ],
   "source": [
    "# XGB one vs rest 1st level 0322\n",
    "\n",
    "file_train      = 'train_blend_xgb_ovr_BM_0322_2017-03-27-19-36' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_ovr_mean_BM_0322_2017-03-27-19-36' + '.csv'\n",
    "file_test_gmean = 'test_blend_xgb_ovr_gmean_BM_0322_2017-03-27-19-36' + '.csv'\n",
    "\n",
    "train_xgb_ovr_0322      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_xgb_mean_ovr_0322  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_xgb_gmean_ovr_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_xgb_ovr_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_xgb_ovr_0322.columns      = ['xgb_0322_ovr_' + x for x in names[:n_column]]\n",
    "test_xgb_mean_ovr_0322.columns  = ['xgb_0322_ovr_' + x for x in names[:n_column]]\n",
    "test_xgb_gmean_ovr_0322.columns = ['xgb_0322_ovr_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_xgb_0322: {}\\t test_xgb_mean_0322:{}\\t test_xgb_gmean_0322:{}'.\\\n",
    "        format(train_xgb_ovr_0322.shape,test_xgb_mean_ovr_0322.shape,test_xgb_gmean_ovr_0322.shape)\n",
    "    \n",
    "print '\\ntrain_xgb_ovr_0322'\n",
    "print train_xgb_ovr_0322.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_lgb_0322: (49352, 15)\t test_lgb_mean_0322:(74659, 15)\t test_lgb_gmean_0322:(74659, 15)\n",
      "\n",
      "train_lgb_0322\n",
      "   lgb_0322_low_0  lgb_0322_medium_0  lgb_0322_high_0\n",
      "0        0.510750           0.439527         0.049723\n",
      "1        0.395873           0.532461         0.071666\n",
      "2        0.793317           0.188224         0.018458\n",
      "3        0.805114           0.187627         0.007258\n",
      "4        0.975688           0.023956         0.000357\n",
      "train_lgb_dart_0322: (49352, 15)\t test_lgb_mean_dart_0322:(74659, 15)\t test_lgb_gmean_dart_0322:(74659, 15)\n",
      "\n",
      "train_lgb_dart_0322\n",
      "   lgb_dart_0322_low_0  lgb_dart_0322_medium_0  lgb_dart_0322_high_0\n",
      "0             0.536502                0.419306              0.044192\n",
      "1             0.394450                0.536137              0.069413\n",
      "2             0.757824                0.223637              0.018538\n",
      "3             0.800108                0.191529              0.008363\n",
      "4             0.975370                0.024224              0.000406\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 1st level 0322\n",
    "\n",
    "file_train      = 'train_blend_LightGBM_BM_0322_2017-03-27-08-21' + '.csv'\n",
    "file_test_mean  = 'test_blend_LightGBM_mean_BM_0322_2017-03-27-08-21' + '.csv'\n",
    "file_test_gmean = 'test_blend_LightGBM_gmean_BM_0322_2017-03-27-08-21' + '.csv'\n",
    "\n",
    "train_lgb_0322      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_lgb_mean_0322  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_lgb_gmean_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_lgb_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_lgb_0322.columns      = ['lgb_0322_' + x for x in names[:n_column]]\n",
    "test_lgb_mean_0322.columns  = ['lgb_0322_' + x for x in names[:n_column]]\n",
    "test_lgb_gmean_0322.columns = ['lgb_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_lgb_0322: {}\\t test_lgb_mean_0322:{}\\t test_lgb_gmean_0322:{}'.\\\n",
    "        format(train_lgb_0322.shape,test_lgb_mean_0322.shape,test_lgb_gmean_0322.shape)\n",
    "    \n",
    "print '\\ntrain_lgb_0322'\n",
    "print train_lgb_0322.iloc[:5,:3]\n",
    "\n",
    "\n",
    "# LightGBM 1st level dart 0322\n",
    "\n",
    "file_train      = 'train_blend_LightGBM_dart_BM_0322_2017-03-31-13-03' + '.csv'\n",
    "file_test_mean  = 'test_blend_LightGBM_dart_mean_BM_0322_2017-03-31-13-03' + '.csv'\n",
    "file_test_gmean = 'test_blend_LightGBM_dart_gmean_BM_0322_2017-03-31-13-03' + '.csv'\n",
    "\n",
    "train_lgb_dart_0322      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_lgb_mean_dart_0322  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_lgb_gmean_dart_0322 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_lgb_dart_0322.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_lgb_dart_0322.columns      = ['lgb_dart_0322_' + x for x in names[:n_column]]\n",
    "test_lgb_mean_dart_0322.columns  = ['lgb_dart_0322_' + x for x in names[:n_column]]\n",
    "test_lgb_gmean_dart_0322.columns = ['lgb_dart_0322_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_lgb_dart_0322: {}\\t test_lgb_mean_dart_0322:{}\\t test_lgb_gmean_dart_0322:{}'.\\\n",
    "        format(train_lgb_dart_0322.shape,test_lgb_mean_dart_0322.shape,test_lgb_gmean_dart_0322.shape)\n",
    "    \n",
    "print '\\ntrain_lgb_dart_0322'\n",
    "print train_lgb_dart_0322.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_lgb_0331: (49352, 15)\t test_lgb_mean_0331:(74659, 15)\t test_lgb_gmean_0331:(74659, 15)\n",
      "\n",
      "train_lgb_0331\n",
      "   lgb_0331_low_0  lgb_0331_medium_0  lgb_0331_high_0\n",
      "0        0.586766           0.365276         0.047959\n",
      "1        0.459089           0.474973         0.065938\n",
      "2        0.654597           0.323706         0.021698\n",
      "3        0.912453           0.086817         0.000730\n",
      "4        0.982751           0.016790         0.000459\n",
      "train_lgb_0401: (49352, 15)\t test_lgb_mean_0401:(74659, 15)\t test_lgb_gmean_0401:(74659, 15)\n",
      "\n",
      "train_lgb_0401\n",
      "   lgb_0401_low_0  lgb_0401_medium_0  lgb_0401_high_0\n",
      "0        0.609713           0.355626         0.034661\n",
      "1        0.470742           0.466250         0.063009\n",
      "2        0.695360           0.285809         0.018831\n",
      "3        0.901242           0.097840         0.000918\n",
      "4        0.981500           0.018019         0.000480\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 1st level 0331\n",
    "\n",
    "file_train      = 'train_blend_LightGBM_BM_0331_2017-04-01-07-33' + '.csv'\n",
    "file_test_mean  = 'test_blend_LightGBM_mean_BM_0331_2017-04-01-07-33' + '.csv'\n",
    "file_test_gmean = 'test_blend_LightGBM_gmean_BM_0331_2017-04-01-07-33' + '.csv'\n",
    "\n",
    "train_lgb_0331      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_lgb_mean_0331  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_lgb_gmean_0331 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_lgb_0331.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_lgb_0331.columns      = ['lgb_0331_' + x for x in names[:n_column]]\n",
    "test_lgb_mean_0331.columns  = ['lgb_0331_' + x for x in names[:n_column]]\n",
    "test_lgb_gmean_0331.columns = ['lgb_0331_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_lgb_0331: {}\\t test_lgb_mean_0331:{}\\t test_lgb_gmean_0331:{}'.\\\n",
    "        format(train_lgb_0331.shape,test_lgb_mean_0331.shape,test_lgb_gmean_0331.shape)\n",
    "    \n",
    "print '\\ntrain_lgb_0331'\n",
    "print train_lgb_0331.iloc[:5,:3]\n",
    "\n",
    "\n",
    "# LightGBM 1st level 0401\n",
    "\n",
    "file_train      = 'train_blend_LightGBM_BM_0401_2017-04-02-12-24' + '.csv'\n",
    "file_test_mean  = 'test_blend_LightGBM_mean_BM_0401_2017-04-02-12-24' + '.csv'\n",
    "file_test_gmean = 'test_blend_LightGBM_gmean_BM_0401_2017-04-02-12-24' + '.csv'\n",
    "\n",
    "train_lgb_0401      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_lgb_mean_0401  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "test_lgb_gmean_0401 = pd.read_csv(data_path + file_test_gmean, header = None)\n",
    "\n",
    "n_column = train_lgb_0401.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_lgb_0401.columns      = ['lgb_0401_' + x for x in names[:n_column]]\n",
    "test_lgb_mean_0401.columns  = ['lgb_0401_' + x for x in names[:n_column]]\n",
    "test_lgb_gmean_0401.columns = ['lgb_0401_' + x for x in names[:n_column]]\n",
    "\n",
    "print 'train_lgb_0401: {}\\t test_lgb_mean_0401:{}\\t test_lgb_gmean_0401:{}'.\\\n",
    "        format(train_lgb_0401.shape,test_lgb_mean_0401.shape,test_lgb_gmean_0401.shape)\n",
    "    \n",
    "print '\\ntrain_lgb_0401'\n",
    "print train_lgb_0401.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nn_0331: (49352, 6)\t test_nn_mean_0331:(74659, 6)\n",
      "\n",
      "train_nn_0331\n",
      "   nn_0331_low_0  nn_0331_medium_0  nn_0331_high_0\n",
      "0       0.414695          0.515356        0.069948\n",
      "1       0.471474          0.451380        0.077146\n",
      "2       0.762575          0.227400        0.010026\n",
      "3       0.917715          0.080477        0.001809\n",
      "4       0.968525          0.031075        0.000400\n",
      "train_nn_0331_1: (49352, 6)\t test_nn_mean_0331_1:(74659, 6)\n",
      "\n",
      "train_nn_0331_1\n",
      "   nn_0331_1_low_0  nn_0331_1_medium_0  nn_0331_1_high_0\n",
      "0         0.457987            0.486389          0.055624\n",
      "1         0.423605            0.476901          0.099494\n",
      "2         0.759374            0.230741          0.009885\n",
      "3         0.894239            0.103938          0.001823\n",
      "4         0.962752            0.036721          0.000526\n"
     ]
    }
   ],
   "source": [
    "# Keras 1st level No.1\n",
    "\n",
    "file_train      = 'train_blend_Keras_BM_0331_2017-04-04-15-32' + '.csv'\n",
    "file_test_mean  = 'test_blend_Keras_BM_0331_2017-04-04-15-32' + '.csv'\n",
    "\n",
    "\n",
    "train_nn_0331      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_nn_mean_0331  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "\n",
    "\n",
    "n_column = train_nn_0331.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_nn_0331.columns      = ['nn_0331_' + x for x in names[:n_column]]\n",
    "test_nn_mean_0331.columns  = ['nn_0331_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "print 'train_nn_0331: {}\\t test_nn_mean_0331:{}'.\\\n",
    "        format(train_nn_0331.shape,test_nn_mean_0331.shape)\n",
    "    \n",
    "print '\\ntrain_nn_0331'\n",
    "print train_nn_0331.iloc[:5,:3]\n",
    "\n",
    "\n",
    "# Keras 1st level No.2\n",
    "\n",
    "file_train      = 'train_blend_Keras_BM_0331_2017-04-04-17-23' + '.csv'\n",
    "file_test_mean  = 'test_blend_Keras_BM_0331_2017-04-04-17-23' + '.csv'\n",
    "\n",
    "\n",
    "train_nn_0331_1      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_nn_mean_0331_1  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "\n",
    "\n",
    "n_column = train_nn_0331_1.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_nn_0331_1.columns      = ['nn_0331_1_' + x for x in names[:n_column]]\n",
    "test_nn_mean_0331_1.columns  = ['nn_0331_1_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "print 'train_nn_0331_1: {}\\t test_nn_mean_0331_1:{}'.\\\n",
    "        format(train_nn_0331_1.shape,test_nn_mean_0331_1.shape)\n",
    "    \n",
    "print '\\ntrain_nn_0331_1'\n",
    "print train_nn_0331_1.iloc[:5,:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nn_ovr_0331: (49352, 6)\t test_nn_mean_ovr_0331:(74659, 6)\n",
      "\n",
      "train_nn_ovr_0331\n",
      "   nn_0331_ovr_low_0  nn_0331_ovr_medium_0  nn_0331_ovr_high_0\n",
      "0           0.535439              0.440819            0.559664\n",
      "1           0.346925              0.352112            0.430188\n",
      "2           0.701298              0.680813            0.289677\n",
      "3           0.934782              0.882168            0.203384\n",
      "4           0.980007              0.972453            0.023712\n"
     ]
    }
   ],
   "source": [
    "# Keras one vs rest 1st level 0331\n",
    "\n",
    "file_train      = 'train_blend_Keras_ovr_BM_0331_2017-04-05-03-37' + '.csv'\n",
    "file_test_mean  = 'test_blend_Keras_ovr_BM_0331_2017-04-05-03-37' + '.csv'\n",
    "\n",
    "\n",
    "train_nn_ovr_0331      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_nn_mean_ovr_0331  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "\n",
    "\n",
    "n_column = train_nn_ovr_0331.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_nn_ovr_0331.columns      = ['nn_0331_ovr_' + x for x in names[:n_column]]\n",
    "test_nn_mean_ovr_0331.columns  = ['nn_0331_ovr_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "print 'train_nn_ovr_0331: {}\\t test_nn_mean_ovr_0331:{}'.\\\n",
    "        format(train_nn_ovr_0331.shape,test_nn_mean_ovr_0331.shape)\n",
    "    \n",
    "print '\\ntrain_nn_ovr_0331'\n",
    "print train_nn_ovr_0331.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nn_bagging: (49352, 6)\t test_nn_mean_bagging:(74659, 6)\n",
      "\n",
      "train_nn_bagging\n",
      "   nn_bagging_low_0  nn_bagging_medium_0  nn_bagging_high_0\n",
      "0          0.525439             0.444089           0.030472\n",
      "1          0.386813             0.526454           0.086732\n",
      "2          0.754997             0.234968           0.010034\n",
      "3          0.950135             0.049288           0.000577\n",
      "4          0.949495             0.049726           0.000779\n"
     ]
    }
   ],
   "source": [
    "# Keras bagging 1st level CV_52571\n",
    "\n",
    "file_train      = 'train_blend_Keras_CV_52571_BM_2017-04-13-13-59' + '.csv'\n",
    "file_test_mean  = 'test_blend_Keras_mean_CV_52571_BM_2017-04-13-13-59' + '.csv'\n",
    "\n",
    "\n",
    "train_nn_bagging      = pd.read_csv(data_path + file_train, header = None)\n",
    "test_nn_mean_bagging  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "\n",
    "\n",
    "n_column = train_nn_bagging.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_nn_bagging.columns      = ['nn_bagging_' + x for x in names[:n_column]]\n",
    "test_nn_mean_bagging.columns  = ['nn_bagging_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "print 'train_nn_bagging: {}\\t test_nn_mean_bagging:{}'.\\\n",
    "        format(train_nn_bagging.shape,test_nn_mean_bagging.shape)\n",
    "    \n",
    "print '\\ntrain_nn_bagging'\n",
    "print train_nn_bagging.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gp: (49352, 3)\t test_gp:(74659, 3)\n",
      "\n",
      "train_gp\n",
      "   gp_low_0  gp_medium_0  gp_high_0\n",
      "0  0.667295     0.414926   0.055642\n",
      "1  0.274272     0.468727   0.164397\n",
      "2  0.824768     0.100327   0.008004\n",
      "3  0.871032     0.132950   0.002816\n",
      "4  0.961603     0.061744   0.007022\n"
     ]
    }
   ],
   "source": [
    "# Genetic Programming 1st level\n",
    "\n",
    "file_train      = 'train_blend_GP_BM_2017-04-09-19-15' + '.csv'\n",
    "file_test_mean  = 'test_blend_GP_BM_2017-04-09-19-15' + '.csv'\n",
    "\n",
    "\n",
    "train_gp = pd.read_csv(data_path + file_train, header = None)\n",
    "test_gp  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "\n",
    "\n",
    "n_column = train_gp.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_gp.columns = ['gp_' + x for x in names[:n_column]]\n",
    "test_gp.columns  = ['gp_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "print 'train_gp: {}\\t test_gp:{}'.\\\n",
    "        format(train_gp.shape,test_gp.shape)\n",
    "    \n",
    "print '\\ntrain_gp'\n",
    "print train_gp.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_bagging_0: (49352, 3)\t test_bagging_0:(74659, 3)\n",
      "\n",
      "train_bagging_0\n",
      "   bagging_0_low_0  bagging_0_medium_0  bagging_0_high_0\n",
      "0         0.703823            0.281914          0.014263\n",
      "1         0.414551            0.499156          0.086294\n",
      "2         0.761033            0.226639          0.012328\n",
      "3         0.933414            0.064185          0.002400\n",
      "4         0.952160            0.047224          0.000617\n",
      "train_bagging_1: (49352, 3)\t test_bagging_1:(74659, 3)\n",
      "\n",
      "train_bagging_1\n",
      "   bagging_0_low_0  bagging_0_medium_0  bagging_0_high_0\n",
      "0         0.703823            0.281914          0.014263\n",
      "1         0.414551            0.499156          0.086294\n",
      "2         0.761033            0.226639          0.012328\n",
      "3         0.933414            0.064185          0.002400\n",
      "4         0.952160            0.047224          0.000617\n"
     ]
    }
   ],
   "source": [
    "# xgb bagging 0\n",
    "\n",
    "file_train      = 'train_blend_XGB_BM_3bagging_CV_MS_52571_2017-04-13-09-33' + '.csv'\n",
    "file_test_mean  = 'test_blend_XGB_BM_3bagging_CV_MS_52571_2017-04-13-09-33' + '.csv'\n",
    "\n",
    "\n",
    "train_bagging_0 = pd.read_csv(data_path + file_train, header = None)\n",
    "test_bagging_0  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "\n",
    "\n",
    "n_column = train_bagging_0.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_bagging_0.columns = ['bagging_0_' + x for x in names[:n_column]]\n",
    "test_bagging_0.columns  = ['bagging_0_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "print 'train_bagging_0: {}\\t test_bagging_0:{}'.\\\n",
    "        format(train_bagging_0.shape,test_bagging_0.shape)\n",
    "    \n",
    "print '\\ntrain_bagging_0'\n",
    "print train_bagging_0.iloc[:5,:3]\n",
    "\n",
    "\n",
    "# xgb bagging 1\n",
    "file_train      = 'train_blend_xgb_141bagging_BM_2017-04-13-10-12' + '.csv'\n",
    "file_test_mean  = 'test_blend_xgb_mean_141bagging_BM_2017-04-13-10-12' + '.csv'\n",
    "\n",
    "\n",
    "train_bagging_1 = pd.read_csv(data_path + file_train, header = None)\n",
    "test_bagging_1  = pd.read_csv(data_path + file_test_mean, header = None)\n",
    "\n",
    "\n",
    "n_column = train_bagging_1.shape[1]\n",
    "total_col += n_column\n",
    "\n",
    "train_bagging_1.columns = ['bagging_1_' + x for x in names[:n_column]]\n",
    "test_bagging_1.columns  = ['bagging_1_' + x for x in names[:n_column]]\n",
    "\n",
    "\n",
    "print 'train_bagging_1: {}\\t test_bagging_1:{}'.\\\n",
    "        format(train_bagging_0.shape,test_bagging_0.shape)\n",
    "    \n",
    "print '\\ntrain_bagging_1'\n",
    "print train_bagging_0.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "source": [
    "print total_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_2nd: (49352, 294)\t test_2nd_mean:(74659, 294)\t test_2nd_gmean:(74659, 294)\n"
     ]
    }
   ],
   "source": [
    "train_2nd      = pd.concat([train_rfc_gini, train_rfc_entropy, train_rfc_gini_0322, train_rfc_entropy_0322, \n",
    "                            train_LR, train_LR_0322, \n",
    "                            train_ET_gini, train_ET_entropy, train_ET_gini_0322, train_ET_entropy_0322,\n",
    "                            train_KNN_uniform, train_KNN_distance, train_KNN_uniform_0322, train_KNN_distance_0322,\n",
    "                            train_FM,train_FM_0322,\n",
    "                            train_MNB,\n",
    "                            train_tsne, train_tsne_0322,\n",
    "                            train_xgb, train_xgb_0322, train_xgb_0331,train_xgb_0331_30fold, train_xgb_cv137,\n",
    "                            train_xgb_cv137_1,train_xgb_cv_price,train_xgb_cv_MS_52571,train_xgb_cv_MS_52571_30fold,\n",
    "                            train_xgb_ovr_0322,\n",
    "                            train_lgb_0322, train_lgb_dart_0322, train_lgb_0331, train_lgb_0401,\n",
    "                            train_nn_0331, train_nn_0331_1,\n",
    "                            train_nn_ovr_0331,train_nn_bagging,\n",
    "                            train_gp,\n",
    "                            train_bagging_0,train_bagging_1\n",
    "                           ], axis = 1)\n",
    "\n",
    "test_2nd_mean  = pd.concat([test_rfc_gini_mean,test_rfc_entropy_mean, test_rfc_gini_mean_0322,test_rfc_entropy_mean_0322, \n",
    "                            test_LR_mean, test_LR_mean_0322, \n",
    "                            test_ET_gini_mean, test_ET_entropy_mean,test_ET_gini_mean_0322, test_ET_entropy_mean_0322,\n",
    "                            test_KNN_uniform_mean, test_KNN_distance_mean, test_KNN_uniform_mean_0322, test_KNN_distance_mean_0322, \n",
    "                            test_FM_mean,test_FM_mean_0322,\n",
    "                            test_MNB_mean,\n",
    "                            test_tsne, test_tsne_0322,\n",
    "                            test_xgb_mean, test_xgb_mean_0322, test_xgb_mean_0331,test_xgb_mean_0331_30fold, test_xgb_mean_cv137,\n",
    "                            test_xgb_mean_cv137_1,test_xgb_mean_cv_price,test_xgb_mean_cv_MS_52571,test_xgb_mean_cv_MS_52571_30fold,\n",
    "                            test_xgb_mean_ovr_0322,\n",
    "                            test_lgb_mean_0322, test_lgb_mean_dart_0322, test_lgb_mean_0331, test_lgb_mean_0401,\n",
    "                            test_nn_mean_0331, test_nn_mean_0331_1,\n",
    "                            test_nn_mean_ovr_0331,test_nn_mean_bagging,\n",
    "                            test_gp,\n",
    "                            test_bagging_0,test_bagging_1\n",
    "                           ], axis = 1)\n",
    "\n",
    "test_2nd_gmean = pd.concat([test_rfc_gini_gmean,test_rfc_entropy_gmean, test_rfc_gini_gmean_0322,test_rfc_entropy_gmean_0322, \n",
    "                            test_LR_gmean, test_LR_gmean_0322, \n",
    "                            test_ET_gini_gmean, test_ET_entropy_gmean,test_ET_gini_gmean_0322, test_ET_entropy_gmean_0322,\n",
    "                            test_KNN_uniform_gmean, test_KNN_distance_gmean,test_KNN_uniform_gmean_0322, test_KNN_distance_gmean_0322,\n",
    "                            test_FM_gmean,test_FM_gmean_0322,\n",
    "                            test_MNB_gmean,\n",
    "                            test_tsne, test_tsne_0322,\n",
    "                            test_xgb_gmean, test_xgb_gmean_0322, test_xgb_gmean_0331,test_xgb_gmean_0331_30fold,test_xgb_gmean_cv137,\n",
    "                            test_xgb_gmean_cv137_1,test_xgb_gmean_cv_price,test_xgb_gmean_cv_MS_52571,test_xgb_gmean_cv_MS_52571_30fold,\n",
    "                            test_xgb_gmean_ovr_0322,\n",
    "                            test_lgb_gmean_0322, test_lgb_gmean_dart_0322, test_lgb_gmean_0331, test_lgb_gmean_0401,\n",
    "                            test_nn_mean_0331, test_nn_mean_0331_1,\n",
    "                            test_nn_mean_ovr_0331,test_nn_mean_bagging,\n",
    "                            test_gp,\n",
    "                            test_bagging_0,test_bagging_1\n",
    "                           ], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "print 'train_2nd: {}\\t test_2nd_mean:{}\\t test_2nd_gmean:{}'.\\\n",
    "            format(train_2nd.shape,test_2nd_mean.shape,test_2nd_gmean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.50526158 -0.49955678 -0.50480861 -0.51607368 -0.52987751]\n",
      "-0.511115632196\n",
      "Spend:  369.177999973\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "rgr = AdaBoostClassifier(ExtraTreesClassifier(n_estimators=1200,n_jobs= -1),\n",
    "                         n_estimators=500)\n",
    "score = cross_val_score(rgr,train_2nd,train_y, scoring = 'neg_log_loss', cv = 5)\n",
    "print score\n",
    "print score.mean()\n",
    "\n",
    "print \"Spend: \", time.time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[-0.50775021 -0.49745357 -0.50441943 -0.51649159 -0.52709206]\n",
    "-0.510641370222\n",
    "Spend:  352.347000122\n",
    "1200,600\n",
    "\n",
    "[-0.50749077 -0.50205757 -0.50073885 -0.51603436 -0.5246598 ]\n",
    "-0.510196268529\n",
    "Spend:  362.513999939\n",
    "1200,500\n",
    "\n",
    "[-0.50979433 -0.49956016 -0.50438662 -0.51367212 -0.53083096]\n",
    "-0.511648839804\n",
    "Spend:  313.575999975\n",
    "1000,500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.50342845 -0.50356766 -0.5030179  -0.51780238 -0.52634812]\n",
      "-0.510832902076\n",
      "Spend:  291.55700016\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "rgr = AdaBoostClassifier(ExtraTreesClassifier(n_estimators=1000,n_jobs= -1),\n",
    "                         n_estimators=500)\n",
    "score = cross_val_score(rgr,train_2nd,train_y, scoring = 'neg_log_loss', cv = 5)\n",
    "print score\n",
    "print score.mean()\n",
    "\n",
    "print \"Spend: \", time.time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.50818233 -0.49971288 -0.50832876 -0.51529011 -0.52641725]\n",
      "-0.511586267565\n",
      "Spend:  287.046999931\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "rgr = AdaBoostClassifier(ExtraTreesClassifier(n_estimators=1000,n_jobs= -1),\n",
    "                         n_estimators=800)\n",
    "score = cross_val_score(rgr,train_2nd,train_y, scoring = 'neg_log_loss', cv = 5)\n",
    "print score\n",
    "print score.mean()\n",
    "\n",
    "print \"Spend: \", time.time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ET_blend(est, train_x, train_y, test_x, fold,randomseed):\n",
    "    N_params = len(est)\n",
    "#     print \"Blend %d estimators for %d folds\" % (N_params, fold)\n",
    "    skf = KFold(n_splits=fold,shuffle=True,random_state=randomseed)\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros((fold,N_params))\n",
    "    best_rounds = np.zeros((fold, N_params))    \n",
    "    \n",
    "    for j, ester in enumerate(est):\n",
    "#         print \"Model %d:\" %(j+1)\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "\n",
    "            \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "#             print \"Model %d fold %d\" %(j+1,i+1)\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]            \n",
    "            \n",
    "\n",
    "            ester.fit(train_x_fold,train_y_fold)\n",
    "            \n",
    "            val_y_predict_fold = ester.predict_proba(val_x_fold)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "#             print \"Score: \", score\n",
    "            scores[i,j]=score            \n",
    "            \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = ester.predict_proba(test_x)\n",
    "            \n",
    "#             print \"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start)            \n",
    "\n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "\n",
    "            \n",
    "#         print \"Score for model %d is %f\" % (j+1,np.mean(scores[:,j]))\n",
    "    print \"Score for blended models is %f\" % (np.mean(scores))\n",
    "    return (train_blend_x, test_blend_x_mean, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for blended models is 0.507740\n",
      "Score for blended models is 0.507000\n",
      "Score for blended models is 0.508361\n",
      "Score for blended models is 0.510161\n",
      "Score for blended models is 0.509860\n",
      "Score for blended models is 0.506445\n",
      "Score for blended models is 0.507865\n",
      "Score for blended models is 0.507746\n",
      "Score for blended models is 0.509064\n",
      "Score for blended models is 0.508519\n",
      "Score for blended models is 0.509390\n",
      "Score for blended models is 0.509068\n",
      "Score for blended models is 0.505901\n",
      "Score for blended models is 0.508768\n",
      "Score for blended models is 0.509769\n",
      "Score for blended models is 0.508336\n",
      "Score for blended models is 0.506088\n",
      "Score for blended models is 0.508967\n",
      "Score for blended models is 0.509667\n",
      "Score for blended models is 0.508485\n",
      "Score for blended models is 0.506718\n",
      "Score for blended models is 0.507781\n",
      "Score for blended models is 0.508561\n",
      "Score for blended models is 0.508188\n",
      "Score for blended models is 0.509026\n",
      "Score for blended models is 0.508212\n",
      "Score for blended models is 0.506153\n",
      "Score for blended models is 0.507882\n",
      "Score for blended models is 0.507651\n",
      "Score for blended models is 0.509562\n",
      "Score for blended models is 0.507729\n",
      "Score for blended models is 0.507907\n",
      "Score for blended models is 0.507747\n",
      "Score for blended models is 0.507626\n",
      "Score for blended models is 0.507565\n",
      "Score for blended models is 0.508320\n",
      "Score for blended models is 0.509536\n",
      "Score for blended models is 0.506693\n",
      "Score for blended models is 0.508166\n",
      "Score for blended models is 0.508229\n",
      "Score for blended models is 0.509105\n",
      "Score for blended models is 0.508340\n",
      "Score for blended models is 0.509298\n",
      "Score for blended models is 0.509506\n",
      "Score for blended models is 0.509826\n",
      "Score for blended models is 0.506529\n",
      "Score for blended models is 0.511783\n",
      "Score for blended models is 0.508422\n",
      "Score for blended models is 0.508449\n",
      "Score for blended models is 0.507955\n",
      "Score for blended models is 0.509748\n",
      "Score for blended models is 0.506529\n",
      "Score for blended models is 0.508410\n",
      "Score for blended models is 0.508942\n",
      "Score for blended models is 0.508663\n",
      "Score for blended models is 0.509046\n",
      "Score for blended models is 0.507731\n",
      "Score for blended models is 0.508273\n",
      "Score for blended models is 0.508004\n",
      "Score for blended models is 0.509224\n",
      "Score for blended models is 0.509036\n",
      "Score for blended models is 0.508486\n",
      "Score for blended models is 0.510787\n",
      "Score for blended models is 0.508082\n",
      "Score for blended models is 0.508235\n",
      "Score for blended models is 0.508730\n",
      "Score for blended models is 0.509054\n",
      "Score for blended models is 0.508241\n",
      "Score for blended models is 0.508087\n",
      "Score for blended models is 0.509093\n",
      "Score for blended models is 0.508568\n",
      "Score for blended models is 0.508011\n",
      "Score for blended models is 0.508102\n",
      "Score for blended models is 0.506258\n",
      "Score for blended models is 0.509997\n",
      "Score for blended models is 0.507465\n",
      "Score for blended models is 0.508654\n",
      "Score for blended models is 0.507956\n",
      "Score for blended models is 0.507384\n",
      "Score for blended models is 0.507397\n",
      "Score for blended models is 0.508997\n",
      "Score for blended models is 0.507110\n",
      "Score for blended models is 0.507828\n",
      "Score for blended models is 0.508776\n",
      "Score for blended models is 0.508023\n",
      "Score for blended models is 0.507472\n",
      "Score for blended models is 0.506357\n",
      "Score for blended models is 0.508268\n",
      "Score for blended models is 0.507894\n",
      "Score for blended models is 0.509231\n",
      "Score for blended models is 0.508658\n",
      "Score for blended models is 0.505718\n",
      "Score for blended models is 0.507180\n",
      "Score for blended models is 0.507547\n",
      "Score for blended models is 0.508244\n",
      "Score for blended models is 0.509593\n",
      "Score for blended models is 0.508881\n",
      "Score for blended models is 0.506940\n",
      "Score for blended models is 0.507498\n",
      "Score for blended models is 0.508963\n"
     ]
    }
   ],
   "source": [
    "train_total = np.zeros((train_2nd.shape[0], 3))\n",
    "test_total = np.zeros((test_2nd_mean.shape[0], 3))\n",
    "score_total = 0\n",
    "count = 100\n",
    "for n in range(count):\n",
    "    randomseed = n\n",
    "    est = [AdaBoostClassifier(ExtraTreesClassifier(n_estimators=1200,n_jobs= -1), n_estimators=500)]\n",
    "    (train_blend_2nd_ADET,\n",
    "     test_blend_2nd_ADET,\n",
    "     blend_scores_2nd_ADET,\n",
    "     best_rounds_2nd_ADET) = ET_blend(est,\n",
    "                                 train_2nd,train_y,\n",
    "                                 test_2nd_mean,\n",
    "                                 10,randomseed)\n",
    "    train_total += train_blend_2nd_ADET\n",
    "    test_total += test_blend_2nd_ADET\n",
    "    score_total += np.mean(blend_scores_2nd_ADET)\n",
    "    \n",
    "train_total = train_total / count\n",
    "test_total = test_total / count\n",
    "score_total = score_total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508270316689\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_2ndADET_100bagging_0413_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_2ndADET_100bagging_0413_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print score_total\n",
    "# print (np.mean(best_rounds_RFC,axis=0))\n",
    "np.savetxt(name_train_blend,train_total, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_total, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_X = pd.read_csv(\"../input/\" + 'test_BM_MB_add03052240.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_2ndADET_100bagging_0413_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_total[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
