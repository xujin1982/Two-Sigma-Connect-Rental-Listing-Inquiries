{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "train_df=pd.read_json('../input/train.json').reset_index(drop = True)\n",
    "test_df=pd.read_json('../input/test.json').reset_index(drop = True)\n",
    "\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 322)\n",
      "(74659, 322)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X_0322 = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X_0322 = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "\n",
    "print train_X_0322.shape\n",
    "print test_X_0322.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_num_map = {'high':2, 'medium':1, 'low':0}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_CV_MS_52571.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_CV_MS_52571.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 223)\n",
      "(74659, 223)\n"
     ]
    }
   ],
   "source": [
    "time_feature = pd.read_csv(data_path + 'listing_image_time.csv')\n",
    "time_feature.columns = ['listing_id','time_stamp']\n",
    "train_X = train_X.merge(time_feature,on='listing_id',how='left')\n",
    "test_X = test_X.merge(time_feature,on='listing_id',how='left')\n",
    "\n",
    "print train_X.shape\n",
    "print test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 223)\n",
      "(9871, 223)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "\n",
    "# import sys  \n",
    "# stdi,stdo,stde=sys.stdin,sys.stdout,sys.stderr\n",
    "# reload(sys)  \n",
    "# sys.stdin,sys.stdout,sys.stderr=stdi,stdo,stde\n",
    "# sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[25]\tvalid_0's multi_logloss: 0.588823\n",
      "[50]\tvalid_0's multi_logloss: 0.538591\n",
      "[75]\tvalid_0's multi_logloss: 0.524487\n",
      "[100]\tvalid_0's multi_logloss: 0.517198\n",
      "[125]\tvalid_0's multi_logloss: 0.51425\n",
      "[150]\tvalid_0's multi_logloss: 0.512217\n",
      "[175]\tvalid_0's multi_logloss: 0.510664\n",
      "[200]\tvalid_0's multi_logloss: 0.509768\n",
      "[225]\tvalid_0's multi_logloss: 0.509511\n",
      "[250]\tvalid_0's multi_logloss: 0.509082\n",
      "[275]\tvalid_0's multi_logloss: 0.509147\n",
      "[300]\tvalid_0's multi_logloss: 0.50957\n",
      "[325]\tvalid_0's multi_logloss: 0.509903\n",
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's multi_logloss: 0.508955\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.set_params(learning_rate = 0.1)\n",
    "clf.set_params(subsample_freq = 1)\n",
    "clf.set_params(objective = 'multiclass')\n",
    "clf.set_params(n_estimators = 100000)\n",
    "        \n",
    "clf = clf.fit(X_train, y_train,\n",
    "              eval_set = [(X_val,y_val)],\n",
    "              eval_metric = 'multi_logloss',\n",
    "              early_stopping_rounds = 50,\n",
    "              verbose = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14490733,  0.62461861,  0.23047406],\n",
       "       [ 0.95660061,  0.03789534,  0.00550405],\n",
       "       [ 0.8776459 ,  0.11560843,  0.00674567],\n",
       "       ..., \n",
       "       [ 0.7207035 ,  0.23590706,  0.04338944],\n",
       "       [ 0.10608034,  0.45213807,  0.44178159],\n",
       "       [ 0.96449493,  0.03358761,  0.00191746]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = clf.predict_proba(test_X, num_iteration = clf.best_iteration)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "# sub_name = '../output/sub_LightGBM_BM_0322_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "# out_df = pd.DataFrame(pred_y[:,:3])\n",
    "# out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "# out_df[\"listing_id\"] = sub_id\n",
    "# out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.set_params(learning_rate = 0.1)\n",
    "clf.set_params(subsample_freq = 1)\n",
    "clf.set_params(objective = 'multiclass')\n",
    "clf.set_params(n_estimators = 100000)\n",
    "\n",
    "tmp  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  \t0.510622313281 751\n",
      "15  \t0.510599053691 445\n",
      "31  \t0.508955275492 286\n",
      "63  \t0.509733744621 157\n",
      "127  \t0.512473910556 105\n",
      "255  \t0.52244729458 69\n"
     ]
    }
   ],
   "source": [
    "for x in [8,15,31,63,127,255]:\n",
    "    clf.set_params(num_leaves = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        num_leaves = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=31,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print num_leaves\n",
    "clf.set_params(num_leaves = num_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20  \t0.508801127766 300\n",
      "30  \t0.510046803883 237\n",
      "50  \t0.508428019615 253\n",
      "70  \t0.50986653128 217\n",
      "80  \t0.507873251903 313\n",
      "90  \t0.50960123034 250\n",
      "100  \t0.508001037864 245\n",
      "110  \t0.507422421625 269\n",
      "120  \t0.508982438783 290\n",
      "150  \t0.507776221775 246\n",
      "170  \t0.507834646192 259\n",
      "200  \t0.508524307346 241\n",
      "230  \t0.508264263442 293\n",
      "260  \t0.509057569341 204\n"
     ]
    }
   ],
   "source": [
    "min_child_samples = 10\n",
    "\n",
    "for x in [20, 30, 50, 70, 80,90,100,110,120,150,170,200,230,260]:\n",
    "    clf.set_params(min_child_samples = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        min_child_samples = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300  \t0.509475978131 280\n",
      "350  \t0.508225751106 235\n",
      "400  \t0.508510220635 265\n",
      "450  \t0.509242192358 227\n",
      "500  \t0.510873003257 266\n"
     ]
    }
   ],
   "source": [
    "for x in [300,350,400,450,500]:\n",
    "    clf.set_params(min_child_samples = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        min_child_samples = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=110, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=31,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print min_child_samples\n",
    "clf.set_params(min_child_samples = min_child_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2  \t0.507058612673 325\n",
      "0.3  \t0.505958981181 285\n",
      "0.4  \t0.507203992338 313\n",
      "0.5  \t0.505348103064 324\n",
      "0.6  \t0.508285337677 334\n",
      "0.7  \t0.507455853861 298\n",
      "0.8  \t0.509746019328 237\n",
      "0.9  \t0.507877264001 270\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = 1\n",
    "for x in [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    clf.set_params(colsample_bytree = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        colsample_bytree = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.5, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=110, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=31,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print colsample_bytree\n",
    "\n",
    "clf.set_params(colsample_bytree = colsample_bytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5  \t0.514180096443 257\n",
      "0.6  \t0.511188112068 280\n",
      "0.7  \t0.509958029638 271\n",
      "0.8  \t0.509227886965 256\n",
      "0.9  \t0.507082987952 315\n"
     ]
    }
   ],
   "source": [
    "subsample = 1.0\n",
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    clf.set_params(subsample = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        subsample = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.5, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=110, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=31,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1.0, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print subsample\n",
    "clf.set_params(subsample = subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15  \t0.514500520046 259\n",
      "31  \t0.509383120011 305\n",
      "63  \t0.507052514588 283\n",
      "127  \t0.50902541054 250\n",
      "511  \t0.506975171613 256\n",
      "1023  \t0.507322946675 257\n",
      "2047  \t0.50721377153 300\n"
     ]
    }
   ],
   "source": [
    "max_bin = 255\n",
    "\n",
    "for x in [15,31,63, 127, 511, 1023, 2047]: #[200,300,400]:#\n",
    "    clf.set_params(max_bin = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        max_bin = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150  \t0.50844991167 287\n",
      "200  \t0.508507936091 253\n",
      "300  \t0.507923013597 317\n",
      "350  \t0.507106259968 275\n",
      "400  \t0.506939260004 257\n"
     ]
    }
   ],
   "source": [
    "for x in [150,200,300,350,400]:\n",
    "    clf.set_params(max_bin = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        max_bin = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550  \t0.508498522582 263\n",
      "600  \t0.507616451545 288\n",
      "650  \t0.50817674737 266\n",
      "700  \t0.508281832035 236\n",
      "750  \t0.507573919401 291\n",
      "800  \t0.506912912043 294\n"
     ]
    }
   ],
   "source": [
    "for x in [550,600,650, 700,750,800]:\n",
    "    clf.set_params(max_bin = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        max_bin = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.5, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=110, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=31,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1.0, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print max_bin\n",
    "clf.set_params(max_bin = max_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "    1 | 02m15s | \u001b[35m  -0.51984\u001b[0m | \u001b[32m            0.2696\u001b[0m | \u001b[32m 453.5988\u001b[0m | \u001b[32m           148.6024\u001b[0m | \u001b[32m     84.7992\u001b[0m | \u001b[32m     0.9807\u001b[0m | \n",
      "    2 | 01m29s |   -0.52106 |             0.2047 |  185.9080 |             89.7965 |      79.6393 |      0.9058 | \n",
      "    3 | 02m30s |   -0.52396 |             0.2121 |  195.1548 |            112.2907 |     116.8766 |      0.8611 | \n",
      "    4 | 01m52s |   -0.52125 |             0.5756 |  234.2694 |            161.3905 |      82.9552 |      0.8089 | \n",
      "    5 | 02m12s | \u001b[35m  -0.51947\u001b[0m | \u001b[32m            0.4735\u001b[0m | \u001b[32m 308.4164\u001b[0m | \u001b[32m           198.0203\u001b[0m | \u001b[32m     68.6747\u001b[0m | \u001b[32m     0.8521\u001b[0m | \n",
      "    6 | 01m54s |   -0.51991 |             0.3404 |  434.3878 |            118.9480 |      62.1921 |      0.8476 | \n",
      "    7 | 02m18s |   -0.52134 |             0.6440 |  244.6533 |             89.8923 |      81.1865 |      0.9984 | \n",
      "    8 | 03m03s |   -0.52017 |             0.4639 |  466.3789 |             89.5699 |      70.5033 |      0.8212 | \n",
      "    9 | 02m22s | \u001b[35m  -0.51908\u001b[0m | \u001b[32m            0.6418\u001b[0m | \u001b[32m 215.3157\u001b[0m | \u001b[32m            74.1774\u001b[0m | \u001b[32m     68.5371\u001b[0m | \u001b[32m     0.8897\u001b[0m | \n",
      "   10 | 01m33s | \u001b[35m  -0.51829\u001b[0m | \u001b[32m            0.3529\u001b[0m | \u001b[32m 140.6032\u001b[0m | \u001b[32m           139.9541\u001b[0m | \u001b[32m     48.0527\u001b[0m | \u001b[32m     0.8837\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "   11 | 02m15s |   -0.51941 |             0.2039 |  509.2355 |            179.5255 |      19.9669 |      0.9249 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -8.49206404e-05]), 'nit': 7, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.22640145e-05]), 'nit': 4, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.56249016e-05]), 'nit': 6, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 02m47s | \u001b[35m  -0.51724\u001b[0m | \u001b[32m            0.3303\u001b[0m | \u001b[32m 149.8989\u001b[0m | \u001b[32m            72.4408\u001b[0m | \u001b[32m     17.7380\u001b[0m | \u001b[32m     0.8735\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00011882]), 'nit': 6, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00035343]), 'nit': 6, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 02m05s |   -0.51876 |             0.3449 |  202.5646 |            197.6180 |      21.1409 |      0.9445 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00040819]), 'nit': 3, 'funcalls': 46}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00020288]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00028026]), 'nit': 2, 'funcalls': 45}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 02m38s |   -0.51897 |             0.6535 |  179.2739 |             72.1150 |      16.9902 |      0.9282 | \n",
      "   15 | 02m23s |   -0.51731 |             0.4360 |  305.3458 |             70.4679 |      16.6436 |      0.8941 | \n",
      "   16 | 03m10s |   -0.51816 |             0.5796 |  138.5868 |            188.4178 |      46.6201 |      0.9784 | \n",
      "   17 | 01m56s |   -0.51834 |             0.2207 |  133.6819 |            131.8981 |      20.1165 |      0.9064 | \n",
      "   18 | 01m35s |   -0.52034 |             0.2316 |  133.9744 |             73.2643 |      39.4984 |      0.8586 | \n",
      "   19 | 02m49s |   -0.51954 |             0.6212 |  420.9165 |            197.2228 |      17.2634 |      0.8751 | \n",
      "   20 | 03m09s |   -0.51812 |             0.3611 |  414.6929 |             70.3574 |      24.6119 |      0.9383 | \n",
      "   21 | 03m34s |   -0.52259 |             0.6633 |  419.9823 |             70.0671 |     126.5746 |      0.9258 | \n",
      "   22 | 02m38s |   -0.51891 |             0.4223 |  496.0241 |             89.3799 |      20.3497 |      0.9081 | \n",
      "   23 | 01m59s |   -0.52092 |             0.3230 |  494.2164 |            196.1145 |     115.4506 |      0.8400 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.98622107e-05]), 'nit': 5, 'funcalls': 57}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -7.18197233e-05]), 'nit': 5, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 04m11s |   -0.51982 |             0.6629 |  336.1426 |             79.7485 |      16.3997 |      0.9399 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  8.70176009e-05]), 'nit': 5, 'funcalls': 61}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 01m43s |   -0.51999 |             0.4739 |  162.5283 |            195.4038 |     126.6713 |      0.9867 | \n",
      "   26 | 02m06s |   -0.51793 |             0.5297 |  226.2377 |             72.3611 |      15.0273 |      0.9315 | \n",
      "   27 | 02m49s |   -0.51841 |             0.3509 |  280.6198 |             72.6335 |      22.1573 |      0.9398 | \n",
      "   28 | 01m49s |   -0.51933 |             0.2206 |  392.8786 |            199.5551 |      69.7294 |      0.9912 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00105749]), 'nit': 4, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 02m25s |   -0.52126 |             0.5859 |  282.0271 |            194.5213 |     116.2780 |      0.9746 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00020344]), 'nit': 6, 'funcalls': 57}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 01m35s |   -0.51770 |             0.3235 |  165.9935 |            181.3839 |      47.9315 |      0.9002 | \n",
      "   31 | 02m58s |   -0.51846 |             0.3318 |  466.5652 |             75.9761 |      21.9407 |      0.9581 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00217028]), 'nit': 5, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 02m10s |   -0.51897 |             0.6926 |  161.9012 |            155.1353 |      51.5838 |      0.9390 | \n",
      "   33 | 02m15s |   -0.51920 |             0.2695 |  449.2952 |            196.1942 |      61.5250 |      0.8778 | \n",
      "   34 | 03m36s |   -0.52256 |             0.6963 |  508.0199 |             73.3694 |     118.5023 |      0.9655 | \n",
      "   35 | 02m00s |   -0.51856 |             0.3360 |  195.0799 |            194.4718 |      62.0153 |      0.9848 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00107522]), 'nit': 5, 'funcalls': 59}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 02m00s |   -0.51784 |             0.2664 |  152.5018 |            170.0339 |      25.0632 |      0.8795 | \n",
      "   37 | 02m30s |   -0.51977 |             0.4207 |  438.3189 |            149.2793 |      17.8988 |      0.9311 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00168772]), 'nit': 4, 'funcalls': 59}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   38 | 02m47s |   -0.51813 |             0.6632 |  142.8504 |            194.8516 |      20.3053 |      0.9043 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00167723]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 02m28s |   -0.52006 |             0.5692 |  370.7397 |            193.7954 |     118.9099 |      0.9159 | \n",
      "   40 | 02m33s |   -0.52069 |             0.2700 |  131.0887 |            199.2556 |      79.2522 |      0.8067 | \n",
      "   41 | 01m24s |   -0.51952 |             0.2348 |  133.8214 |            161.4403 |      31.6986 |      0.8055 | \n",
      "   42 | 02m30s |   -0.51916 |             0.5266 |  327.4980 |            182.1242 |      26.7996 |      0.9831 | \n",
      "   43 | 01m55s |   -0.51826 |             0.3772 |  183.3714 |            137.9335 |      20.2016 |      0.8503 | \n",
      "   44 | 02m30s |   -0.51902 |             0.3446 |  171.9214 |             99.4287 |      16.7945 |      0.9639 | \n",
      "   45 | 03m07s |   -0.51826 |             0.3943 |  149.4050 |            199.1900 |      39.1987 |      0.8583 | \n",
      "   46 | 02m45s |   -0.51859 |             0.4529 |  265.4177 |            160.5125 |      15.3743 |      0.8353 | \n",
      "   47 | 03m13s |   -0.52098 |             0.6557 |  413.9109 |            199.7558 |     113.8973 |      0.9666 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00093492]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 03m05s | \u001b[35m  -0.51676\u001b[0m | \u001b[32m            0.4170\u001b[0m | \u001b[32m 150.3986\u001b[0m | \u001b[32m            86.0221\u001b[0m | \u001b[32m     16.1275\u001b[0m | \u001b[32m     0.8598\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.74070063e-05]), 'nit': 6, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 02m45s |   -0.52063 |             0.5935 |  316.0501 |            196.7603 |      18.5986 |      0.9865 | \n",
      "   50 | 02m04s |   -0.51855 |             0.4869 |  507.4570 |            149.6155 |      47.6210 |      0.9752 | \n"
     ]
    }
   ],
   "source": [
    "def lgbm_cv(max_bin, num_leaves, min_child_samples, colsample_bytree, subsample, learning_rate=0.1):\n",
    "    skf = KFold(n_splits=5,random_state=seed)\n",
    "    scores=[]\n",
    "    for i, (train, val) in enumerate(skf.split(train_X)):\n",
    "        est=lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                               max_bin=int(max_bin),\n",
    "                               num_leaves=int(num_leaves),\n",
    "                               min_child_samples=int(min_child_samples),\n",
    "                               colsample_bytree=colsample_bytree,\n",
    "                               subsample=subsample,\n",
    "                               subsample_freq = 1\n",
    "                              )\n",
    " \n",
    "        train_x_fold = train_X.iloc[train]\n",
    "        train_y_fold = train_y[train]\n",
    "        val_x_fold = train_X.iloc[val]\n",
    "        val_y_fold = train_y[val]\n",
    "        est.set_params( n_estimators=100000)\n",
    "        est.fit(train_x_fold,\n",
    "                train_y_fold,\n",
    "                eval_set=[(val_x_fold, val_y_fold)],\n",
    "                eval_metric='multi_logloss',\n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False\n",
    "               )\n",
    "        val_y_predict_fold = est.predict_proba(val_x_fold,num_iteration=est.best_iteration)\n",
    "        score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "        scores.append(score)\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "lgbm_BO = BayesianOptimization(lgbm_cv, \n",
    "                               {\n",
    "                                'max_bin': (127,511),\n",
    "                                'num_leaves': (15,127),\n",
    "                                'min_child_samples' :(70,200),\n",
    "                                'colsample_bytree': (0.2,0.7),\n",
    "                                'subsample' : (0.8,1)})\n",
    "\n",
    "lgbm_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>max_bin</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16.127511</td>\n",
       "      <td>86.022102</td>\n",
       "      <td>150.398557</td>\n",
       "      <td>0.416957</td>\n",
       "      <td>0.859761</td>\n",
       "      <td>-0.516757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.737979</td>\n",
       "      <td>72.440783</td>\n",
       "      <td>149.898851</td>\n",
       "      <td>0.330273</td>\n",
       "      <td>0.873543</td>\n",
       "      <td>-0.517244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.643581</td>\n",
       "      <td>70.467945</td>\n",
       "      <td>305.345802</td>\n",
       "      <td>0.436046</td>\n",
       "      <td>0.894116</td>\n",
       "      <td>-0.517307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>47.931491</td>\n",
       "      <td>181.383895</td>\n",
       "      <td>165.993511</td>\n",
       "      <td>0.323495</td>\n",
       "      <td>0.900225</td>\n",
       "      <td>-0.517696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.063164</td>\n",
       "      <td>170.033934</td>\n",
       "      <td>152.501751</td>\n",
       "      <td>0.266445</td>\n",
       "      <td>0.879513</td>\n",
       "      <td>-0.517844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.027258</td>\n",
       "      <td>72.361097</td>\n",
       "      <td>226.237672</td>\n",
       "      <td>0.529690</td>\n",
       "      <td>0.931497</td>\n",
       "      <td>-0.517932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24.611915</td>\n",
       "      <td>70.357354</td>\n",
       "      <td>414.692930</td>\n",
       "      <td>0.361137</td>\n",
       "      <td>0.938300</td>\n",
       "      <td>-0.518121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20.305277</td>\n",
       "      <td>194.851596</td>\n",
       "      <td>142.850370</td>\n",
       "      <td>0.663189</td>\n",
       "      <td>0.904251</td>\n",
       "      <td>-0.518133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46.620119</td>\n",
       "      <td>188.417768</td>\n",
       "      <td>138.586753</td>\n",
       "      <td>0.579620</td>\n",
       "      <td>0.978396</td>\n",
       "      <td>-0.518157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>39.198748</td>\n",
       "      <td>199.190016</td>\n",
       "      <td>149.404955</td>\n",
       "      <td>0.394342</td>\n",
       "      <td>0.858294</td>\n",
       "      <td>-0.518260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  min_child_samples     max_bin  colsample_bytree  subsample  \\\n",
       "37   16.127511          86.022102  150.398557          0.416957   0.859761   \n",
       "1    17.737979          72.440783  149.898851          0.330273   0.873543   \n",
       "4    16.643581          70.467945  305.345802          0.436046   0.894116   \n",
       "19   47.931491         181.383895  165.993511          0.323495   0.900225   \n",
       "25   25.063164         170.033934  152.501751          0.266445   0.879513   \n",
       "15   15.027258          72.361097  226.237672          0.529690   0.931497   \n",
       "9    24.611915          70.357354  414.692930          0.361137   0.938300   \n",
       "27   20.305277         194.851596  142.850370          0.663189   0.904251   \n",
       "5    46.620119         188.417768  138.586753          0.579620   0.978396   \n",
       "34   39.198748         199.190016  149.404955          0.394342   0.858294   \n",
       "\n",
       "       score  \n",
       "37 -0.516757  \n",
       "1  -0.517244  \n",
       "4  -0.517307  \n",
       "19 -0.517696  \n",
       "25 -0.517844  \n",
       "15 -0.517932  \n",
       "9  -0.518121  \n",
       "27 -0.518133  \n",
       "5  -0.518157  \n",
       "34 -0.518260  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_bo_scores = pd.DataFrame([[s[0]['num_leaves'],\n",
    "                               s[0]['min_child_samples'],\n",
    "                               s[0]['max_bin'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[1]] for s in zip(lgbm_BO.res['all']['params'],lgbm_BO.res['all']['values'])],\n",
    "                            columns = ['num_leaves',\n",
    "                                       'min_child_samples',\n",
    "                                       'max_bin',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'score'])\n",
    "gbm_bo_scores=gbm_bo_scores.sort_values('score',ascending=False)\n",
    "gbm_bo_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgbm_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=50, randomseed = 1234):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,shuffle = True, random_state=randomseed)\n",
    "    N_class = len(set(train_y))\n",
    "\n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros((fold,N_params))\n",
    "    best_rounds = np.zeros((fold, N_params))    \n",
    "\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(learning_rate = 0.01)\n",
    "        est.set_params(subsample_freq = 1)\n",
    "        est.set_params(objective = 'multiclass')\n",
    "        est.set_params(n_estimators = 100000)\n",
    "\n",
    "        \n",
    "#         print (\"Model %d: %s\" %(j+1, est)) \n",
    "\n",
    "        \n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]\n",
    "            \n",
    "            est.fit(train_x_fold, train_y_fold,\n",
    "                   eval_set = [(val_x_fold,val_y_fold)],\n",
    "                   eval_metric = 'multi_logloss',\n",
    "                   early_stopping_rounds = early_stopping_rounds,\n",
    "                   verbose = False)\n",
    "            \n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            \n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,num_iteration = best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score   \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,num_iteration=best_round)\n",
    "            \n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "            \n",
    "           \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "#         test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "#                 np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "#                           gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "#                           gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print \"Score for blended models is %f\" % (np.mean(scores))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 5727\n",
      "('Score: ', 0.51204396688238618)\n",
      "Model 1 fold 1 fitting finished in 249.140s\n",
      "Model 1 fold 2\n",
      "best round 5581\n",
      "('Score: ', 0.5104832430369759)\n",
      "Model 1 fold 2 fitting finished in 218.344s\n",
      "Model 1 fold 3\n",
      "best round 5738\n",
      "('Score: ', 0.50602478747063229)\n",
      "Model 1 fold 3 fitting finished in 222.025s\n",
      "Model 1 fold 4\n",
      "best round 6407\n",
      "('Score: ', 0.51403399520257476)\n",
      "Model 1 fold 4 fitting finished in 297.210s\n",
      "Model 1 fold 5\n",
      "best round 5850\n",
      "('Score: ', 0.51980381725085945)\n",
      "Model 1 fold 5 fitting finished in 241.291s\n",
      "Score for model 1 is 0.512478\n",
      "Score for blended models is 0.512478\n",
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 5957\n",
      "('Score: ', 0.5192722189842166)\n",
      "Model 1 fold 1 fitting finished in 280.374s\n",
      "Model 1 fold 2\n",
      "best round 5151\n",
      "('Score: ', 0.52322885895018023)\n",
      "Model 1 fold 2 fitting finished in 224.218s\n",
      "Model 1 fold 3\n",
      "best round 6284\n",
      "('Score: ', 0.50965059886113395)\n",
      "Model 1 fold 3 fitting finished in 245.084s\n",
      "Model 1 fold 4\n",
      "best round 6609\n",
      "('Score: ', 0.50461099771447482)\n",
      "Model 1 fold 4 fitting finished in 219.553s\n",
      "Model 1 fold 5\n",
      "best round 5868\n",
      "('Score: ', 0.51230774184651695)\n",
      "Model 1 fold 5 fitting finished in 184.444s\n",
      "Score for model 1 is 0.513814\n",
      "Score for blended models is 0.513814\n",
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 6134\n",
      "('Score: ', 0.51254365236398769)\n",
      "Model 1 fold 1 fitting finished in 224.464s\n",
      "Model 1 fold 2\n",
      "best round 5529\n",
      "('Score: ', 0.52434594952299285)\n",
      "Model 1 fold 2 fitting finished in 185.380s\n",
      "Model 1 fold 3\n",
      "best round 7046\n",
      "('Score: ', 0.50605769699001668)\n",
      "Model 1 fold 3 fitting finished in 213.342s\n",
      "Model 1 fold 4\n",
      "best round 5467\n",
      "('Score: ', 0.51320968141617118)\n",
      "Model 1 fold 4 fitting finished in 234.852s\n",
      "Model 1 fold 5\n",
      "best round 5631\n",
      "('Score: ', 0.51714648301526556)\n",
      "Model 1 fold 5 fitting finished in 185.117s\n",
      "Score for model 1 is 0.514661\n",
      "Score for blended models is 0.514661\n",
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 6089\n",
      "('Score: ', 0.52136212197412379)\n",
      "Model 1 fold 1 fitting finished in 193.045s\n",
      "Model 1 fold 2\n",
      "best round 6106\n",
      "('Score: ', 0.51239992418895497)\n",
      "Model 1 fold 2 fitting finished in 223.795s\n",
      "Model 1 fold 3\n",
      "best round 6440\n",
      "('Score: ', 0.50170725490946821)\n",
      "Model 1 fold 3 fitting finished in 197.173s\n",
      "Model 1 fold 4\n",
      "best round 5925\n",
      "('Score: ', 0.51658468688830195)\n",
      "Model 1 fold 4 fitting finished in 186.830s\n",
      "Model 1 fold 5\n",
      "best round 5709\n",
      "('Score: ', 0.51850359376792066)\n",
      "Model 1 fold 5 fitting finished in 217.107s\n",
      "Score for model 1 is 0.514112\n",
      "Score for blended models is 0.514112\n",
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 5643\n",
      "('Score: ', 0.50904577046651522)\n",
      "Model 1 fold 1 fitting finished in 253.895s\n",
      "Model 1 fold 2\n",
      "best round 5779\n",
      "('Score: ', 0.51634213947067298)\n",
      "Model 1 fold 2 fitting finished in 176.742s\n",
      "Model 1 fold 3\n",
      "best round 6309\n",
      "('Score: ', 0.50886878418168902)\n",
      "Model 1 fold 3 fitting finished in 233.107s\n",
      "Model 1 fold 4\n",
      "best round 5167\n",
      "('Score: ', 0.52390244357032034)\n",
      "Model 1 fold 4 fitting finished in 161.433s\n",
      "Model 1 fold 5\n",
      "best round 5651\n",
      "('Score: ', 0.50568620151584875)\n",
      "Model 1 fold 5 fitting finished in 179.907s\n",
      "Score for model 1 is 0.512769\n",
      "Score for blended models is 0.512769\n",
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 5734\n",
      "('Score: ', 0.51512492606910909)\n",
      "Model 1 fold 1 fitting finished in 238.867s\n",
      "Model 1 fold 2\n",
      "best round 7240\n",
      "('Score: ', 0.49984704334132346)\n",
      "Model 1 fold 2 fitting finished in 215.158s\n",
      "Model 1 fold 3\n",
      "best round 6526\n",
      "('Score: ', 0.514185937619418)\n",
      "Model 1 fold 3 fitting finished in 196.416s\n",
      "Model 1 fold 4\n",
      "best round 5439\n",
      "('Score: ', 0.52339492194194659)\n",
      "Model 1 fold 4 fitting finished in 203.153s\n",
      "Model 1 fold 5\n",
      "best round 5458\n",
      "('Score: ', 0.51224548731563313)\n",
      "Model 1 fold 5 fitting finished in 169.422s\n",
      "Score for model 1 is 0.512960\n",
      "Score for blended models is 0.512960\n",
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 6189\n",
      "('Score: ', 0.50910956665661833)\n",
      "Model 1 fold 1 fitting finished in 189.872s\n",
      "Model 1 fold 2\n",
      "best round 6089\n",
      "('Score: ', 0.52338057382802161)\n",
      "Model 1 fold 2 fitting finished in 222.482s\n",
      "Model 1 fold 3\n",
      "best round 5553\n",
      "('Score: ', 0.51979497979629707)\n",
      "Model 1 fold 3 fitting finished in 171.810s\n",
      "Model 1 fold 4\n",
      "best round 6660\n",
      "('Score: ', 0.51018949171370176)\n",
      "Model 1 fold 4 fitting finished in 199.885s\n",
      "Model 1 fold 5\n",
      "best round 5746\n",
      "('Score: ', 0.51400900806309602)\n",
      "Model 1 fold 5 fitting finished in 213.795s\n",
      "Score for model 1 is 0.515297\n",
      "Score for blended models is 0.515297\n",
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 5416\n",
      "('Score: ', 0.50951124874226483)\n",
      "Model 1 fold 1 fitting finished in 164.071s\n",
      "Model 1 fold 2\n",
      "best round 5827\n",
      "('Score: ', 0.51758216671701218)\n",
      "Model 1 fold 2 fitting finished in 174.773s\n",
      "Model 1 fold 3\n",
      "best round 6083\n",
      "('Score: ', 0.51608485159628836)\n",
      "Model 1 fold 3 fitting finished in 222.111s\n",
      "Model 1 fold 4\n",
      "best round 5917\n",
      "('Score: ', 0.50697630536971505)\n",
      "Model 1 fold 4 fitting finished in 179.686s\n",
      "Model 1 fold 5\n",
      "best round 6659\n",
      "('Score: ', 0.51358543909916932)\n",
      "Model 1 fold 5 fitting finished in 204.533s\n",
      "Score for model 1 is 0.512748\n",
      "Score for blended models is 0.512748\n",
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 7105\n",
      "('Score: ', 0.5133187312390074)\n",
      "Model 1 fold 1 fitting finished in 253.473s\n",
      "Model 1 fold 2\n",
      "best round 5570\n",
      "('Score: ', 0.51361385551032768)\n",
      "Model 1 fold 2 fitting finished in 176.295s\n",
      "Model 1 fold 3\n",
      "best round 6673\n",
      "('Score: ', 0.50962956554935468)\n",
      "Model 1 fold 3 fitting finished in 202.436s\n",
      "Model 1 fold 4\n",
      "best round 5136\n",
      "('Score: ', 0.50944449186966978)\n",
      "Model 1 fold 4 fitting finished in 197.782s\n",
      "Model 1 fold 5\n",
      "best round 5963\n",
      "('Score: ', 0.51830528514389851)\n",
      "Model 1 fold 5 fitting finished in 179.691s\n",
      "Score for model 1 is 0.512862\n",
      "Score for blended models is 0.512862\n",
      "Blend 1 estimators for 5 folds\n",
      "Model 1 fold 1\n",
      "best round 6079\n",
      "('Score: ', 0.51791935876042372)\n",
      "Model 1 fold 1 fitting finished in 182.038s\n",
      "Model 1 fold 2\n",
      "best round 6012\n",
      "('Score: ', 0.50798718583447444)\n",
      "Model 1 fold 2 fitting finished in 219.919s\n",
      "Model 1 fold 3\n",
      "best round 6309\n",
      "('Score: ', 0.50909095824935047)\n",
      "Model 1 fold 3 fitting finished in 192.901s\n",
      "Model 1 fold 4\n",
      "best round 6241\n",
      "('Score: ', 0.50116327331733701)\n",
      "Model 1 fold 4 fitting finished in 199.098s\n",
      "Model 1 fold 5\n",
      "best round 6058\n",
      "('Score: ', 0.53020042044419557)\n",
      "Model 1 fold 5 fitting finished in 227.739s\n",
      "Score for model 1 is 0.513272\n",
      "Score for blended models is 0.513272\n"
     ]
    }
   ],
   "source": [
    "train_total = np.zeros((train_X.shape[0], 3))\n",
    "test_total = np.zeros((test_X.shape[0], 3))\n",
    "name_train_blend = '../tmp/train_lightgbm.csv'\n",
    "name_test_blend = '../tmp/test_lightgbm.csv'\n",
    "score_total = 0\n",
    "count = 10\n",
    "\n",
    "for n in range(count):\n",
    "    randomseed = n + 42745\n",
    "    est =       [lgb.LGBMClassifier(num_leaves = 16,\n",
    "                                    min_child_samples = 86,\n",
    "                                    colsample_bytree = 0.416957,\n",
    "                                    subsample = 0.859761,\n",
    "                                    max_bin = 150)]\n",
    "    \n",
    "#  \t \tnum_leaves \tmin_child_samples \tmax_bin \tcolsample_bytree \tsubsample \tscore\n",
    "# 37 \t16.127511 \t86.022102 \t \t \t150.398557 \t0.416957 \t \t \t0.859761 \t-0.516757\n",
    "\n",
    "    (train_blend_x_gbm,\n",
    "     test_blend_x_gbm_mean,\n",
    "     test_blend_x_gbm_gmean,\n",
    "     blend_scores_gbm,\n",
    "     best_rounds_gbm)= lgbm_blend(est,\n",
    "                                  train_X, train_y,\n",
    "                                  test_X,\n",
    "                                  5,\n",
    "                                  300, randomseed)\n",
    "    \n",
    "    train_total += train_blend_x_gbm\n",
    "    test_total += test_blend_x_gbm_mean\n",
    "    score_total += np.mean(blend_scores_gbm)\n",
    "    \n",
    "    np.savetxt(name_train_blend,train_total, delimiter=\",\")\n",
    "    np.savetxt(name_test_blend,test_total, delimiter=\",\")\n",
    "    \n",
    "train_total = train_total / count\n",
    "test_total = test_total / count\n",
    "score_total = score_total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lightgbm = pd.DataFrame(train_total)\n",
    "train_lightgbm.columns = [\"low\", \"medium\", \"high\"]\n",
    "train_lightgbm[\"listing_id\"] = train_X.listing_id.values\n",
    "\n",
    "test_lightgbm_mean = pd.DataFrame(test_total)\n",
    "test_lightgbm_mean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_lightgbm_mean[\"listing_id\"] = test_X.listing_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_train = train_X_0322[['listing_id']].merge(train_lightgbm,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_mean = test_X_0322[['listing_id']].merge(test_lightgbm_mean,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.513497233685\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_LightGBM_last_10bagging_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_LightGBM_mean_last_10bagging_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "# name_test_blend_gmean = '../blend/test_blend_LightGBM_gmean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print score_total\n",
    "# print (np.mean(best_rounds_gbm,axis=0))\n",
    "np.savetxt(name_train_blend,tmp_train, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,tmp_test_mean, delimiter=\",\")\n",
    "# np.savetxt(name_test_blend_gmean,test_blend_x_gbm_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_LightGBM_last_10bagging_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(tmp_test_mean)\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X_0322.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508599719699\n"
     ]
    }
   ],
   "source": [
    "y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "\n",
    "print log_loss(y,tmp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
