{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 398) (74659, 398) (49352L,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_CV_statistics2.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_CV_statistics2.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'train_y_CV_statistics.csv',header=None))\n",
    "sub_id = test_X.listing_id.astype('int32').values\n",
    "\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 398)\n",
      "(9871, 398)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "\n",
    "# import sys  \n",
    "# stdi,stdo,stde=sys.stdin,sys.stdout,sys.stderr\n",
    "# reload(sys)  \n",
    "# sys.stdin,sys.stdout,sys.stderr=stdi,stdo,stde\n",
    "# sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[25]\tvalid_0's multi_logloss: 0.600748\n",
      "[50]\tvalid_0's multi_logloss: 0.553274\n",
      "[75]\tvalid_0's multi_logloss: 0.539869\n",
      "[100]\tvalid_0's multi_logloss: 0.533978\n",
      "[125]\tvalid_0's multi_logloss: 0.531351\n",
      "[150]\tvalid_0's multi_logloss: 0.528829\n",
      "[175]\tvalid_0's multi_logloss: 0.52773\n",
      "[200]\tvalid_0's multi_logloss: 0.527708\n",
      "[225]\tvalid_0's multi_logloss: 0.527244\n",
      "[250]\tvalid_0's multi_logloss: 0.527715\n",
      "[275]\tvalid_0's multi_logloss: 0.527564\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's multi_logloss: 0.527176\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.set_params(learning_rate = 0.1)\n",
    "clf.set_params(subsample_freq = 1)\n",
    "clf.set_params(objective = 'multiclass')\n",
    "clf.set_params(n_estimators = 100000)\n",
    "        \n",
    "clf = clf.fit(X_train, y_train,\n",
    "              eval_set = [(X_val,y_val)],\n",
    "              eval_metric = 'multi_logloss',\n",
    "              early_stopping_rounds = 50,\n",
    "              verbose = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[223]\tvalid_0's multi_logloss: 0.533439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.87241777e-01,   4.59754244e-01,   5.30039791e-02],\n",
       "       [  9.39061072e-01,   2.87975851e-02,   3.21413429e-02],\n",
       "       [  9.00711190e-01,   8.74221884e-02,   1.18666212e-02],\n",
       "       ..., \n",
       "       [  9.79164336e-01,   1.99874435e-02,   8.48220964e-04],\n",
       "       [  9.85101415e-01,   1.46340209e-02,   2.64564034e-04],\n",
       "       [  6.40233923e-01,   3.43340830e-01,   1.64252476e-02]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = clf.predict_proba(test_X, num_iteration = clf.best_iteration)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=31,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "# sub_name = '../output/sub_LightGBM_BM_0322_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "# out_df = pd.DataFrame(pred_y[:,:3])\n",
    "# out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "# out_df[\"listing_id\"] = sub_id\n",
    "# out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.set_params(learning_rate = 0.1)\n",
    "clf.set_params(subsample_freq = 1)\n",
    "clf.set_params(objective = 'multiclass')\n",
    "clf.set_params(n_estimators = 100000)\n",
    "\n",
    "tmp  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  \t0.527041278996 793\n",
      "15  \t0.527078513996 370\n",
      "31  \t0.527176416198 227\n",
      "63  \t0.527274346296 143\n",
      "127  \t0.531434596588 91\n",
      "255  \t0.537356896044 70\n"
     ]
    }
   ],
   "source": [
    "for x in [8,15,31,63,127,255]:\n",
    "    clf.set_params(num_leaves = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        num_leaves = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20  \t0.526385745858 393\n",
      "40  \t0.525487289967 202\n",
      "50  \t0.527927222495 152\n",
      "70  \t0.528879383675 135\n",
      "80  \t0.528587738266 140\n",
      "90  \t0.52881305334 135\n",
      "100  \t0.529835264449 112\n"
     ]
    }
   ],
   "source": [
    "for x in [20,40,50,70,80,90,100]:\n",
    "    clf.set_params(num_leaves = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        num_leaves = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=40,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print num_leaves\n",
    "clf.set_params(num_leaves = num_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20  \t0.527344050351 245\n",
      "30  \t0.526075261377 244\n",
      "50  \t0.527824890434 167\n",
      "70  \t0.527667410327 181\n",
      "80  \t0.526741742421 178\n",
      "90  \t0.526054703678 221\n",
      "100  \t0.527322600072 205\n",
      "110  \t0.526716682857 220\n",
      "120  \t0.526160737465 173\n",
      "150  \t0.526137552135 206\n",
      "170  \t0.52639317896 220\n",
      "200  \t0.526716082566 229\n",
      "230  \t0.527000361857 228\n",
      "260  \t0.528410197917 147\n"
     ]
    }
   ],
   "source": [
    "min_child_samples = 10\n",
    "\n",
    "for x in [20, 30, 50, 70, 80,90,100,110,120,150,170,200,230,260]:\n",
    "    clf.set_params(min_child_samples = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        min_child_samples = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300  \t0.526215358666 194\n",
      "350  \t0.526511677588 260\n",
      "400  \t0.53021506304 174\n",
      "450  \t0.527192693563 243\n",
      "500  \t0.528374245325 193\n"
     ]
    }
   ],
   "source": [
    "for x in [300,350,400,450,500]:\n",
    "    clf.set_params(min_child_samples = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        min_child_samples = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  \t0.525487289967 202\n",
      "5  \t0.525487289967 202\n",
      "15  \t0.527908054708 228\n"
     ]
    }
   ],
   "source": [
    "for x in [2,5,15]:\n",
    "    clf.set_params(min_child_samples = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        min_child_samples = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=40,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print min_child_samples\n",
    "clf.set_params(min_child_samples = min_child_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2  \t0.525192945714 321\n",
      "0.3  \t0.524793214907 233\n",
      "0.4  \t0.524509420866 209\n",
      "0.5  \t0.52526129895 279\n",
      "0.6  \t0.527018874265 254\n",
      "0.7  \t0.52695130558 234\n",
      "0.8  \t0.526803467182 246\n",
      "0.9  \t0.527618523417 232\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = 1\n",
    "for x in [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    clf.set_params(colsample_bytree = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        colsample_bytree = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.4, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=40,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print colsample_bytree\n",
    "\n",
    "clf.set_params(colsample_bytree = colsample_bytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5  \t0.530614618756 217\n",
      "0.6  \t0.528097245047 166\n",
      "0.7  \t0.525933107883 256\n",
      "0.8  \t0.525863502725 209\n",
      "0.9  \t0.525326682139 225\n"
     ]
    }
   ],
   "source": [
    "subsample = 1.0\n",
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    clf.set_params(subsample = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        subsample = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.4, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=40,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1.0, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print subsample\n",
    "clf.set_params(subsample = subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15  \t0.526064061531 310\n",
      "31  \t0.52635679076 359\n",
      "63  \t0.523683112095 318\n",
      "127  \t0.523561569349 264\n",
      "511  \t0.525713325305 228\n",
      "1023  \t0.525161061192 234\n",
      "2047  \t0.52483700656 212\n"
     ]
    }
   ],
   "source": [
    "max_bin = 255\n",
    "\n",
    "for x in [15,31,63, 127, 511, 1023, 2047]: #[200,300,400]:#\n",
    "    clf.set_params(max_bin = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        max_bin = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  \t0.527117139211 230\n",
      "80  \t0.527459616846 262\n",
      "110  \t0.524080345071 217\n",
      "150  \t0.522634049854 284\n",
      "180  \t0.525442944145 274\n",
      "210  \t0.52506481323 261\n",
      "300  \t0.52534347792 244\n",
      "350  \t0.524350980286 245\n",
      "400  \t0.525151462678 268\n",
      "450  \t0.524252545145 260\n",
      "550  \t0.524723690999 195\n",
      "600  \t0.526557533148 215\n"
     ]
    }
   ],
   "source": [
    "for x in [50,80, 110, 150,180, 210, 300, 350,400,450, 550,600]:\n",
    "    clf.set_params(max_bin = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        max_bin = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700  \t0.525780854119 216\n",
      "800  \t0.524122312911 278\n",
      "900  \t0.524841964157 202\n",
      "1200  \t0.526485123393 234\n",
      "1300  \t0.524583789748 248\n",
      "1500  \t0.524620156821 242\n",
      "1700  \t0.524406246904 271\n",
      "1900  \t0.524610462787 288\n"
     ]
    }
   ],
   "source": [
    "for x in [700,800,900,1200,1300,1500,1700,1900]:\n",
    "    clf.set_params(max_bin = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        max_bin = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.4, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=150, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=40,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1.0, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print max_bin\n",
    "clf.set_params(max_bin = max_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "    1 | 01m26s | \u001b[35m  -0.53330\u001b[0m | \u001b[32m            0.2356\u001b[0m | \u001b[32m 341.1413\u001b[0m | \u001b[32m            89.1886\u001b[0m | \u001b[32m     43.9605\u001b[0m | \u001b[32m     0.8478\u001b[0m | \n",
      "    2 | 02m24s |   -0.53615 |             0.5326 |  370.5819 |             32.5007 |      55.0066 |      0.8930 | \n",
      "    3 | 02m11s |   -0.53495 |             0.5391 |  370.8547 |             39.4240 |      39.2428 |      0.8294 | \n",
      "    4 | 02m17s |   -0.53543 |             0.5711 |  203.1610 |             82.0747 |      50.5593 |      0.9160 | \n",
      "    5 | 03m19s |   -0.53624 |             0.3881 |  385.2582 |             66.5734 |      28.7896 |      0.9056 | \n",
      "    6 | 02m24s |   -0.53573 |             0.4685 |  308.1932 |             37.2609 |      34.0030 |      0.9030 | \n",
      "    7 | 02m09s |   -0.53579 |             0.3965 |  280.0005 |             89.0733 |      42.7268 |      0.9191 | \n",
      "    8 | 01m34s |   -0.53734 |             0.2088 |  241.0300 |             27.6417 |      33.8089 |      0.8951 | \n",
      "    9 | 01m35s |   -0.53523 |             0.2092 |  267.2467 |             46.1963 |      47.9058 |      0.9258 | \n",
      "   10 | 02m12s |   -0.53415 |             0.2535 |  148.0516 |             78.9433 |      61.3325 |      0.8398 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "   11 | 01m59s |   -0.53653 |             0.4654 |  108.2649 |             15.4082 |      54.7465 |      0.9829 | \n",
      "   12 | 01m42s |   -0.53559 |             0.2750 |   80.5497 |             58.3769 |      30.4360 |      0.9647 | \n",
      "   13 | 01m29s |   -0.53519 |             0.3243 |   80.6893 |             64.5047 |      60.0183 |      0.8094 | \n",
      "   14 | 01m52s |   -0.53386 |             0.2997 |  336.9639 |             77.4738 |      47.2264 |      0.8856 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.78441866e-05]), 'nit': 6, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 02m59s |   -0.53639 |             0.2995 |  334.9221 |             85.2584 |      23.1761 |      0.9634 | \n",
      "   16 | 02m49s |   -0.53554 |             0.5825 |  347.8508 |             89.8336 |      62.9133 |      0.9289 | \n",
      "   17 | 01m41s |   -0.53509 |             0.3940 |  104.2733 |             85.5616 |      32.3929 |      0.8197 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00012934]), 'nit': 3, 'funcalls': 46}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 02m09s |   -0.53544 |             0.3238 |  371.6555 |             13.9422 |      31.5505 |      0.9743 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  9.09714963e-05]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 02m37s |   -0.53665 |             0.2726 |  291.4607 |             13.0467 |      53.6573 |      0.9604 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.89326090e-05]), 'nit': 6, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 01m59s |   -0.53539 |             0.4969 |  178.9722 |             31.9216 |      55.2478 |      0.8347 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00045515]), 'nit': 3, 'funcalls': 46}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00017998]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 01m50s |   -0.53498 |             0.3211 |  141.7267 |             62.8979 |      35.8699 |      0.8657 | \n",
      "   22 | 01m40s |   -0.53534 |             0.3522 |  129.9365 |             62.8356 |      60.7925 |      0.8375 | \n",
      "   23 | 02m02s |   -0.53613 |             0.3622 |  257.0582 |             75.3045 |      62.8147 |      0.9453 | \n",
      "   24 | 02m28s |   -0.53514 |             0.3001 |   93.8251 |              9.5577 |      20.4295 |      0.8180 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00073592]), 'nit': 4, 'funcalls': 59}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 02m23s |   -0.53660 |             0.5949 |  165.2242 |             76.0086 |      30.9940 |      0.9602 | \n",
      "   26 | 01m25s |   -0.53481 |             0.2711 |  116.2822 |             85.3056 |      61.4459 |      0.8505 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00041195]), 'nit': 4, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 01m48s |   -0.53614 |             0.2538 |  149.1975 |             11.9283 |      23.8183 |      0.9831 | \n",
      "   28 | 02m31s |   -0.53609 |             0.5810 |  399.6546 |             30.4571 |      43.3566 |      0.8426 | \n",
      "   29 | 02m28s |   -0.53469 |             0.3278 |  311.6200 |             75.4017 |      58.1006 |      0.8300 | \n",
      "   30 | 01m33s |   -0.53633 |             0.3505 |   82.8129 |             10.1692 |      58.6160 |      0.8570 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00037081]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 01m43s |   -0.53478 |             0.3448 |   82.8083 |             84.2359 |      40.5581 |      0.8313 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00065313]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00069967]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -8.16538527e-05]), 'nit': 4, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 02m03s |   -0.53560 |             0.3600 |  333.2086 |             89.4848 |      53.1634 |      0.8196 | \n",
      "   33 | 01m59s |   -0.53424 |             0.2744 |  348.2830 |             81.2616 |      42.6914 |      0.9050 | \n",
      "   34 | 03m16s |   -0.53560 |             0.5112 |  308.9816 |             38.5077 |      62.5161 |      0.8364 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00011343]), 'nit': 4, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 02m14s |   -0.53619 |             0.3619 |  399.6125 |             87.3991 |      30.3797 |      0.8865 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.04836800e-05]), 'nit': 4, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  9.80445809e-05]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 02m34s |   -0.53576 |             0.5630 |  326.4525 |             56.2440 |      44.9520 |      0.8095 | \n",
      "   37 | 01m55s |   -0.53390 |             0.2702 |  293.3899 |             55.7680 |      56.8832 |      0.9136 | \n",
      "   38 | 02m44s |   -0.53506 |             0.5004 |  174.6413 |             56.2852 |      60.8253 |      0.8256 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00012587]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 02m06s |   -0.53642 |             0.4466 |  222.0290 |             19.4466 |      57.9596 |      0.8582 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -8.41634782e-05]), 'nit': 6, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 | 03m00s |   -0.53644 |             0.5496 |  395.4920 |             36.6357 |      21.5344 |      0.8070 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00017451]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.79865155e-05]), 'nit': 6, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.15372802e-05]), 'nit': 6, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 01m58s |   -0.53534 |             0.2459 |  392.4199 |             88.7462 |      58.2734 |      0.8013 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.0001139]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 02m44s |   -0.53620 |             0.3995 |  189.6259 |              9.3057 |      60.2366 |      0.9995 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.0002799]), 'nit': 1, 'funcalls': 43}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00092376]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 01m54s |   -0.53518 |             0.2859 |  298.6996 |             63.1689 |      43.9520 |      0.8012 | \n",
      "   44 | 02m02s |   -0.53508 |             0.5167 |  141.4436 |             87.3187 |      41.9752 |      0.8718 | \n",
      "   45 | 02m46s |   -0.53726 |             0.5580 |  336.7110 |             10.8807 |      25.3556 |      0.9164 | \n",
      "   46 | 02m51s |   -0.53708 |             0.4413 |  191.5267 |             85.4909 |      58.7518 |      0.9767 | \n",
      "   47 | 01m50s |   -0.53473 |             0.2371 |  218.0256 |             79.4527 |      26.4683 |      0.8358 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00056359]), 'nit': 6, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 02m12s |   -0.53686 |             0.4967 |  210.2524 |             58.7173 |      39.5812 |      0.9544 | \n",
      "   49 | 01m56s |   -0.53571 |             0.2701 |  239.3193 |             80.7619 |      23.4652 |      0.8486 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  6.37713110e-05]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 03m09s |   -0.53709 |             0.3999 |  396.6137 |              9.8225 |      25.4306 |      0.8048 | \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-ec64ac0ef3c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                                 'subsample' : (0.8,1)})\n\u001b[1;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mlgbm_BO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\bayes_opt\\bayesian_optimization.pyc\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[1;31m# Append most recently generated values to X and Y arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[1;31m# Updating the GP.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-ec64ac0ef3c4>\u001b[0m in \u001b[0;36mlgbm_cv\u001b[0;34m(max_bin, num_leaves, min_child_samples, colsample_bytree, subsample, learning_rate)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'multi_logloss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                )\n\u001b[1;32m     26\u001b[0m         \u001b[0mval_y_predict_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\lightgbm-0.1-py2.7.egg\\lightgbm\\sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    585\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\lightgbm-0.1-py2.7.egg\\lightgbm\\sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_sample_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    408\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\lightgbm-0.1-py2.7.egg\\lightgbm\\engine.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, callbacks)\u001b[0m\n\u001b[1;32m    177\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\lightgbm-0.1-py2.7.egg\\lightgbm\\basic.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1343\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1345\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lgbm_cv(max_bin, num_leaves, min_child_samples, colsample_bytree, subsample, learning_rate=0.1):\n",
    "    skf = KFold(n_splits=5,random_state=seed)\n",
    "    scores=[]\n",
    "    for i, (train, val) in enumerate(skf.split(train_X)):\n",
    "        est=lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                               max_bin=int(max_bin),\n",
    "                               num_leaves=int(num_leaves),\n",
    "                               min_child_samples=int(min_child_samples),\n",
    "                               colsample_bytree=colsample_bytree,\n",
    "                               subsample=subsample,\n",
    "                               subsample_freq = 1\n",
    "                              )\n",
    " \n",
    "        train_x_fold = train_X.iloc[train]\n",
    "        train_y_fold = train_y[train]\n",
    "        val_x_fold = train_X.iloc[val]\n",
    "        val_y_fold = train_y[val]\n",
    "        est.set_params( n_estimators=100000)\n",
    "        est.fit(train_x_fold,\n",
    "                train_y_fold,\n",
    "                eval_set=[(val_x_fold, val_y_fold)],\n",
    "                eval_metric='multi_logloss',\n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False\n",
    "               )\n",
    "        val_y_predict_fold = est.predict_proba(val_x_fold)\n",
    "        score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "        scores.append(score)\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "lgbm_BO = BayesianOptimization(lgbm_cv, \n",
    "                               {\n",
    "                                'max_bin': (80,400),\n",
    "                                'num_leaves': (20,63),\n",
    "                                'min_child_samples' :(9,90),\n",
    "                                'colsample_bytree': (0.2,0.6),\n",
    "                                'subsample' : (0.8,1)})\n",
    "\n",
    "lgbm_BO.maximize(init_points=10, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  \tnum_leaves \t \tmin_child_samples \tmax_bin \tcolsample_bytree \tsubsample \tscore\n",
    "# 34 \t17.342582 \t158.175569 \t \t \t453.587691 \t0.309807 \t \t \t0.951246 \t-0.523952\n",
    "# 36 \t34.809317 \t175.689702 \t \t \t431.124869 \t0.420417 \t \t \t0.980390 \t-0.524356\n",
    "# 16 \t13.123686 \t120.179447 \t \t \t689.223522 \t0.706641 \t \t \t0.769943 \t-0.524734\n",
    "# 33 \t18.297130 \t121.709972 \t \t \t452.154081 \t0.467294 \t \t \t0.913592 \t-0.524832\n",
    "# 24 \t8.498056 \t122.380717 \t \t \t540.797144 \t0.318956 \t \t \t0.953308 \t-0.524889\n",
    "\n",
    "# 0331 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>max_bin</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22.382049</td>\n",
       "      <td>64.962952</td>\n",
       "      <td>376.640680</td>\n",
       "      <td>0.306975</td>\n",
       "      <td>0.947558</td>\n",
       "      <td>-0.524254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31.615417</td>\n",
       "      <td>66.021705</td>\n",
       "      <td>421.213915</td>\n",
       "      <td>0.425728</td>\n",
       "      <td>0.899097</td>\n",
       "      <td>-0.524894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17.194424</td>\n",
       "      <td>64.222584</td>\n",
       "      <td>559.939981</td>\n",
       "      <td>0.497790</td>\n",
       "      <td>0.934519</td>\n",
       "      <td>-0.525071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16.389240</td>\n",
       "      <td>66.216210</td>\n",
       "      <td>357.642431</td>\n",
       "      <td>0.623331</td>\n",
       "      <td>0.934423</td>\n",
       "      <td>-0.525089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.471950</td>\n",
       "      <td>106.924120</td>\n",
       "      <td>397.842570</td>\n",
       "      <td>0.453457</td>\n",
       "      <td>0.924038</td>\n",
       "      <td>-0.525457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.508117</td>\n",
       "      <td>182.304842</td>\n",
       "      <td>712.794090</td>\n",
       "      <td>0.420441</td>\n",
       "      <td>0.930807</td>\n",
       "      <td>-0.525571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.481535</td>\n",
       "      <td>62.365550</td>\n",
       "      <td>207.070979</td>\n",
       "      <td>0.471294</td>\n",
       "      <td>0.781278</td>\n",
       "      <td>-0.525590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.533528</td>\n",
       "      <td>117.166334</td>\n",
       "      <td>232.383120</td>\n",
       "      <td>0.450393</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>-0.525687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.207873</td>\n",
       "      <td>68.105397</td>\n",
       "      <td>536.009959</td>\n",
       "      <td>0.405839</td>\n",
       "      <td>0.954524</td>\n",
       "      <td>-0.525693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.765542</td>\n",
       "      <td>93.186696</td>\n",
       "      <td>597.508214</td>\n",
       "      <td>0.610208</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>-0.525743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  min_child_samples     max_bin  colsample_bytree  subsample  \\\n",
       "24   22.382049          64.962952  376.640680          0.306975   0.947558   \n",
       "31   31.615417          66.021705  421.213915          0.425728   0.899097   \n",
       "15   17.194424          64.222584  559.939981          0.497790   0.934519   \n",
       "39   16.389240          66.216210  357.642431          0.623331   0.934423   \n",
       "4    10.471950         106.924120  397.842570          0.453457   0.924038   \n",
       "9    14.508117         182.304842  712.794090          0.420441   0.930807   \n",
       "3    19.481535          62.365550  207.070979          0.471294   0.781278   \n",
       "0    25.533528         117.166334  232.383120          0.450393   0.896000   \n",
       "21   13.207873          68.105397  536.009959          0.405839   0.954524   \n",
       "11   14.765542          93.186696  597.508214          0.610208   0.809859   \n",
       "\n",
       "       score  \n",
       "24 -0.524254  \n",
       "31 -0.524894  \n",
       "15 -0.525071  \n",
       "39 -0.525089  \n",
       "4  -0.525457  \n",
       "9  -0.525571  \n",
       "3  -0.525590  \n",
       "0  -0.525687  \n",
       "21 -0.525693  \n",
       "11 -0.525743  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_bo_scores = pd.DataFrame([[s[0]['num_leaves'],\n",
    "                               s[0]['min_child_samples'],\n",
    "                               s[0]['max_bin'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[1]] for s in zip(lgbm_BO.res['all']['params'],lgbm_BO.res['all']['values'])],\n",
    "                            columns = ['num_leaves',\n",
    "                                       'min_child_samples',\n",
    "                                       'max_bin',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'score'])\n",
    "gbm_bo_scores=gbm_bo_scores.sort_values('score',ascending=False)\n",
    "gbm_bo_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgbm_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=50):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,random_state=seed)\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "#     train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "#     test_blend_x = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "#     scores = np.zeros ((fold,N_params))\n",
    "#     best_rounds = np.zeros ((fold, N_params))\n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros((fold,N_params))\n",
    "    best_rounds = np.zeros((fold, N_params))    \n",
    "\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(learning_rate = 0.005)\n",
    "        est.set_params(subsample_freq = 1)\n",
    "        est.set_params(objective = 'multiclass')\n",
    "        est.set_params(n_estimators = 1000000)\n",
    "\n",
    "        \n",
    "        print (\"Model %d: %s\" %(j+1, est)) \n",
    "\n",
    "        \n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]\n",
    "            \n",
    "            est.fit(train_x_fold, train_y_fold,\n",
    "                   eval_set = [(val_x_fold,val_y_fold)],\n",
    "                   eval_metric = 'multi_logloss',\n",
    "                   early_stopping_rounds = early_stopping_rounds,\n",
    "                   verbose = False)\n",
    "            \n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            \n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,num_iteration = best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score   \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,num_iteration=best_round)\n",
    "            \n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "            \n",
    "#         test_blend_x[:,(j*N_class):(j+1)*N_class] = \\\n",
    "#                 np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "#                           test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "#                           test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 10 folds\n",
      "Model 1: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.2356, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.005, max_bin=341, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=89, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=1000000, nthread=-1, num_leaves=43,\n",
      "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
      "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
      "        skip_drop=0.5, subsample=0.8478, subsample_for_bin=50000,\n",
      "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 1 fold 1\n",
      "best round 7464\n",
      "('Score: ', 0.54215349038012606)\n",
      "Model 1 fold 1 fitting finished in 708.631s\n",
      "Model 1 fold 2\n",
      "best round 7872\n",
      "('Score: ', 0.52898572392866161)\n",
      "Model 1 fold 2 fitting finished in 803.146s\n",
      "Model 1 fold 3\n",
      "best round 8149\n",
      "('Score: ', 0.51244088700520318)\n",
      "Model 1 fold 3 fitting finished in 713.988s\n",
      "Model 1 fold 4\n",
      "best round 6860\n",
      "('Score: ', 0.52543760552092333)\n",
      "Model 1 fold 4 fitting finished in 583.861s\n",
      "Model 1 fold 5\n",
      "best round 7909\n",
      "('Score: ', 0.51096463935982217)\n",
      "Model 1 fold 5 fitting finished in 630.532s\n",
      "Model 1 fold 6\n",
      "best round 6934\n",
      "('Score: ', 0.53030370353450729)\n",
      "Model 1 fold 6 fitting finished in 851.886s\n",
      "Model 1 fold 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-860be863ece4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                                \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                                \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                                1000) #as the learning rate decreases the number of stopping rounds need to be increased\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-044a44fa54ff>\u001b[0m in \u001b[0;36mlgbm_blend\u001b[0;34m(estimators, train_x, train_y, test_x, fold, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     39\u001b[0m                    \u001b[0meval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'multi_logloss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                    \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                    verbose = False)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mbest_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\lightgbm-0.1-py2.7.egg\\lightgbm\\sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    585\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\lightgbm-0.1-py2.7.egg\\lightgbm\\sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_sample_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    408\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\lightgbm-0.1-py2.7.egg\\lightgbm\\engine.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, callbacks)\u001b[0m\n\u001b[1;32m    177\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\python\\Anaconda2\\lib\\site-packages\\lightgbm-0.1-py2.7.egg\\lightgbm\\basic.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1343\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1345\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "est =       [lgb.LGBMClassifier(num_leaves = 43,\n",
    "                                min_child_samples = 89,\n",
    "                                colsample_bytree = 0.2356,\n",
    "                                subsample = 0.8478,\n",
    "                                max_bin = 341),\n",
    "#              lgb.LGBMClassifier(num_leaves = 22,\n",
    "#                                 min_child_samples = 64,\n",
    "#                                 colsample_bytree = 0.306975,\n",
    "#                                 subsample = 0.947558,\n",
    "#                                 max_bin = 376),\n",
    "#              lgb.LGBMClassifier(num_leaves = 31,\n",
    "#                                 min_child_samples = 66,\n",
    "#                                 colsample_bytree = 0.425728,\n",
    "#                                 subsample = 0.899097,\n",
    "#                                 max_bin = 421),\n",
    "#              lgb.LGBMClassifier(num_leaves = 17,\n",
    "#                                 min_child_samples = 64,\n",
    "#                                 colsample_bytree = 0.497790,\n",
    "#                                 subsample = 0.934519,\n",
    "#                                 max_bin = 559),\n",
    "#              lgb.LGBMClassifier(num_leaves = 16,\n",
    "#                                 min_child_samples = 66,\n",
    "#                                 colsample_bytree = 0.623331,\n",
    "#                                 subsample = 0.934423,\n",
    "#                                 max_bin = 357)\n",
    "            ]\n",
    "\n",
    "#  Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
    "#     1 | 01m26s |   -0.53330 |             0.2356 |  341.1413 |             89.1886 |      43.9605 |      0.8478 | \n",
    "\n",
    "\n",
    "(train_blend_x_gbm,\n",
    " test_blend_x_gbm_mean,\n",
    " test_blend_x_gbm_gmean,\n",
    " blend_scores_gbm,\n",
    " best_rounds_gbm)= lgbm_blend(est, \n",
    "                               train_X, train_y, \n",
    "                               test_X,\n",
    "                               10,\n",
    "                               1000) #as the learning rate decreases the number of stopping rounds need to be increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51770578  0.51729681  0.51737595  0.51798511  0.518612  ]\n",
      "[ 14772.2  12224.4   8384.3  13985.8  14431.3]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_LightGBM_BM_0401_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_LightGBM_mean_BM_0401_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../blend/test_blend_LightGBM_gmean_BM_0401_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_gbm,axis=0))\n",
    "print (np.mean(best_rounds_gbm,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_gbm, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_gbm_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_gbm_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_LightGBM_BM_0401_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_blend_x_gbm_mean[:,6:9])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = sub_id\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data 0322\n",
    "\n",
    "# [ 0.52309656  0.52262419  0.52356597  0.52188342  0.52198129]\n",
    "# [ 15266.3  12448.   15418.7   7687.9  11589.2]\n",
    "\n",
    "# data 0331\n",
    "# [ 0.51778446  0.51758745  0.51859108  0.51763268  0.51941101]\n",
    "# [ 15053.7   8042.4  16049.9  13754.3  28486.6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = (test_blend_x_gbm_mean[:,6:9] +test_blend_x_gbm_gmean[:,6:9])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_LightGBM_BM_0331_total_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(temp)\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = sub_id\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
