{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 16)\n",
      "(74659, 15)\n",
      "49352\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file).reset_index()\n",
    "test_df = pd.read_json(test_file).reset_index()\n",
    "ntrain = train_df.shape[0]\n",
    "print train_df.shape\n",
    "print test_df.shape\n",
    "print ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sc_price\n",
    "tmp = pd.concat([train_df['price'],test_df['price']])\n",
    "ulimit = np.percentile(tmp.values, 99)\n",
    "llimit = np.percentile(tmp.values, 1)\n",
    "\n",
    "train_df.loc[:,'sc_price'] = train_df['price'].values.reshape(-1, 1)\n",
    "test_df.loc[:,'sc_price'] = test_df['price'].values.reshape(-1, 1)\n",
    "\n",
    "train_df.loc[train_df['sc_price']>ulimit, ['sc_price']] = ulimit\n",
    "test_df.loc[test_df['sc_price']>ulimit, ['sc_price']] = ulimit\n",
    "train_df.loc[train_df['sc_price']<llimit, ['sc_price']] = llimit\n",
    "test_df.loc[test_df['sc_price']<llimit, ['sc_price']] = llimit\n",
    "\n",
    "\n",
    "\n",
    "# sc_ba_price\n",
    "inx_train = train_df['bathrooms'] == 0\n",
    "inx_test = test_df['bathrooms'] == 0\n",
    "\n",
    "non0_inx_train = ~inx_train\n",
    "non0_inx_test = ~inx_test\n",
    "\n",
    "train_df.loc[non0_inx_train,'sc_ba_price'] = train_df.loc[non0_inx_train,'sc_price']\\\n",
    "                                                /train_df.loc[non0_inx_train,'bathrooms']\n",
    "test_df.loc[non0_inx_test,'sc_ba_price'] = test_df.loc[non0_inx_test,'sc_price']\\\n",
    "                                                /test_df.loc[non0_inx_test,'bathrooms']\n",
    "\n",
    "train_df.loc[inx_train,'sc_ba_price'] = 0\n",
    "test_df.loc[inx_test,'sc_ba_price'] = 0\n",
    "\n",
    "train_df.loc[non0_inx_train,'bathrooms0'] = 1\n",
    "test_df.loc[non0_inx_test,'bathrooms0'] = 1\n",
    "\n",
    "train_df.loc[inx_train,'bathrooms0'] = 0\n",
    "test_df.loc[inx_test,'bathrooms0'] = 0\n",
    "\n",
    "# price per bedrooms\n",
    "\n",
    "inx_train = train_df['bedrooms'] == 0\n",
    "inx_test = test_df['bedrooms'] == 0\n",
    "\n",
    "non0_inx_train = ~inx_train\n",
    "non0_inx_test = ~inx_test\n",
    "\n",
    "train_df.loc[non0_inx_train,'sc_be_price'] = train_df.loc[non0_inx_train,'sc_price'] \\\n",
    "                                                /train_df.loc[non0_inx_train,'bedrooms']\n",
    "test_df.loc[non0_inx_test,'sc_be_price'] = test_df.loc[non0_inx_test,'sc_price']\\\n",
    "                                                /test_df.loc[non0_inx_test,'bedrooms']\n",
    "\n",
    "train_df.loc[inx_train,'sc_be_price'] = 0\n",
    "test_df.loc[inx_test,'sc_be_price'] = 0\n",
    "\n",
    "train_df.loc[non0_inx_train,'bedrooms0'] = 1\n",
    "test_df.loc[non0_inx_test,'bedrooms0'] = 1\n",
    "\n",
    "train_df.loc[inx_train,'bedrooms0'] = 0\n",
    "test_df.loc[inx_test,'bedrooms0'] = 0\n",
    "# bathrooms\n",
    "\n",
    "ulimit = 5\n",
    "\n",
    "train_df['sc_bathrooms']=train_df['bathrooms']\n",
    "test_df['sc_bathrooms']=test_df['bathrooms']\n",
    "\n",
    "train_df.loc[train_df['sc_bathrooms']>ulimit,['sc_bathrooms']] = ulimit\n",
    "test_df.loc[test_df['sc_bathrooms']>ulimit,['sc_bathrooms']] = ulimit\n",
    "\n",
    "# bedrooms\n",
    "\n",
    "ulimit = 8\n",
    "\n",
    "train_df['sc_bedrooms']=train_df['bedrooms']\n",
    "test_df['sc_bedrooms']=test_df['bedrooms']\n",
    "\n",
    "train_df.loc[train_df['sc_bedrooms']>ulimit, ['sc_bedrooms']] = ulimit\n",
    "test_df.loc[test_df['sc_bedrooms']>ulimit,['sc_bedrooms']] = ulimit\n",
    "\n",
    "# longitude\n",
    "\n",
    "tmp = pd.concat([train_df['longitude'],test_df['longitude']])\n",
    "llimit = np.percentile(tmp.values, 0.1)\n",
    "ulimit = np.percentile(tmp.values, 99.9)\n",
    "\n",
    "train_df['sc_longitude']=train_df['longitude']\n",
    "test_df['sc_longitude']=test_df['longitude']\n",
    "\n",
    "train_df.loc[train_df['sc_longitude']>ulimit, ['sc_longitude']] = ulimit\n",
    "test_df.loc[test_df['sc_longitude']>ulimit, ['sc_longitude']] = ulimit\n",
    "train_df.loc[train_df['sc_longitude']<llimit, ['sc_longitude']] = llimit\n",
    "test_df.loc[test_df['sc_longitude']<llimit, ['sc_longitude']] = llimit\n",
    "\n",
    "# latitude\n",
    "\n",
    "tmp = pd.concat([train_df['latitude'],test_df['latitude']])\n",
    "llimit = np.percentile(tmp.values, 0.1)\n",
    "ulimit = np.percentile(tmp.values, 99.9)\n",
    "\n",
    "train_df['sc_latitude']=train_df['latitude']\n",
    "test_df['sc_latitude']=test_df['latitude']\n",
    "\n",
    "train_df.loc[train_df['sc_latitude']>ulimit, ['sc_latitude']] = ulimit\n",
    "test_df.loc[test_df['sc_latitude']>ulimit, ['sc_latitude']] = ulimit\n",
    "train_df.loc[train_df['sc_latitude']<llimit, ['sc_latitude']] = llimit\n",
    "test_df.loc[test_df['sc_latitude']<llimit, ['sc_latitude']] = llimit\n",
    "\n",
    "\n",
    "features_to_use  = [\"sc_bathrooms\", \"sc_bedrooms\", \"sc_latitude\", \"sc_longitude\",\n",
    "                    \"sc_price\", \"sc_ba_price\", \"sc_be_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "# adding all these new features to use list #\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\", \"created_month\", \n",
    "                        \"created_day\", \"created_hour\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_bathrooms \t-0.974792935849\n",
      "sc_bedrooms \t0.474243433469\n",
      "sc_longitude \t-12.8479106804\n",
      "sc_price \t0.34122013083\n",
      "sc_ba_price \t0.668968094532\n",
      "sc_be_price \t0.462918736223\n",
      "num_photos \t0.475560723219\n",
      "num_features \t0.359523382085\n",
      "num_description_words \t0.543711145224\n",
      "created_hour \t-0.389913999668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "full_data=pd.concat([train_df,test_df])\n",
    "\n",
    "# SSL = preprocessing.StandardScaler()\n",
    "# for col in features_to_use:\n",
    "#     full_data[col], lam = boxcox(full_data[col] - full_data[col].min() + 1)\n",
    "#     full_data[col] = SSL.fit_transform(full_data[col].values.reshape(-1,1)) \n",
    "skewed_cols = full_data[features_to_use].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "SSL = preprocessing.StandardScaler()\n",
    "skewed_cols = skewed_cols[skewed_cols > 0.25].index.values\n",
    "for skewed_col in skewed_cols:\n",
    "    full_data[skewed_col], lam = boxcox(full_data[skewed_col] - full_data[skewed_col].min() + 1)\n",
    "    print skewed_col, '\\t', lam\n",
    "for col in features_to_use:\n",
    "    full_data[col] = SSL.fit_transform(full_data[col].values.reshape(-1,1))\n",
    "    train_df[col] = full_data.iloc[:ntrain][col]\n",
    "    test_df[col] = full_data.iloc[ntrain:][col]\n",
    "\n",
    "    \n",
    "del full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use.extend([\"listing_id\",\"bedrooms0\",'bathrooms0'])\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                     \n",
      "1    doorman elevator fitness_center cats_allowed d...\n",
      "2    laundry_in_building dishwasher hardwood_floors...\n",
      "3                               hardwood_floors no_fee\n",
      "4                                              pre-war\n",
      "Name: features, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df['features'] = train_df[\"features\"]\\\n",
    "                        .apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\\\n",
    "                        .apply(lambda x: x.lower())\n",
    "test_df['features'] = test_df[\"features\"]\\\n",
    "                        .apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\\\n",
    "                        .apply(lambda x: x.lower())\n",
    "\n",
    "print(train_df[\"features\"].head())\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "tr_sparse = tfidf.fit_transform(train_df[\"features\"])\n",
    "te_sparse = tfidf.transform(test_df[\"features\"])\n",
    "\n",
    "sparse_features = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 220) (74659, 220)\n"
     ]
    }
   ],
   "source": [
    "train_X = sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\n",
    "test_X = sparse.hstack([test_df[features_to_use], te_sparse]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "weight_num_map = {'high':1, 'medium':1, 'low':1}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "W_train = np.array(train_df['interest_level'].apply(lambda x: weight_num_map[x]))\n",
    "\n",
    "all_features = features_to_use + sparse_features\n",
    "print train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_dataset = lgb.Dataset(train_X, train_y,\n",
    "                         weight = W_train, free_raw_data = False,\n",
    "                        feature_name = all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# index_low = train[train['interest_level'] == 'low']\n",
    "# index_medium = train[train['interest_level'] == 'medium']\n",
    "# index_high = train[train['interest_level'] == 'high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index_tmp = (list(index_medium.index[:3839])\n",
    "#                     +list(index_high.index)\n",
    "#                     +list(index_low.index[:3839]))\n",
    "# # index_tmp= index_tmp.iloc(np.random.permutation(len(index_tmp)))\n",
    "# # index_tmp\n",
    "\n",
    "# random.shuffle(index_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_X = train_X[index_tmp,:]\n",
    "# train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tune LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### num_leaves, default=127, type=int, alias=num_leaf\n",
    "\n",
    "    number of leaves in one tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  \t0.553575161847 1213\n",
      "15  \t0.552250341503 725\n",
      "31  \t0.552726428184 337\n",
      "63  \t0.554048933244 164\n",
      "127  \t0.555666503054 111\n",
      "255  \t0.559468993011 80\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'metric': 'multi_logloss',\n",
    "}\n",
    "# params['metrics'] = 'multi_logloss'\n",
    "\n",
    "for x in [8,15,31,63,127,255]:\n",
    "    params['num_leaves'] = x\n",
    "    clf = lgb.cv(params, cv_dataset,\n",
    "                num_boost_round = 100000, nfold =5,\n",
    "#                 metrics = 'multi_logloss',\n",
    "                early_stopping_rounds = 50)\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.values()[0][-1], len(clf.values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params['num_leaves'] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_child_samples : int, default= 100\n",
    "    Minimum number of data need in a child(leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  \t0.554113822397 675\n",
      "20  \t0.554113822397 675\n",
      "30  \t0.553227873486 591\n",
      "50  \t0.552712734654 665\n",
      "70  \t0.552539757989 586\n",
      "80  \t0.552722214662 629\n",
      "90  \t0.552966841255 613\n",
      "100  \t0.552250341503 725\n",
      "110  \t0.553045514728 692\n",
      "120  \t0.553015043433 616\n",
      "150  \t0.553441603 577\n",
      "170  \t0.552646081281 636\n",
      "200  \t0.553032807676 578\n",
      "230  \t0.553528665355 612\n",
      "260  \t0.554649077941 647\n"
     ]
    }
   ],
   "source": [
    "for x in [10, 20, 30, 50, 70, 80,90,100,110,120,150,170,200,230,260]:\n",
    "#     rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "#                              n_estimators=100000,\n",
    "#                              num_leaves=num_leaves,\n",
    "#                              min_child_samples = x)\n",
    "\n",
    "#     rgr.fit(X_train,y_train,\n",
    "#             eval_set=[(X_val,y_val)],\n",
    "#             eval_metric='multi_logloss',\n",
    "#             early_stopping_rounds=50,\n",
    "#             verbose = False)\n",
    "    params['min_child_samples'] = x\n",
    "    clf = lgb.cv(params, cv_dataset,\n",
    "                num_boost_round = 100000, nfold =5,\n",
    "#                 metrics = 'multi_logloss',\n",
    "                early_stopping_rounds = 50)    \n",
    "\n",
    "    print x, ' \\t', clf.values()[0][-1], len(clf.values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params['min_child_samples'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### colsample_bytree : float default 1\n",
    "    Subsample ratio of columns when constructing each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3  \t0.550691942962 852\n",
      "0.4  \t0.550463882194 882\n",
      "0.5  \t0.55100349824 762\n",
      "0.6  \t0.550119194943 763\n",
      "0.7  \t0.55154402256 702\n",
      "0.8  \t0.551548629086 692\n",
      "0.9  \t0.552326580205 744\n"
     ]
    }
   ],
   "source": [
    "for x in [0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "#     rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "#                              n_estimators=100000,\n",
    "#                              num_leaves=num_leaves,\n",
    "#                              min_child_samples = min_child_samples,\n",
    "#                              colsample_bytree = x)\n",
    "\n",
    "#     rgr.fit(X_train,y_train,\n",
    "#             eval_set=[(X_val,y_val)],\n",
    "#             eval_metric='multi_logloss',\n",
    "#             early_stopping_rounds=50,\n",
    "#             verbose = False)\n",
    "\n",
    "    params['colsample_bytree'] = x\n",
    "    clf = lgb.cv(params, cv_dataset,\n",
    "                num_boost_round = 100000, nfold =5,\n",
    "#                 metrics = 'multi_logloss',\n",
    "                early_stopping_rounds = 50)    \n",
    "\n",
    "    print x, ' \\t', clf.values()[0][-1], len(clf.values()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['colsample_bytree'] = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subsample : float default 1\n",
    "    Subsample ratio of the training instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5  \t0.553908986422 630\n",
      "0.6  \t0.552878611779 622\n",
      "0.7  \t0.551081202293 700\n",
      "0.8  \t0.550509596922 654\n",
      "0.9  \t0.549961643423 688\n"
     ]
    }
   ],
   "source": [
    "params['subsample_freq'] = 1\n",
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "#     rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "#                              n_estimators=100000,\n",
    "#                              num_leaves=num_leaves,\n",
    "#                              min_child_samples = min_child_samples,\n",
    "#                              colsample_bytree = colsample_bytree,\n",
    "#                              subsample = x,\n",
    "#                              subsample_freq=1)\n",
    "\n",
    "#     rgr.fit(X_train,y_train,\n",
    "#             eval_set=[(X_val,y_val)],\n",
    "#             eval_metric='multi_logloss',\n",
    "#             early_stopping_rounds=50,\n",
    "#             verbose = False)\n",
    "\n",
    "    params['subsample'] = x\n",
    "    clf = lgb.cv(params, cv_dataset,\n",
    "                num_boost_round = 100000, nfold =5,\n",
    "#                 metrics = 'multi_logloss',\n",
    "                early_stopping_rounds = 50) \n",
    "    \n",
    "\n",
    "    print x, ' \\t', clf.values()[0][-1], len(clf.values()[0])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['subsample'] = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_bin : int, required default 255\n",
    "    Max number of discrete bin for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400  \t0.549412961147 744\n",
      "600  \t0.548322117656 733\n",
      "800  \t0.548239016015 744\n"
     ]
    }
   ],
   "source": [
    "for x in [400,600,800]:#[15,31,63, 127, 255, 511, 1023, 2047]:\n",
    "#     rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "#                              n_estimators=100000,\n",
    "#                              num_leaves=num_leaves,\n",
    "#                              min_child_samples = min_child_samples,\n",
    "#                              colsample_bytree = colsample_bytree,\n",
    "#                              subsample = subsample,\n",
    "#                              subsample_freq=1,\n",
    "#                              max_bin = x )\n",
    "\n",
    "#     rgr.fit(X_train,y_train,\n",
    "#             eval_set=[(X_val,y_val)],\n",
    "#             eval_metric='multi_logloss',\n",
    "#             early_stopping_rounds=50,\n",
    "#             verbose = False)\n",
    "\n",
    "    cv_dataset = lgb.Dataset(train_X, train_y, max_bin = x)\n",
    "    clf = lgb.cv(params, cv_dataset,\n",
    "                 num_boost_round = 100000, nfold =5,\n",
    "                 early_stopping_rounds = 50)    \n",
    "\n",
    "    print x, ' \\t', clf.values()[0][-1], len(clf.values()[0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_bin'] = 511\n",
    "# 15  \t0.562066632169 742\n",
    "# 31  \t0.555903950821 668\n",
    "# 63  \t0.552083399795 753\n",
    "# 127  \t0.55038645295 765\n",
    "# 255  \t0.549961643423 688\n",
    "# 400  \t0.549412961147 744\n",
    "# 511  \t0.547701027983 751\n",
    "# 600  \t0.548322117656 733\n",
    "# 800  \t0.548239016015 744\n",
    "# 1023  \t0.547832184875 710\n",
    "# 2047  \t0.548073888446 734\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "    1 | 02m04s | \u001b[35m  -0.54612\u001b[0m | \u001b[32m            0.5566\u001b[0m | \u001b[32m 566.4739\u001b[0m | \u001b[32m            87.2015\u001b[0m | \u001b[32m     25.7100\u001b[0m | \u001b[32m     0.8027\u001b[0m | \n",
      "    2 | 02m24s |   -0.54772 |             0.7255 |  578.7116 |             62.5294 |      11.7273 |      0.9756 | \n",
      "    3 | 01m35s |   -0.54646 |             0.5531 |  558.3118 |             77.4114 |      13.5178 |      0.8810 | \n",
      "    4 | 01m37s | \u001b[35m  -0.54597\u001b[0m | \u001b[32m            0.6344\u001b[0m | \u001b[32m 475.2773\u001b[0m | \u001b[32m            79.1004\u001b[0m | \u001b[32m     19.2260\u001b[0m | \u001b[32m     0.9573\u001b[0m | \n",
      "    5 | 01m28s |   -0.54603 |             0.5613 |  477.8774 |             80.0803 |      22.8155 |      0.8127 | \n",
      "    6 | 01m35s |   -0.54632 |             0.5221 |  508.7282 |             95.1859 |      23.6469 |      0.8801 | \n",
      "    7 | 01m49s |   -0.54720 |             0.6102 |  483.3105 |            108.0539 |      15.9079 |      0.9960 | \n",
      "    8 | 01m36s |   -0.54796 |             0.6674 |  459.0888 |             64.5691 |      13.9254 |      0.8421 | \n",
      "    9 | 01m51s |   -0.54672 |             0.6158 |  519.5072 |             94.1202 |      14.7238 |      0.9508 | \n",
      "   10 | 01m30s |   -0.54688 |             0.6101 |  553.0949 |             91.4332 |      27.0496 |      0.9856 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00060436]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00016249]), 'nit': 5, 'funcalls': 56}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "   11 | 02m28s |   -0.54675 |             0.6415 |  599.5779 |            117.6014 |      23.2794 |      0.8050 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.08115968e-05]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 02m10s |   -0.54859 |             0.6612 |  494.5595 |             71.1490 |      11.5849 |      0.9833 | \n",
      "   13 | 01m58s |   -0.54618 |             0.6221 |  412.4731 |            104.4564 |      28.7699 |      0.9186 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00013768]), 'nit': 5, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 02m11s |   -0.54771 |             0.7165 |  452.9419 |             93.7425 |      23.0354 |      0.9909 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.0001241]), 'nit': 5, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 01m54s |   -0.54732 |             0.6058 |  400.4679 |             75.9077 |      28.4973 |      0.9992 | \n",
      "   16 | 02m13s |   -0.54691 |             0.7311 |  577.3500 |             96.6358 |      13.6325 |      0.8132 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00026461]), 'nit': 5, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 01m59s |   -0.54647 |             0.6266 |  589.3831 |             84.0254 |      27.0597 |      0.9344 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.34722420e-05]), 'nit': 6, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 01m59s |   -0.54636 |             0.5515 |  548.8760 |            118.7113 |      29.6050 |      0.9724 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00123078]), 'nit': 3, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 02m10s |   -0.54712 |             0.5551 |  405.0306 |             98.4312 |      11.6243 |      0.8174 | \n",
      "   20 | 02m02s |   -0.54691 |             0.7468 |  402.5445 |            114.0822 |      24.3473 |      0.9278 | \n",
      "   21 | 02m04s |   -0.54614 |             0.7922 |  522.8040 |            119.9334 |      22.6048 |      0.8142 | \n",
      "   22 | 01m54s |   -0.54747 |             0.7755 |  508.0405 |            117.7329 |      28.3975 |      0.8044 | \n",
      "   23 | 01m57s |   -0.54653 |             0.5051 |  535.3217 |            119.7718 |      20.0027 |      0.9221 | \n",
      "   24 | 02m03s |   -0.54687 |             0.5289 |  571.8713 |             56.3974 |      30.9888 |      0.9800 | \n",
      "   25 | 02m01s | \u001b[35m  -0.54555\u001b[0m | \u001b[32m            0.6690\u001b[0m | \u001b[32m 570.0909\u001b[0m | \u001b[32m           118.7819\u001b[0m | \u001b[32m     29.8525\u001b[0m | \u001b[32m     0.9063\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00144798]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 02m04s |   -0.54603 |             0.6827 |  579.2329 |            119.8639 |      24.1867 |      0.9708 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.00032217e-05]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/bayes_opt/helpers.py:95: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = (mean - y_max - xi)/std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 02m16s |   -0.54645 |             0.6416 |  510.5639 |            105.6057 |      10.1130 |      0.8279 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00020471]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 01m58s |   -0.54683 |             0.7050 |  585.2052 |            104.6802 |      28.2808 |      0.9754 | \n",
      "   29 | 02m28s |   -0.54755 |             0.7482 |  569.4362 |            119.8460 |       8.1779 |      0.8088 | \n",
      "   30 | 01m59s |   -0.54576 |             0.6856 |  597.4458 |             61.2024 |      27.2546 |      0.9171 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00090651]), 'nit': 5, 'funcalls': 59}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 01m59s |   -0.54704 |             0.6571 |  590.6902 |             75.9938 |      30.7247 |      0.8283 | \n",
      "   32 | 02m01s |   -0.54643 |             0.6733 |  585.5322 |             50.2514 |      26.6451 |      0.9713 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.12055445e-05]), 'nit': 5, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 02m09s |   -0.54632 |             0.7033 |  599.5889 |             62.1199 |      17.6787 |      0.8202 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  7.45852885e-05]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 02m26s |   -0.54689 |             0.6364 |  476.4463 |             89.6965 |      11.7977 |      0.9267 | \n",
      "   35 | 01m56s |   -0.54670 |             0.5433 |  467.0653 |             74.9139 |      28.5904 |      0.8375 | \n",
      "   36 | 01m55s |   -0.54625 |             0.6159 |  533.4039 |             57.8186 |      29.0605 |      0.8340 | \n",
      "   37 | 02m00s |   -0.54707 |             0.7888 |  542.5980 |             65.8196 |      30.9262 |      0.8497 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00013919]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   38 | 02m07s |   -0.54707 |             0.7467 |  425.9196 |            119.1409 |      17.7467 |      0.9500 | \n",
      "   39 | 02m01s |   -0.54683 |             0.6751 |  548.8476 |             54.1955 |      22.6648 |      0.9525 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.66498504e-05]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 | 02m00s |   -0.54568 |             0.5729 |  599.3557 |             57.6702 |      27.4275 |      0.8941 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00090652]), 'nit': 2, 'funcalls': 45}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00061308]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 01m52s |   -0.54743 |             0.5775 |  416.2467 |             59.4078 |      29.9540 |      0.8051 | \n",
      "   42 | 02m06s |   -0.54636 |             0.7282 |  480.8344 |             50.1764 |      26.4009 |      0.8885 | \n",
      "   43 | 02m01s |   -0.54721 |             0.7275 |  517.2765 |             66.0866 |      29.4154 |      0.9816 | \n",
      "   44 | 02m26s |   -0.54715 |             0.5547 |  514.1266 |            118.6257 |      10.6884 |      0.9596 | \n",
      "   45 | 01m57s |   -0.54685 |             0.5995 |  419.8164 |             89.1895 |      24.3038 |      0.9705 | \n",
      "   46 | 02m11s |   -0.54701 |             0.6964 |  404.4829 |             50.7134 |      16.6157 |      0.9757 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00013836]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00123032]), 'nit': 3, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   47 | 02m06s |   -0.54726 |             0.7368 |  488.5258 |             89.5767 |      26.7085 |      0.9948 | \n",
      "   48 | 02m02s |   -0.54665 |             0.5081 |  594.8393 |             52.0899 |      29.4904 |      0.8755 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00015032]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 02m08s |   -0.54707 |             0.7599 |  521.7725 |            103.5942 |      30.0244 |      0.9829 | \n",
      "   50 | 02m08s |   -0.54641 |             0.6675 |  440.6464 |             50.8460 |      29.0112 |      0.9466 | \n"
     ]
    }
   ],
   "source": [
    "def lgbm_cv(max_bin, num_leaves, min_child_samples, colsample_bytree, subsample, learning_rate=0.1):\n",
    "    skf = list(KFold(len(train_y), 5))\n",
    "    scores=[]\n",
    "    for i, (train, val) in enumerate(skf):\n",
    "        est=lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                               max_bin=int(max_bin),\n",
    "                               num_leaves=int(num_leaves),\n",
    "                               min_child_samples=int(min_child_samples),\n",
    "                               colsample_bytree=colsample_bytree,\n",
    "                               subsample=subsample,\n",
    "                               subsample_freq = 1\n",
    "                              )\n",
    " \n",
    "        train_x_fold = train_X[train]\n",
    "        train_y_fold = train_y[train]\n",
    "        val_x_fold = train_X[val]\n",
    "        val_y_fold = train_y[val]\n",
    "        est.set_params( n_estimators=100000)\n",
    "        est.fit(train_x_fold,\n",
    "                train_y_fold,\n",
    "                eval_set=[(val_x_fold, val_y_fold)],\n",
    "                eval_metric='multi_logloss',\n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False\n",
    "               )\n",
    "        val_y_predict_fold = est.predict_proba(val_x_fold)\n",
    "        score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "        scores.append(score)\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "lgbm_BO = BayesianOptimization(lgbm_cv, \n",
    "                               {\n",
    "                                'max_bin': (400,600),\n",
    "                                'num_leaves': (8,31),\n",
    "                                'min_child_samples' :(50,120),\n",
    "                                'colsample_bytree': (0.5,0.8),\n",
    "                                'subsample' : (0.8,1)})\n",
    "\n",
    "lgbm_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>max_bin</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29.852527</td>\n",
       "      <td>118.781925</td>\n",
       "      <td>570.090868</td>\n",
       "      <td>0.668988</td>\n",
       "      <td>0.906338</td>\n",
       "      <td>-0.545548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27.427507</td>\n",
       "      <td>57.670210</td>\n",
       "      <td>599.355654</td>\n",
       "      <td>0.572919</td>\n",
       "      <td>0.894120</td>\n",
       "      <td>-0.545682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27.254632</td>\n",
       "      <td>61.202351</td>\n",
       "      <td>597.445820</td>\n",
       "      <td>0.685552</td>\n",
       "      <td>0.917137</td>\n",
       "      <td>-0.545765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24.186654</td>\n",
       "      <td>119.863943</td>\n",
       "      <td>579.232870</td>\n",
       "      <td>0.682721</td>\n",
       "      <td>0.970793</td>\n",
       "      <td>-0.546031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.604751</td>\n",
       "      <td>119.933426</td>\n",
       "      <td>522.803963</td>\n",
       "      <td>0.792176</td>\n",
       "      <td>0.814238</td>\n",
       "      <td>-0.546135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  min_child_samples     max_bin  colsample_bytree  subsample  \\\n",
       "14   29.852527         118.781925  570.090868          0.668988   0.906338   \n",
       "29   27.427507          57.670210  599.355654          0.572919   0.894120   \n",
       "19   27.254632          61.202351  597.445820          0.685552   0.917137   \n",
       "15   24.186654         119.863943  579.232870          0.682721   0.970793   \n",
       "10   22.604751         119.933426  522.803963          0.792176   0.814238   \n",
       "\n",
       "       score  \n",
       "14 -0.545548  \n",
       "29 -0.545682  \n",
       "19 -0.545765  \n",
       "15 -0.546031  \n",
       "10 -0.546135  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_bo_scores = pd.DataFrame([[s[0]['num_leaves'],\n",
    "                               s[0]['min_child_samples'],\n",
    "                               s[0]['max_bin'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[1]] for s in zip(lgbm_BO.res['all']['params'],lgbm_BO.res['all']['values'])],\n",
    "                            columns = ['num_leaves',\n",
    "                                       'min_child_samples',\n",
    "                                       'max_bin',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'score'])\n",
    "gbm_bo_scores=gbm_bo_scores.sort_values('score',ascending=False)\n",
    "gbm_bo_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "def lgbm_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,random_state=seed)\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(learning_rate = 0.01)\n",
    "        est.set_params(subsample_freq = 1)\n",
    "#         est.set_params(num_class = 3)\n",
    "        est.set_params(objective = 'multiclass')\n",
    "        est.set_params(n_estimators = 100000)\n",
    "#         param['learning_rate']=0.01\n",
    "#         param['subsample_freq']=1\n",
    "# #         param['metrics'] = 'multi_logloss'  \n",
    "#         param['num_class'] = 3\n",
    "#         param['objective'] = 'multiclass'\n",
    "#         param['subsample_freq'] = 1\n",
    "        \n",
    "        print (\"Model %d: %s\" %(j+1, est)) \n",
    "\n",
    "        \n",
    "#         cv_dataset = lgb.Dataset(train_x, train_y, max_bin = param['max_bin'])\n",
    "#         clf = lgb.cv(param, cv_dataset,\n",
    "# #                      num_boost_round = 100000, nfold =fold,\n",
    "#                      num_boost_round = 100, nfold =fold,\n",
    "#                      metrics = 'multi_logloss',\n",
    "#                      early_stopping_rounds = early_stopping_rounds) \n",
    "      \n",
    "#         best_round = len(clf.values()[0])\n",
    "#         print 'best_round',best_round\n",
    "#         best_rounds[j]=best_round\n",
    "        \n",
    "#         all_round = best_round / (1 - 1. / fold)\n",
    "# #         est_test_blend = lgb.train(param, cv_dataset,num_boost_round=int(all_round))\n",
    "#         est_test_blend = lgb.LGBMClassifier(learning_rate=param['learning_rate'],\n",
    "#                                             max_bin= param['max_bin'],\n",
    "#                                             num_leaves= param['num_leaves'],\n",
    "#                                             min_child_samples= param['min_child_samples'],\n",
    "#                                             colsample_bytree= param['colsample_bytree'],\n",
    "#                                             subsample= param['subsample'],\n",
    "#                                             subsample_freq = param['subsample_freq'],\n",
    "#                                             n_estimators= int(all_round)\n",
    "#                                            )\n",
    "#         print est_test_blend\n",
    "#         est_test_blend.fit(train_x, train_y)\n",
    "\n",
    "#         test_blend_x[:,(j*N_class):(j+1)*N_class] = est_test_blend.predict_proba(test_x)\n",
    "        \n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x[val_index]\n",
    "            val_y_fold = train_y[val_index]\n",
    "            \n",
    "#             data_fold = lgb.Dataset(train_x_fold, train_y_fold, max_bin = param['max_bin'])\n",
    "#             est_train_blend = lgb.train(param, data_fold,num_boost_round=best_round)\n",
    "\n",
    "#             est_train_blend = lgb.LGBMClassifier(learning_rate=param['learning_rate'],\n",
    "#                                                  max_bin= param['max_bin'],\n",
    "#                                                  num_leaves= param['num_leaves'],\n",
    "#                                                  min_child_samples= param['min_child_samples'],\n",
    "#                                                  colsample_bytree= param['colsample_bytree'],\n",
    "#                                                  subsample= param['subsample'],\n",
    "#                                                  subsample_freq = param['subsample_freq'],\n",
    "#                                                  n_estimators= int(best_round)\n",
    "#                                                 )\n",
    "            est.fit(train_x_fold, train_y_fold,\n",
    "                   eval_set = [(val_x_fold,val_y_fold)],\n",
    "                   eval_metric = 'multi_logloss',\n",
    "                   early_stopping_rounds = early_stopping_rounds,\n",
    "                   verbose = False)\n",
    "            \n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            \n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,num_iteration = best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score   \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,num_iteration=best_round)\n",
    "            \n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "            \n",
    "        test_blend_x[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 10 folds\n",
      "Model 1: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.668988, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=570, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=118, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=29,\n",
      "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
      "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
      "        skip_drop=0.5, subsample=0.906338, subsample_for_bin=50000,\n",
      "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 1 fold 1\n",
      "best round 4414\n",
      "('Score: ', 0.54742059022788603)\n",
      "Model 1 fold 1 fitting finished in 263.999s\n",
      "Model 1 fold 2\n",
      "best round 4484\n",
      "('Score: ', 0.53834564169299826)\n",
      "Model 1 fold 2 fitting finished in 264.343s\n",
      "Model 1 fold 3\n",
      "best round 5433\n",
      "('Score: ', 0.52002354479242485)\n",
      "Model 1 fold 3 fitting finished in 319.295s\n",
      "Model 1 fold 4\n",
      "best round 4580\n",
      "('Score: ', 0.53299288102913467)\n",
      "Model 1 fold 4 fitting finished in 278.350s\n",
      "Model 1 fold 5\n",
      "best round 4423\n",
      "('Score: ', 0.5292383384785998)\n",
      "Model 1 fold 5 fitting finished in 268.835s\n",
      "Model 1 fold 6\n",
      "best round 4734\n",
      "('Score: ', 0.53758369648872439)\n",
      "Model 1 fold 6 fitting finished in 281.519s\n",
      "Model 1 fold 7\n",
      "best round 4165\n",
      "('Score: ', 0.54643068082996216)\n",
      "Model 1 fold 7 fitting finished in 255.253s\n",
      "Model 1 fold 8\n",
      "best round 4476\n",
      "('Score: ', 0.53807925392600509)\n",
      "Model 1 fold 8 fitting finished in 270.407s\n",
      "Model 1 fold 9\n",
      "best round 4355\n",
      "('Score: ', 0.55025280027964596)\n",
      "Model 1 fold 9 fitting finished in 266.744s\n",
      "Model 1 fold 10\n",
      "best round 4373\n",
      "('Score: ', 0.55056816953500876)\n",
      "Model 1 fold 10 fitting finished in 268.334s\n",
      "Score for model 1 is 0.539094\n",
      "Score for blended models is 0.539094\n"
     ]
    }
   ],
   "source": [
    "lgb_params = [lgb.LGBMClassifier(num_leaves = 29,\n",
    "                                min_child_samples = 118,\n",
    "                                colsample_bytree = 0.668988,\n",
    "                                subsample = 0.906338,\n",
    "                                max_bin = 570)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# [{'num_leaves': 29,\n",
    "#                'min_child_samples': 118,\n",
    "#                'colsample_bytree': 0.668988,\n",
    "#                'subsample': 0.906338,\n",
    "#                'max_bin': 570},\n",
    "#               {'num_leaves': 27,\n",
    "#                'min_child_samples': 57,\n",
    "#                'colsample_bytree': 0.572919,\n",
    "#                'subsample': 0.894120,\n",
    "#                'max_bin': 599},\n",
    "#               {'num_leaves': 27,\n",
    "#                'min_child_samples': 61,\n",
    "#                'colsample_bytree': 0.685552,\n",
    "#                'subsample': 0.917137,\n",
    "#                'max_bin': 597},\n",
    "#               {'num_leaves': 24,\n",
    "#                'min_child_samples': 119,\n",
    "#                'colsample_bytree': 0.682721,\n",
    "#                'subsample': 0.970793,\n",
    "#                'max_bin': 579},\n",
    "#               {'num_leaves': 22,\n",
    "#                'min_child_samples': 119,\n",
    "#                'colsample_bytree': 0.792176,\n",
    "#                'subsample': 0.814238,\n",
    "#                'max_bin': 522}\n",
    "#              ]\n",
    "\n",
    "#  \tnum_leaves \tmin_child_samples \tmax_bin \tcolsample_bytree \tsubsample \tscore\n",
    "# 14 \t29.852527 \t118.781925 \t\t\t570.090868 \t0.668988 \t\t\t0.906338 \t-0.545548\n",
    "# 29 \t27.427507 \t57.670210 \t\t\t599.355654 \t0.572919 \t\t\t0.894120 \t-0.545682\n",
    "# 19 \t27.254632 \t61.202351 \t\t\t597.445820 \t0.685552 \t\t\t0.917137 \t-0.545765\n",
    "# 15 \t24.186654 \t119.863943 \t\t\t579.232870 \t0.682721 \t\t\t0.970793 \t-0.546031\n",
    "# 10 \t22.604751 \t119.933426 \t\t\t522.803963 \t0.792176 \t\t\t0.814238 \t-0.546135\n",
    "\n",
    "(train_blend_x_gbm,\n",
    " test_blend_x_gbm,\n",
    " blend_scores_gbm,\n",
    " best_rounds_gbm) = lgbm_blend(lgb_params, \n",
    "                               train_X, train_y, \n",
    "                               test_X,\n",
    "                               10,\n",
    "                               500) #as the learning rate decreases the number of stopping rounds need to be increased\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rounds_gbm[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 2, 2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "sub_name = '../output/sub_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_blend_x_gbm[:,:3])\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54336879  0.54314207  0.54391966  0.54451063  0.54393703]\n",
      "4863.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend = '../output/test_blend_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_gbm,axis=0))\n",
    "print (np.mean(best_rounds_gbm,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_gbm, delimiter=\",\")\n",
    "np.savetxt(name_test_blend,test_blend_x_gbm, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "df = pd.read_json(open(\"../input/test.json\", \"r\"))\n",
    "labels2idx ={'high': 0, 'low': 2, 'medium': 1}\n",
    "sub_name = '../output/sub_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = df[\"listing_id\"]\n",
    "\n",
    "y_test = np.zeros((df.shape[0], 3))\n",
    "\n",
    "for N in range(3):\n",
    "    y_test[:,N] = pd.DataFrame(test_blend_x_gbm).iloc[:,[x for x in range(test_blend_x_gbm.shape[1]) if x%3 == N]].mean(axis=1)\n",
    "    \n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_test[:, labels2idx[label]]\n",
    "sub.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "df = pd.read_json(open(\"../input/test.json\", \"r\"))\n",
    "sub_name = '../output/sub_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "# sub = pd.DataFrame()\n",
    "tmp2[\"listing_id\"] = df[\"listing_id\"].values\n",
    "# tmp1.columns = ['0','1','2']\n",
    "# for label in [\"high\", \"medium\", \"low\"]:\n",
    "#     sub[label] = tmp2.iloc[:,label].values\n",
    "tmp2.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
