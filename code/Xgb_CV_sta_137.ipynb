{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.stats.mstats import gmean\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import skew, boxcox,boxcox_normmax\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 137) (74659, 137) (49352,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_CV_statistics1.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_CV_statistics1.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'train_y_CV_statistics.csv',header=None))\n",
    "sub_id = test_X.listing_id.astype('int32').values\n",
    "\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 137)\n",
      "(9871, 137)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "# xgtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rgr = xgb.XGBClassifier(objective = 'multi:softprob',\n",
    "#                        learning_rate = 0.1,\n",
    "#                        n_estimators = 10000,\n",
    "#                        nthread = -1,\n",
    "#                        max_depth=10)\n",
    "\n",
    "# rgr.fit(X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "# #         num_class = 3,\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=25\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pred_y = rgr.predict_proba(test_X, ntree_limit = rgr.best_iteration)\n",
    "# pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tune XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t0.531135 621\n",
      "4 \t0.528788 436\n",
      "5 \t0.528401 334\n",
      "6 \t0.529342 216\n",
      "7 \t0.532007 141\n",
      "8 \t0.532342 134\n",
      "9 \t0.536764 97\n",
      "10 \t0.538813 76\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "best_score = 1000\n",
    "train_param = 0\n",
    "for x in [3,4,5,6,7,8,9,10]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= x,\n",
    "        nthread = -1,\n",
    "        silent = False\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "max_depth = train_param\n",
    "print max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t0.527937 309\n",
      "4 \t0.528707 243\n",
      "8 \t0.529375 381\n",
      "12 \t0.528663 316\n",
      "16 \t0.528997 323\n",
      "20 \t0.52832 333\n",
      "24 \t0.528435 398\n",
      "28 \t0.528545 315\n",
      "32 \t0.528707 339\n",
      "40 \t0.527865 337\n",
      "48 \t0.529024 336\n",
      "64 \t0.528953 376\n",
      "128 \t0.531708 381\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [2,4,8,12,16,20,24,28,32,40,48,64,128]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 \t0.527787 391\n",
      "75 \t0.528922 367\n",
      "80 \t0.529824 473\n",
      "100 \t0.530926 383\n",
      "120 \t0.531655 449\n",
      "140 \t0.530849 445\n",
      "160 \t0.531763 498\n",
      "200 \t0.533395 648\n"
     ]
    }
   ],
   "source": [
    "for x in [50,75,80,100,120,140,160,200]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "min_child_weight = train_param\n",
    "print min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 \t0.533177 678\n",
      "0.1 \t0.528575 489\n",
      "0.2 \t0.527417 305\n",
      "0.3 \t0.527616 336\n",
      "0.4 \t0.527998 362\n",
      "0.5 \t0.526321 366\n",
      "0.6 \t0.527867 387\n",
      "0.7 \t0.52753 435\n",
      "0.8 \t0.527293 383\n",
      "0.9 \t0.529772 324\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = train_param\n",
    "print colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 \t0.532237 396\n",
      "0.6 \t0.52943 395\n",
      "0.7 \t0.528151 379\n",
      "0.8 \t0.528136 420\n",
      "0.9 \t0.52825 357\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        subsample = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "subsample = train_param\n",
    "print subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 \t0.527882 329\n",
      "0.6 \t0.527404 389\n",
      "0.9 \t0.528133 318\n",
      "1.2 \t0.526418 497\n",
      "1.5 \t0.528352 345\n",
      "1.8 \t0.528509 354\n",
      "2.1 \t0.527858 409\n",
      "2.4 \t0.52787 549\n",
      "2.7 \t0.525604 525\n",
      "3.0 \t0.527605 393\n"
     ]
    }
   ],
   "source": [
    "train_param = 0\n",
    "for x in [0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3.0]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        subsample = subsample,\n",
    "        gamma = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7\n"
     ]
    }
   ],
   "source": [
    "gamma = train_param\n",
    "print gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.3 \t0.52431 436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[800]\ttrain-mlogloss:0.359776+0.00266422\ttest-mlogloss:0.524082+0.00630427\n",
      "\n",
      "    1 | 14m49s | \u001b[35m  -0.52408\u001b[0m | \u001b[32m            0.3699\u001b[0m | \u001b[32m   2.7645\u001b[0m | \u001b[32m     5.2078\u001b[0m | \u001b[32m           45.4868\u001b[0m | \u001b[32m     0.8879\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[285]\ttrain-mlogloss:0.325537+0.0016814\ttest-mlogloss:0.524654+0.00677044\n",
      "\n",
      "    2 | 14m57s |   -0.52465 |             0.6851 |    2.4539 |      8.3154 |            45.7695 |      0.7657 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[551]\ttrain-mlogloss:0.339858+0.00319843\ttest-mlogloss:0.524485+0.00638942\n",
      "\n",
      "    3 | 13m06s |   -0.52448 |             0.4012 |    2.0265 |      6.6715 |            66.1248 |      0.9127 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[378]\ttrain-mlogloss:0.358955+0.0019046\ttest-mlogloss:0.525668+0.00705407\n",
      "\n",
      "    4 | 16m34s |   -0.52567 |             0.6038 |    2.8094 |      8.4318 |            97.0481 |      0.8596 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[525]\ttrain-mlogloss:0.342282+0.00196847\ttest-mlogloss:0.524124+0.00757812\n",
      "\n",
      "    5 | 13m30s |   -0.52412 |             0.3605 |    2.8978 |      7.1435 |            53.8190 |      0.8468 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[782]\ttrain-mlogloss:0.351144+0.00161723\ttest-mlogloss:0.524529+0.00639481\n",
      "\n",
      "    6 | 15m21s |   -0.52453 |             0.3991 |    2.4316 |      5.0829 |            57.9487 |      0.8338 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[314]\ttrain-mlogloss:0.3425+0.00196518\ttest-mlogloss:0.526062+0.00626777\n",
      "\n",
      "    7 | 10m58s |   -0.52606 |             0.4355 |    2.4102 |      8.7372 |            56.8017 |      0.7136 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[306]\ttrain-mlogloss:0.345179+0.00184774\ttest-mlogloss:0.525209+0.00630689\n",
      "\n",
      "    8 | 11m46s |   -0.52521 |             0.4772 |    2.5824 |      8.0178 |            57.0593 |      0.8172 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[316]\ttrain-mlogloss:0.313947+0.00197842\ttest-mlogloss:0.523528+0.00573488\n",
      "\n",
      "    9 | 13m36s | \u001b[35m  -0.52353\u001b[0m | \u001b[32m            0.5539\u001b[0m | \u001b[32m   2.0509\u001b[0m | \u001b[32m     8.4740\u001b[0m | \u001b[32m           50.0463\u001b[0m | \u001b[32m     0.9698\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[542]\ttrain-mlogloss:0.346406+0.00224511\ttest-mlogloss:0.525039+0.00622661\n",
      "\n",
      "   10 | 18m33s |   -0.52504 |             0.6295 |    2.1406 |      6.1119 |            87.9358 |      0.8766 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[971]\ttrain-mlogloss:0.374173+0.00182065\ttest-mlogloss:0.524782+0.00653497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 26m10s |   -0.52478 |             0.7417 |    2.8924 |      4.6909 |            30.0294 |      0.9526 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1019]\ttrain-mlogloss:0.403717+0.00185238\ttest-mlogloss:0.526458+0.00635421\n",
      "\n",
      "   12 | 21m50s |   -0.52646 |             0.5782 |    2.8339 |      4.0838 |            99.9071 |      0.9376 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1056]\ttrain-mlogloss:0.409918+0.00266758\ttest-mlogloss:0.52689+0.00596366\n",
      "\n",
      "   13 | 27m46s |   -0.52689 |             0.7657 |    2.9047 |      4.3252 |            75.1984 |      0.9944 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[316]\ttrain-mlogloss:0.296025+0.00157446\ttest-mlogloss:0.523184+0.00707509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.71315229e-05]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00051215]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00011172]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 11m22s | \u001b[35m  -0.52318\u001b[0m | \u001b[32m            0.3500\u001b[0m | \u001b[32m   2.4217\u001b[0m | \u001b[32m     9.9616\u001b[0m | \u001b[32m           30.0457\u001b[0m | \u001b[32m     0.9948\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[407]\ttrain-mlogloss:0.319775+0.00179118\ttest-mlogloss:0.52196+0.00636937\n",
      "\n",
      "   15 | 13m48s | \u001b[35m  -0.52196\u001b[0m | \u001b[32m            0.3431\u001b[0m | \u001b[32m   2.9852\u001b[0m | \u001b[32m     9.8936\u001b[0m | \u001b[32m           38.6922\u001b[0m | \u001b[32m     0.9886\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[527]\ttrain-mlogloss:0.325852+0.00169995\ttest-mlogloss:0.523349+0.00587314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00076742]), 'nit': 3, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 15m21s |   -0.52335 |             0.3117 |    2.5705 |      9.8625 |            83.4601 |      0.9881 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[243]\ttrain-mlogloss:0.288896+0.00319662\ttest-mlogloss:0.523907+0.00612811\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.58001912e-05]), 'nit': 7, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 17m09s |   -0.52391 |             0.7668 |    2.0165 |      9.3644 |            36.4631 |      0.9824 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[388]\ttrain-mlogloss:0.282784+0.00140062\ttest-mlogloss:0.523435+0.00518146\n",
      "\n",
      "   18 | 12m26s |   -0.52343 |             0.3160 |    2.0538 |      9.9078 |            42.3049 |      0.9979 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[443]\ttrain-mlogloss:0.347299+0.000955969\ttest-mlogloss:0.523667+0.00616503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00011712]), 'nit': 7, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 17m23s |   -0.52367 |             0.4510 |    2.9674 |      9.6916 |            89.0906 |      0.9825 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[415]\ttrain-mlogloss:0.314453+0.00197418\ttest-mlogloss:0.522546+0.00639241\n",
      "\n",
      "   20 | 13m38s |   -0.52255 |             0.3289 |    2.9662 |      9.4430 |            33.0534 |      0.9911 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[417]\ttrain-mlogloss:0.334694+0.00199873\ttest-mlogloss:0.523154+0.00626636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00160544]), 'nit': 3, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 17m51s |   -0.52315 |             0.4872 |    2.9812 |      9.9585 |            70.2075 |      0.9688 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[390]\ttrain-mlogloss:0.325184+0.00175253\ttest-mlogloss:0.522479+0.00583294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00016806]), 'nit': 7, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 13m26s |   -0.52248 |             0.3550 |    2.8788 |      9.7572 |            47.8806 |      0.9858 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1111]\ttrain-mlogloss:0.392529+0.00268541\ttest-mlogloss:0.525521+0.00659181\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00022543]), 'nit': 6, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 | 26m05s |   -0.52552 |             0.6639 |    2.9345 |      4.1309 |            51.0818 |      0.9879 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1384]\ttrain-mlogloss:0.401367+0.00477641\ttest-mlogloss:0.525243+0.00638665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00098198]), 'nit': 3, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00050873]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 18m30s |   -0.52524 |             0.3105 |    2.9130 |      4.5316 |            38.7214 |      0.9996 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1250]\ttrain-mlogloss:0.419666+0.00303129\ttest-mlogloss:0.526337+0.00621042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00082169]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 16m49s |   -0.52634 |             0.3076 |    2.8708 |      4.0273 |            93.2869 |      0.9934 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[430]\ttrain-mlogloss:0.325488+0.00255702\ttest-mlogloss:0.523205+0.00662472\n",
      "\n",
      "   26 | 16m00s |   -0.52320 |             0.4217 |    2.1147 |      9.5000 |            99.9846 |      0.9990 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[404]\ttrain-mlogloss:0.311997+0.002719\ttest-mlogloss:0.523532+0.00662383\n",
      "\n",
      "   27 | 13m03s |   -0.52353 |             0.3322 |    2.0162 |      9.7306 |            76.0949 |      0.9801 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[480]\ttrain-mlogloss:0.300542+0.00238513\ttest-mlogloss:0.522665+0.00687734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00020576]), 'nit': 3, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 14m42s |   -0.52266 |             0.3077 |    2.7993 |      9.9480 |            35.9872 |      0.9760 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[395]\ttrain-mlogloss:0.332722+0.00233335\ttest-mlogloss:0.523675+0.00629095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00062535]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 13m05s |   -0.52368 |             0.3406 |    2.7163 |      9.9466 |            63.6880 |      0.9916 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[424]\ttrain-mlogloss:0.321994+0.0016189\ttest-mlogloss:0.523886+0.00600027\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.0001597]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00029559]), 'nit': 5, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 14m00s |   -0.52389 |             0.3525 |    2.0270 |      9.9218 |            93.3794 |      0.9899 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[499]\ttrain-mlogloss:0.322601+0.00186049\ttest-mlogloss:0.522958+0.00598764\n",
      "\n",
      "   31 | 15m14s |   -0.52296 |             0.3203 |    2.9330 |      9.2927 |            51.2480 |      0.9928 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[396]\ttrain-mlogloss:0.32169+0.00280418\ttest-mlogloss:0.522762+0.00677553\n",
      "\n",
      "   32 | 14m25s |   -0.52276 |             0.3757 |    2.9831 |      9.3205 |            40.7963 |      0.9942 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[528]\ttrain-mlogloss:0.33185+0.00227839\ttest-mlogloss:0.522142+0.00630805\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00149224]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 14m36s |   -0.52214 |             0.3036 |    2.9123 |      8.0124 |            47.3447 |      0.9935 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[563]\ttrain-mlogloss:0.329555+0.00272212\ttest-mlogloss:0.523007+0.00633885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00057485]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 15m06s |   -0.52301 |             0.3080 |    2.9096 |      8.2670 |            49.2890 |      0.9955 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[271]\ttrain-mlogloss:0.331888+0.00343583\ttest-mlogloss:0.523843+0.00606784\n",
      "\n",
      "   35 | 12m00s |   -0.52384 |             0.4469 |    2.0094 |      9.7599 |            68.5086 |      0.9940 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1248]\ttrain-mlogloss:0.408691+0.0032489\ttest-mlogloss:0.525518+0.00615553\n",
      "\n",
      "   36 | 18m16s |   -0.52552 |             0.3439 |    2.9296 |      4.1428 |            63.8607 |      0.9949 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[680]\ttrain-mlogloss:0.328734+0.00150574\ttest-mlogloss:0.522417+0.00681082\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00236639]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 15m53s |   -0.52242 |             0.3050 |    2.9975 |      7.4795 |            30.6884 |      0.9898 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[455]\ttrain-mlogloss:0.32923+0.00185983\ttest-mlogloss:0.522154+0.00654895\n",
      "\n",
      "   38 | 12m38s |   -0.52215 |             0.3041 |    2.8941 |      8.7357 |            37.7799 |      0.9874 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[529]\ttrain-mlogloss:0.332931+0.00176829\ttest-mlogloss:0.523188+0.00578049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00010286]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00011302]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 15m45s |   -0.52319 |             0.3103 |    2.8375 |      9.6975 |            72.8310 |      0.9928 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[913]\ttrain-mlogloss:0.380035+0.00234085\ttest-mlogloss:0.524865+0.0066144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.28581421e-05]), 'nit': 7, 'funcalls': 61}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.76151077e-05]), 'nit': 6, 'funcalls': 62}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 | 17m47s |   -0.52486 |             0.4831 |    2.5172 |      4.7847 |            45.3399 |      0.9268 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[875]\ttrain-mlogloss:0.398898+0.00195013\ttest-mlogloss:0.524852+0.00578102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.01061867e-05]), 'nit': 7, 'funcalls': 61}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00040987]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 14m45s |   -0.52485 |             0.3042 |    2.9897 |      5.7696 |            81.2279 |      0.9923 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[546]\ttrain-mlogloss:0.340599+0.0023427\ttest-mlogloss:0.523179+0.00643942\n",
      "\n",
      "   42 | 12m13s |   -0.52318 |             0.3284 |    2.4206 |      6.9817 |            33.0168 |      0.9909 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[495]\ttrain-mlogloss:0.33266+0.00159504\ttest-mlogloss:0.522333+0.00656059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  6.18415797e-05]), 'nit': 5, 'funcalls': 90}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 13m35s |   -0.52233 |             0.3018 |    2.8663 |      8.0424 |            46.9486 |      0.9958 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[311]\ttrain-mlogloss:0.329929+0.00202065\ttest-mlogloss:0.523588+0.00648347\n",
      "\n",
      "   44 | 11m02s |   -0.52359 |             0.3237 |    2.8720 |      9.9537 |            38.2804 |      0.9071 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[337]\ttrain-mlogloss:0.343478+0.00299261\ttest-mlogloss:0.524647+0.00534775\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00092394]), 'nit': 4, 'funcalls': 57}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 21m18s |   -0.52465 |             0.7460 |    2.9599 |      9.5553 |            79.9405 |      0.9984 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[528]\ttrain-mlogloss:0.344857+0.00165415\ttest-mlogloss:0.524154+0.00757224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00138208]), 'nit': 3, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 | 22m45s |   -0.52415 |             0.7843 |    2.9799 |      6.0434 |            34.6694 |      0.9908 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[288]\ttrain-mlogloss:0.332665+0.00313116\ttest-mlogloss:0.524482+0.0062659\n",
      "\n",
      "   47 | 19m37s |   -0.52448 |             0.7885 |    2.0738 |      9.4162 |            86.3951 |      0.9749 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[452]\ttrain-mlogloss:0.355489+0.00215729\ttest-mlogloss:0.523887+0.00647073\n",
      "\n",
      "   48 | 15m32s |   -0.52389 |             0.3705 |    2.9251 |      9.9386 |            99.9056 |      0.9590 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[428]\ttrain-mlogloss:0.339964+0.00199377\ttest-mlogloss:0.524351+0.006255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.0018803]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.0016431]), 'nit': 3, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 20m27s |   -0.52435 |             0.7165 |    2.9591 |      7.7461 |            44.1374 |      0.9968 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[848]\ttrain-mlogloss:0.366512+0.00208806\ttest-mlogloss:0.52401+0.00637071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00026417]), 'nit': 4, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 16m46s |   -0.52401 |             0.3021 |    2.9954 |      6.0283 |            69.7415 |      0.9776 | \n"
     ]
    }
   ],
   "source": [
    "xgtrain = xgb.DMatrix(train_X, label=train_y) \n",
    "\n",
    "def xgb_evaluate(min_child_weight, colsample_bytree, max_depth, subsample, gamma):\n",
    "    params = dict()\n",
    "    params['objective']='multi:softprob'\n",
    "    params['eval_metric']='mlogloss',\n",
    "    params['num_class']=3\n",
    "    params['silent']=1\n",
    "    params['eta'] = 0.1\n",
    "    params['verbose_eval'] = True\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    \n",
    "    cv_result = xgb.cv(\n",
    "        params, xgtrain, \n",
    "        num_boost_round=10000, nfold=5,\n",
    "        metrics = 'mlogloss',\n",
    "        seed=seed,callbacks=[xgb.callback.early_stop(50)]\n",
    "    )\n",
    "    \n",
    "    return -cv_result['test-mlogloss-mean'].values[-1]\n",
    "\n",
    "\n",
    "xgb_BO = BayesianOptimization(\n",
    "    xgb_evaluate, \n",
    "    {\n",
    "        'max_depth': (4,10),\n",
    "        'min_child_weight': (30,100),\n",
    "        'colsample_bytree': (0.3,0.8),\n",
    "        'subsample': (0.7,1),\n",
    "        'gamma': (2,3)\n",
    "    }\n",
    ")\n",
    "\n",
    "xgb_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>gamma</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.893582</td>\n",
       "      <td>38.692208</td>\n",
       "      <td>0.343099</td>\n",
       "      <td>0.988641</td>\n",
       "      <td>2.985231</td>\n",
       "      <td>-0.521960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.012421</td>\n",
       "      <td>47.344712</td>\n",
       "      <td>0.303623</td>\n",
       "      <td>0.993480</td>\n",
       "      <td>2.912287</td>\n",
       "      <td>-0.522142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.735716</td>\n",
       "      <td>37.779927</td>\n",
       "      <td>0.304125</td>\n",
       "      <td>0.987374</td>\n",
       "      <td>2.894111</td>\n",
       "      <td>-0.522154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.042435</td>\n",
       "      <td>46.948556</td>\n",
       "      <td>0.301839</td>\n",
       "      <td>0.995753</td>\n",
       "      <td>2.866326</td>\n",
       "      <td>-0.522333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.479458</td>\n",
       "      <td>30.688415</td>\n",
       "      <td>0.305018</td>\n",
       "      <td>0.989820</td>\n",
       "      <td>2.997530</td>\n",
       "      <td>-0.522417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.757235</td>\n",
       "      <td>47.880630</td>\n",
       "      <td>0.355007</td>\n",
       "      <td>0.985846</td>\n",
       "      <td>2.878814</td>\n",
       "      <td>-0.522479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.442971</td>\n",
       "      <td>33.053379</td>\n",
       "      <td>0.328882</td>\n",
       "      <td>0.991066</td>\n",
       "      <td>2.966176</td>\n",
       "      <td>-0.522546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.947977</td>\n",
       "      <td>35.987158</td>\n",
       "      <td>0.307668</td>\n",
       "      <td>0.976048</td>\n",
       "      <td>2.799263</td>\n",
       "      <td>-0.522665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.320539</td>\n",
       "      <td>40.796274</td>\n",
       "      <td>0.375652</td>\n",
       "      <td>0.994171</td>\n",
       "      <td>2.983123</td>\n",
       "      <td>-0.522762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.292661</td>\n",
       "      <td>51.247953</td>\n",
       "      <td>0.320341</td>\n",
       "      <td>0.992831</td>\n",
       "      <td>2.933025</td>\n",
       "      <td>-0.522958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  colsample_bytree  subsample     gamma  \\\n",
       "4    9.893582         38.692208          0.343099   0.988641  2.985231   \n",
       "22   8.012421         47.344712          0.303623   0.993480  2.912287   \n",
       "27   8.735716         37.779927          0.304125   0.987374  2.894111   \n",
       "32   8.042435         46.948556          0.301839   0.995753  2.866326   \n",
       "26   7.479458         30.688415          0.305018   0.989820  2.997530   \n",
       "11   9.757235         47.880630          0.355007   0.985846  2.878814   \n",
       "9    9.442971         33.053379          0.328882   0.991066  2.966176   \n",
       "17   9.947977         35.987158          0.307668   0.976048  2.799263   \n",
       "21   9.320539         40.796274          0.375652   0.994171  2.983123   \n",
       "20   9.292661         51.247953          0.320341   0.992831  2.933025   \n",
       "\n",
       "       score  \n",
       "4  -0.521960  \n",
       "22 -0.522142  \n",
       "27 -0.522154  \n",
       "32 -0.522333  \n",
       "26 -0.522417  \n",
       "11 -0.522479  \n",
       "9  -0.522546  \n",
       "17 -0.522665  \n",
       "21 -0.522762  \n",
       "20 -0.522958  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bo_scores = pd.DataFrame([[s[0]['max_depth'],\n",
    "                               s[0]['min_child_weight'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[0]['gamma'],\n",
    "                               s[1]] for s in zip(xgb_BO.res['all']['params'],xgb_BO.res['all']['values'])],\n",
    "                            columns = ['max_depth',\n",
    "                                       'min_child_weight',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'gamma',\n",
    "                                       'score'])\n",
    "xgb_bo_scores=xgb_bo_scores.sort_values('score',ascending=False)\n",
    "xgb_bo_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgb_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,random_state=5555)\n",
    "    N_class = len(set(train_y))\n",
    "        \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(objective = 'multi:softprob')\n",
    "        est.set_params(silent = False)\n",
    "        est.set_params(learning_rate = 0.02)\n",
    "        est.set_params(n_estimators=100000)\n",
    "        \n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "    \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]      \n",
    "\n",
    "            est.fit(train_x_fold,train_y_fold,\n",
    "                    eval_set = [(val_x_fold, val_y_fold)],\n",
    "                    eval_metric = 'mlogloss',\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose=False)\n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,ntree_limit=best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score\n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,ntree_limit=best_round)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 5 folds\n",
      "Model 1: XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.343099,\n",
      "       gamma=2.985231, learning_rate=0.02, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=38, missing=None, n_estimators=100000, nthread=-1,\n",
      "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=False, subsample=0.988641)\n",
      "Model 1 fold 1\n",
      "best round 2961\n",
      "('Score: ', 0.52787300051941943)\n",
      "Model 1 fold 1 fitting finished in 1228.371s\n",
      "Model 1 fold 2\n",
      "best round 2786\n",
      "('Score: ', 0.51394843915298571)\n",
      "Model 1 fold 2 fitting finished in 1151.684s\n",
      "Model 1 fold 3\n",
      "best round 2585\n",
      "('Score: ', 0.50899454391635279)\n",
      "Model 1 fold 3 fitting finished in 1085.774s\n",
      "Model 1 fold 4\n",
      "best round 2206\n",
      "('Score: ', 0.51631266030810785)\n",
      "Model 1 fold 4 fitting finished in 955.296s\n",
      "Model 1 fold 5\n",
      "best round 2169\n",
      "('Score: ', 0.53492282837144667)\n",
      "Model 1 fold 5 fitting finished in 981.424s\n",
      "Score for model 1 is 0.520410\n",
      "Score for blended models is 0.520410\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "#             xgb.XGBClassifier(max_depth = 7,\n",
    "#                               min_child_weight = 5,\n",
    "#                               colsample_bytree = 0.293906 ,\n",
    "#                               subsample = 0.947733 ,\n",
    "#                               gamma = 2.983057),\n",
    "#              xgb.XGBClassifier(max_depth = 6,\n",
    "#                               min_child_weight = 2,\n",
    "#                               colsample_bytree = 0.200079,\n",
    "#                               subsample = 0.976483,\n",
    "#                               gamma = 2.872736),\n",
    "#              xgb.XGBClassifier(max_depth = 6,\n",
    "#                               min_child_weight = 25,\n",
    "#                               colsample_bytree = 0.273249,\n",
    "#                               subsample = 0.983080,\n",
    "#                               gamma = 2.978747),         \n",
    "#              xgb.XGBClassifier(max_depth = 7,\n",
    "#                               min_child_weight = 4,\n",
    "#                               colsample_bytree = 0.219052,\n",
    "#                               subsample = 0.741765,\n",
    "#                               gamma = 2.649557),  \n",
    "             xgb.XGBClassifier(max_depth = 9,\n",
    "                              min_child_weight = 38,\n",
    "                              colsample_bytree = 0.343099,\n",
    "                              subsample = 0.988641,\n",
    "                              gamma = 2.985231)              \n",
    "             ]\n",
    "\n",
    "#  \tmax_depth \tmin_child_weight \tcolsample_bytree \tsubsample \tgamma \tscore\n",
    "# 4 \t9.893582 \t38.692208 \t0.343099 \t0.988641 \t2.985231 \t-0.521960\n",
    "\n",
    "(train_blend_x_xgb,\n",
    " test_blend_x_xgb_mean,\n",
    " test_blend_x_xgb_gmean,\n",
    " blend_scores_xgb,\n",
    " best_rounds_xgb) = xgb_blend(estimators,\n",
    "                              train_X,train_y,\n",
    "                              test_X,\n",
    "                              5,\n",
    "                              500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52041029]\n",
      "[ 2541.4]\n"
     ]
    }
   ],
   "source": [
    "# now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_xgb_cv137_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_mean_cv137_5blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../output/test_blend_xgb_gmean_cv137_5blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb,axis=0))\n",
    "print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_xgb, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_xgb_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_xgb_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data 0322\n",
    "# [ 0.52385999  0.52420308  0.52429754  0.52366222  0.52450185]\n",
    "# [ 2866.7  3979.7  3102.9  2783.1  4450.5]\n",
    "\n",
    "# data 0331 seed = 2017\n",
    "# [ 0.5161796   0.51727863  0.51867825  0.517129    0.51732854]\n",
    "# [ 4857.5  6379.5  5516.4  3337.9  1674.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "sub_name = '../output/sub_XGB_mean_cv137_5blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_blend_x_xgb_mean[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)\n",
    "\n",
    "\n",
    "# ypreds.columns = cols\n",
    "\n",
    "# df = pd.read_json(open(\"../input/test.json\", \"r\"))\n",
    "# ypreds['listing_id'] = df[\"listing_id\"]\n",
    "\n",
    "# ypreds.to_csv('my_preds.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.922978</td>\n",
       "      <td>0.073872</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>7211212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.992813</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>7150865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.375499</td>\n",
       "      <td>0.488779</td>\n",
       "      <td>0.135722</td>\n",
       "      <td>6887163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.962468</td>\n",
       "      <td>0.035217</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>6888711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995041</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>6934781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        low    medium      high  listing_id\n",
       "0  0.922978  0.073872  0.003150     7211212\n",
       "1  0.992813  0.006688  0.000499     7150865\n",
       "2  0.375499  0.488779  0.135722     6887163\n",
       "3  0.962468  0.035217  0.002315     6888711\n",
       "4  0.995041  0.004485  0.000474     6934781"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_blend_x_xgb = pd.DataFrame(train_blend_x_xgb[:,:3])\n",
    "# train_blend_x_xgb.columns = [\"low\", \"medium\", \"high\"]\n",
    "train_blend_x_xgb[\"listing_id\"] = train_X.listing_id.values\n",
    "\n",
    "train_blend_x_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396023</td>\n",
       "      <td>0.536280</td>\n",
       "      <td>0.067697</td>\n",
       "      <td>7142618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.009421</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>7210040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.656210</td>\n",
       "      <td>0.297715</td>\n",
       "      <td>0.046075</td>\n",
       "      <td>7103890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511647</td>\n",
       "      <td>0.458835</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>7143442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734743</td>\n",
       "      <td>0.241889</td>\n",
       "      <td>0.023367</td>\n",
       "      <td>6860601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        low    medium      high  listing_id\n",
       "0  0.396023  0.536280  0.067697     7142618\n",
       "1  0.986368  0.009421  0.004211     7210040\n",
       "2  0.656210  0.297715  0.046075     7103890\n",
       "3  0.511647  0.458835  0.029519     7143442\n",
       "4  0.734743  0.241889  0.023367     6860601"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_mean = pd.DataFrame(test_blend_x_xgb_mean[:,:3])\n",
    "test_blend_x_xgb_mean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_blend_x_xgb_mean[\"listing_id\"] = test_X.listing_id.values\n",
    "\n",
    "test_blend_x_xgb_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.393007</td>\n",
       "      <td>0.533316</td>\n",
       "      <td>0.066480</td>\n",
       "      <td>7142618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.986366</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>7210040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.654150</td>\n",
       "      <td>0.293499</td>\n",
       "      <td>0.044069</td>\n",
       "      <td>7103890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509876</td>\n",
       "      <td>0.456535</td>\n",
       "      <td>0.029082</td>\n",
       "      <td>7143442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734156</td>\n",
       "      <td>0.240056</td>\n",
       "      <td>0.022615</td>\n",
       "      <td>6860601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        low    medium      high  listing_id\n",
       "0  0.393007  0.533316  0.066480     7142618\n",
       "1  0.986366  0.009226  0.004062     7210040\n",
       "2  0.654150  0.293499  0.044069     7103890\n",
       "3  0.509876  0.456535  0.029082     7143442\n",
       "4  0.734156  0.240056  0.022615     6860601"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_gmean = pd.DataFrame(test_blend_x_xgb_gmean[:,:3])\n",
    "test_blend_x_xgb_gmean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_blend_x_xgb_gmean[\"listing_id\"] = test_X.listing_id.values\n",
    "\n",
    "test_blend_x_xgb_gmean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 412) (74659, 412) (49352,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X_BM = pd.read_csv(data_path + 'train_BM_0331.csv')\n",
    "test_X_BM = pd.read_csv(data_path + 'test_BM_0331.csv')\n",
    "\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X_BM.shape, test_X_BM.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_train = train_X_BM[['listing_id']].merge(train_blend_x_xgb,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_mean = test_X_BM[['listing_id']].merge(test_blend_x_xgb_mean,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_gmean = test_X_BM[['listing_id']].merge(test_blend_x_xgb_gmean,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.56072533e-01,   4.26701188e-01,   1.72263067e-02],\n",
       "       [  2.39746541e-01,   6.89633489e-01,   7.06200078e-02],\n",
       "       [  7.54969776e-01,   2.35079646e-01,   9.95059591e-03],\n",
       "       [  9.22977567e-01,   7.38724321e-02,   3.15006310e-03],\n",
       "       [  9.70618367e-01,   2.88818572e-02,   4.99760092e-04],\n",
       "       [  8.11421454e-01,   1.43444538e-01,   4.51340489e-02],\n",
       "       [  8.50631237e-01,   1.33262530e-01,   1.61062721e-02],\n",
       "       [  2.07395151e-01,   3.02040905e-01,   4.90563989e-01],\n",
       "       [  9.58970487e-01,   3.08461860e-02,   1.01832952e-02],\n",
       "       [  9.57956672e-01,   4.12852764e-02,   7.58066250e-04]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 137)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52041029]\n",
      "[ 2541.4]\n"
     ]
    }
   ],
   "source": [
    "name_train_blend = '../output/train_blend_xgb_cv137_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_mean_cv137_5blend_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../output/test_blend_xgb_gmean_cv137_5blend_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb,axis=0))\n",
    "print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,tmp_train, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,tmp_test_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,tmp_test_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39300703,  0.5333155 ,  0.06647976],\n",
       "       [ 0.98636611,  0.00922575,  0.00406247],\n",
       "       [ 0.65414999,  0.29349853,  0.04406867],\n",
       "       ..., \n",
       "       [ 0.51356489,  0.42521578,  0.04422116],\n",
       "       [ 0.21262641,  0.46016629,  0.31441058],\n",
       "       [ 0.96598009,  0.03009712,  0.00326856]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_gmean[[\"low\", \"medium\", \"high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
