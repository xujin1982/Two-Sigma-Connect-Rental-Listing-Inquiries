{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV,StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "from scipy.stats.mstats import gmean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 322) (74659, 322) (49352L,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "ntrain = train_X.shape[0]\n",
    "sub_id = test_X.listing_id.values\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 323)\n",
      "(74659, 323)\n"
     ]
    }
   ],
   "source": [
    "time_feature = pd.read_csv(data_path + 'listing_image_time.csv')\n",
    "time_feature.columns = ['listing_id','time_stamp']\n",
    "train_X = train_X.merge(time_feature,on='listing_id',how='left')\n",
    "test_X = test_X.merge(time_feature,on='listing_id',how='left')\n",
    "\n",
    "print train_X.shape\n",
    "print test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "full_data=pd.concat([train_X,test_X])\n",
    "features_to_use = train_X.columns.values\n",
    "\n",
    "skewed_cols = full_data[features_to_use].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "SSL = preprocessing.StandardScaler()\n",
    "skewed_cols = skewed_cols[skewed_cols > 0.25].index.values\n",
    "for skewed_col in skewed_cols:\n",
    "    full_data[skewed_col], lam = boxcox(full_data[skewed_col] - full_data[skewed_col].min() + 1)\n",
    "#     print skewed_col, '\\t', lam\n",
    "for col in features_to_use:\n",
    "    full_data[col] = SSL.fit_transform(full_data[col].values.reshape(-1,1))\n",
    "    train_X[col] = full_data.iloc[:ntrain][col]\n",
    "    test_X[col] = full_data.iloc[ntrain:][col]\n",
    "\n",
    "    \n",
    "del full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN_cv(n_neighbors=5, leaf_size=30, min_samples_leaf  =1):\n",
    "    est=KNeighborsClassifier(n_neighbors=n_neighbors,\n",
    "                             weights='uniform',\n",
    "                             algorithm = 'auto', \n",
    "                             leaf_size=30,\n",
    "                             p=2,\n",
    "                             metric='minkowski',\n",
    "                             metric_params=None,\n",
    "                             n_jobs = 6\n",
    "                            )\n",
    "    return cross_val_score(est,train_X,train_y, scoring = 'neg_log_loss', cv = 3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t-7.09210073073\n",
      "4 \t-3.73297381782\n",
      "8 \t-1.83860387785\n",
      "16 \t-1.04193767543\n",
      "32 \t-0.751189283361\n",
      "64 \t-0.660328991117\n",
      "128 \t-0.639124405776\n",
      "256 \t-0.642574262549\n",
      "512 \t-0.647533513654\n",
      "1024 \t-0.658912240531\n"
     ]
    }
   ],
   "source": [
    "cv_score = -1\n",
    "for x in [2,4,8,16,32,64,128,256,512,1024]:\n",
    "    score = KNN_cv(n_neighbors = x)\n",
    "    if score > cv_score:\n",
    "        n_neighbors = x\n",
    "        cv_score = score\n",
    "    print x,'\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def KNN_blend(est, train_x, train_y, test_x, fold):\n",
    "    N_params = len(est)\n",
    "    print \"Blend %d estimators for %d folds\" % (N_params, fold)\n",
    "    skf = KFold(n_splits=fold,random_state=seed)\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros((fold,N_params))\n",
    "    best_rounds = np.zeros((fold, N_params))    \n",
    "    \n",
    "    for j, ester in enumerate(est):\n",
    "        print \"Model %d:\" %(j+1)\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "\n",
    "            \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print \"Model %d fold %d\" %(j+1,i+1)\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]            \n",
    "            \n",
    "\n",
    "            ester.fit(train_x_fold,train_y_fold)\n",
    "            \n",
    "            val_y_predict_fold = ester.predict_proba(val_x_fold)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print \"Score: \", score\n",
    "            scores[i,j]=score            \n",
    "            \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = ester.predict_proba(test_x)\n",
    "            \n",
    "            print \"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start)            \n",
    "\n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print \"Score for model %d is %f\" % (j+1,np.mean(scores[:,j]))\n",
    "    print \"Score for blended models is %f\" % (np.mean(scores))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 5 folds\n",
      "Model 1:\n",
      "Model 1 fold 1\n",
      "Score:  0.615340703901\n",
      "Model 1 fold 1 fitting finished in 758.533s\n",
      "Model 1 fold 2\n",
      "Score:  0.630051206412\n",
      "Model 1 fold 2 fitting finished in 780.405s\n",
      "Model 1 fold 3\n",
      "Score:  0.639113280129\n",
      "Model 1 fold 3 fitting finished in 778.060s\n",
      "Model 1 fold 4\n",
      "Score:  0.646832124864\n",
      "Model 1 fold 4 fitting finished in 774.767s\n",
      "Model 1 fold 5\n",
      "Score:  0.633237520276\n",
      "Model 1 fold 5 fitting finished in 756.105s\n",
      "Score for model 1 is 0.632915\n",
      "Score for blended models is 0.632915\n"
     ]
    }
   ],
   "source": [
    "est = [KNeighborsClassifier(n_neighbors=128,\n",
    "                             weights='uniform',\n",
    "                             algorithm = 'auto', \n",
    "                             leaf_size=30,\n",
    "                             p=2,\n",
    "                             metric='minkowski',\n",
    "                             metric_params=None,\n",
    "                             n_jobs = -1\n",
    "                            )]\n",
    "\n",
    "(train_blend_x_KNN,\n",
    " test_blend_x_KNN_mean,\n",
    " test_blend_x_KNN_gmean,\n",
    " blend_scores_KNN,\n",
    " best_rounds_KNN) = KNN_blend(est,\n",
    "                             train_X,train_y,\n",
    "                             test_X,\n",
    "                             5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63291497]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_KNN_uniform_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_KNN_uniform_mean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../blend/test_blend_KNN_uniform_gmean_last_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_KNN,axis=0))\n",
    "# print (np.mean(best_rounds_RFC,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_KNN, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_KNN_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_KNN_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sub_name = '../output/sub_KNN_uniform_gmean_BM_MB_add03052240_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "# out_df = pd.DataFrame(test_blend_x_KNN_gmean[:,:3])\n",
    "# out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "# out_df[\"listing_id\"] = test_X.listing_id.values\n",
    "# out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN_cv(n_neighbors=5, leaf_size=30, min_samples_leaf  =1):\n",
    "    est=KNeighborsClassifier(n_neighbors=n_neighbors,\n",
    "                             weights='distance',\n",
    "                             algorithm = 'auto', \n",
    "                             leaf_size=30,\n",
    "                             p=2,\n",
    "                             metric='minkowski',\n",
    "                             metric_params=None,\n",
    "                             n_jobs = -1\n",
    "                            )\n",
    "    return cross_val_score(est,train_X,train_y, scoring = 'neg_log_loss', cv = 3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t-6.74028696187\n",
      "5 \t-2.84410674478\n",
      "10 \t-1.42473827356\n",
      "15 \t-1.02514569526\n",
      "20 \t-0.852458642738\n",
      "25 \t-0.795439441562\n",
      "30 \t-0.748694567391\n"
     ]
    }
   ],
   "source": [
    "cv_score = -1\n",
    "for x in [2,5,10,15,20,25,30]:\n",
    "    score = KNN_cv(n_neighbors = x)\n",
    "    if score > cv_score:\n",
    "        n_neighbors = x\n",
    "        cv_score = score\n",
    "    print x,'\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 \t-0.687346768991\n",
      "50 \t-0.664688373783\n",
      "60 \t-0.6557283919\n",
      "80 \t-0.638479123695\n",
      "100 \t-0.63483641848\n",
      "125 \t-0.634912690654\n",
      "150 \t-0.634423405086\n"
     ]
    }
   ],
   "source": [
    "for x in [40,50,60,80,100,125,150]:\n",
    "    score = KNN_cv(n_neighbors = x)\n",
    "    if score > cv_score:\n",
    "        n_neighbors = x\n",
    "        cv_score = score\n",
    "    print x,'\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 \t-0.634442797659\n",
      "250 \t-0.636678241098\n",
      "300 \t-0.638700703964\n",
      "350 \t-0.637935333453\n",
      "400 \t-0.636769025963\n"
     ]
    }
   ],
   "source": [
    "for x in [200,250,300,350,400]:\n",
    "    score = KNN_cv(n_neighbors = x)\n",
    "    if score > cv_score:\n",
    "        n_neighbors = x\n",
    "        cv_score = score\n",
    "    print x,'\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 \t-0.636009959328\n",
      "225 \t-0.635686166346\n"
     ]
    }
   ],
   "source": [
    "for x in [175,225]:\n",
    "    score = KNN_cv(n_neighbors = x)\n",
    "    if score > cv_score:\n",
    "        n_neighbors = x\n",
    "        cv_score = score\n",
    "    print x,'\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 \t-0.635504409\n",
      "140 \t-0.636607688128\n",
      "160 \t-0.634973522827\n"
     ]
    }
   ],
   "source": [
    "for x in [130,140,160]:\n",
    "    score = KNN_cv(n_neighbors = x)\n",
    "    if score > cv_score:\n",
    "        n_neighbors = x\n",
    "        cv_score = score\n",
    "    print x,'\\t', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 5 estimators for 10 folds\n",
      "Model 1:\n",
      "Model 1 fold 1\n",
      "Score:  0.650497165873\n",
      "Model 1 fold 1 fitting finished in 718.635s\n",
      "Model 1 fold 2\n",
      "Score:  0.609021997115\n",
      "Model 1 fold 2 fitting finished in 723.306s\n",
      "Model 1 fold 3\n",
      "Score:  0.657031316184\n",
      "Model 1 fold 3 fitting finished in 705.383s\n",
      "Model 1 fold 4\n",
      "Score:  0.643341596082\n",
      "Model 1 fold 4 fitting finished in 728.448s\n",
      "Model 1 fold 5\n",
      "Score:  0.694507298754\n",
      "Model 1 fold 5 fitting finished in 759.582s\n",
      "Model 1 fold 6\n",
      "Score:  0.621773534412\n",
      "Model 1 fold 6 fitting finished in 784.528s\n",
      "Model 1 fold 7\n",
      "Score:  0.633047300826\n",
      "Model 1 fold 7 fitting finished in 777.207s\n",
      "Model 1 fold 8\n",
      "Score:  0.668423050631\n",
      "Model 1 fold 8 fitting finished in 778.556s\n",
      "Model 1 fold 9\n",
      "Score:  0.652535946646\n",
      "Model 1 fold 9 fitting finished in 781.776s\n",
      "Model 1 fold 10\n",
      "Score:  0.628253396408\n",
      "Model 1 fold 10 fitting finished in 775.940s\n",
      "Score for model 1 is 0.645843\n",
      "Model 2:\n",
      "Model 2 fold 1\n",
      "Score:  0.628534441397\n",
      "Model 2 fold 1 fitting finished in 796.388s\n",
      "Model 2 fold 2\n",
      "Score:  0.603607815944\n",
      "Model 2 fold 2 fitting finished in 808.506s\n",
      "Model 2 fold 3\n",
      "Score:  0.643970535591\n",
      "Model 2 fold 3 fitting finished in 775.865s\n",
      "Model 2 fold 4\n",
      "Score:  0.615325281392\n",
      "Model 2 fold 4 fitting finished in 755.594s\n",
      "Model 2 fold 5\n",
      "Score:  0.657746877281\n",
      "Model 2 fold 5 fitting finished in 731.875s\n",
      "Model 2 fold 6\n",
      "Score:  0.61407131912\n",
      "Model 2 fold 6 fitting finished in 735.870s\n",
      "Model 2 fold 7\n",
      "Score:  0.626931263385\n",
      "Model 2 fold 7 fitting finished in 735.600s\n",
      "Model 2 fold 8\n",
      "Score:  0.657270126396\n",
      "Model 2 fold 8 fitting finished in 724.622s\n",
      "Model 2 fold 9\n",
      "Score:  0.633170263295\n",
      "Model 2 fold 9 fitting finished in 724.479s\n",
      "Model 2 fold 10\n",
      "Score:  0.62419224497\n",
      "Model 2 fold 10 fitting finished in 720.072s\n",
      "Score for model 2 is 0.630482\n",
      "Model 3:\n",
      "Model 3 fold 1\n",
      "Score:  0.627380641705\n",
      "Model 3 fold 1 fitting finished in 740.458s\n",
      "Model 3 fold 2\n",
      "Score:  0.613811478033\n",
      "Model 3 fold 2 fitting finished in 736.598s\n",
      "Model 3 fold 3\n",
      "Score:  0.638071693978\n",
      "Model 3 fold 3 fitting finished in 732.582s\n",
      "Model 3 fold 4\n",
      "Score:  0.622611374692\n",
      "Model 3 fold 4 fitting finished in 739.981s\n",
      "Model 3 fold 5\n",
      "Score:  0.660680138748\n",
      "Model 3 fold 5 fitting finished in 731.455s\n",
      "Model 3 fold 6\n",
      "Score:  0.621899428102\n",
      "Model 3 fold 6 fitting finished in 746.609s\n",
      "Model 3 fold 7\n",
      "Score:  0.634501226662\n",
      "Model 3 fold 7 fitting finished in 737.754s\n",
      "Model 3 fold 8\n",
      "Score:  0.658368427025\n",
      "Model 3 fold 8 fitting finished in 735.506s\n",
      "Model 3 fold 9\n",
      "Score:  0.638900690508\n",
      "Model 3 fold 9 fitting finished in 734.656s\n",
      "Model 3 fold 10\n",
      "Score:  0.631234623494\n",
      "Model 3 fold 10 fitting finished in 735.060s\n",
      "Score for model 3 is 0.634746\n",
      "Model 4:\n",
      "Model 4 fold 1\n",
      "Score:  0.635719324125\n",
      "Model 4 fold 1 fitting finished in 749.785s\n",
      "Model 4 fold 2\n",
      "Score:  0.618305381334\n",
      "Model 4 fold 2 fitting finished in 745.503s\n",
      "Model 4 fold 3\n",
      "Score:  0.641302135885\n",
      "Model 4 fold 3 fitting finished in 745.375s\n",
      "Model 4 fold 4\n",
      "Score:  0.625700933581\n",
      "Model 4 fold 4 fitting finished in 753.163s\n",
      "Model 4 fold 5\n",
      "Score:  0.655924759534\n",
      "Model 4 fold 5 fitting finished in 746.514s\n",
      "Model 4 fold 6\n",
      "Score:  0.631281016294\n",
      "Model 4 fold 6 fitting finished in 749.874s\n",
      "Model 4 fold 7\n",
      "Score:  0.64334094825\n",
      "Model 4 fold 7 fitting finished in 745.996s\n",
      "Model 4 fold 8\n",
      "Score:  0.659970915977\n",
      "Model 4 fold 8 fitting finished in 746.342s\n",
      "Model 4 fold 9\n",
      "Score:  0.647936285802\n",
      "Model 4 fold 9 fitting finished in 745.617s\n",
      "Model 4 fold 10\n",
      "Score:  0.637537591427\n",
      "Model 4 fold 10 fitting finished in 743.818s\n",
      "Score for model 4 is 0.639702\n",
      "Model 5:\n",
      "Model 5 fold 1\n",
      "Score:  0.646568608967\n",
      "Model 5 fold 1 fitting finished in 768.002s\n",
      "Model 5 fold 2\n",
      "Score:  0.630039660312\n",
      "Model 5 fold 2 fitting finished in 769.108s\n",
      "Model 5 fold 3\n",
      "Score:  0.651805286949\n",
      "Model 5 fold 3 fitting finished in 773.781s\n",
      "Model 5 fold 4\n",
      "Score:  0.637190570603\n",
      "Model 5 fold 4 fitting finished in 767.125s\n",
      "Model 5 fold 5\n",
      "Score:  0.666535646145\n",
      "Model 5 fold 5 fitting finished in 773.596s\n",
      "Model 5 fold 6\n",
      "Score:  0.642535941338\n",
      "Model 5 fold 6 fitting finished in 780.840s\n",
      "Model 5 fold 7\n",
      "Score:  0.654655860901\n",
      "Model 5 fold 7 fitting finished in 766.454s\n",
      "Model 5 fold 8\n",
      "Score:  0.670330653752\n",
      "Model 5 fold 8 fitting finished in 773.798s\n",
      "Model 5 fold 9\n",
      "Score:  0.658358950377\n",
      "Model 5 fold 9 fitting finished in 779.639s\n",
      "Model 5 fold 10\n",
      "Score:  0.646926999911\n",
      "Model 5 fold 10 fitting finished in 765.716s\n",
      "Score for model 5 is 0.650495\n",
      "Score for blended models is 0.640254\n"
     ]
    }
   ],
   "source": [
    "est = [KNeighborsClassifier(n_neighbors=64,\n",
    "                             weights='distance',\n",
    "                             algorithm = 'auto', \n",
    "                             leaf_size=30,\n",
    "                             p=2,\n",
    "                             metric='minkowski',\n",
    "                             metric_params=None,\n",
    "                             n_jobs = 6\n",
    "                            ),\n",
    "      KNeighborsClassifier(n_neighbors=128,\n",
    "                             weights='distance',\n",
    "                             algorithm = 'auto', \n",
    "                             leaf_size=30,\n",
    "                             p=2,\n",
    "                             metric='minkowski',\n",
    "                             metric_params=None,\n",
    "                             n_jobs = 6\n",
    "                            ),\n",
    "      KNeighborsClassifier(n_neighbors=256,\n",
    "                             weights='distance',\n",
    "                             algorithm = 'auto', \n",
    "                             leaf_size=30,\n",
    "                             p=2,\n",
    "                             metric='minkowski',\n",
    "                             metric_params=None,\n",
    "                             n_jobs = 6\n",
    "                            ),\n",
    "      KNeighborsClassifier(n_neighbors=512,\n",
    "                             weights='distance',\n",
    "                             algorithm = 'auto', \n",
    "                             leaf_size=30,\n",
    "                             p=2,\n",
    "                             metric='minkowski',\n",
    "                             metric_params=None,\n",
    "                             n_jobs = 6\n",
    "                            ),\n",
    "      KNeighborsClassifier(n_neighbors=1024,\n",
    "                             weights='distance',\n",
    "                             algorithm = 'auto', \n",
    "                             leaf_size=30,\n",
    "                             p=2,\n",
    "                             metric='minkowski',\n",
    "                             metric_params=None,\n",
    "                             n_jobs = 6\n",
    "                            )]\n",
    "\n",
    "(train_blend_x_KNN,\n",
    " test_blend_x_KNN_mean,\n",
    " test_blend_x_KNN_gmean,\n",
    " blend_scores_KNN,\n",
    " best_rounds_KNN) = KNN_blend(est,\n",
    "                             train_X,train_y,\n",
    "                             test_X,\n",
    "                             10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64584326  0.63048202  0.63474597  0.63970193  0.65049482]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_KNN_distance_BM_0322_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_KNN_distance_mean_BM_0322_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../blend/test_blend_KNN_distance_gmean_BM_0322_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_KNN,axis=0))\n",
    "# print (np.mean(best_rounds_RFC,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_KNN, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_KNN_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_KNN_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
