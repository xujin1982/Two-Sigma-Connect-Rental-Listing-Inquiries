{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 412) (74659, 412) (49352L,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_BM_0331.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_BM_0331.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "sub_id = test_X.listing_id.astype('int32').values\n",
    "\n",
    "null_ind = test_X.num_loc_price_diff.isnull()\n",
    "test_X['num_loc_price_diff'] = test_X['num_price'] - test_X['num_loc_median_price']\n",
    "# test_X[null_ind][['num_loc_price_diff','num_price','num_loc_median_price']]\n",
    "\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 412)\n",
      "(9871, 412)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "\n",
    "# import sys  \n",
    "# stdi,stdo,stde=sys.stdin,sys.stdout,sys.stderr\n",
    "# reload(sys)  \n",
    "# sys.stdin,sys.stdout,sys.stderr=stdi,stdo,stde\n",
    "# sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[25]\tvalid_0's multi_logloss: 0.604683\n",
      "[50]\tvalid_0's multi_logloss: 0.556987\n",
      "[75]\tvalid_0's multi_logloss: 0.544693\n",
      "[100]\tvalid_0's multi_logloss: 0.539017\n",
      "[125]\tvalid_0's multi_logloss: 0.536772\n",
      "[150]\tvalid_0's multi_logloss: 0.535167\n",
      "[175]\tvalid_0's multi_logloss: 0.534229\n",
      "[200]\tvalid_0's multi_logloss: 0.533892\n",
      "[225]\tvalid_0's multi_logloss: 0.533346\n",
      "[250]\tvalid_0's multi_logloss: 0.533719\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's multi_logloss: 0.533274\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.set_params(learning_rate = 0.1)\n",
    "clf.set_params(subsample_freq = 1)\n",
    "clf.set_params(objective = 'multiclass')\n",
    "clf.set_params(n_estimators = 100000)\n",
    "        \n",
    "clf = clf.fit(X_train, y_train,\n",
    "              eval_set = [(X_val,y_val)],\n",
    "              eval_metric = 'multi_logloss',\n",
    "              early_stopping_rounds = 50,\n",
    "              verbose = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.49234624e-01,   4.70735749e-01,   8.00296264e-02],\n",
       "       [  9.78020218e-01,   1.22130189e-02,   9.76676308e-03],\n",
       "       [  8.96809228e-01,   9.19339499e-02,   1.12568216e-02],\n",
       "       ..., \n",
       "       [  9.77052516e-01,   2.18812615e-02,   1.06622257e-03],\n",
       "       [  9.73375177e-01,   2.56800302e-02,   9.44793072e-04],\n",
       "       [  6.67708476e-01,   3.23468858e-01,   8.82266579e-03]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = clf.predict_proba(test_X, num_iteration = clf.best_iteration)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "# sub_name = '../output/sub_LightGBM_BM_0322_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "# out_df = pd.DataFrame(pred_y[:,:3])\n",
    "# out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "# out_df[\"listing_id\"] = sub_id\n",
    "# out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.set_params(learning_rate = 0.1)\n",
    "clf.set_params(subsample_freq = 1)\n",
    "clf.set_params(objective = 'multiclass')\n",
    "clf.set_params(n_estimators = 100000)\n",
    "\n",
    "tmp  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  \t0.533202507807 760\n",
      "15  \t0.533380582035 407\n",
      "31  \t0.533273698004 215\n",
      "63  \t0.532785716326 167\n",
      "127  \t0.537808911467 83\n",
      "255  \t0.541784028451 63\n"
     ]
    }
   ],
   "source": [
    "for x in [8,15,31,63,127,255]:\n",
    "    clf.set_params(num_leaves = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        num_leaves = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=63,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print num_leaves\n",
    "clf.set_params(num_leaves = num_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20  \t0.534607432529 181\n",
      "30  \t0.5338408244 168\n",
      "50  \t0.534499336841 154\n",
      "70  \t0.532744830038 176\n",
      "80  \t0.534183574303 158\n",
      "90  \t0.533888731728 170\n",
      "100  \t0.534698093143 157\n",
      "110  \t0.533009200404 146\n",
      "120  \t0.532805048572 141\n",
      "150  \t0.532923835951 168\n",
      "170  \t0.532091685442 197\n",
      "200  \t0.532975844929 187\n",
      "230  \t0.531032983749 174\n",
      "260  \t0.532318413446 158\n"
     ]
    }
   ],
   "source": [
    "min_child_samples = 10\n",
    "\n",
    "for x in [20, 30, 50, 70, 80,90,100,110,120,150,170,200,230,260]:\n",
    "    clf.set_params(min_child_samples = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        min_child_samples = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300  \t0.531014922999 182\n",
      "350  \t0.533646237117 179\n",
      "400  \t0.532047579469 163\n",
      "450  \t0.533212823642 193\n",
      "500  \t0.532004110603 174\n"
     ]
    }
   ],
   "source": [
    "for x in [300,350,400,450,500]:\n",
    "    clf.set_params(min_child_samples = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        min_child_samples = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=300, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=63,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print min_child_samples\n",
    "clf.set_params(min_child_samples = min_child_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2  \t0.53054947819 246\n",
      "0.3  \t0.530053128272 188\n",
      "0.4  \t0.529074280746 207\n",
      "0.5  \t0.530259562988 168\n",
      "0.6  \t0.529655608372 149\n",
      "0.7  \t0.531195321452 201\n",
      "0.8  \t0.530592604433 171\n",
      "0.9  \t0.532657872604 147\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = 1\n",
    "for x in [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    clf.set_params(colsample_bytree = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        colsample_bytree = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.4, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=300, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=63,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print colsample_bytree\n",
    "\n",
    "clf.set_params(colsample_bytree = colsample_bytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5  \t0.537608174333 189\n",
      "0.6  \t0.535259431507 191\n",
      "0.7  \t0.533627915798 184\n",
      "0.8  \t0.531106184833 215\n",
      "0.9  \t0.531171144842 164\n"
     ]
    }
   ],
   "source": [
    "subsample = 1.0\n",
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    clf.set_params(subsample = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        subsample = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.4, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=300, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=63,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1.0, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print subsample\n",
    "clf.set_params(subsample = subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15  \t0.531162807544 189\n",
      "31  \t0.530269914319 200\n",
      "63  \t0.529735792077 238\n",
      "127  \t0.529204712417 174\n",
      "511  \t0.528204412632 188\n",
      "1023  \t0.528746638861 186\n",
      "2047  \t0.528513074537 225\n"
     ]
    }
   ],
   "source": [
    "max_bin = 255\n",
    "\n",
    "for x in [15,31,63, 127, 511, 1023, 2047]: #[200,300,400]:#\n",
    "    clf.set_params(max_bin = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        max_bin = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350  \t0.529161914318 204\n",
      "400  \t0.52807891238 240\n",
      "550  \t0.529057888889 160\n",
      "600  \t0.52838262318 173\n",
      "700  \t0.528477930237 215\n",
      "1300  \t0.528727048419 164\n",
      "1500  \t0.529334495305 193\n",
      "1800  \t0.52907526234 181\n",
      "2100  \t0.529803681644 168\n",
      "2400  \t0.528498643638 150\n"
     ]
    }
   ],
   "source": [
    "for x in [350,400,550,600,700,1300,1500,1800,2100,2400]:\n",
    "    clf.set_params(max_bin = x)\n",
    "    clf = clf.fit(X_train, y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  eval_metric = 'multi_logloss',\n",
    "                  early_stopping_rounds = 50,\n",
    "                  verbose = False)\n",
    "    if tmp > clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]:\n",
    "        max_bin = x\n",
    "        tmp = clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1]\n",
    "\n",
    "\n",
    "    print x, ' \\t', clf.evals_result.values()[0]['multi_logloss'][clf.best_iteration -1], clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.4, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=400, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=300, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=63,\n",
       "        objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
       "        scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1.0, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print max_bin\n",
    "clf.set_params(max_bin = max_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "    1 | 01m48s | \u001b[35m  -0.52698\u001b[0m | \u001b[32m            0.6292\u001b[0m | \u001b[32m 655.4609\u001b[0m | \u001b[32m           196.0590\u001b[0m | \u001b[32m     58.7500\u001b[0m | \u001b[32m     0.7726\u001b[0m | \n",
      "    2 | 01m36s |   -0.52792 |             0.4858 |  420.2007 |            456.8544 |      55.5553 |      0.8656 | \n",
      "    3 | 01m57s |   -0.53286 |             0.6414 |  572.6798 |            466.0000 |      52.2623 |      0.7147 | \n",
      "    4 | 01m29s | \u001b[35m  -0.52568\u001b[0m | \u001b[32m            0.3994\u001b[0m | \u001b[32m 444.5476\u001b[0m | \u001b[32m           221.5861\u001b[0m | \u001b[32m     50.6166\u001b[0m | \u001b[32m     0.8743\u001b[0m | \n",
      "    5 | 01m57s |   -0.52687 |             0.4622 |  314.4790 |            327.1643 |      11.0416 |      0.8433 | \n",
      "    6 | 02m16s |   -0.52727 |             0.3405 |  333.9474 |            409.0500 |      15.6851 |      0.8429 | \n",
      "    7 | 02m03s |   -0.52660 |             0.5215 |  569.6177 |            301.4100 |      12.5608 |      0.7935 | \n",
      "    8 | 01m22s |   -0.52593 |             0.3765 |  278.7642 |            280.5521 |      26.1988 |      0.7825 | \n",
      "    9 | 02m37s |   -0.52678 |             0.6918 |  520.8498 |            166.0578 |       8.5578 |      0.8393 | \n",
      "   10 | 01m20s |   -0.52686 |             0.3054 |  360.3369 |            178.3738 |      79.8761 |      0.8273 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "   11 | 03m18s |   -0.52851 |             0.7445 |  315.6710 |            328.1602 |      78.8993 |      0.9104 | \n",
      "   12 | 02m17s |   -0.52598 |             0.7667 |  261.8070 |            134.4494 |      21.5381 |      0.7794 | \n",
      "   13 | 01m46s |   -0.53128 |             0.4773 |  261.8798 |            486.2007 |      25.1352 |      0.7809 | \n",
      "   14 | 02m34s |   -0.52679 |             0.7624 |  458.9977 |            245.4998 |      14.8349 |      0.8038 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.70795892e-05]), 'nit': 5, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 03m01s |   -0.52851 |             0.7158 |  551.4119 |            220.7177 |      78.7243 |      0.7649 | \n",
      "   16 | 02m46s |   -0.52601 |             0.7614 |  695.9861 |            160.7555 |      30.0256 |      0.9576 | \n",
      "   17 | 02m46s | \u001b[35m  -0.52504\u001b[0m | \u001b[32m            0.7168\u001b[0m | \u001b[32m 347.8642\u001b[0m | \u001b[32m           186.9693\u001b[0m | \u001b[32m     17.8923\u001b[0m | \u001b[32m     0.9671\u001b[0m | \n",
      "   18 | 02m59s |   -0.52593 |             0.5840 |  271.7977 |            217.2170 |      11.7845 |      0.8581 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  2.32671227e-05]), 'nit': 2, 'funcalls': 44}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 02m45s |   -0.52578 |             0.6508 |  380.6639 |            148.0683 |      10.7668 |      0.8918 | \n",
      "   20 | 03m08s |   -0.52641 |             0.7199 |  663.2364 |            245.4941 |      12.6071 |      0.9776 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00015477]), 'nit': 6, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 01m22s |   -0.52709 |             0.4273 |  405.7218 |            221.0959 |      26.3853 |      0.7211 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  3.31561542e-05]), 'nit': 4, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 03m14s |   -0.52610 |             0.6826 |  650.6457 |            161.3106 |      12.5134 |      0.7609 | \n",
      "   23 | 03m25s |   -0.52615 |             0.7912 |  318.1193 |            193.0608 |      10.6307 |      0.7718 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00036184]), 'nit': 5, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.71958523e-05]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00045121]), 'nit': 6, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 02m44s |   -0.52742 |             0.4388 |  489.4472 |            411.6182 |       9.5533 |      0.9017 | \n",
      "   25 | 02m21s |   -0.52614 |             0.7183 |  681.3723 |            124.2430 |      49.5388 |      0.8366 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00014082]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 02m20s |   -0.52737 |             0.5185 |  270.8408 |            133.8418 |      65.0826 |      0.7725 | \n",
      "   27 | 02m30s | \u001b[35m  -0.52473\u001b[0m | \u001b[32m            0.7066\u001b[0m | \u001b[32m 689.2235\u001b[0m | \u001b[32m           120.1794\u001b[0m | \u001b[32m     13.1237\u001b[0m | \u001b[32m     0.7699\u001b[0m | \n",
      "   28 | 01m41s |   -0.52707 |             0.3471 |  460.8146 |            313.7642 |      74.7979 |      0.9864 | \n",
      "   29 | 02m16s |   -0.52537 |             0.4538 |  699.2984 |            289.4009 |      16.4335 |      0.9253 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -4.32303821e-05]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 03m02s |   -0.52746 |             0.6559 |  695.7992 |            370.7342 |      12.4807 |      0.7927 | \n",
      "   31 | 02m10s |   -0.52528 |             0.6567 |  349.7725 |            161.3051 |      26.1966 |      0.9721 | \n",
      "   32 | 01m40s |   -0.52669 |             0.4055 |  438.2872 |            139.6188 |      67.6488 |      0.7992 | \n",
      "   33 | 02m37s |   -0.52668 |             0.7951 |  258.8889 |            283.6357 |      12.3130 |      0.8895 | \n",
      "   34 | 02m26s |   -0.52874 |             0.5685 |  690.8754 |            252.6525 |      78.3750 |      0.7904 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -8.14021623e-05]), 'nit': 7, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00122538]), 'nit': 6, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 02m26s |   -0.52489 |             0.3190 |  540.7971 |            122.3807 |       8.4981 |      0.9533 | \n",
      "   36 | 01m37s |   -0.52580 |             0.4154 |  257.0006 |            231.9925 |      45.0309 |      0.9206 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00131349]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 02m01s |   -0.52528 |             0.4218 |  600.9347 |            129.0075 |      13.3609 |      0.9141 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00161887]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00059439]), 'nit': 7, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   38 | 01m50s |   -0.52640 |             0.4491 |  426.9602 |            366.7376 |      22.8055 |      0.8766 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00025203]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00108111]), 'nit': 6, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  3.03896959e-05]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 03m22s |   -0.52510 |             0.7421 |  472.4078 |            120.1093 |      16.1651 |      0.9315 | \n",
      "   40 | 01m25s |   -0.52738 |             0.3558 |  330.3053 |            252.5348 |      49.3628 |      0.8111 | \n",
      "   41 | 02m15s |   -0.52566 |             0.6987 |  544.2726 |            121.7552 |      49.7833 |      0.9015 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  2.41909673e-05]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 02m13s |   -0.52591 |             0.4619 |  670.6837 |            303.2779 |      18.1906 |      0.9554 | \n",
      "   43 | 02m46s |   -0.53124 |             0.7114 |  426.0716 |            498.9683 |      17.6822 |      0.8162 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  5.91756052e-05]), 'nit': 5, 'funcalls': 56}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   44 | 01m59s |   -0.52483 |             0.4673 |  452.1541 |            121.7100 |      18.2971 |      0.9136 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00019069]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 01m35s | \u001b[35m  -0.52395\u001b[0m | \u001b[32m            0.3098\u001b[0m | \u001b[32m 453.5877\u001b[0m | \u001b[32m           158.1756\u001b[0m | \u001b[32m     17.3426\u001b[0m | \u001b[32m     0.9512\u001b[0m | \n",
      "   46 | 01m49s |   -0.52534 |             0.4146 |  461.4220 |            171.9331 |      18.7899 |      0.9245 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00045142]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   47 | 01m44s |   -0.52436 |             0.4204 |  431.1249 |            175.6897 |      34.8093 |      0.9804 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.00563527e-05]), 'nit': 5, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.19657744e-05]), 'nit': 7, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 02m17s |   -0.52541 |             0.4077 |  434.8329 |            129.9591 |      16.9366 |      0.9998 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.82032415e-05]), 'nit': 5, 'funcalls': 56}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\python\\Anaconda2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00143427]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 02m26s |   -0.53201 |             0.5063 |  689.9913 |            483.8530 |      28.7450 |      0.7858 | \n",
      "   50 | 01m47s |   -0.52677 |             0.4601 |  429.3074 |            167.6773 |      19.2457 |      0.7308 | \n"
     ]
    }
   ],
   "source": [
    "def lgbm_cv(max_bin, num_leaves, min_child_samples, colsample_bytree, subsample, learning_rate=0.1):\n",
    "    skf = KFold(n_splits=5,random_state=seed)\n",
    "    scores=[]\n",
    "    for i, (train, val) in enumerate(skf.split(train_X)):\n",
    "        est=lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                               max_bin=int(max_bin),\n",
    "                               num_leaves=int(num_leaves),\n",
    "                               min_child_samples=int(min_child_samples),\n",
    "                               colsample_bytree=colsample_bytree,\n",
    "                               subsample=subsample,\n",
    "                               subsample_freq = 1\n",
    "                              )\n",
    " \n",
    "        train_x_fold = train_X.iloc[train]\n",
    "        train_y_fold = train_y[train]\n",
    "        val_x_fold = train_X.iloc[val]\n",
    "        val_y_fold = train_y[val]\n",
    "        est.set_params( n_estimators=100000)\n",
    "        est.fit(train_x_fold,\n",
    "                train_y_fold,\n",
    "                eval_set=[(val_x_fold, val_y_fold)],\n",
    "                eval_metric='multi_logloss',\n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False\n",
    "               )\n",
    "        val_y_predict_fold = est.predict_proba(val_x_fold)\n",
    "        score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "        scores.append(score)\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "lgbm_BO = BayesianOptimization(lgbm_cv, \n",
    "                               {\n",
    "                                'max_bin': (255,700),\n",
    "                                'num_leaves': (8,80),\n",
    "                                'min_child_samples' :(120,500),\n",
    "                                'colsample_bytree': (0.3,0.8),\n",
    "                                'subsample' : (0.7,1)})\n",
    "\n",
    "lgbm_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  \t \tnum_leaves \tmin_child_samples \tmax_bin \tcolsample_bytree \tsubsample \tscore\n",
    "# 7 \t16.783674 \t168.394127 \t \t \t357.870498 \t0.398779 \t \t \t0.946050 \t-0.528477\n",
    "# 0 \t18.426665 \t87.476334 \t \t \t226.334635 \t0.716400 \t \t \t0.898679 \t-0.528612\n",
    "# 38 \t15.042746 \t171.830790 \t \t \t351.539184 \t0.396770 \t \t \t0.970258 \t-0.528655\n",
    "# 18 \t36.8216 \t120.8350\t \t \t338.2488 \t0.4020 \t \t \t \t0.9845 \t\t-0.52866\n",
    "# 24 \t21.760862 \t80.973547 \t \t \t232.334088 \t0.562594 \t \t \t0.886285 \t-0.528852\n",
    "# 34 \t23.050184 \t82.442485 \t \t \t215.680602 \t0.375532 \t \t \t0.905054 \t-0.528863\n",
    "\n",
    "# 0322 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>max_bin</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17.342582</td>\n",
       "      <td>158.175569</td>\n",
       "      <td>453.587691</td>\n",
       "      <td>0.309807</td>\n",
       "      <td>0.951246</td>\n",
       "      <td>-0.523952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>34.809317</td>\n",
       "      <td>175.689702</td>\n",
       "      <td>431.124869</td>\n",
       "      <td>0.420417</td>\n",
       "      <td>0.980390</td>\n",
       "      <td>-0.524356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.123686</td>\n",
       "      <td>120.179447</td>\n",
       "      <td>689.223522</td>\n",
       "      <td>0.706641</td>\n",
       "      <td>0.769943</td>\n",
       "      <td>-0.524734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>18.297130</td>\n",
       "      <td>121.709972</td>\n",
       "      <td>452.154081</td>\n",
       "      <td>0.467294</td>\n",
       "      <td>0.913592</td>\n",
       "      <td>-0.524832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.498056</td>\n",
       "      <td>122.380717</td>\n",
       "      <td>540.797144</td>\n",
       "      <td>0.318956</td>\n",
       "      <td>0.953308</td>\n",
       "      <td>-0.524889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.892270</td>\n",
       "      <td>186.969297</td>\n",
       "      <td>347.864169</td>\n",
       "      <td>0.716843</td>\n",
       "      <td>0.967100</td>\n",
       "      <td>-0.525036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16.165073</td>\n",
       "      <td>120.109258</td>\n",
       "      <td>472.407759</td>\n",
       "      <td>0.742136</td>\n",
       "      <td>0.931532</td>\n",
       "      <td>-0.525098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>26.196643</td>\n",
       "      <td>161.305052</td>\n",
       "      <td>349.772457</td>\n",
       "      <td>0.656672</td>\n",
       "      <td>0.972073</td>\n",
       "      <td>-0.525277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.360864</td>\n",
       "      <td>129.007466</td>\n",
       "      <td>600.934654</td>\n",
       "      <td>0.421792</td>\n",
       "      <td>0.914086</td>\n",
       "      <td>-0.525285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18.789924</td>\n",
       "      <td>171.933123</td>\n",
       "      <td>461.422015</td>\n",
       "      <td>0.414570</td>\n",
       "      <td>0.924544</td>\n",
       "      <td>-0.525342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  min_child_samples     max_bin  colsample_bytree  subsample  \\\n",
       "34   17.342582         158.175569  453.587691          0.309807   0.951246   \n",
       "36   34.809317         175.689702  431.124869          0.420417   0.980390   \n",
       "16   13.123686         120.179447  689.223522          0.706641   0.769943   \n",
       "33   18.297130         121.709972  452.154081          0.467294   0.913592   \n",
       "24    8.498056         122.380717  540.797144          0.318956   0.953308   \n",
       "6    17.892270         186.969297  347.864169          0.716843   0.967100   \n",
       "28   16.165073         120.109258  472.407759          0.742136   0.931532   \n",
       "20   26.196643         161.305052  349.772457          0.656672   0.972073   \n",
       "26   13.360864         129.007466  600.934654          0.421792   0.914086   \n",
       "35   18.789924         171.933123  461.422015          0.414570   0.924544   \n",
       "\n",
       "       score  \n",
       "34 -0.523952  \n",
       "36 -0.524356  \n",
       "16 -0.524734  \n",
       "33 -0.524832  \n",
       "24 -0.524889  \n",
       "6  -0.525036  \n",
       "28 -0.525098  \n",
       "20 -0.525277  \n",
       "26 -0.525285  \n",
       "35 -0.525342  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_bo_scores = pd.DataFrame([[s[0]['num_leaves'],\n",
    "                               s[0]['min_child_samples'],\n",
    "                               s[0]['max_bin'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[1]] for s in zip(lgbm_BO.res['all']['params'],lgbm_BO.res['all']['values'])],\n",
    "                            columns = ['num_leaves',\n",
    "                                       'min_child_samples',\n",
    "                                       'max_bin',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'score'])\n",
    "gbm_bo_scores=gbm_bo_scores.sort_values('score',ascending=False)\n",
    "gbm_bo_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgbm_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=50):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,random_state=seed)\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "#     train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "#     test_blend_x = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "#     scores = np.zeros ((fold,N_params))\n",
    "#     best_rounds = np.zeros ((fold, N_params))\n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros((fold,N_params))\n",
    "    best_rounds = np.zeros((fold, N_params))    \n",
    "\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(learning_rate = 0.005)\n",
    "        est.set_params(subsample_freq = 1)\n",
    "        est.set_params(objective = 'multiclass')\n",
    "        est.set_params(n_estimators = 1000000)\n",
    "\n",
    "        \n",
    "        print (\"Model %d: %s\" %(j+1, est)) \n",
    "\n",
    "        \n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]\n",
    "            \n",
    "            est.fit(train_x_fold, train_y_fold,\n",
    "                   eval_set = [(val_x_fold,val_y_fold)],\n",
    "                   eval_metric = 'multi_logloss',\n",
    "                   early_stopping_rounds = early_stopping_rounds,\n",
    "                   verbose = False)\n",
    "            \n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            \n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,num_iteration = best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score   \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,num_iteration=best_round)\n",
    "            \n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "            \n",
    "#         test_blend_x[:,(j*N_class):(j+1)*N_class] = \\\n",
    "#                 np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "#                           test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "#                           test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception KeyboardInterrupt in <bound method Booster.__del__ of <lightgbm.basic.Booster object at 0x0000000016AA6208>> ignored\n",
      "Exception KeyboardInterrupt in <bound method Booster.__del__ of <lightgbm.basic.Booster object at 0x0000000016ACCE10>> ignored\n"
     ]
    }
   ],
   "source": [
    "est =       [lgb.LGBMClassifier(num_leaves = 17,\n",
    "                                min_child_samples = 158,\n",
    "                                colsample_bytree = 0.309807,\n",
    "                                subsample = 0.951246,\n",
    "                                max_bin = 453),\n",
    "             lgb.LGBMClassifier(num_leaves = 34,\n",
    "                                min_child_samples = 175,\n",
    "                                colsample_bytree = 0.420417,\n",
    "                                subsample = 0.980390,\n",
    "                                max_bin = 431),\n",
    "             lgb.LGBMClassifier(num_leaves = 13,\n",
    "                                min_child_samples = 120,\n",
    "                                colsample_bytree = 0.706641,\n",
    "                                subsample = 0.769943,\n",
    "                                max_bin = 689),\n",
    "             lgb.LGBMClassifier(num_leaves = 18,\n",
    "                                min_child_samples = 121,\n",
    "                                colsample_bytree = 0.467294,\n",
    "                                subsample = 0.913592,\n",
    "                                max_bin = 452),\n",
    "             lgb.LGBMClassifier(num_leaves = 8,\n",
    "                                min_child_samples = 122,\n",
    "                                colsample_bytree = 0.318956,\n",
    "                                subsample = 0.953308,\n",
    "                                max_bin = 540)]\n",
    "\n",
    "#  \tnum_leaves \t \tmin_child_samples \tmax_bin \tcolsample_bytree \tsubsample \tscore\n",
    "# 34 \t17.342582 \t158.175569 \t \t \t453.587691 \t0.309807 \t \t \t0.951246 \t-0.523952\n",
    "# 36 \t34.809317 \t175.689702 \t \t \t431.124869 \t0.420417 \t \t \t0.980390 \t-0.524356\n",
    "# 16 \t13.123686 \t120.179447 \t \t \t689.223522 \t0.706641 \t \t \t0.769943 \t-0.524734\n",
    "# 33 \t18.297130 \t121.709972 \t \t \t452.154081 \t0.467294 \t \t \t0.913592 \t-0.524832\n",
    "# 24 \t8.498056 \t122.380717 \t \t \t540.797144 \t0.318956 \t \t \t0.953308 \t-0.524889\n",
    "\n",
    "\n",
    "\n",
    "(train_blend_x_gbm,\n",
    " test_blend_x_gbm_mean,\n",
    " test_blend_x_gbm_gmean,\n",
    " blend_scores_gbm,\n",
    " best_rounds_gbm)= lgbm_blend(est, \n",
    "                               train_X, train_y, \n",
    "                               test_X,\n",
    "                               10,\n",
    "                               1000) #as the learning rate decreases the number of stopping rounds need to be increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data 0322\n",
    "\n",
    "\n",
    "# Blend 5 estimators for 10 folds\n",
    "# Model 1: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.398779, drop_rate=0.1,\n",
    "#         is_unbalance=False, learning_rate=0.005, max_bin=357, max_depth=-1,\n",
    "#         max_drop=50, min_child_samples=168, min_child_weight=5,\n",
    "#         min_split_gain=0, n_estimators=1000000, nthread=-1, num_leaves=16,\n",
    "#         objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
    "#         scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
    "#         skip_drop=0.5, subsample=0.94605, subsample_for_bin=50000,\n",
    "#         subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)\n",
    "# Model 1 fold 1\n",
    "# best round 13658\n",
    "# ('Score: ', 0.51511027734945769)\n",
    "# Model 1 fold 1 fitting finished in 666.358s\n",
    "# Model 1 fold 2\n",
    "# best round 18966\n",
    "# ('Score: ', 0.49748491939132805)\n",
    "# Model 1 fold 2 fitting finished in 933.243s\n",
    "# Model 1 fold 3\n",
    "# best round 16912\n",
    "# ('Score: ', 0.52418540090167209)\n",
    "# Model 1 fold 3 fitting finished in 744.659s\n",
    "# Model 1 fold 4\n",
    "# best round 17529\n",
    "# ('Score: ', 0.49909289305104237)\n",
    "# Model 1 fold 4 fitting finished in 671.642s\n",
    "# Model 1 fold 5\n",
    "# best round 12866\n",
    "# ('Score: ', 0.53343311318041697)\n",
    "# Model 1 fold 5 fitting finished in 568.086s\n",
    "# Model 1 fold 6\n",
    "# best round 13399\n",
    "# ('Score: ', 0.52049272741295138)\n",
    "# Model 1 fold 6 fitting finished in 505.250s\n",
    "# Model 1 fold 7\n",
    "# best round 13580\n",
    "# ('Score: ', 0.52872157155539778)\n",
    "# Model 1 fold 7 fitting finished in 472.583s\n",
    "# Model 1 fold 8\n",
    "# best round 14739\n",
    "# ('Score: ', 0.54319696370850756)\n",
    "# Model 1 fold 8 fitting finished in 526.231s\n",
    "# Model 1 fold 9\n",
    "# best round 15989\n",
    "# ('Score: ', 0.53855626201600892)\n",
    "# Model 1 fold 9 fitting finished in 591.713s\n",
    "# Model 1 fold 10\n",
    "# best round 15025\n",
    "# ('Score: ', 0.53069150503223939)\n",
    "# Model 1 fold 10 fitting finished in 553.884s\n",
    "# Score for model 1 is 0.523097\n",
    "# Model 2: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.7164, drop_rate=0.1,\n",
    "#         is_unbalance=False, learning_rate=0.005, max_bin=226, max_depth=-1,\n",
    "#         max_drop=50, min_child_samples=87, min_child_weight=5,\n",
    "#         min_split_gain=0, n_estimators=1000000, nthread=-1, num_leaves=18,\n",
    "#         objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
    "#         scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
    "#         skip_drop=0.5, subsample=0.898679, subsample_for_bin=50000,\n",
    "#         subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)\n",
    "# Model 2 fold 1\n",
    "# best round 10248\n",
    "# ('Score: ', 0.51279527489887844)\n",
    "# Model 2 fold 1 fitting finished in 463.937s\n",
    "# Model 2 fold 2\n",
    "# best round 15443\n",
    "# ('Score: ', 0.4976452352207959)\n",
    "# Model 2 fold 2 fitting finished in 638.788s\n",
    "# Model 2 fold 3\n",
    "# best round 12373\n",
    "# ('Score: ', 0.52193792417675422)\n",
    "# Model 2 fold 3 fitting finished in 523.411s\n",
    "# Model 2 fold 4\n",
    "# best round 12944\n",
    "# ('Score: ', 0.4994116556253469)\n",
    "# Model 2 fold 4 fitting finished in 548.260s\n",
    "# Model 2 fold 5\n",
    "# best round 10491\n",
    "# ('Score: ', 0.53427000487297915)\n",
    "# Model 2 fold 5 fitting finished in 480.181s\n",
    "# Model 2 fold 6\n",
    "# best round 11402\n",
    "# ('Score: ', 0.52198833831101743)\n",
    "# Model 2 fold 6 fitting finished in 446.453s\n",
    "# Model 2 fold 7\n",
    "# best round 11700\n",
    "# ('Score: ', 0.52975063233231268)\n",
    "# Model 2 fold 7 fitting finished in 508.264s\n",
    "# Model 2 fold 8\n",
    "# best round 13942\n",
    "# ('Score: ', 0.54124823287843038)\n",
    "# Model 2 fold 8 fitting finished in 579.405s\n",
    "# Model 2 fold 9\n",
    "# best round 13851\n",
    "# ('Score: ', 0.53849899306996529)\n",
    "# Model 2 fold 9 fitting finished in 575.462s\n",
    "# Model 2 fold 10\n",
    "# best round 12086\n",
    "# ('Score: ', 0.52869565211129366)\n",
    "# Model 2 fold 10 fitting finished in 512.622s\n",
    "# Score for model 2 is 0.522624\n",
    "# Model 3: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.39677, drop_rate=0.1,\n",
    "#         is_unbalance=False, learning_rate=0.005, max_bin=351, max_depth=-1,\n",
    "#         max_drop=50, min_child_samples=171, min_child_weight=5,\n",
    "#         min_split_gain=0, n_estimators=1000000, nthread=-1, num_leaves=15,\n",
    "#         objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
    "#         scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
    "#         skip_drop=0.5, subsample=0.970258, subsample_for_bin=50000,\n",
    "#         subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)\n",
    "# Model 3 fold 1\n",
    "# best round 12874\n",
    "# ('Score: ', 0.51579970828744059)\n",
    "# Model 3 fold 1 fitting finished in 460.611s\n",
    "# Model 3 fold 2\n",
    "# best round 18224\n",
    "# ('Score: ', 0.49875315482793847)\n",
    "# Model 3 fold 2 fitting finished in 617.800s\n",
    "# Model 3 fold 3\n",
    "# best round 16410\n",
    "# ('Score: ', 0.52445295623291099)\n",
    "# Model 3 fold 3 fitting finished in 556.717s\n",
    "# Model 3 fold 4\n",
    "# best round 15824\n",
    "# ('Score: ', 0.50021228553164887)\n",
    "# Model 3 fold 4 fitting finished in 564.615s\n",
    "# Model 3 fold 5\n",
    "# best round 15533\n",
    "# ('Score: ', 0.53396460910535426)\n",
    "# Model 3 fold 5 fitting finished in 532.299s\n",
    "# Model 3 fold 6\n",
    "# best round 12458\n",
    "# ('Score: ', 0.52040391903309924)\n",
    "# Model 3 fold 6 fitting finished in 421.335s\n",
    "# Model 3 fold 7\n",
    "# best round 15590\n",
    "# ('Score: ', 0.52977879904304848)\n",
    "# Model 3 fold 7 fitting finished in 538.673s\n",
    "# Model 3 fold 8\n",
    "# best round 15934\n",
    "# ('Score: ', 0.54355795947963481)\n",
    "# Model 3 fold 8 fitting finished in 552.762s\n",
    "# Model 3 fold 9\n",
    "# best round 16181\n",
    "# ('Score: ', 0.53803790113040595)\n",
    "# Model 3 fold 9 fitting finished in 553.873s\n",
    "# Model 3 fold 10\n",
    "# best round 15159\n",
    "# ('Score: ', 0.53069840648618571)\n",
    "# Model 3 fold 10 fitting finished in 531.805s\n",
    "# Score for model 3 is 0.523566\n",
    "# Model 4: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.402, drop_rate=0.1,\n",
    "#         is_unbalance=False, learning_rate=0.005, max_bin=338, max_depth=-1,\n",
    "#         max_drop=50, min_child_samples=120, min_child_weight=5,\n",
    "#         min_split_gain=0, n_estimators=1000000, nthread=-1, num_leaves=36,\n",
    "#         objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
    "#         scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
    "#         skip_drop=0.5, subsample=0.9845, subsample_for_bin=50000,\n",
    "#         subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)\n",
    "# Model 4 fold 1\n",
    "# best round 6780\n",
    "# ('Score: ', 0.51297224026086863)\n",
    "# Model 4 fold 1 fitting finished in 388.870s\n",
    "# Model 4 fold 2\n",
    "# best round 9795\n",
    "# ('Score: ', 0.49493678490657994)\n",
    "# Model 4 fold 2 fitting finished in 456.681s\n",
    "# Model 4 fold 3\n",
    "# best round 8109\n",
    "# ('Score: ', 0.52283766823302491)\n",
    "# Model 4 fold 3 fitting finished in 446.561s\n",
    "# Model 4 fold 4\n",
    "# best round 8156\n",
    "# ('Score: ', 0.49875483248461955)\n",
    "# Model 4 fold 4 fitting finished in 438.891s\n",
    "# Model 4 fold 5\n",
    "# best round 6897\n",
    "# ('Score: ', 0.53322646425989406)\n",
    "# Model 4 fold 5 fitting finished in 356.814s\n",
    "# Model 4 fold 6\n",
    "# best round 6370\n",
    "# ('Score: ', 0.52000404633950559)\n",
    "# Model 4 fold 6 fitting finished in 469.238s\n",
    "# Model 4 fold 7\n",
    "# best round 7291\n",
    "# ('Score: ', 0.52866228253282754)\n",
    "# Model 4 fold 7 fitting finished in 406.877s\n",
    "# Model 4 fold 8\n",
    "# best round 8043\n",
    "# ('Score: ', 0.54111737889176825)\n",
    "# Model 4 fold 8 fitting finished in 426.052s\n",
    "# Model 4 fold 9\n",
    "# best round 7127\n",
    "# ('Score: ', 0.53782950085297831)\n",
    "# Model 4 fold 9 fitting finished in 370.410s\n",
    "# Model 4 fold 10\n",
    "# best round 8311\n",
    "# ('Score: ', 0.52849296178887739)\n",
    "# Model 4 fold 10 fitting finished in 467.649s\n",
    "# Score for model 4 is 0.521883\n",
    "# Model 5: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.562594, drop_rate=0.1,\n",
    "#         is_unbalance=False, learning_rate=0.005, max_bin=232, max_depth=-1,\n",
    "#         max_drop=50, min_child_samples=80, min_child_weight=5,\n",
    "#         min_split_gain=0, n_estimators=1000000, nthread=-1, num_leaves=21,\n",
    "#         objective='multiclass', reg_alpha=0, reg_lambda=0,\n",
    "#         scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
    "#         skip_drop=0.5, subsample=0.886285, subsample_for_bin=50000,\n",
    "#         subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)\n",
    "# Model 5 fold 1\n",
    "# best round 11339\n",
    "# ('Score: ', 0.51246952947927349)\n",
    "# Model 5 fold 1 fitting finished in 473.511s\n",
    "# Model 5 fold 2\n",
    "# best round 13498\n",
    "# ('Score: ', 0.49665250024834595)\n",
    "# Model 5 fold 2 fitting finished in 544.382s\n",
    "# Model 5 fold 3\n",
    "# best round 12945\n",
    "# ('Score: ', 0.52162202839399208)\n",
    "# Model 5 fold 3 fitting finished in 522.065s\n",
    "# Model 5 fold 4\n",
    "# best round 12176\n",
    "# ('Score: ', 0.49930094273345088)\n",
    "# Model 5 fold 4 fitting finished in 478.193s\n",
    "# Model 5 fold 5\n",
    "# best round 10737\n",
    "# ('Score: ', 0.53347270474127595)\n",
    "# Model 5 fold 5 fitting finished in 464.415s\n",
    "# Model 5 fold 6\n",
    "# best round 9892\n",
    "# ('Score: ', 0.52071472372899585)\n",
    "# Model 5 fold 6 fitting finished in 436.333s\n",
    "# Model 5 fold 7\n",
    "# best round 10177\n",
    "# ('Score: ', 0.52835928323419556)\n",
    "# Model 5 fold 7 fitting finished in 411.271s\n",
    "# Model 5 fold 8\n",
    "# best round 11398\n",
    "# ('Score: ', 0.54099733268775996)\n",
    "# Model 5 fold 8 fitting finished in 449.035s\n",
    "# Model 5 fold 9\n",
    "# best round 11651\n",
    "# ('Score: ', 0.53796773146228249)\n",
    "# Model 5 fold 9 fitting finished in 503.545s\n",
    "# Model 5 fold 10\n",
    "# best round 12079\n",
    "# ('Score: ', 0.5282561706228871)\n",
    "# Model 5 fold 10 fitting finished in 498.074s\n",
    "# Score for model 5 is 0.521981\n",
    "# Score for blended models is 0.522630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51778446  0.51758745  0.51859108  0.51763268  0.51941101]\n",
      "[ 15053.7   8042.4  16049.9  13754.3  28486.6]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../blend/train_blend_LightGBM_BM_0331_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../blend/test_blend_LightGBM_mean_BM_0331_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../blend/test_blend_LightGBM_gmean_BM_0331_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_gbm,axis=0))\n",
    "print (np.mean(best_rounds_gbm,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_gbm, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_gbm_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_gbm_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_LightGBM_BM_0331_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_blend_x_gbm_mean[:,6:9])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = sub_id\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data 0322\n",
    "\n",
    "# [ 0.52309656  0.52262419  0.52356597  0.52188342  0.52198129]\n",
    "# [ 15266.3  12448.   15418.7   7687.9  11589.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = (test_blend_x_gbm_mean[:,6:9] +test_blend_x_gbm_gmean[:,6:9])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = '../output/sub_LightGBM_BM_0331_total_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(temp)\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = sub_id\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
