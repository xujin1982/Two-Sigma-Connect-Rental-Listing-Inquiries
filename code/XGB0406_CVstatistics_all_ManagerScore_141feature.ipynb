{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn import model_selection,ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import time\n",
    "import random\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, LabelBinarizer, MultiLabelBinarizer,LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats.mstats import gmean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_train(train,y,max_depth = 6,min_child_weight = 1,colsample_bytree = 1, subsample = 1, gamma = 0 , verbose_eval = None,\n",
    "            seed = 0, early_stop = 50, nfold = 5, eta=0.3):\n",
    "    xgtrain = xgb.DMatrix(train, label=y)\n",
    "    params = dict()\n",
    "    params['objective']='multi:softprob'\n",
    "    params['eval_metric']='mlogloss',\n",
    "    params['num_class']=3\n",
    "    params['silent']=0\n",
    "    params['eta'] = eta\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    params['colsample_bytree'] = colsample_bytree\n",
    "    params['subsample'] = subsample\n",
    "    params['gamma'] = gamma\n",
    "    \n",
    "    cv_result = xgb.cv(\n",
    "        params, xgtrain, \n",
    "        num_boost_round=10000, nfold=nfold,\n",
    "        metrics = 'mlogloss', verbose_eval = verbose_eval,\n",
    "        seed=seed,callbacks=[xgb.callback.early_stop(early_stop, maximize=False, verbose=False)]\n",
    "    )\n",
    "\n",
    "    return cv_result['test-mlogloss-mean'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CV_st(train,test,feature1,feature2):\n",
    "    index=list(range(train.shape[0]))\n",
    "    random.seed(a=0)\n",
    "    random.shuffle(index)\n",
    "    kf = KFold(n_splits=5,shuffle=True, random_state=0)\n",
    "    \n",
    "    # median feature names\n",
    "    features_tmp = []\n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_low_median') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_medium_median') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_high_median')\n",
    "    \n",
    "    # train data \n",
    "    f_low=pd.Series([np.nan]*len(train))\n",
    "    f_medium=pd.Series([np.nan]*len(train))\n",
    "    f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "    for train_index, test_index in kf.split(index):\n",
    "        tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].median().\\\n",
    "                reset_index().rename(columns={feature2:'new'})\n",
    "        f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')\n",
    "        f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')\n",
    "        f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')   \n",
    "    train[features_tmp[0]] = f_low\n",
    "    train[features_tmp[1]] = f_medium\n",
    "    train[features_tmp[2]] = f_high\n",
    "\n",
    "    # test data\n",
    "    tmp = train.groupby(['interest_level',feature1])[feature2].median().\\\n",
    "            reset_index().rename(columns={feature2:'new'})    \n",
    "    test[features_tmp[0]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32')\n",
    "    test[features_tmp[1]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32')\n",
    "    test[features_tmp[2]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32') \n",
    "    \n",
    "\n",
    "    # mean feature names\n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_low_mean') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_medium_mean') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_high_mean')\n",
    "    \n",
    "    # train data \n",
    "    f_low=pd.Series([np.nan]*len(train))\n",
    "    f_medium=pd.Series([np.nan]*len(train))\n",
    "    f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "    for train_index, test_index in kf.split(index):\n",
    "        tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].mean().\\\n",
    "                reset_index().rename(columns={feature2:'new'})\n",
    "        f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')\n",
    "        f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')\n",
    "        f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')   \n",
    "    train[features_tmp[3]] = f_low\n",
    "    train[features_tmp[4]] = f_medium\n",
    "    train[features_tmp[5]] = f_high\n",
    "\n",
    "    # test data\n",
    "    tmp = train.groupby(['interest_level',feature1])[feature2].mean().\\\n",
    "            reset_index().rename(columns={feature2:'new'})    \n",
    "    test[features_tmp[3]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32')\n",
    "    test[features_tmp[4]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32')\n",
    "    test[features_tmp[5]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32') \n",
    "    \n",
    "    # max feature names\n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_low_max') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_medium_max') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_high_max')\n",
    "    \n",
    "    # train data \n",
    "    f_low=pd.Series([np.nan]*len(train))\n",
    "    f_medium=pd.Series([np.nan]*len(train))\n",
    "    f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "    for train_index, test_index in kf.split(index):\n",
    "        tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].max().\\\n",
    "                reset_index().rename(columns={feature2:'new'})\n",
    "        f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')\n",
    "        f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')\n",
    "        f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')   \n",
    "    train[features_tmp[6]] = f_low\n",
    "    train[features_tmp[7]] = f_medium\n",
    "    train[features_tmp[8]] = f_high\n",
    "\n",
    "    # test data\n",
    "    tmp = train.groupby(['interest_level',feature1])[feature2].max().\\\n",
    "            reset_index().rename(columns={feature2:'new'})    \n",
    "    test[features_tmp[6]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32')\n",
    "    test[features_tmp[7]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32')\n",
    "    test[features_tmp[8]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32') \n",
    "    \n",
    "    # min feature names\n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_low_min') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_medium_min') \n",
    "    features_tmp.append(feature1 + '_' + feature2 + '_high_min')\n",
    "    \n",
    "    # train data \n",
    "    f_low=pd.Series([np.nan]*len(train))\n",
    "    f_medium=pd.Series([np.nan]*len(train))\n",
    "    f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "    for train_index, test_index in kf.split(index):\n",
    "        tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].min().\\\n",
    "                reset_index().rename(columns={feature2:'new'})\n",
    "        f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')\n",
    "        f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')\n",
    "        f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "                                                            on=feature1,how='left')['new'].values.astype('float32')   \n",
    "    train[features_tmp[9]] = f_low\n",
    "    train[features_tmp[10]] = f_medium\n",
    "    train[features_tmp[11]] = f_high\n",
    "\n",
    "    # test data\n",
    "    tmp = train.groupby(['interest_level',feature1])[feature2].min().\\\n",
    "            reset_index().rename(columns={feature2:'new'})    \n",
    "    test[features_tmp[9]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32')\n",
    "    test[features_tmp[10]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32')\n",
    "    test[features_tmp[11]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "                                       on=feature1,how='left')['new'].values.astype('float32') \n",
    "\n",
    "#     # std feature names\n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_low_std') \n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_medium_std') \n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_high_std')\n",
    "    \n",
    "#     # train data \n",
    "#     f_low=pd.Series([np.nan]*len(train))\n",
    "#     f_medium=pd.Series([np.nan]*len(train))\n",
    "#     f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "#     for train_index, test_index in kf.split(index):\n",
    "#         tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].std().\\\n",
    "#                 reset_index().rename(columns={feature2:'new'})\n",
    "#         f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "#                                                             on=feature1,how='left')['new'].values\n",
    "#         f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "#                                                             on=feature1,how='left')['new'].values\n",
    "#         f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "#                                                             on=feature1,how='left')['new'].values   \n",
    "#     train[features_tmp[12]] = f_low\n",
    "#     train[features_tmp[13]] = f_medium\n",
    "#     train[features_tmp[14]] = f_high\n",
    "\n",
    "#     # test data\n",
    "#     tmp = train.groupby(['interest_level',feature1])[feature2].std().\\\n",
    "#             reset_index().rename(columns={feature2:'new'})    \n",
    "#     test[features_tmp[12]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "#                                        on=feature1,how='left')['new'].values\n",
    "#     test[features_tmp[13]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "#                                        on=feature1,how='left')['new'].values\n",
    "#     test[features_tmp[14]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "#                                        on=feature1,how='left')['new'].values \n",
    "    \n",
    "#     # var feature names\n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_low_var') \n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_medium_var') \n",
    "#     features_tmp.append(feature1 + '_' + feature2 + '_high_var')\n",
    "    \n",
    "#     # train data \n",
    "#     f_low=pd.Series([np.nan]*len(train))\n",
    "#     f_medium=pd.Series([np.nan]*len(train))\n",
    "#     f_high=pd.Series([np.nan]*len(train))\n",
    "\n",
    "#     for train_index, test_index in kf.split(index):\n",
    "#         tmp = train.iloc[train_index].groupby(['interest_level',feature1])[feature2].var().\\\n",
    "#                 reset_index().rename(columns={feature2:'new'})\n",
    "#         f_low[test_index]    = train.iloc[test_index].merge(tmp[tmp.interest_level == 'low'],\n",
    "#                                                             on=feature1,how='left')['new'].values\n",
    "#         f_medium[test_index] = train.iloc[test_index].merge(tmp[tmp.interest_level == 'medium'],\n",
    "#                                                             on=feature1,how='left')['new'].values\n",
    "#         f_high[test_index]   = train.iloc[test_index].merge(tmp[tmp.interest_level == 'high'],\n",
    "#                                                             on=feature1,how='left')['new'].values   \n",
    "#     train[features_tmp[15]] = f_low\n",
    "#     train[features_tmp[16]] = f_medium\n",
    "#     train[features_tmp[17]] = f_high\n",
    "\n",
    "#     # test data\n",
    "#     tmp = train.groupby(['interest_level',feature1])[feature2].var().\\\n",
    "#             reset_index().rename(columns={feature2:'new'})    \n",
    "#     test[features_tmp[15]] = test.merge(tmp[tmp.interest_level == 'low'],\n",
    "#                                        on=feature1,how='left')['new'].values\n",
    "#     test[features_tmp[16]] = test.merge(tmp[tmp.interest_level == 'medium'],\n",
    "#                                        on=feature1,how='left')['new'].values\n",
    "#     test[features_tmp[17]] = test.merge(tmp[tmp.interest_level == 'high'],\n",
    "#                                        on=feature1,how='left')['new'].values \n",
    "    \n",
    "#     # ratio/diff feature\n",
    "#     cols = features_tmp[:]\n",
    "# #     features_tmp = []\n",
    "#     for col in cols:\n",
    "#         new_feature = col+'_ratio'\n",
    "#         train[new_feature] = train[col] / train[feature2]\n",
    "#         test[new_feature] = test[col] / test[feature2]\n",
    "#         features_tmp.append(new_feature)\n",
    "        \n",
    "#     print feature1,' vs ', feature2,'Done!'\n",
    "    return train,test,features_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "train_df=pd.read_json('../input/train.json').reset_index(drop = True)\n",
    "test_df=pd.read_json('../input/test.json').reset_index(drop = True)\n",
    "test_df.loc[test_df.bathrooms == 112.0,'bathrooms'] = 1.5    \n",
    "test_df.loc[test_df.bathrooms == 20.0,'bathrooms'] = 2.0\n",
    "test_df.loc[test_df.listing_id == 7220763,'bedrooms'] = 3\n",
    "test_df.loc[test_df.listing_id == 7047074,'bedrooms'] = 6\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    fmt = lambda s: s.replace(\"\\u00a0\", \"\").strip().lower()\n",
    "    df[\"num_photo_count\"] = df[\"photos\"].apply(len)\n",
    "    df[\"street_address\"] = df['street_address'].apply(fmt)\n",
    "    df[\"display_address\"] = df[\"display_address\"].apply(fmt)\n",
    "    df[\"num_desc_wordcount\"] = df[\"description\"].apply(len)\n",
    "    df[\"num_pricePerBed\"] = df['price'] / df['bedrooms']\n",
    "    df[\"num_pricePerBath\"] = df['price'] / df['bathrooms']\n",
    "    df[\"num_pricePerRoom\"] = df['price'] / (df['bedrooms'] + df['bathrooms'])\n",
    "    df[\"num_bedPerBath\"] = df['bedrooms'] / df['bathrooms']\n",
    "    df[\"num_bedBathDiff\"] = df['bedrooms'] - df['bathrooms']\n",
    "    df[\"num_bedBathSum\"] = df[\"bedrooms\"] + df['bathrooms']\n",
    "    df[\"num_bedsPerc\"] = df[\"bedrooms\"] / (df['bedrooms'] + df['bathrooms'])\n",
    "\n",
    "    df = df.fillna(-1).replace(np.inf, -1)\n",
    "    return df\n",
    "\n",
    "# Add common features\n",
    "train_df = add_features(train_df)\n",
    "test_df = add_features(test_df) \n",
    "\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "train_df['num_desc_length_null'] = (train_df.description.str.len()==0).astype(float)\n",
    "test_df['num_desc_length_null'] = (test_df.description.str.len()==0).astype(float)\n",
    "    \n",
    "features_to_use=[\n",
    "    \"latitude\", \"longitude\",\"num_pricePerBed\",\n",
    "    'num_bedBathSum','num_pricePerBath','num_pricePerRoom','num_bedPerBath',\n",
    "    'num_bedBathDiff','num_bedsPerc',\n",
    "    \"num_photo_count\", \"num_features\", \"num_desc_wordcount\",'num_desc_length_null',\n",
    "    \"listing_id\"]\n",
    "\n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Location features: Latitude, longitude\n",
    "precision = 3\n",
    "x = np.sqrt(((train_df.latitude - train_df.latitude.median())**2) + (train_df.longitude - train_df.longitude.median())**2)\n",
    "train_df['num_dist_from_center'] = x.values\n",
    "x = np.sqrt(((test_df.latitude - train_df.latitude.median())**2) + (test_df.longitude - train_df.longitude.median())**2)\n",
    "test_df['num_dist_from_center'] = x.values\n",
    "train_df['position'] = train_df.longitude.round(precision).astype(str) + '_' + train_df.latitude.round(precision).astype(str)\n",
    "test_df['position'] = test_df.longitude.round(precision).astype(str) + '_' + test_df.latitude.round(precision).astype(str)\n",
    "\n",
    "new_feature = ['num_dist_from_center']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Degree of \"outlierness\"\n",
    "OutlierAggregated = (train_df.bedrooms > 4).astype(float)\n",
    "OutlierAggregated2 = (test_df.bedrooms > 4).astype(float)\n",
    "OutlierAggregated += (train_df.bathrooms > 3).astype(float)\n",
    "OutlierAggregated2 += (test_df.bathrooms > 3).astype(float)\n",
    "OutlierAggregated += (train_df.bathrooms < 1).astype(float)\n",
    "OutlierAggregated2 += (test_df.bathrooms < 1).astype(float)\n",
    "x = np.abs((train_df.price - train_df.price.median())/train_df.price.std()) > 0.30\n",
    "OutlierAggregated += x.astype(float)\n",
    "x2 = np.abs((test_df.price - train_df.price.median())/train_df.price.std()) > 0.30\n",
    "OutlierAggregated2 += x2.astype(float)\n",
    "x = np.log1p(train_df.price/(train_df.bedrooms.clip(1,3) + train_df.bathrooms.clip(1,2))) > 8.2\n",
    "OutlierAggregated += x.astype(float)\n",
    "x2 = np.log1p(test_df.price/(test_df.bedrooms.clip(1,3) + test_df.bathrooms.clip(1,2))) > 8.2\n",
    "OutlierAggregated2 += x2.astype(float)\n",
    "x = np.sqrt(((train_df.latitude - train_df.latitude.median())**2) + (train_df.longitude - train_df.longitude.median())**2) > 0.30\n",
    "OutlierAggregated += x.astype(float)\n",
    "x2 = np.sqrt(((test_df.latitude - train_df.latitude.median())**2) + (test_df.longitude - train_df.longitude.median())**2) > 0.30\n",
    "OutlierAggregated2 += x2.astype(float)\n",
    "train_df['num_OutlierAggregated'] = OutlierAggregated.values\n",
    "test_df['num_OutlierAggregated'] = OutlierAggregated2.values\n",
    "\n",
    "\n",
    "new_feature = ['num_OutlierAggregated']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Density in unique locations at given precision\n",
    "vals = train_df['position'].value_counts()\n",
    "dvals = vals.to_dict()\n",
    "train_df['num_pos_density'] = train_df['position'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "test_df['num_pos_density'] = test_df['position'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "\n",
    "# Building null\n",
    "train_df['num_building_null'] = (train_df.building_id=='0').astype(float)\n",
    "test_df['num_building_null'] = (test_df.building_id=='0').astype(float)\n",
    "\n",
    "\n",
    "new_feature = ['num_pos_density','num_building_null']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Creation time features\n",
    "train_df['created'] = pd.to_datetime(train_df.created)\n",
    "train_df['num_created_weekday'] = train_df.created.dt.dayofweek.astype(float)\n",
    "train_df['num_created_weekofyear'] = train_df.created.dt.weekofyear\n",
    "train_df['num_created_day'] = train_df.created.dt.day\n",
    "train_df['num_created_month'] = train_df.created.dt.month\n",
    "train_df['num_created_hour'] = train_df.created.dt.hour\n",
    "  \n",
    "test_df['created'] = pd.to_datetime(test_df.created)\n",
    "test_df['num_created_weekday'] = test_df.created.dt.dayofweek\n",
    "test_df['num_created_weekofyear'] = test_df.created.dt.weekofyear\n",
    "test_df['num_created_day'] = test_df.created.dt.day\n",
    "test_df['num_created_month'] = test_df.created.dt.month\n",
    "test_df['num_created_hour'] = test_df.created.dt.hour\n",
    "\n",
    "\n",
    "new_feature = ['num_created_weekday','num_created_weekofyear','num_created_day','num_created_month','num_created_hour']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Bedrooms/Bathrooms/Price\n",
    "train_df['num_bathrooms'] = train_df.bathrooms.clip_upper(4)\n",
    "test_df['num_bathrooms'] = test_df.bathrooms.clip_upper(4)\n",
    "\n",
    "train_df['num_bedrooms'] = train_df.bedrooms.clip_upper(5)\n",
    "test_df['num_bedrooms'] = test_df.bedrooms.clip_upper(5)\n",
    "\n",
    "train_df['num_price'] = train_df.price.clip_upper(10000)\n",
    "test_df['num_price'] = test_df.price.clip_upper(10000)\n",
    "\n",
    "bins = train_df.price.quantile(np.arange(0.05, 1, 0.05))\n",
    "train_df['num_price_q'] = np.digitize(train_df.price, bins)\n",
    "test_df['num_price_q'] = np.digitize(test_df.price, bins)\n",
    "\n",
    "\n",
    "new_feature = ['num_bathrooms','num_bedrooms','num_price','num_price_q']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Composite features based on: \n",
    "# https://www.kaggle.com/arnaldcat/two-sigma-connect-rental-listing-inquiries/a-proxy-for-sqft-and-the-interest-on-1-2-baths\n",
    "train_df['num_priceXroom'] = (train_df.price / (1 + train_df.bedrooms.clip(1, 4) + 0.5*train_df.bathrooms.clip(0, 2))).values\n",
    "test_df['num_priceXroom'] = (test_df.price / (1 + test_df.bedrooms.clip(1, 4) + 0.5*test_df.bathrooms.clip(0, 2))).values\n",
    "\n",
    "train_df['num_even_bathrooms'] = ((np.round(train_df.bathrooms) - train_df.bathrooms)==0).astype(float)\n",
    "test_df['num_even_bathrooms'] = ((np.round(test_df.bathrooms) - test_df.bathrooms)==0).astype(float)\n",
    "\n",
    "new_feature = ['num_priceXroom','num_even_bathrooms']\n",
    "for f in new_feature:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "\n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\",'position']\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            if f not in features_to_use:\n",
    "                features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dftemp = train_df.copy()\n",
    "for i in ['latitude', 'longitude']:\n",
    "    while(1):\n",
    "        x = dftemp[i].median()\n",
    "        ix = abs(dftemp[i] - x) > 3*dftemp[i].std()\n",
    "        if ix.sum()==0:\n",
    "            break\n",
    "        dftemp.loc[ix, i] = np.nan\n",
    "dftemp = dftemp.loc[dftemp[['latitude', 'longitude']].isnull().sum(1) == 0, :]\n",
    "\n",
    "dfm = DataFrameMapper([(['latitude'], [StandardScaler()]), (['longitude'], [StandardScaler()])])\n",
    "\n",
    "for i in [6]:\n",
    "    pipe_location = make_pipeline(dfm, KMeans(n_clusters=i, random_state=1))\n",
    "    pipe_location.fit(dftemp);\n",
    "    train_df['location_'+str(i)] = pipe_location.predict(train_df).astype(str)\n",
    "    test_df['location_'+str(i)] = pipe_location.predict(test_df).astype(str)\n",
    "for i in train_df.location_6.unique():\n",
    "    f = 'num_location_6_'+str(i)\n",
    "    train_df[f] = (train_df.location_6==i).astype(float)\n",
    "    test_df[f] = (test_df.location_6==i).astype(float)\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "    \n",
    "    \n",
    "train_df['tmp_bathrooms'] = train_df.bathrooms.clip_upper(2)\n",
    "test_df['tmp_bathrooms'] = test_df.bathrooms.clip_upper(2)\n",
    "train_df['tmp_bedrooms'] = train_df.bedrooms.clip_upper(4)\n",
    "test_df['tmp_bedrooms'] = test_df.bedrooms.clip_upper(4)\n",
    "train_df['roomcal'] = train_df.tmp_bedrooms.astype(str) + '_' + train_df.tmp_bathrooms.astype(str)    \n",
    "test_df['roomcal'] = test_df.tmp_bedrooms.astype(str) + '_' + test_df.tmp_bathrooms.astype(str)    \n",
    "\n",
    "room_lb = LabelBinarizer()\n",
    "room_lb.fit(train_df['roomcal'])\n",
    "room_col = ['num_room_type_' + str(x) for x in range(len(train_df['roomcal'].unique()))]\n",
    "for f in room_col:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "\n",
    "train_df = train_df.join(pd.DataFrame(room_lb.transform(train_df['roomcal']),columns=room_col,index=train_df.index))\n",
    "test_df = test_df.join(pd.DataFrame(room_lb.transform(test_df['roomcal']),columns=room_col,index=test_df.index))\n",
    "\n",
    "tmp = train_df.groupby(['roomcal','location_6'])['num_price'].median().\\\n",
    "            reset_index().rename(columns={'num_price':'num_6_median_price'})\n",
    "    \n",
    "train_df = train_df.merge(tmp,on=['roomcal','location_6'],how='left')\n",
    "test_df = test_df.merge(tmp,on=['roomcal','location_6'],how='left')\n",
    "\n",
    "test_df.loc[27462,'num_6_median_price'] =  7200.0\n",
    "\n",
    "train_df['num_6_price_ratio'] = train_df['num_price'] / train_df['num_6_median_price']\n",
    "train_df['num_6_price_diff'] = train_df['num_price'] - train_df['num_6_median_price']\n",
    "test_df['num_6_price_ratio'] = test_df['num_price'] / test_df['num_6_median_price']\n",
    "test_df['num_6_price_diff'] = test_df['num_price'] - test_df['num_6_median_price']\n",
    "\n",
    "\n",
    "for f in ['num_6_median_price','num_6_price_ratio','num_6_price_diff']:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)\n",
    "        \n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = train_df.groupby(['num_bedrooms','location_6'])['num_price'].median().\\\n",
    "            reset_index().rename(columns={'num_price':'num_6_median_price_bedroom'})\n",
    "    \n",
    "train_df = train_df.merge(tmp,on=['num_bedrooms','location_6'],how='left')\n",
    "test_df = test_df.merge(tmp,on=['num_bedrooms','location_6'],how='left')\n",
    "\n",
    "train_df['num_6_price_ratio_bedroom'] = train_df['num_price'] / train_df['num_6_median_price_bedroom']\n",
    "train_df['num_6_price_diff_bedroom'] = train_df['num_price'] - train_df['num_6_median_price_bedroom']\n",
    "test_df['num_6_price_ratio_bedroom'] = test_df['num_price'] / test_df['num_6_median_price_bedroom']\n",
    "test_df['num_6_price_diff_bedroom'] = test_df['num_price'] - test_df['num_6_median_price_bedroom']\n",
    "\n",
    "\n",
    "for f in ['num_6_median_price_bedroom','num_6_price_ratio_bedroom','num_6_price_diff_bedroom']:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_binary_features(df):\n",
    "    bows = {\n",
    "        \"dogs\": (\"dogs\", \"dog\",'pet friendly','pets'),\n",
    "        \"cats\": (\"cats\",'pet friendly','pets'),\n",
    "        \"nofee\": (\"no fee\", \"no-fee\", \"no  fee\", \"nofee\", \"no_fee\"),\n",
    "        \"lowfee\": (\"reduced_fee\", \"low_fee\", \"reduced fee\", \"low fee\"),\n",
    "        \"furnished\": (\"furnished\",'equipped'),\n",
    "        \"parquet\": (\"parquet\", \"hardwood\"),\n",
    "        \"concierge\": (\"concierge\", \"doorman\", \"housekeep\", \"in_super\"),\n",
    "        \"prewar\": (\"prewar\", \"pre_war\", \"pre war\", \"pre-war\"),\n",
    "        \"laundry\": (\"laundry\", \"lndry\"),\n",
    "        \"health\": (\"health\", \"gym\", \"fitness\", \"training\"),\n",
    "        \"transport\": (\"train\", \"subway\", \"transport\"),\n",
    "        \"parking\": (\"parking\",),\n",
    "        \"utilities\": (\"utilities\", \"heat water\", \"water included\"),\n",
    "        'fireplace': ('fireplace','fireplaces'),\n",
    "        'elevator': ('elevator'),\n",
    "        'pool':('pool'),\n",
    "        'loft':('loft'),\n",
    "        'luxury':('luxury','valet'),\n",
    "        'marble':('marble'),\n",
    "        'onemounthfree': ('1 month free','one month free'),\n",
    "        'washer':('washer','dryer')\n",
    "    }\n",
    "\n",
    "    def indicator(bow):\n",
    "        return lambda s: int(any([x in s for x in bow]))\n",
    "\n",
    "    features = df[\"features\"].apply(lambda f: \" \".join(f).lower())   # convert features to string\n",
    "    for key in bows:\n",
    "        tmp_key = \"feature_\" + key\n",
    "        df[tmp_key] = features.apply(indicator(bows[key]))\n",
    "        if tmp_key not in features_to_use:\n",
    "            features_to_use.append(tmp_key)\n",
    "    return df\n",
    "\n",
    "# Create binarized features\n",
    "train_df = create_binary_features(train_df)\n",
    "test_df = create_binary_features(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 322)\n",
      "(74659, 322)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X_0322 = pd.read_csv(data_path + 'train_BM_MB_add03052240.csv')\n",
    "test_X_0322 = pd.read_csv(data_path + 'test_BM_MB_add03052240.csv')\n",
    "\n",
    "print train_X_0322.shape\n",
    "print test_X_0322.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment = [\n",
    "#     'building_id_mean_med','building_id_mean_high', \n",
    "#     'manager_id_mean_med','manager_id_mean_high',\n",
    "    'median_price_bed', 'ratio_bed',\n",
    "       'compound', 'neg', 'neu', 'pos', 'street',\n",
    "       'avenue', 'east', 'west', 'north', 'south', 'other_address',\n",
    "       'Zero_building_id', 'top_10_building', 'top_25_building',\n",
    "       'top_5_building', 'top_50_building', 'top_1_building',\n",
    "       'top_2_building', 'top_15_building', 'top_20_building',\n",
    "       'top_30_building','listing_id'\n",
    "]\n",
    "\n",
    "train_df = train_df.merge(train_X_0322[sentiment],on='listing_id', how='left')\n",
    "test_df = test_df.merge(test_X_0322[sentiment],on='listing_id', how='left')\n",
    "\n",
    "for f in sentiment:\n",
    "    if f not in features_to_use:\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init_feature = features_to_use[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CV statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV_feature = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index=list(range(train_df.shape[0]))\n",
    "random.seed(a=0)\n",
    "random.shuffle(index)\n",
    "a=[np.nan]*len(train_df)\n",
    "b=[np.nan]*len(train_df)\n",
    "c=[np.nan]*len(train_df)\n",
    "\n",
    "for i in range(5):\n",
    "    building_level={}\n",
    "    for j in train_df['manager_id'].values:\n",
    "        building_level[j]=[0,0,0]\n",
    "    test_index=index[int((i*train_df.shape[0])/5):int(((i+1)*train_df.shape[0])/5)]\n",
    "    train_index=list(set(index).difference(test_index))\n",
    "    for j in train_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if temp['interest_level']=='low':\n",
    "            building_level[temp['manager_id']][0]+=1\n",
    "        if temp['interest_level']=='medium':\n",
    "            building_level[temp['manager_id']][1]+=1\n",
    "        if temp['interest_level']=='high':\n",
    "            building_level[temp['manager_id']][2]+=1\n",
    "    for j in test_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if sum(building_level[temp['manager_id']])!=0:\n",
    "            a[j]=building_level[temp['manager_id']][0]*1.0/sum(building_level[temp['manager_id']])\n",
    "            b[j]=building_level[temp['manager_id']][1]*1.0/sum(building_level[temp['manager_id']])\n",
    "            c[j]=building_level[temp['manager_id']][2]*1.0/sum(building_level[temp['manager_id']])\n",
    "train_df['manager_level_low']=a\n",
    "train_df['manager_level_medium']=b\n",
    "train_df['manager_level_high']=c\n",
    "\n",
    "\n",
    "\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "building_level={}\n",
    "for j in train_df['manager_id'].values:\n",
    "    building_level[j]=[0,0,0]\n",
    "for j in range(train_df.shape[0]):\n",
    "    temp=train_df.iloc[j]\n",
    "    if temp['interest_level']=='low':\n",
    "        building_level[temp['manager_id']][0]+=1\n",
    "    if temp['interest_level']=='medium':\n",
    "        building_level[temp['manager_id']][1]+=1\n",
    "    if temp['interest_level']=='high':\n",
    "        building_level[temp['manager_id']][2]+=1\n",
    "\n",
    "for i in test_df['manager_id'].values:\n",
    "    if i not in building_level.keys():\n",
    "        a.append(np.nan)\n",
    "        b.append(np.nan)\n",
    "        c.append(np.nan)\n",
    "    else:\n",
    "        a.append(building_level[i][0]*1.0/sum(building_level[i]))\n",
    "        b.append(building_level[i][1]*1.0/sum(building_level[i]))\n",
    "        c.append(building_level[i][2]*1.0/sum(building_level[i]))\n",
    "test_df['manager_level_low']=a\n",
    "test_df['manager_level_medium']=b\n",
    "test_df['manager_level_high']=c\n",
    "\n",
    "# features_to_use = []\n",
    "features_to_use.append('manager_level_low') \n",
    "features_to_use.append('manager_level_medium') \n",
    "features_to_use.append('manager_level_high')\n",
    "# CV_feature.append(features_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index=list(range(train_df.shape[0]))\n",
    "random.seed(a=0)\n",
    "random.shuffle(index)\n",
    "a=[np.nan]*len(train_df)\n",
    "b=[np.nan]*len(train_df)\n",
    "c=[np.nan]*len(train_df)\n",
    "\n",
    "for i in range(5):\n",
    "    building_level={}\n",
    "    for j in train_df['building_id'].values:\n",
    "        building_level[j]=[0,0,0]\n",
    "    test_index=index[int((i*train_df.shape[0])/5):int(((i+1)*train_df.shape[0])/5)]\n",
    "    train_index=list(set(index).difference(test_index))\n",
    "    for j in train_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if temp['interest_level']=='low':\n",
    "            building_level[temp['building_id']][0]+=1\n",
    "        if temp['interest_level']=='medium':\n",
    "            building_level[temp['building_id']][1]+=1\n",
    "        if temp['interest_level']=='high':\n",
    "            building_level[temp['building_id']][2]+=1\n",
    "    for j in test_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if sum(building_level[temp['building_id']])!=0:\n",
    "            a[j]=building_level[temp['building_id']][0]*1.0/sum(building_level[temp['building_id']])\n",
    "            b[j]=building_level[temp['building_id']][1]*1.0/sum(building_level[temp['building_id']])\n",
    "            c[j]=building_level[temp['building_id']][2]*1.0/sum(building_level[temp['building_id']])\n",
    "train_df['building_level_low']=a\n",
    "train_df['building_level_medium']=b\n",
    "train_df['building_level_high']=c\n",
    "\n",
    "\n",
    "\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "building_level={}\n",
    "for j in train_df['building_id'].values:\n",
    "    building_level[j]=[0,0,0]\n",
    "for j in range(train_df.shape[0]):\n",
    "    temp=train_df.iloc[j]\n",
    "    if temp['interest_level']=='low':\n",
    "        building_level[temp['building_id']][0]+=1\n",
    "    if temp['interest_level']=='medium':\n",
    "        building_level[temp['building_id']][1]+=1\n",
    "    if temp['interest_level']=='high':\n",
    "        building_level[temp['building_id']][2]+=1\n",
    "\n",
    "for i in test_df['building_id'].values:\n",
    "    if i not in building_level.keys():\n",
    "        a.append(np.nan)\n",
    "        b.append(np.nan)\n",
    "        c.append(np.nan)\n",
    "    else:\n",
    "        a.append(building_level[i][0]*1.0/sum(building_level[i]))\n",
    "        b.append(building_level[i][1]*1.0/sum(building_level[i]))\n",
    "        c.append(building_level[i][2]*1.0/sum(building_level[i]))\n",
    "test_df['building_level_low']=a\n",
    "test_df['building_level_medium']=b\n",
    "test_df['building_level_high']=c\n",
    "\n",
    "\n",
    "# features_to_use = []\n",
    "features_to_use.append('building_level_low') \n",
    "features_to_use.append('building_level_medium') \n",
    "features_to_use.append('building_level_high')\n",
    "# CV_feature.append(features_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'manager_id','ratio_bed')\n",
    "features_to_use.extend(new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df, new_feature = CV_st(train_df,test_df,'building_id','num_price_q')\n",
    "features_to_use.extend(new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude',\n",
       " 'longitude',\n",
       " 'num_pricePerBed',\n",
       " 'num_bedBathSum',\n",
       " 'num_pricePerBath',\n",
       " 'num_pricePerRoom',\n",
       " 'num_bedPerBath',\n",
       " 'num_bedBathDiff',\n",
       " 'num_bedsPerc',\n",
       " 'num_photo_count',\n",
       " 'num_features',\n",
       " 'num_desc_wordcount',\n",
       " 'num_desc_length_null',\n",
       " 'listing_id',\n",
       " 'num_dist_from_center',\n",
       " 'num_OutlierAggregated',\n",
       " 'num_pos_density',\n",
       " 'num_building_null',\n",
       " 'num_created_weekday',\n",
       " 'num_created_weekofyear',\n",
       " 'num_created_day',\n",
       " 'num_created_month',\n",
       " 'num_created_hour',\n",
       " 'num_bathrooms',\n",
       " 'num_bedrooms',\n",
       " 'num_price',\n",
       " 'num_price_q',\n",
       " 'num_priceXroom',\n",
       " 'num_even_bathrooms',\n",
       " 'display_address',\n",
       " 'manager_id',\n",
       " 'building_id',\n",
       " 'street_address',\n",
       " 'position',\n",
       " 'num_location_6_3',\n",
       " 'num_location_6_1',\n",
       " 'num_location_6_0',\n",
       " 'num_location_6_5',\n",
       " 'num_location_6_4',\n",
       " 'num_location_6_2',\n",
       " 'num_room_type_0',\n",
       " 'num_room_type_1',\n",
       " 'num_room_type_2',\n",
       " 'num_room_type_3',\n",
       " 'num_room_type_4',\n",
       " 'num_room_type_5',\n",
       " 'num_room_type_6',\n",
       " 'num_room_type_7',\n",
       " 'num_room_type_8',\n",
       " 'num_room_type_9',\n",
       " 'num_room_type_10',\n",
       " 'num_room_type_11',\n",
       " 'num_room_type_12',\n",
       " 'num_room_type_13',\n",
       " 'num_room_type_14',\n",
       " 'num_room_type_15',\n",
       " 'num_room_type_16',\n",
       " 'num_room_type_17',\n",
       " 'num_room_type_18',\n",
       " 'num_room_type_19',\n",
       " 'num_6_median_price',\n",
       " 'num_6_price_ratio',\n",
       " 'num_6_price_diff',\n",
       " 'num_6_median_price_bedroom',\n",
       " 'num_6_price_ratio_bedroom',\n",
       " 'num_6_price_diff_bedroom',\n",
       " 'feature_washer',\n",
       " 'feature_laundry',\n",
       " 'feature_prewar',\n",
       " 'feature_furnished',\n",
       " 'feature_parking',\n",
       " 'feature_utilities',\n",
       " 'feature_elevator',\n",
       " 'feature_marble',\n",
       " 'feature_concierge',\n",
       " 'feature_cats',\n",
       " 'feature_health',\n",
       " 'feature_pool',\n",
       " 'feature_onemounthfree',\n",
       " 'feature_parquet',\n",
       " 'feature_lowfee',\n",
       " 'feature_luxury',\n",
       " 'feature_nofee',\n",
       " 'feature_fireplace',\n",
       " 'feature_dogs',\n",
       " 'feature_transport',\n",
       " 'feature_loft',\n",
       " 'median_price_bed',\n",
       " 'ratio_bed',\n",
       " 'compound',\n",
       " 'neg',\n",
       " 'neu',\n",
       " 'pos',\n",
       " 'street',\n",
       " 'avenue',\n",
       " 'east',\n",
       " 'west',\n",
       " 'north',\n",
       " 'south',\n",
       " 'other_address',\n",
       " 'Zero_building_id',\n",
       " 'top_10_building',\n",
       " 'top_25_building',\n",
       " 'top_5_building',\n",
       " 'top_50_building',\n",
       " 'top_1_building',\n",
       " 'top_2_building',\n",
       " 'top_15_building',\n",
       " 'top_20_building',\n",
       " 'top_30_building',\n",
       " 'manager_level_low',\n",
       " 'manager_level_medium',\n",
       " 'manager_level_high',\n",
       " 'manager_id_ratio_bed_low_median',\n",
       " 'manager_id_ratio_bed_medium_median',\n",
       " 'manager_id_ratio_bed_high_median',\n",
       " 'manager_id_ratio_bed_low_mean',\n",
       " 'manager_id_ratio_bed_medium_mean',\n",
       " 'manager_id_ratio_bed_high_mean',\n",
       " 'manager_id_ratio_bed_low_max',\n",
       " 'manager_id_ratio_bed_medium_max',\n",
       " 'manager_id_ratio_bed_high_max',\n",
       " 'manager_id_ratio_bed_low_min',\n",
       " 'manager_id_ratio_bed_medium_min',\n",
       " 'manager_id_ratio_bed_high_min',\n",
       " 'building_id_num_price_q_low_median',\n",
       " 'building_id_num_price_q_medium_median',\n",
       " 'building_id_num_price_q_high_median',\n",
       " 'building_id_num_price_q_low_mean',\n",
       " 'building_id_num_price_q_medium_mean',\n",
       " 'building_id_num_price_q_high_mean',\n",
       " 'building_id_num_price_q_low_max',\n",
       " 'building_id_num_price_q_medium_max',\n",
       " 'building_id_num_price_q_high_max',\n",
       " 'building_id_num_price_q_low_min',\n",
       " 'building_id_num_price_q_medium_min',\n",
       " 'building_id_num_price_q_high_min',\n",
       " 'building_level_low',\n",
       " 'building_level_medium',\n",
       " 'building_level_high']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_feature1 = used_feature[:]\n",
    "used_feature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52888760000000001"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 141) (74659, 141)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_df[features_to_use]\n",
    "test_X = test_df[features_to_use]\n",
    "\n",
    "train_X.replace(np.inf, np.nan)\n",
    "test_X.replace(np.inf, np.nan)\n",
    "\n",
    "train_X.loc[:,'num_nan'] = train_X.isnull().sum(axis=1)\n",
    "test_X.loc[:,'num_nan'] = test_X.isnull().sum(axis=1)\n",
    "\n",
    "target_num_map = {'high':2, 'medium':1, 'low':0}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "print train_X.shape, test_X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.905261+0.000641652\ttest-mlogloss:0.910695+0.00110889\n",
      "[10]\ttrain-mlogloss:0.528161+0.00146897\ttest-mlogloss:0.572251+0.00323927\n",
      "[20]\ttrain-mlogloss:0.471311+0.00206303\ttest-mlogloss:0.545762+0.00446619\n",
      "[30]\ttrain-mlogloss:0.434981+0.00233531\ttest-mlogloss:0.537474+0.00501406\n",
      "[40]\ttrain-mlogloss:0.407295+0.00276496\ttest-mlogloss:0.533319+0.00574307\n",
      "[50]\ttrain-mlogloss:0.384502+0.00375174\ttest-mlogloss:0.53113+0.00580746\n",
      "[60]\ttrain-mlogloss:0.363385+0.00261623\ttest-mlogloss:0.52972+0.00608787\n",
      "[70]\ttrain-mlogloss:0.344761+0.00298249\ttest-mlogloss:0.528976+0.00589441\n",
      "[80]\ttrain-mlogloss:0.326979+0.00329575\ttest-mlogloss:0.529332+0.00600917\n",
      "[90]\ttrain-mlogloss:0.309887+0.0032997\ttest-mlogloss:0.529932+0.00615072\n",
      "0.528882\n",
      "\n",
      "Training :227.23s\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "print cv_train(train_X,train_y,verbose_eval = 10, early_stop = 20)\n",
    "print '\\nTraining :{:0.2f}s'.format(time.time() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:0.929519\n",
      "[20]\tvalidation_0-mlogloss:0.576712\n",
      "[40]\tvalidation_0-mlogloss:0.561279\n",
      "[60]\tvalidation_0-mlogloss:0.555683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
       "       gamma=0, learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=1, subsample=0.7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=2016)\n",
    "rgr = xgb.XGBClassifier(\n",
    "            objective='multi:softprob',\n",
    "            seed = 0, # use a fixed seed during tuning so we can reproduce the results\n",
    "            learning_rate = 0.3,\n",
    "            n_estimators = 80,\n",
    "            max_depth= 6,\n",
    "            nthread = -1,\n",
    "            colsample_bytree = 0.3,\n",
    "            subsample =0.7,\n",
    "            silent = 1\n",
    "        )\n",
    "rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=20,\n",
    "        verbose=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgbfir\n",
    "xgbfir.saveXgbFI(rgr, feature_names=X_train.columns, OutputXlsxFile = '../FE/FI.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 394)\n",
      "(9871, 394)\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)\n",
    "# print X_train.shape\n",
    "# print X_val.shape\n",
    "# # xgtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[312]\ttrain-mlogloss:0.395492+0.00170774\ttest-mlogloss:0.527702+0.00663205\n",
      "\n",
      "3 \t0.5277018\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[141]\ttrain-mlogloss:0.396861+0.00183942\ttest-mlogloss:0.527621+0.00736431\n",
      "\n",
      "4 \t0.5276214\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mlogloss:0.357724+0.00219303\ttest-mlogloss:0.528282+0.00654119\n",
      "\n",
      "5 \t0.5282822\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[57]\ttrain-mlogloss:0.35853+0.0039214\ttest-mlogloss:0.530243+0.00654921\n",
      "\n",
      "6 \t0.530243\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[59]\ttrain-mlogloss:0.283875+0.00317202\ttest-mlogloss:0.535384+0.00751206\n",
      "\n",
      "7 \t0.5353838\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[34]\ttrain-mlogloss:0.291909+0.00288588\ttest-mlogloss:0.538363+0.00620757\n",
      "\n",
      "8 \t0.538363\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[26]\ttrain-mlogloss:0.267564+0.0038825\ttest-mlogloss:0.541642+0.00515766\n",
      "\n",
      "9 \t0.541642\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[20]\ttrain-mlogloss:0.244491+0.00434577\ttest-mlogloss:0.546812+0.0055212\n",
      "\n",
      "10 \t0.5468122\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[20]\ttrain-mlogloss:0.195892+0.00375725\ttest-mlogloss:0.550402+0.00728209\n",
      "\n",
      "11 \t0.5504024\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[17]\ttrain-mlogloss:0.17067+0.00195634\ttest-mlogloss:0.557329+0.00518613\n",
      "\n",
      "12 \t0.557329\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-mlogloss:0.149427+0.00259833\ttest-mlogloss:0.562298+0.00633625\n",
      "\n",
      "13 \t0.5622976\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[14]\ttrain-mlogloss:0.126763+0.00196544\ttest-mlogloss:0.569518+0.00782982\n",
      "\n",
      "14 \t0.5695176\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[14]\ttrain-mlogloss:0.10453+0.00319293\ttest-mlogloss:0.572249+0.00606784\n",
      "\n",
      "15 \t0.5722486\n"
     ]
    }
   ],
   "source": [
    "best_score = 1000\n",
    "for x in [3,4,5,6,7,8,9,10]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= x,\n",
    "#         nthread = -1,\n",
    "#         silent = False\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "    tmp = cv_train(train_X,train_y,max_depth = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# max_depth = train_param\n",
    "max_depth = train_param\n",
    "print max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[186]\ttrain-mlogloss:0.367066+0.00186211\ttest-mlogloss:0.527145+0.0074838\n",
      "\n",
      "2 \t0.5271452\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[213]\ttrain-mlogloss:0.352706+0.00230145\ttest-mlogloss:0.526443+0.00732842\n",
      "\n",
      "4 \t0.5264426\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[159]\ttrain-mlogloss:0.390464+0.00279415\ttest-mlogloss:0.527391+0.00724981\n",
      "\n",
      "8 \t0.5273912\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[177]\ttrain-mlogloss:0.381805+0.00237731\ttest-mlogloss:0.526913+0.00594032\n",
      "\n",
      "12 \t0.5269126\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[231]\ttrain-mlogloss:0.354327+0.00325227\ttest-mlogloss:0.525994+0.00717634\n",
      "\n",
      "16 \t0.5259938\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[159]\ttrain-mlogloss:0.398036+0.00265041\ttest-mlogloss:0.527198+0.00718988\n",
      "\n",
      "20 \t0.5271978\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[167]\ttrain-mlogloss:0.393573+0.00269923\ttest-mlogloss:0.526977+0.00679354\n",
      "\n",
      "24 \t0.5269766\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[179]\ttrain-mlogloss:0.388478+0.00255418\ttest-mlogloss:0.527911+0.00768457\n",
      "\n",
      "28 \t0.527911\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[189]\ttrain-mlogloss:0.385292+0.00262723\ttest-mlogloss:0.527001+0.00775232\n",
      "\n",
      "32 \t0.5270012\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[189]\ttrain-mlogloss:0.389593+0.00185931\ttest-mlogloss:0.527247+0.00665882\n",
      "\n",
      "40 \t0.5272468\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[202]\ttrain-mlogloss:0.387127+0.00289643\ttest-mlogloss:0.526661+0.00611834\n",
      "\n",
      "48 \t0.5266614\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[195]\ttrain-mlogloss:0.396135+0.00319157\ttest-mlogloss:0.526655+0.00698115\n",
      "\n",
      "64 \t0.5266546\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[188]\ttrain-mlogloss:0.404784+0.002127\ttest-mlogloss:0.527635+0.00737379\n",
      "\n",
      "80 \t0.5276348\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[214]\ttrain-mlogloss:0.40653+0.00239865\ttest-mlogloss:0.528011+0.00761088\n",
      "\n",
      "128 \t0.5280108\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [8,12,16,20,24,28,32,40,48,64,80,128]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= max_depth,\n",
    "#         nthread = -1,\n",
    "#         silent = False,\n",
    "#         min_child_weight = x\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "    \n",
    "    tmp = cv_train(train_X,train_y,max_depth = max_depth,min_child_weight = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "min_child_weight = train_param\n",
    "print min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[262]\ttrain-mlogloss:0.395672+0.00192811\ttest-mlogloss:0.532532+0.00697024\n",
      "\n",
      "0.05 \t0.5325316\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[251]\ttrain-mlogloss:0.38311+0.00308902\ttest-mlogloss:0.529113+0.00529031\n",
      "\n",
      "0.1 \t0.5291126\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[212]\ttrain-mlogloss:0.387354+0.0026151\ttest-mlogloss:0.526019+0.00693851\n",
      "\n",
      "0.2 \t0.5260188\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[205]\ttrain-mlogloss:0.384431+0.00255739\ttest-mlogloss:0.526169+0.00587901\n",
      "\n",
      "0.3 \t0.5261692\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[202]\ttrain-mlogloss:0.381644+0.00252687\ttest-mlogloss:0.526699+0.00705682\n",
      "\n",
      "0.4 \t0.5266986\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[204]\ttrain-mlogloss:0.377252+0.00326099\ttest-mlogloss:0.527301+0.00618384\n",
      "\n",
      "0.5 \t0.5273014\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[218]\ttrain-mlogloss:0.367054+0.00132444\ttest-mlogloss:0.526421+0.00760733\n",
      "\n",
      "0.6 \t0.5264212\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[219]\ttrain-mlogloss:0.364027+0.00250635\ttest-mlogloss:0.526563+0.00715006\n",
      "\n",
      "0.7 \t0.5265626\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[168]\ttrain-mlogloss:0.392891+0.00148548\ttest-mlogloss:0.526076+0.00678444\n",
      "\n",
      "0.8 \t0.5260764\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[192]\ttrain-mlogloss:0.376406+0.00267377\ttest-mlogloss:0.526586+0.00671319\n",
      "\n",
      "0.9 \t0.5265856\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= max_depth,\n",
    "#         nthread = -1,\n",
    "#         silent = False,\n",
    "#         min_child_weight = min_child_weight,\n",
    "#         colsample_bytree = x\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "    tmp = cv_train(train_X,train_y,max_depth = max_depth,min_child_weight = min_child_weight, colsample_bytree = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = train_param\n",
    "print colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[114]\ttrain-mlogloss:0.429981+0.00163237\ttest-mlogloss:0.535683+0.0063162\n",
      "\n",
      "0.5 \t0.5356834\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[127]\ttrain-mlogloss:0.417173+0.00106604\ttest-mlogloss:0.532641+0.0071292\n",
      "\n",
      "0.6 \t0.5326408\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[117]\ttrain-mlogloss:0.422807+0.00248712\ttest-mlogloss:0.530766+0.00658263\n",
      "\n",
      "0.7 \t0.5307656\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[138]\ttrain-mlogloss:0.406591+0.002293\ttest-mlogloss:0.52841+0.00609406\n",
      "\n",
      "0.8 \t0.5284098\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[184]\ttrain-mlogloss:0.378796+0.00269963\ttest-mlogloss:0.528253+0.00591205\n",
      "\n",
      "0.9 \t0.528253\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.7,0.8,0.9]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= max_depth,\n",
    "#         nthread = -1,\n",
    "#         silent = False,\n",
    "#         min_child_weight = min_child_weight,\n",
    "#         colsample_bytree = colsample_bytree,\n",
    "#         subsample = x\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "    tmp = cv_train(train_X,train_y,max_depth = max_depth,min_child_weight = min_child_weight, \n",
    "                   colsample_bytree = colsample_bytree, subsample = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "subsample = train_param\n",
    "print subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[164]\ttrain-mlogloss:0.393296+0.00247187\ttest-mlogloss:0.526782+0.00697394\n",
      "\n",
      "0.3 \t0.5267822\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[186]\ttrain-mlogloss:0.378468+0.00338923\ttest-mlogloss:0.526772+0.00705368\n",
      "\n",
      "0.6 \t0.526772\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[175]\ttrain-mlogloss:0.38681+0.00159871\ttest-mlogloss:0.526846+0.00696989\n",
      "\n",
      "0.9 \t0.526846\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[167]\ttrain-mlogloss:0.390969+0.002374\ttest-mlogloss:0.527127+0.00787015\n",
      "\n",
      "1.2 \t0.527127\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[206]\ttrain-mlogloss:0.370844+0.00353107\ttest-mlogloss:0.526113+0.00799753\n",
      "\n",
      "1.5 \t0.5261126\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[227]\ttrain-mlogloss:0.375197+0.0107539\ttest-mlogloss:0.526744+0.0071078\n",
      "\n",
      "1.8 \t0.5267444\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[193]\ttrain-mlogloss:0.386555+0.00438174\ttest-mlogloss:0.526173+0.00798028\n",
      "\n",
      "2.1 \t0.5261726\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[161]\ttrain-mlogloss:0.411347+0.00406703\ttest-mlogloss:0.526713+0.00664277\n",
      "\n",
      "2.4 \t0.5267126\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[187]\ttrain-mlogloss:0.419464+0.00941197\ttest-mlogloss:0.527696+0.00723329\n",
      "\n",
      "2.7 \t0.527696\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[205]\ttrain-mlogloss:0.425483+0.00607894\ttest-mlogloss:0.52768+0.00621536\n",
      "\n",
      "3.0 \t0.5276796\n"
     ]
    }
   ],
   "source": [
    "train_param = 0\n",
    "for x in [0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3.0]:\n",
    "#     rgr = xgb.XGBClassifier(\n",
    "#         objective='multi:softprob',\n",
    "#         seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "#         learning_rate = learning_rate,\n",
    "#         n_estimators = 10000,\n",
    "#         max_depth= max_depth,\n",
    "#         nthread = -1,\n",
    "#         silent = False,\n",
    "#         min_child_weight = min_child_weight,\n",
    "#         colsample_bytree = colsample_bytree,\n",
    "#         subsample = subsample,\n",
    "#         gamma = x\n",
    "#     )\n",
    "#     rgr.fit(\n",
    "#         X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "    tmp = cv_train(train_X,train_y,max_depth = max_depth,min_child_weight = min_child_weight, \n",
    "                   colsample_bytree = colsample_bytree, subsample = subsample, gamma = x)\n",
    "    if  tmp < best_score:\n",
    "        best_score = tmp\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "gamma = train_param\n",
    "print gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[157]\ttrain-mlogloss:0.23395+0.00122047\ttest-mlogloss:0.524207+0.00616704\n",
      "\n",
      "    1 | 18m19s | \u001b[35m  -0.52421\u001b[0m | \u001b[32m            0.3187\u001b[0m | \u001b[32m   1.8873\u001b[0m | \u001b[32m    14.5286\u001b[0m | \u001b[32m           15.1511\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[761]\ttrain-mlogloss:0.399624+0.00264638\ttest-mlogloss:0.524972+0.00588274\n",
      "\n",
      "    2 | 19m25s |   -0.52497 |             0.6128 |    1.5493 |      4.6842 |            71.0705 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[625]\ttrain-mlogloss:0.400042+0.00227647\ttest-mlogloss:0.523561+0.0066483\n",
      "\n",
      "    3 | 09m08s | \u001b[35m  -0.52356\u001b[0m | \u001b[32m            0.4218\u001b[0m | \u001b[32m   1.2088\u001b[0m | \u001b[32m     4.7160\u001b[0m | \u001b[32m           31.4924\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[220]\ttrain-mlogloss:0.323732+0.00268261\ttest-mlogloss:0.522883+0.00667203\n",
      "\n",
      "    4 | 09m53s | \u001b[35m  -0.52288\u001b[0m | \u001b[32m            0.6583\u001b[0m | \u001b[32m   0.8139\u001b[0m | \u001b[32m     8.2266\u001b[0m | \u001b[32m           36.0415\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[209]\ttrain-mlogloss:0.31547+0.00199631\ttest-mlogloss:0.52307+0.00702139\n",
      "\n",
      "    5 | 12m56s |   -0.52307 |             0.6125 |    2.7251 |     12.3013 |            45.5590 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[447]\ttrain-mlogloss:0.355118+0.00184364\ttest-mlogloss:0.521942+0.00698152\n",
      "\n",
      "    6 | 06m52s | \u001b[35m  -0.52194\u001b[0m | \u001b[32m            0.2595\u001b[0m | \u001b[32m   1.8428\u001b[0m | \u001b[32m     6.5018\u001b[0m | \u001b[32m           35.8611\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[220]\ttrain-mlogloss:0.299013+0.00176259\ttest-mlogloss:0.523703+0.00685391\n",
      "\n",
      "    7 | 11m00s |   -0.52370 |             0.3964 |    2.4189 |     14.4695 |            46.0494 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[246]\ttrain-mlogloss:0.328609+0.00114041\ttest-mlogloss:0.522675+0.00615224\n",
      "\n",
      "    8 | 09m07s |   -0.52268 |             0.6175 |    0.4386 |      7.2693 |            24.1068 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[187]\ttrain-mlogloss:0.285003+0.00268718\ttest-mlogloss:0.522512+0.00664379\n",
      "\n",
      "    9 | 06m11s |   -0.52251 |             0.3165 |    1.6296 |     10.9398 |            24.5599 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[376]\ttrain-mlogloss:0.351049+0.00230855\ttest-mlogloss:0.523725+0.00634924\n",
      "\n",
      "   10 | 17m56s |   -0.52372 |             0.7087 |    2.9664 |      9.7212 |            79.0607 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1275]\ttrain-mlogloss:0.384035+0.00357539\ttest-mlogloss:0.522706+0.00735617\n",
      "\n",
      "   11 | 22m45s |   -0.52271 |             0.5637 |    2.8357 |      4.1744 |             8.0558 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[425]\ttrain-mlogloss:0.324894+0.000821843\ttest-mlogloss:0.523193+0.00646264\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.51709752e-05]), 'nit': 6, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 14m08s |   -0.52319 |             0.2640 |    2.9058 |     14.9508 |            66.8396 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1334]\ttrain-mlogloss:0.418507+0.00200147\ttest-mlogloss:0.524462+0.00647836\n",
      "\n",
      "   13 | 12m30s |   -0.52446 |             0.2136 |    2.8573 |      4.0338 |            51.0298 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1049]\ttrain-mlogloss:0.396552+0.00368615\ttest-mlogloss:0.523874+0.00596379\n",
      "\n",
      "   14 | 21m59s |   -0.52387 |             0.7004 |    2.9854 |      4.0457 |            20.4812 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[233]\ttrain-mlogloss:0.31083+0.00168768\ttest-mlogloss:0.524399+0.00723121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.24758371e-05]), 'nit': 2, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 07m34s |   -0.52440 |             0.2268 |    0.0235 |     14.6446 |            79.4545 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[757]\ttrain-mlogloss:0.37502+0.000834533\ttest-mlogloss:0.523353+0.0065462\n",
      "\n",
      "   16 | 08m25s |   -0.52335 |             0.2603 |    0.0289 |      4.3906 |            10.8162 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-mlogloss:0.179749+0.00297028\ttest-mlogloss:0.534121+0.00831265\n",
      "\n",
      "   17 | 05m06s |   -0.53412 |             0.2494 |    0.6160 |     14.8996 |             8.0272 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[739]\ttrain-mlogloss:0.413823+0.00204196\ttest-mlogloss:0.524501+0.00685289\n",
      "\n",
      "   18 | 07m37s |   -0.52450 |             0.2202 |    0.0547 |      4.0154 |            79.7524 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[312]\ttrain-mlogloss:0.314163+0.00118025\ttest-mlogloss:0.521965+0.00700006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00024533]), 'nit': 3, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 10m03s |   -0.52196 |             0.2231 |    2.9957 |     14.6389 |            33.2639 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1404]\ttrain-mlogloss:0.396343+0.00268244\ttest-mlogloss:0.52397+0.00633921\n",
      "\n",
      "   20 | 28m49s |   -0.52397 |             0.7037 |    2.9951 |      4.1527 |            40.6643 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[394]\ttrain-mlogloss:0.338903+0.00173118\ttest-mlogloss:0.522425+0.00721242\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00016339]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 11m12s |   -0.52242 |             0.2334 |    2.9479 |     12.6802 |            57.2975 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[459]\ttrain-mlogloss:0.332138+0.00115371\ttest-mlogloss:0.521091+0.00701603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.43152746e-05]), 'nit': 6, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00019953]), 'nit': 6, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 08m50s | \u001b[35m  -0.52109\u001b[0m | \u001b[32m            0.2203\u001b[0m | \u001b[32m   2.9524\u001b[0m | \u001b[32m     8.0637\u001b[0m | \u001b[32m           14.5202\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[461]\ttrain-mlogloss:0.33277+0.00138585\ttest-mlogloss:0.521888+0.00664911\n",
      "\n",
      "   23 | 10m26s |   -0.52189 |             0.2173 |    2.9724 |     10.8705 |            39.5027 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[428]\ttrain-mlogloss:0.324331+0.00113049\ttest-mlogloss:0.520749+0.00630795\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.0001546]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 09m04s | \u001b[35m  -0.52075\u001b[0m | \u001b[32m            0.2196\u001b[0m | \u001b[32m   2.9991\u001b[0m | \u001b[32m     9.9786\u001b[0m | \u001b[32m           17.9067\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[508]\ttrain-mlogloss:0.326938+0.000692585\ttest-mlogloss:0.52163+0.00584595\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00012871]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 11m05s |   -0.52163 |             0.2209 |    2.9016 |      9.7721 |            31.3829 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[750]\ttrain-mlogloss:0.373866+0.00227905\ttest-mlogloss:0.521902+0.00690022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.14210399e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 11m19s |   -0.52190 |             0.2107 |    2.9886 |      7.6344 |            61.3300 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[252]\ttrain-mlogloss:0.336469+0.00218109\ttest-mlogloss:0.522949+0.00666208\n",
      "\n",
      "   27 | 05m42s |   -0.52295 |             0.2092 |    0.0029 |      9.1155 |            60.5460 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1297]\ttrain-mlogloss:0.402724+0.00187718\ttest-mlogloss:0.522849+0.00631957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -4.42318510e-05]), 'nit': 6, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 14m38s |   -0.52285 |             0.2665 |    2.9725 |      4.0401 |            13.8616 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[198]\ttrain-mlogloss:0.271867+0.00145997\ttest-mlogloss:0.522183+0.00691938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00023219]), 'nit': 6, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 06m13s |   -0.52218 |             0.2430 |    0.0136 |      9.5056 |            18.3178 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[317]\ttrain-mlogloss:0.295096+0.00105552\ttest-mlogloss:0.523096+0.00605109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00020497]), 'nit': 4, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.50051701e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 19m02s |   -0.52310 |             0.7740 |    2.9917 |      9.2091 |            16.3239 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[303]\ttrain-mlogloss:0.320382+0.0021877\ttest-mlogloss:0.522868+0.00622288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00025432]), 'nit': 4, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.19419159e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 05m57s |   -0.52287 |             0.2014 |    0.0477 |      8.5258 |            44.3389 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[656]\ttrain-mlogloss:0.348866+0.00212292\ttest-mlogloss:0.521771+0.00663447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.08808724e-05]), 'nit': 4, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 10m22s |   -0.52177 |             0.2070 |    2.9618 |      7.3106 |            23.5246 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[548]\ttrain-mlogloss:0.34419+0.00189499\ttest-mlogloss:0.522579+0.00646543\n",
      "\n",
      "   33 | 12m28s |   -0.52258 |             0.2098 |    2.9181 |     11.0907 |            71.9354 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[342]\ttrain-mlogloss:0.289751+0.00167157\ttest-mlogloss:0.521939+0.00695795\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.42415586e-05]), 'nit': 5, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 11m14s |   -0.52194 |             0.2141 |    2.8797 |     13.7639 |            20.5322 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[187]\ttrain-mlogloss:0.271868+0.00204199\ttest-mlogloss:0.523538+0.00687634\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00052661]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.60020261e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 05m46s |   -0.52354 |             0.2102 |    0.1569 |     11.0299 |            32.1360 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[356]\ttrain-mlogloss:0.336891+0.00153242\ttest-mlogloss:0.523284+0.00716312\n",
      "\n",
      "   36 | 12m29s |   -0.52328 |             0.2847 |    2.7754 |     14.8875 |            79.9029 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[582]\ttrain-mlogloss:0.345618+0.00146564\ttest-mlogloss:0.522022+0.00678958\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.86097519e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 12m33s |   -0.52202 |             0.2175 |    2.9719 |     10.3356 |            64.7402 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[499]\ttrain-mlogloss:0.334555+0.00142179\ttest-mlogloss:0.522136+0.00695774\n",
      "\n",
      "   38 | 10m39s |   -0.52214 |             0.2029 |    2.8065 |     10.3466 |            50.1483 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[433]\ttrain-mlogloss:0.362511+0.00196944\ttest-mlogloss:0.522037+0.00631406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00026055]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 08m00s |   -0.52204 |             0.2014 |    2.9767 |      8.7965 |            35.7313 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[694]\ttrain-mlogloss:0.396012+0.00174065\ttest-mlogloss:0.523436+0.00683814\n",
      "\n",
      "   40 | 10m46s |   -0.52344 |             0.2257 |    0.2491 |      4.0482 |            24.1539 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[385]\ttrain-mlogloss:0.332956+0.00125381\ttest-mlogloss:0.521049+0.00672689\n",
      "\n",
      "   41 | 14m52s |   -0.52105 |             0.2191 |    2.6892 |      8.4803 |            19.8283 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[707]\ttrain-mlogloss:0.355832+0.00183321\ttest-mlogloss:0.521293+0.00750902\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00342142]), 'nit': 3, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 10m58s |   -0.52129 |             0.2223 |    2.9244 |      6.9990 |            11.2221 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[374]\ttrain-mlogloss:0.302449+0.00141864\ttest-mlogloss:0.521144+0.00642974\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  8.06729440e-05]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 10m15s |   -0.52114 |             0.2206 |    2.9852 |     11.9499 |            17.4165 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[326]\ttrain-mlogloss:0.302866+0.000916377\ttest-mlogloss:0.521396+0.00659012\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.83772419e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   44 | 08m17s |   -0.52140 |             0.2133 |    2.6109 |     10.3001 |            19.8886 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[346]\ttrain-mlogloss:0.290526+0.00123105\ttest-mlogloss:0.522693+0.0065156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00047645]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.34887401e-05]), 'nit': 7, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.03718392e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 11m24s |   -0.52269 |             0.2262 |    2.8142 |     14.9305 |            28.4110 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[443]\ttrain-mlogloss:0.376112+0.00197498\ttest-mlogloss:0.521707+0.00691315\n",
      "\n",
      "   46 | 08m35s |   -0.52171 |             0.2135 |    2.9574 |      8.0057 |            57.1056 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[491]\ttrain-mlogloss:0.329543+0.00140547\ttest-mlogloss:0.520369+0.00691078\n",
      "\n",
      "   47 | 09m26s | \u001b[35m  -0.52037\u001b[0m | \u001b[32m            0.2151\u001b[0m | \u001b[32m   2.8569\u001b[0m | \u001b[32m     8.1622\u001b[0m | \u001b[32m           18.5155\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[539]\ttrain-mlogloss:0.35257+0.00124752\ttest-mlogloss:0.521999+0.00680883\n",
      "\n",
      "   48 | 08m06s |   -0.52200 |             0.2163 |    2.4097 |      6.4854 |            18.3337 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1349]\ttrain-mlogloss:0.425245+0.00203004\ttest-mlogloss:0.5249+0.00651993\n",
      "\n",
      "   49 | 15m58s |   -0.52490 |             0.3070 |    2.9179 |      4.2131 |            79.6065 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[735]\ttrain-mlogloss:0.406724+0.00136388\ttest-mlogloss:0.524799+0.00717867\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  2.21826049e-05]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 08m13s |   -0.52480 |             0.2362 |    0.0639 |      4.0108 |            59.2135 | \n"
     ]
    }
   ],
   "source": [
    "xgtrain = xgb.DMatrix(train_X, label=train_y) \n",
    "\n",
    "def xgb_evaluate(min_child_weight, colsample_bytree, max_depth, gamma): #, subsample\n",
    "    params = dict()\n",
    "    params['objective']='multi:softprob'\n",
    "    params['eval_metric']='mlogloss',\n",
    "    params['num_class']=3\n",
    "    params['silent']=1\n",
    "    params['eta'] = 0.1\n",
    "    params['verbose_eval'] = True\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = 0.99     # max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    \n",
    "    cv_result = xgb.cv(\n",
    "        params, xgtrain, \n",
    "        num_boost_round=10000, nfold=5,\n",
    "        metrics = 'mlogloss',\n",
    "        seed=1234,callbacks=[xgb.callback.early_stop(50)]\n",
    "    )\n",
    "    \n",
    "    return -cv_result['test-mlogloss-mean'].values[-1]\n",
    "\n",
    "\n",
    "xgb_BO = BayesianOptimization(\n",
    "    xgb_evaluate, \n",
    "    {\n",
    "        'max_depth': (4,15),\n",
    "        'min_child_weight': (8,80),\n",
    "        'colsample_bytree': (0.2,0.8),\n",
    "#         'subsample': (0.7,1),\n",
    "        'gamma': (0,3)\n",
    "    }\n",
    ")\n",
    "\n",
    "xgb_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight | \n",
    "# Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
    "\n",
    "# Will train until test-mlogloss hasn't improved in 50 rounds.\n",
    "# Stopping. Best iteration:\n",
    "# [201]\ttrain-mlogloss:0.293189+0.00192919\ttest-mlogloss:0.521722+0.00743877\n",
    "\n",
    "#     1 | 08m41s |   -0.52172 |             0.3187 |    1.8873 |      9.7000 |            15.1511 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8.162198</td>\n",
       "      <td>18.515538</td>\n",
       "      <td>0.215099</td>\n",
       "      <td>2.856949</td>\n",
       "      <td>-0.520369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.978596</td>\n",
       "      <td>17.906659</td>\n",
       "      <td>0.219601</td>\n",
       "      <td>2.999130</td>\n",
       "      <td>-0.520749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8.480326</td>\n",
       "      <td>19.828347</td>\n",
       "      <td>0.219113</td>\n",
       "      <td>2.689181</td>\n",
       "      <td>-0.521049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.063680</td>\n",
       "      <td>14.520219</td>\n",
       "      <td>0.220268</td>\n",
       "      <td>2.952387</td>\n",
       "      <td>-0.521091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11.949935</td>\n",
       "      <td>17.416496</td>\n",
       "      <td>0.220621</td>\n",
       "      <td>2.985171</td>\n",
       "      <td>-0.521144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.999021</td>\n",
       "      <td>11.222119</td>\n",
       "      <td>0.222311</td>\n",
       "      <td>2.924356</td>\n",
       "      <td>-0.521293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10.300054</td>\n",
       "      <td>19.888567</td>\n",
       "      <td>0.213301</td>\n",
       "      <td>2.610908</td>\n",
       "      <td>-0.521396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.772146</td>\n",
       "      <td>31.382917</td>\n",
       "      <td>0.220899</td>\n",
       "      <td>2.901584</td>\n",
       "      <td>-0.521630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8.005700</td>\n",
       "      <td>57.105623</td>\n",
       "      <td>0.213530</td>\n",
       "      <td>2.957402</td>\n",
       "      <td>-0.521707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.310599</td>\n",
       "      <td>23.524609</td>\n",
       "      <td>0.206995</td>\n",
       "      <td>2.961841</td>\n",
       "      <td>-0.521771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  colsample_bytree     gamma     score\n",
       "36   8.162198         18.515538          0.215099  2.856949 -0.520369\n",
       "13   9.978596         17.906659          0.219601  2.999130 -0.520749\n",
       "30   8.480326         19.828347          0.219113  2.689181 -0.521049\n",
       "11   8.063680         14.520219          0.220268  2.952387 -0.521091\n",
       "32  11.949935         17.416496          0.220621  2.985171 -0.521144\n",
       "31   6.999021         11.222119          0.222311  2.924356 -0.521293\n",
       "33  10.300054         19.888567          0.213301  2.610908 -0.521396\n",
       "14   9.772146         31.382917          0.220899  2.901584 -0.521630\n",
       "35   8.005700         57.105623          0.213530  2.957402 -0.521707\n",
       "21   7.310599         23.524609          0.206995  2.961841 -0.521771"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bo_scores = pd.DataFrame([[s[0]['max_depth'],\n",
    "                               s[0]['min_child_weight'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "#                                s[0]['subsample'],\n",
    "                               s[0]['gamma'],\n",
    "                               s[1]] for s in zip(xgb_BO.res['all']['params'],xgb_BO.res['all']['values'])],\n",
    "                            columns = ['max_depth',\n",
    "                                       'min_child_weight',\n",
    "                                       'colsample_bytree',\n",
    "#                                        'subsample',\n",
    "                                       'gamma',\n",
    "                                       'score'])\n",
    "xgb_bo_scores=xgb_bo_scores.sort_values('score',ascending=False)\n",
    "xgb_bo_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0,randomseed=1234):\n",
    "    N_params = len(estimators)\n",
    "#     print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,shuffle=True,random_state=randomseed)\n",
    "    N_class = len(set(train_y))\n",
    "        \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(objective = 'multi:softprob')\n",
    "        est.set_params(silent = False)\n",
    "        est.set_params(learning_rate = 0.02)\n",
    "        est.set_params(n_estimators=1000000)\n",
    "        \n",
    "#         print (\"Model %d: %s\" %(j+1, est))\n",
    "\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "    \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "#             print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]      \n",
    "\n",
    "            est.fit(train_x_fold,train_y_fold,\n",
    "                    eval_set = [(val_x_fold, val_y_fold)],\n",
    "                    eval_metric = 'mlogloss',\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose=False)\n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "#             print (\"best round %d\" % (best_round))\n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,ntree_limit=best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print \"Score: \", score\n",
    "            scores[i,j]=score\n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,ntree_limit=best_round)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fm\" % (j+1,i+1, (time.time() - fold_start)/60))\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "#         print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.515082505834\n",
      "Model 1 fold 1 fitting finished in 10.988m\n",
      "Score:  0.512235477029\n",
      "Model 1 fold 2 fitting finished in 26.918m\n",
      "Score:  0.520604877548\n",
      "Model 1 fold 3 fitting finished in 9.655m\n",
      "Score:  0.511695108693\n",
      "Model 1 fold 4 fitting finished in 12.752m\n",
      "Score:  0.511981690547\n",
      "Model 1 fold 5 fitting finished in 17.613m\n",
      "Score:  0.521202828917\n",
      "Model 1 fold 6 fitting finished in 11.254m\n",
      "Score for blended models is 0.515467\n",
      "Score:  0.512940925513\n",
      "Model 1 fold 1 fitting finished in 13.341m\n",
      "Score:  0.515271860963\n",
      "Model 1 fold 2 fitting finished in 9.429m\n",
      "Score:  0.524370546769\n",
      "Model 1 fold 3 fitting finished in 14.211m\n",
      "Score:  0.514223065154\n",
      "Model 1 fold 4 fitting finished in 14.095m\n",
      "Score:  0.50739124694\n",
      "Model 1 fold 5 fitting finished in 17.170m\n",
      "Score:  0.518891196996\n",
      "Model 1 fold 6 fitting finished in 17.798m\n",
      "Score for blended models is 0.515515\n",
      "Score:  0.522438349286\n",
      "Model 1 fold 1 fitting finished in 9.580m\n",
      "Score:  0.517003901371\n",
      "Model 1 fold 2 fitting finished in 14.412m\n",
      "Score:  0.516416520976\n",
      "Model 1 fold 3 fitting finished in 14.219m\n",
      "Score:  0.50877527315\n",
      "Model 1 fold 4 fitting finished in 20.005m\n",
      "Score:  0.521848714859\n",
      "Model 1 fold 5 fitting finished in 14.400m\n",
      "Score:  0.508283947503\n",
      "Model 1 fold 6 fitting finished in 13.461m\n",
      "Score for blended models is 0.515794\n",
      "Score:  0.508644491924\n",
      "Model 1 fold 1 fitting finished in 16.997m\n",
      "Score:  0.520836058732\n",
      "Model 1 fold 2 fitting finished in 12.970m\n",
      "Score:  0.514243955556\n",
      "Model 1 fold 3 fitting finished in 11.478m\n",
      "Score:  0.516334808607\n",
      "Model 1 fold 4 fitting finished in 15.031m\n",
      "Score:  0.517523880319\n",
      "Model 1 fold 5 fitting finished in 10.499m\n",
      "Score:  0.519753928022\n",
      "Model 1 fold 6 fitting finished in 10.453m\n",
      "Score for blended models is 0.516223\n",
      "Score:  0.542376723902\n",
      "Model 1 fold 1 fitting finished in 10.158m\n",
      "Score:  0.508723401461\n",
      "Model 1 fold 2 fitting finished in 23.672m\n",
      "Score:  0.508737304971\n",
      "Model 1 fold 3 fitting finished in 13.777m\n",
      "Score:  0.506093679608\n",
      "Model 1 fold 4 fitting finished in 15.115m\n",
      "Score:  0.522305929447\n",
      "Model 1 fold 5 fitting finished in 9.881m\n",
      "Score:  0.507187644117\n",
      "Model 1 fold 6 fitting finished in 17.124m\n",
      "Score for blended models is 0.515904\n"
     ]
    }
   ],
   "source": [
    "train_total = np.zeros((train_X.shape[0], 3))\n",
    "test_total = np.zeros((test_X.shape[0], 3))\n",
    "score_total = 0\n",
    "count = 5\n",
    "\n",
    "for n in range(count):\n",
    "    randomseed = n\n",
    "    estimators = [\n",
    "                 xgb.XGBClassifier(max_depth = 8,\n",
    "                                  min_child_weight = 18,\n",
    "                                  colsample_bytree = 0.215099,\n",
    "                                  subsample = 0.99,\n",
    "                                  gamma = 2.856949),  \n",
    "                 ]\n",
    "\n",
    "    (train_blend_x_xgb,\n",
    "     test_blend_x_xgb_mean,\n",
    "     test_blend_x_xgb_gmean,\n",
    "     blend_scores_xgb,\n",
    "     best_rounds_xgb) = xgb_blend(estimators,\n",
    "                                  train_X,train_y,\n",
    "                                  test_X,\n",
    "                                  6,\n",
    "                                  500,randomseed)\n",
    "    train_total += train_blend_x_xgb\n",
    "    test_total += test_blend_x_xgb_mean\n",
    "    score_total += np.mean(blend_scores_xgb)\n",
    "    \n",
    "train_total = train_total / count\n",
    "test_total = test_total / count\n",
    "score_total = score_total / count\n",
    "\n",
    "#  \t \tmax_depth \tmin_child_weight \tcolsample_bytree \tgamma \tscore\n",
    "# 36 \t8.162198 \t18.515538 \t \t \t0.215099 \t \t \t2.856949 \t-0.520369\n",
    "# 13 \t9.978596 \t17.906659 \t \t \t0.219601 \t \t \t2.999130 \t-0.520749\n",
    "# 30 \t8.480326 \t19.828347 \t \t \t0.219113 \t \t \t2.689181 \t-0.521049\n",
    "# 11 \t8.063680 \t14.520219 \t \t \t0.220268 \t \t \t2.952387 \t-0.521091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5157806614905075"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_blend_x_xgb = pd.DataFrame(train_total)\n",
    "train_blend_x_xgb.columns = [\"low\", \"medium\", \"high\"]\n",
    "train_blend_x_xgb[\"listing_id\"] = train_X.listing_id.values\n",
    "\n",
    "test_blend_x_xgb_mean = pd.DataFrame(test_total)\n",
    "test_blend_x_xgb_mean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_blend_x_xgb_mean[\"listing_id\"] = test_X.listing_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_train = train_X_0322[['listing_id']].merge(train_blend_x_xgb,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_mean = test_X_0322[['listing_id']].merge(test_blend_x_xgb_mean,on = 'listing_id', how = 'left')[[\"low\", \"medium\", \"high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51590411]\n",
      "[ 3839.66666667]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_xgb_141bagging_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_mean_141bagging_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb,axis=0))\n",
    "print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,tmp_train, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,tmp_test_mean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "sub_name = '../output/sub_XGB_mean_141bagging_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(tmp_test_mean[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X_0322.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
