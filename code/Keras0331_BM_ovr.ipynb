{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU,LeakyReLU,ELU,ParametricSoftplus,ThresholdedReLU,SReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Nadam\n",
    "from keras.regularizers import WeightRegularizer, ActivityRegularizer,l2, activity_l2\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 412) (74659, 412) (49352, 3)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_BM_0331.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_BM_0331.csv')\n",
    "\n",
    "ntrain = train_X.shape[0]\n",
    "sub_id = test_X.listing_id.astype('int32').values\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_ind = test_X.num_loc_price_diff.isnull()\n",
    "test_X['num_loc_price_diff'] = test_X['num_price'] - test_X['num_loc_median_price']\n",
    "# test_X[null_ind][['num_loc_price_diff','num_price','num_loc_median_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124011, 412)\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.concat([train_X,test_X])\n",
    "print full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_to_use = ['building_id_mean_med', 'building_id_mean_high',\n",
    "       'manager_id_mean_med', 'manager_id_mean_high', 'median_price_bed',\n",
    "       'ratio_bed', 'compound', 'neg', 'neu', 'pos', \n",
    "#                'street', 'avenue',\n",
    "#        'east', 'west', 'north', 'south', 'other_address', 'top_10_manager',\n",
    "#        'top_25_manager', 'top_5_manager', 'top_50_manager',\n",
    "#        'top_1_manager', 'top_2_manager', 'top_15_manager',\n",
    "#        'top_20_manager', 'top_30_manager', 'Zero_building_id',\n",
    "#        'top_10_building', 'top_25_building', 'top_5_building',\n",
    "#        'top_50_building', 'top_1_building', 'top_2_building',\n",
    "#        'top_15_building', 'top_20_building', 'top_30_building',\n",
    "       'listing_id', 'num_latitude', 'num_longitude',\n",
    "       'num_dist_from_center', 'num_OutlierAggregated', 'num_pos_density',\n",
    "       'num_building_null', 'num_fbuilding', 'num_fmanager',\n",
    "       'num_created_weekday', 'num_created_weekofyear', 'num_created_day',\n",
    "       'num_created_month', 'num_created_hour', 'num_bathrooms',\n",
    "       'num_bedrooms', 'num_price', 'num_price_q', 'num_priceXroom',\n",
    "       'num_even_bathrooms', 'num_features', 'num_photos',\n",
    "       'num_desc_length', 'num_desc_length_null',\n",
    "#                'num_location_6_3',\n",
    "#        'num_location_6_1', 'num_location_6_0', 'num_location_6_5',\n",
    "#        'num_location_6_4', 'num_location_6_2', 'num_location_40_18',\n",
    "#        'num_location_40_31', 'num_location_40_11', 'num_location_40_24',\n",
    "#        'num_location_40_14', 'num_location_40_36', 'num_location_40_3',\n",
    "#        'num_location_40_7', 'num_location_40_33', 'num_location_40_5',\n",
    "#        'num_location_40_37', 'num_location_40_12', 'num_location_40_16',\n",
    "#        'num_location_40_2', 'num_location_40_20', 'num_location_40_34',\n",
    "#        'num_location_40_9', 'num_location_40_0', 'num_location_40_21',\n",
    "#        'num_location_40_26', 'num_location_40_13', 'num_location_40_25',\n",
    "#        'num_location_40_32', 'num_location_40_19', 'num_location_40_17',\n",
    "#        'num_location_40_4', 'num_location_40_15', 'num_location_40_35',\n",
    "#        'num_location_40_22', 'num_location_40_30', 'num_location_40_1',\n",
    "#        'num_location_40_23', 'num_location_40_10', 'num_location_40_38',\n",
    "#        'num_location_40_28', 'num_location_40_6', 'num_location_40_29',\n",
    "#        'num_location_40_27', 'num_location_40_39', 'num_location_40_8',\n",
    "#        'num_room_type_0', 'num_room_type_1', 'num_room_type_2',\n",
    "#        'num_room_type_3', 'num_room_type_4', 'num_room_type_5',\n",
    "#        'num_room_type_6', 'num_room_type_7', 'num_room_type_8',\n",
    "#        'num_room_type_9', 'num_room_type_10', 'num_room_type_11',\n",
    "#        'num_room_type_12', 'num_room_type_13', 'num_room_type_14',\n",
    "#        'num_room_type_15', 'num_room_type_16', 'num_room_type_17',\n",
    "#        'num_room_type_18', 'num_room_type_19', \n",
    "               'num_6_median_price',\n",
    "       'num_6_price_ratio', 'num_6_price_diff', 'num_loc_median_price',\n",
    "       'num_loc_price_ratio', 'num_loc_price_diff', 'num_loc_ratio',\n",
    "       'num_loc_diff', 'hcc_pos_pred_1', 'hcc_pos_pred_2', 'building_id',\n",
    "       'display_address', 'manager_id', 'street_address',\n",
    "       'num_pricePerBed', 'num_pricePerBath', 'num_pricePerRoom',\n",
    "       'num_bedPerBath', 'num_bedBathDiff', 'num_bedBathSum',\n",
    "       'num_bedsPerc', \n",
    "#                'hcc_building_id_pred_1', 'hcc_building_id_pred_2',\n",
    "#        'hcc_manager_id_pred_1', 'hcc_manager_id_pred_2',\n",
    "               \n",
    "#        'feature_1_month_free', 'feature_24/7_concierge',\n",
    "#        'feature_24/7_doorman', 'feature_24/7_doorman_concierge',\n",
    "#        'feature_actual_apt._photos', 'feature_air_conditioning',\n",
    "#        'feature_all_pets_ok', 'feature_all_utilities_included',\n",
    "#        'feature_assigned-parking-space', 'feature_attended_lobby',\n",
    "#        'feature_backyard', 'feature_balcony', 'feature_basement_storage',\n",
    "#        'feature_basketball_court', 'feature_bike_room',\n",
    "#        'feature_bike_storage', 'feature_billiards_room',\n",
    "#        'feature_billiards_table_and_wet_bar', 'feature_brand_new',\n",
    "#        'feature_breakfast_bar', 'feature_bright', 'feature_brownstone',\n",
    "#        'feature_building-common-outdoor-space', 'feature_business_center',\n",
    "#        'feature_cable/satellite_tv', 'feature_cable_ready',\n",
    "#        'feature_call/text_abraham_caro_@_917-373-0862',\n",
    "#        'feature_cats_allowed', 'feature_central_a/c', 'feature_central_ac',\n",
    "#        'feature_central_air', 'feature_chefs_kitchen',\n",
    "#        \"feature_children's_playroom\", 'feature_childrens_playroom',\n",
    "#        'feature_cinema_room', 'feature_city_view',\n",
    "#        'feature_close_to_subway', 'feature_closets_galore!',\n",
    "#        'feature_club_sun_deck_has_spectacular_city_and_river_views',\n",
    "#        'feature_cold_storage', 'feature_common_backyard',\n",
    "#        'feature_common_garden', 'feature_common_outdoor_space',\n",
    "#        'feature_common_parking/garage', 'feature_common_roof_deck',\n",
    "#        'feature_common_storage', 'feature_common_terrace',\n",
    "#        'feature_community_recreation_facilities',\n",
    "#        'feature_complimentary_sunday_brunch', 'feature_concierge',\n",
    "#        'feature_concierge_service', 'feature_condo_finishes',\n",
    "#        'feature_courtyard', 'feature_crown_moldings', 'feature_deck',\n",
    "#        'feature_deco_brick_wall', 'feature_decorative_fireplace',\n",
    "#        'feature_dining_room', 'feature_dishwasher', 'feature_dogs_allowed',\n",
    "#        'feature_doorman', 'feature_dry_cleaning_service',\n",
    "#        'feature_dryer_in_unit', 'feature_duplex', 'feature_duplex_lounge',\n",
    "#        'feature_eat-in_kitchen', 'feature_eat_in_kitchen',\n",
    "#        'feature_elegant_glass-enclosed_private_lounge_with_magnificent_river_views',\n",
    "#        'feature_elevator', 'feature_exclusive',\n",
    "#        'feature_exercise/yoga_studio', 'feature_exposed_brick',\n",
    "#        'feature_extra_room', 'feature_fireplace', 'feature_fireplaces',\n",
    "#        'feature_fitness_center', 'feature_fitness_room', 'feature_flex-2',\n",
    "#        'feature_flex-3', 'feature_free_wifi_in_club_lounge',\n",
    "#        'feature_ft_doorman', 'feature_full-time_doorman',\n",
    "#        'feature_full_service_garage',\n",
    "#        'feature_fully-equipped_club_fitness_center',\n",
    "#        'feature_fully__equipped', 'feature_furnished', 'feature_game_room',\n",
    "#        'feature_garage', 'feature_garbage_disposal', 'feature_garden',\n",
    "#        'feature_garden/patio', 'feature_granite_countertops',\n",
    "#        'feature_granite_kitchen', 'feature_green_building',\n",
    "#        'feature_guarantors_accepted', 'feature_gut_renovated',\n",
    "#        'feature_gym', 'feature_gym/fitness', 'feature_gym_in_building',\n",
    "#        'feature_hardwood', 'feature_hardwood_floors',\n",
    "#        'feature_health_club', 'feature_hi_rise',\n",
    "#        'feature_high-speed_internet', 'feature_high_ceiling',\n",
    "#        'feature_high_ceilings', 'feature_high_speed_internet',\n",
    "#        'feature_highrise', 'feature_housekeeping_service',\n",
    "#        'feature_in-unit_washer/dryer', 'feature_indoor_pool',\n",
    "#        'feature_intercom', 'feature_jacuzzi', 'feature_large_living_room',\n",
    "#        'feature_laundry', 'feature_laundry_&_housekeeping',\n",
    "#        'feature_laundry_in_building', 'feature_laundry_in_unit',\n",
    "#        'feature_laundry_on_every_floor', 'feature_laundry_on_floor',\n",
    "#        'feature_laundry_room', 'feature_light', 'feature_live-in_super',\n",
    "#        'feature_live-in_superintendent', 'feature_live/work',\n",
    "#        'feature_live_in_super', 'feature_loft', 'feature_lounge',\n",
    "#        'feature_lounge_room', 'feature_lowrise', 'feature_luxury_building',\n",
    "#        'feature_magnificent_venetian-style', 'feature_mail_room',\n",
    "#        'feature_marble_bath', 'feature_marble_bathroom',\n",
    "#        'feature_media_room', 'feature_media_screening_room',\n",
    "#        'feature_microwave', 'feature_midrise', 'feature_multi-level',\n",
    "#        'feature_new_construction', 'feature_newly_renovated',\n",
    "#        'feature_no_fee', 'feature_no_pets', 'feature_on-site_atm_machine',\n",
    "#        'feature_on-site_attended_garage', 'feature_on-site_garage',\n",
    "#        'feature_on-site_laundry', 'feature_on-site_parking',\n",
    "#        'feature_on-site_parking_available', 'feature_on-site_parking_lot',\n",
    "#        'feature_on-site_super', 'feature_one_month_free',\n",
    "#        'feature_outdoor_areas', 'feature_outdoor_entertainment_space',\n",
    "#        'feature_outdoor_pool',\n",
    "#        'feature_outdoor_roof_deck_overlooking_new_york_harbor_and_battery_park',\n",
    "#        'feature_outdoor_space', 'feature_package_room', 'feature_parking',\n",
    "#        'feature_parking_available', 'feature_parking_space',\n",
    "#        'feature_part-time_doorman', 'feature_party_room', 'feature_patio',\n",
    "#        'feature_penthouse', 'feature_pet_friendly', 'feature_pets',\n",
    "#        'feature_pets_allowed', 'feature_pets_on_approval',\n",
    "#        'feature_playroom', 'feature_playroom/nursery', 'feature_pool',\n",
    "#        'feature_post-war', 'feature_post_war', 'feature_pre-war',\n",
    "#        'feature_pre_war', 'feature_prewar', 'feature_private-balcony',\n",
    "#        'feature_private-outdoor-space', 'feature_private_backyard',\n",
    "#        'feature_private_balcony', 'feature_private_deck',\n",
    "#        'feature_private_garden',\n",
    "#        'feature_private_laundry_room_on_every_floor',\n",
    "#        'feature_private_outdoor_space', 'feature_private_parking',\n",
    "#        'feature_private_roof_deck', 'feature_private_roofdeck',\n",
    "#        'feature_private_terrace', 'feature_publicoutdoor',\n",
    "#        'feature_queen_size_bedrooms', 'feature_queen_sized_rooms',\n",
    "#        'feature_reduced_fee', 'feature_renovated',\n",
    "#        'feature_renovated_kitchen', 'feature_residents_garden',\n",
    "#        'feature_residents_lounge', 'feature_roof-deck',\n",
    "#        'feature_roof_access', 'feature_roof_deck',\n",
    "#        'feature_roof_deck_with_grills', 'feature_roofdeck',\n",
    "#        'feature_rooftop_deck', 'feature_rooftop_terrace',\n",
    "#        'feature_s/s_appliances', 'feature_sauna', 'feature_screening_room',\n",
    "#        'feature_separate_kitchen', 'feature_shared_backyard',\n",
    "#        'feature_shared_garden', 'feature_shares_ok',\n",
    "#        'feature_short_term_allowed', 'feature_simplex', 'feature_skylight',\n",
    "#        'feature_skylight_atrium', 'feature_southern_exposure',\n",
    "#        'feature_spa_services', 'feature_ss_appliances',\n",
    "#        'feature_stainless_steel', 'feature_stainless_steel_appliances',\n",
    "#        'feature_state-of-the-art_fitness_center', 'feature_storage',\n",
    "#        'feature_storage_available', 'feature_storage_facilities_available',\n",
    "#        'feature_storage_room', 'feature_sublet', 'feature_subway',\n",
    "#        'feature_sundeck', 'feature_swimming_pool', 'feature_tenant_lounge',\n",
    "#        'feature_terrace', 'feature_terraces_/_balconies',\n",
    "#        'feature_tons_of_natural_light', 'feature_valet',\n",
    "#        'feature_valet_parking', 'feature_valet_service',\n",
    "#        'feature_valet_services',\n",
    "#        'feature_valet_services_including_dry_cleaning',\n",
    "#        'feature_video_intercom', 'feature_view', 'feature_virtual_doorman',\n",
    "#        'feature_virtual_tour', 'feature_walk-in_closet', 'feature_walk-up',\n",
    "#        'feature_walk_in_closet', 'feature_walk_in_closet(s)',\n",
    "#        'feature_washer/dryer', 'feature_washer/dryer_hookup',\n",
    "#        'feature_washer/dryer_in-unit', 'feature_washer/dryer_in_building',\n",
    "#        'feature_washer/dryer_in_unit', 'feature_washer_&_dryer',\n",
    "#        'feature_washer_in_unit', 'feature_wheelchair_access',\n",
    "#        'feature_wheelchair_ramp', 'feature_wifi', 'feature_wifi_access',\n",
    "#        'feature_wood-burning_fireplace', 'feature_yard',\n",
    "#        'feature_yoga_classes'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 412)\n",
      "(74659, 412)\n"
     ]
    }
   ],
   "source": [
    "for col in feat_to_use:\n",
    "    full_data.loc[:,col] = preprocessing.StandardScaler().fit_transform(full_data[col].values.reshape(-1,1))\n",
    "train_df_nn = full_data[:ntrain]\n",
    "test_df_nn = full_data[ntrain:]\n",
    "\n",
    "train_df_nn = sparse.csr_matrix(train_df_nn)\n",
    "test_df_nn = sparse.csr_matrix(test_df_nn)\n",
    "\n",
    "\n",
    "print train_df_nn.shape\n",
    "print test_df_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "# train_y = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34284\n"
     ]
    }
   ],
   "source": [
    "y_low =[]\n",
    "for i in range(train_X.shape[0]):\n",
    "    y_low.append(1 if train_y[i] == 0 else 0)\n",
    "    \n",
    "y_low = np.array(y_low)  \n",
    "print np.sum(y_low)\n",
    "y_low = to_categorical(y_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df_nn, y_low, train_size=.80, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.5281 - val_loss: 0.4341\n",
      "Epoch 2/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4373 - val_loss: 0.4194\n",
      "Epoch 3/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4293 - val_loss: 0.4183\n",
      "Epoch 4/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4213 - val_loss: 0.4149\n",
      "Epoch 5/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4190 - val_loss: 0.4115\n",
      "Epoch 6/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4168 - val_loss: 0.4162\n",
      "Epoch 7/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4149 - val_loss: 0.4101\n",
      "Epoch 8/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4124 - val_loss: 0.4087\n",
      "Epoch 9/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4108 - val_loss: 0.4101\n",
      "Epoch 10/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4073 - val_loss: 0.4102\n",
      "Epoch 11/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4038 - val_loss: 0.4129\n",
      "Epoch 12/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4063 - val_loss: 0.4043\n",
      "Epoch 13/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4006 - val_loss: 0.4044\n",
      "Epoch 14/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.4028 - val_loss: 0.4040\n",
      "Epoch 15/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3970 - val_loss: 0.4036\n",
      "Epoch 16/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3974 - val_loss: 0.4044\n",
      "Epoch 17/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3955 - val_loss: 0.4018\n",
      "Epoch 18/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3978 - val_loss: 0.4061\n",
      "Epoch 19/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3887 - val_loss: 0.4039\n",
      "Epoch 20/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3901 - val_loss: 0.4020\n",
      "Epoch 21/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.3901 - val_loss: 0.4012\n",
      "Epoch 22/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.3931 - val_loss: 0.3998\n",
      "Epoch 23/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3857 - val_loss: 0.4014\n",
      "Epoch 24/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3865 - val_loss: 0.4008\n",
      "Epoch 25/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3828 - val_loss: 0.4028\n",
      "Epoch 26/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3861 - val_loss: 0.4032\n",
      "Epoch 27/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.3827 - val_loss: 0.3983\n",
      "Epoch 28/1000\n",
      "49408/49352 [==============================] - 9s - loss: 0.3825 - val_loss: 0.4008\n",
      "Epoch 29/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.3810 - val_loss: 0.4006\n",
      "Epoch 30/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.3787 - val_loss: 0.4009\n",
      "Epoch 31/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.3779 - val_loss: 0.4013\n",
      "Epoch 32/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.3793 - val_loss: 0.4009\n",
      "Epoch 33/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.3777 - val_loss: 0.4027\n",
      "0.3983338265\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', # custom metric\n",
    "                           patience=5, #early stopping for epoch\n",
    "                           verbose=0)\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", \n",
    "                               monitor='val_loss', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    init = 'glorot_uniform'\n",
    "    \n",
    "    \n",
    "    model.add(Dense(200, # number of input units: needs to be tuned\n",
    "                    input_dim = input_dim, # fixed length: number of columns of X\n",
    "                    init=init,\n",
    "                   ))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU()) # activation function\n",
    "    model.add(BatchNormalization()) # normalization\n",
    "    model.add(Dropout(0.4)) #dropout rate. needs to be tuned\n",
    "        \n",
    "    model.add(Dense(80,init=init)) # number of hidden1 units. needs to be tuned.\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.4)) #dropout rate. needs to be tuned\n",
    "    \n",
    "#     model.add(Dense(9,init=init)) # number of hidden2 units. needs to be tuned.\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.add(PReLU())\n",
    "#     model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.4)) #dropout rate. needs to be tuned\n",
    "    \n",
    "    model.add(Dense(2,\n",
    "                   init = init,\n",
    "                   activation = 'softmax')) # 1 for regression \n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "#                   metrics=[mae_log],\n",
    "                  optimizer = 'adam' # optimizer. you may want to try different ones\n",
    "                 )\n",
    "    return(model)\n",
    "\n",
    "\n",
    "\n",
    "model = create_model(X_train.shape[1])\n",
    "fit= model.fit_generator(generator=batch_generator(X_train, y_train, 128, True),\n",
    "                         nb_epoch=1000,\n",
    "                         samples_per_epoch=ntrain,\n",
    "                         validation_data=(X_val.todense(), y_val),\n",
    "                         callbacks=[early_stop,checkpointer]\n",
    "                         )\n",
    "\n",
    "print min(fit.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def nn_model(params):\n",
    "    model = Sequential()\n",
    "    init = 'glorot_normal'\n",
    "    \n",
    "    model.add(Dense(params['input_size'], # number of input units: needs to be tuned\n",
    "                    input_dim = params['input_dim'], # fixed length: number of columns of X\n",
    "                    init=init,\n",
    "                   ))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU()) # activation function\n",
    "    model.add(BatchNormalization()) # normalization\n",
    "    model.add(Dropout(params['input_drop_out'])) #dropout rate. needs to be tuned\n",
    "        \n",
    "    model.add(Dense(params['hidden_size'],\n",
    "                    init=init)) # number of hidden1 units. needs to be tuned.\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(params['hidden_drop_out'])) #dropout rate. needs to be tuned\n",
    "    \n",
    "#     model.add(Dense(20,init=init)) # number of hidden2 units. needs to be tuned.\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.add(PReLU())\n",
    "#     model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.5)) #dropout rate. needs to be tuned\n",
    "    \n",
    "    model.add(Dense(2,\n",
    "                    init = init,\n",
    "                    activation = 'softmax')) # 1 for regression \n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'adam' # optimizer. you may want to try different ones\n",
    "                 )\n",
    "    return(model)\n",
    "\n",
    "\n",
    "\n",
    "def nn_blend_data(parameters, train_x, train_y, test_x, fold, early_stopping_rounds=0, batch_size=128):\n",
    "    N_params = len(parameters)\n",
    "    print (\"Blend %d estimators for %d folds\" % (len(parameters), fold))\n",
    "    skf = KFold(n_splits=fold,random_state=seed)\n",
    "    N_class = train_y.shape[1]\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "\n",
    "    \n",
    "    for j, nn_params in enumerate(parameters):\n",
    "        print (\"Model %d: %s\" %(j+1, nn_params))\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "        \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x[val_index]\n",
    "            val_y_fold = train_y[val_index]\n",
    "            \n",
    "\n",
    "            model = nn_model(nn_params)\n",
    "#             print (model)\n",
    "            fit= model.fit_generator(generator=batch_generator(train_x_fold, train_y_fold, 128, True),\n",
    "                                     nb_epoch=70,\n",
    "                                     samples_per_epoch=train_x_fold.shape[0],\n",
    "                                     validation_data=(val_x_fold.todense(), val_y_fold),\n",
    "                                     verbose = 0,\n",
    "                                     callbacks=[ModelCheckpoint(filepath=\"weights.hdf5\", \n",
    "                                                                monitor='val_loss', \n",
    "                                                                verbose=0, save_best_only=True)]\n",
    "                                    )\n",
    "\n",
    "            best_round=len(fit.epoch)-early_stopping_rounds-1\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            \n",
    "            model.load_weights(\"weights.hdf5\")\n",
    "            # Compile model (required to make predictions)\n",
    "            model.compile(loss = 'categorical_crossentropy',optimizer = 'adam' )\n",
    "            \n",
    "            # print (mean_absolute_error(np.exp(y_val)-200, pred_y))\n",
    "            val_y_predict_fold = model.predict_proba(x=val_x_fold.toarray(),verbose=0)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score   \n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            model.load_weights(\"weights.hdf5\")\n",
    "            # Compile model (required to make predictions)\n",
    "            model.compile(loss = 'categorical_crossentropy',optimizer = 'adam' )            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = model.predict_proba(x=test_x.toarray(),verbose=0)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "            \n",
    "        test_blend_x[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x, scores,best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 200 0.4 80 0.4 'glorot_uniform' 'adam' 0.3983338265\n",
    "# 100 0.5 30 0.5 'glorot_uniform' 'adam' 0.400189068724\n",
    "# 100 0.4 30 0.4 'glorot_uniform' 'adam' 0.399582461623\n",
    "# 100 0.4 30 0.4 'glorot_uniform' 'Adamax' 0.397478998776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 2 estimators for 10 folds\n",
      "Model 1: {'input_size': 200, 'input_drop_out': 0.4, 'hidden_drop_out': 0.4, 'hidden_size': 80, 'input_dim': 412}\n",
      "Model 1 fold 1\n",
      "best round 64\n",
      "('Score: ', 0.38914003093726507)\n",
      "Model 1 fold 1 fitting finished in 434.233s\n",
      "Model 1 fold 2\n",
      "best round 64\n",
      "('Score: ', 0.38246933278471729)\n",
      "Model 1 fold 2 fitting finished in 433.652s\n",
      "Model 1 fold 3\n",
      "best round 64\n",
      "('Score: ', 0.38937678736809528)\n",
      "Model 1 fold 3 fitting finished in 434.996s\n",
      "Model 1 fold 4\n",
      "best round 64\n",
      "('Score: ', 0.38047057304827325)\n",
      "Model 1 fold 4 fitting finished in 440.853s\n",
      "Model 1 fold 5\n",
      "best round 64\n",
      "('Score: ', 0.39706287425003256)\n",
      "Model 1 fold 5 fitting finished in 433.695s\n",
      "Model 1 fold 6\n",
      "best round 64\n",
      "('Score: ', 0.39289705687625626)\n",
      "Model 1 fold 6 fitting finished in 436.556s\n",
      "Model 1 fold 7\n",
      "best round 64\n",
      "('Score: ', 0.39864745915227312)\n",
      "Model 1 fold 7 fitting finished in 435.180s\n",
      "Model 1 fold 8\n",
      "best round 64\n",
      "('Score: ', 0.40288639700001533)\n",
      "Model 1 fold 8 fitting finished in 435.340s\n",
      "Model 1 fold 9\n",
      "best round 64\n",
      "('Score: ', 0.40437813582944837)\n",
      "Model 1 fold 9 fitting finished in 435.662s\n",
      "Model 1 fold 10\n",
      "best round 64\n",
      "('Score: ', 0.40250016346773987)\n",
      "Model 1 fold 10 fitting finished in 434.149s\n",
      "Score for model 1 is 0.393983\n",
      "Model 2: {'input_size': 100, 'input_drop_out': 0.4, 'hidden_drop_out': 0.4, 'hidden_size': 30, 'input_dim': 412}\n",
      "Model 2 fold 1\n",
      "best round 64\n",
      "('Score: ', 0.38727503462782653)\n",
      "Model 2 fold 1 fitting finished in 261.289s\n",
      "Model 2 fold 2\n",
      "best round 64\n",
      "('Score: ', 0.3815040333603939)\n",
      "Model 2 fold 2 fitting finished in 261.791s\n",
      "Model 2 fold 3\n",
      "best round 64\n",
      "('Score: ', 0.39101484916033741)\n",
      "Model 2 fold 3 fitting finished in 263.090s\n",
      "Model 2 fold 4\n",
      "best round 64\n",
      "('Score: ', 0.37809046115602385)\n",
      "Model 2 fold 4 fitting finished in 267.068s\n",
      "Model 2 fold 5\n",
      "best round 64\n",
      "('Score: ', 0.39622850079972133)\n",
      "Model 2 fold 5 fitting finished in 262.991s\n",
      "Model 2 fold 6\n",
      "best round 64\n",
      "('Score: ', 0.39397002534033576)\n",
      "Model 2 fold 6 fitting finished in 260.140s\n",
      "Model 2 fold 7\n",
      "best round 64\n",
      "('Score: ', 0.39692283039150633)\n",
      "Model 2 fold 7 fitting finished in 260.647s\n",
      "Model 2 fold 8\n",
      "best round 64\n",
      "('Score: ', 0.40381337020623098)\n",
      "Model 2 fold 8 fitting finished in 261.522s\n",
      "Model 2 fold 9\n",
      "best round 64\n",
      "('Score: ', 0.40237582159299862)\n",
      "Model 2 fold 9 fitting finished in 261.392s\n",
      "Model 2 fold 10\n",
      "best round 64\n",
      "('Score: ', 0.40382950509581789)\n",
      "Model 2 fold 10 fitting finished in 259.843s\n",
      "Score for model 2 is 0.393502\n",
      "Score for blended models is 0.393743\n"
     ]
    }
   ],
   "source": [
    "nn_parameters = [\n",
    "    { 'input_size' :200 ,\n",
    "     'input_dim' : train_X.shape[1],\n",
    "     'input_drop_out' : 0.4 ,\n",
    "     'hidden_size' : 80 ,\n",
    "     'hidden_drop_out' :0.4},\n",
    "    { 'input_size' :100 ,\n",
    "     'input_dim' : train_X.shape[1],\n",
    "     'input_drop_out' : 0.4 ,\n",
    "     'hidden_size' : 30 ,\n",
    "     'hidden_drop_out' :0.4}\n",
    "\n",
    "]\n",
    "\n",
    "(train_blend_x_low, test_blend_x_low, blend_scores,best_round) = nn_blend_data(nn_parameters, train_df_nn, y_low, test_df_nn,\n",
    "                                                         10,\n",
    "                                                         5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46456146,  0.53543854,  0.55918074,  0.44081929],\n",
       "       [ 0.65307534,  0.34692469,  0.64788789,  0.35211208],\n",
       "       [ 0.298702  ,  0.701298  ,  0.31918669,  0.68081331],\n",
       "       ..., \n",
       "       [ 0.75917244,  0.24082758,  0.59385377,  0.40614626],\n",
       "       [ 0.38399851,  0.61600149,  0.33006418,  0.66993582],\n",
       "       [ 0.82922602,  0.170774  ,  0.86132485,  0.13867518]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_blend_x_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.39398288  0.39350244]\n",
      "[ 64.  64.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_Keras_0331_ovr_low_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend = '../output/test_blend_Keras_0331_ovr_low_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores,axis=0))\n",
    "print (np.mean(best_round,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_low, delimiter=\",\")\n",
    "np.savetxt(name_test_blend,test_blend_x_low, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y_medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11229\n"
     ]
    }
   ],
   "source": [
    "y_medium =[]\n",
    "for i in range(train_X.shape[0]):\n",
    "    y_medium.append(1 if train_y[i] == 1 else 0)\n",
    "    \n",
    "y_medium = np.array(y_medium)  \n",
    "print np.sum(y_medium)\n",
    "y_medium = to_categorical(y_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df_nn, y_medium, train_size=.80, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.5763 - val_loss: 0.4497\n",
      "Epoch 2/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4599 - val_loss: 0.4426\n",
      "Epoch 3/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4482 - val_loss: 0.4414\n",
      "Epoch 4/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4411 - val_loss: 0.4345\n",
      "Epoch 5/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.4372 - val_loss: 0.4346\n",
      "Epoch 6/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4345 - val_loss: 0.4346\n",
      "Epoch 7/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4361 - val_loss: 0.4333\n",
      "Epoch 8/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4334 - val_loss: 0.4327\n",
      "Epoch 9/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4318 - val_loss: 0.4308\n",
      "Epoch 10/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4308 - val_loss: 0.4341\n",
      "Epoch 11/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4297 - val_loss: 0.4321\n",
      "Epoch 12/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4291 - val_loss: 0.4319\n",
      "Epoch 13/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4284 - val_loss: 0.4333\n",
      "Epoch 14/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4246 - val_loss: 0.4296\n",
      "Epoch 15/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4274 - val_loss: 0.4321\n",
      "Epoch 16/1000\n",
      "49408/49352 [==============================] - 10s - loss: 0.4246 - val_loss: 0.4298\n",
      "Epoch 17/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4228 - val_loss: 0.4289\n",
      "Epoch 18/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4250 - val_loss: 0.4314\n",
      "Epoch 19/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4209 - val_loss: 0.4304\n",
      "Epoch 20/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4199 - val_loss: 0.4301\n",
      "Epoch 21/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4216 - val_loss: 0.4286\n",
      "Epoch 22/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4160 - val_loss: 0.4336\n",
      "Epoch 23/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4174 - val_loss: 0.4297\n",
      "Epoch 24/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4153 - val_loss: 0.4304\n",
      "Epoch 25/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4145 - val_loss: 0.4315\n",
      "Epoch 26/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4144 - val_loss: 0.4287\n",
      "Epoch 27/1000\n",
      "49408/49352 [==============================] - 11s - loss: 0.4135 - val_loss: 0.4292\n",
      "0.428629088134\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', # custom metric\n",
    "                           patience=5, #early stopping for epoch\n",
    "                           verbose=0)\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", \n",
    "                               monitor='val_loss', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    init = 'glorot_uniform'\n",
    "    \n",
    "    \n",
    "    model.add(Dense(200, # number of input units: needs to be tuned\n",
    "                    input_dim = input_dim, # fixed length: number of columns of X\n",
    "                    init=init,\n",
    "                   ))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU()) # activation function\n",
    "    model.add(BatchNormalization()) # normalization\n",
    "    model.add(Dropout(0.4)) #dropout rate. needs to be tuned\n",
    "        \n",
    "    model.add(Dense(80,init=init)) # number of hidden1 units. needs to be tuned.\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.4)) #dropout rate. needs to be tuned\n",
    "    \n",
    "#     model.add(Dense(9,init=init)) # number of hidden2 units. needs to be tuned.\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.add(PReLU())\n",
    "#     model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.4)) #dropout rate. needs to be tuned\n",
    "    \n",
    "    model.add(Dense(2,\n",
    "                   init = init,\n",
    "                   activation = 'softmax')) # 1 for regression \n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "#                   metrics=[mae_log],\n",
    "                  optimizer = 'adam' # optimizer. you may want to try different ones\n",
    "                 )\n",
    "    return(model)\n",
    "\n",
    "\n",
    "\n",
    "model = create_model(X_train.shape[1])\n",
    "fit= model.fit_generator(generator=batch_generator(X_train, y_train, 128, True),\n",
    "                         nb_epoch=1000,\n",
    "                         samples_per_epoch=ntrain,\n",
    "                         validation_data=(X_val.todense(), y_val),\n",
    "                         callbacks=[early_stop,checkpointer]\n",
    "                         )\n",
    "\n",
    "print min(fit.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 2 estimators for 10 folds\n",
      "Model 1: {'input_size': 200, 'input_drop_out': 0.4, 'hidden_drop_out': 0.4, 'hidden_size': 80, 'input_dim': 412}\n",
      "Model 1 fold 1\n",
      "best round 64\n",
      "('Score: ', 0.42495074071473649)\n",
      "Model 1 fold 1 fitting finished in 532.408s\n",
      "Model 1 fold 2\n",
      "best round 64\n",
      "('Score: ', 0.4100714709242152)\n",
      "Model 1 fold 2 fitting finished in 442.508s\n",
      "Model 1 fold 3\n",
      "best round 64\n",
      "('Score: ', 0.42379029264446894)\n",
      "Model 1 fold 3 fitting finished in 433.691s\n",
      "Model 1 fold 4\n",
      "best round 64\n",
      "('Score: ', 0.41671803610460934)\n",
      "Model 1 fold 4 fitting finished in 434.629s\n",
      "Model 1 fold 5\n",
      "best round 64\n",
      "('Score: ', 0.42797873356288629)\n",
      "Model 1 fold 5 fitting finished in 435.883s\n",
      "Model 1 fold 6\n",
      "best round 64\n",
      "('Score: ', 0.42772061567152725)\n",
      "Model 1 fold 6 fitting finished in 434.727s\n",
      "Model 1 fold 7\n",
      "best round 64\n",
      "('Score: ', 0.4321141383811945)\n",
      "Model 1 fold 7 fitting finished in 434.209s\n",
      "Model 1 fold 8\n",
      "best round 64\n",
      "('Score: ', 0.43773896025676917)\n",
      "Model 1 fold 8 fitting finished in 436.058s\n",
      "Model 1 fold 9\n",
      "best round 64\n",
      "('Score: ', 0.4318616723127261)\n",
      "Model 1 fold 9 fitting finished in 433.830s\n",
      "Model 1 fold 10\n",
      "best round 64\n",
      "('Score: ', 0.43069480525656956)\n",
      "Model 1 fold 10 fitting finished in 434.469s\n",
      "Score for model 1 is 0.426364\n",
      "Model 2: {'input_size': 100, 'input_drop_out': 0.4, 'hidden_drop_out': 0.4, 'hidden_size': 30, 'input_dim': 412}\n",
      "Model 2 fold 1\n",
      "best round 64\n",
      "('Score: ', 0.42365624863569279)\n",
      "Model 2 fold 1 fitting finished in 260.518s\n",
      "Model 2 fold 2\n",
      "best round 64\n",
      "('Score: ', 0.40722859164774466)\n",
      "Model 2 fold 2 fitting finished in 259.085s\n",
      "Model 2 fold 3\n",
      "best round 64\n",
      "('Score: ', 0.42373769549757201)\n",
      "Model 2 fold 3 fitting finished in 259.877s\n",
      "Model 2 fold 4\n",
      "best round 64\n",
      "('Score: ', 0.41601396109900562)\n",
      "Model 2 fold 4 fitting finished in 260.207s\n",
      "Model 2 fold 5\n",
      "best round 64\n",
      "('Score: ', 0.4287063040475011)\n",
      "Model 2 fold 5 fitting finished in 259.767s\n",
      "Model 2 fold 6\n",
      "best round 64\n",
      "('Score: ', 0.42678473312289783)\n",
      "Model 2 fold 6 fitting finished in 261.503s\n",
      "Model 2 fold 7\n",
      "best round 64\n",
      "('Score: ', 0.43021832309333513)\n",
      "Model 2 fold 7 fitting finished in 260.933s\n",
      "Model 2 fold 8\n",
      "best round 64\n",
      "('Score: ', 0.43585038475616256)\n",
      "Model 2 fold 8 fitting finished in 260.655s\n",
      "Model 2 fold 9\n",
      "best round 64\n",
      "('Score: ', 0.43257464391899814)\n",
      "Model 2 fold 9 fitting finished in 258.946s\n",
      "Model 2 fold 10\n",
      "best round 64\n",
      "('Score: ', 0.43057542495504297)\n",
      "Model 2 fold 10 fitting finished in 260.638s\n",
      "Score for model 2 is 0.425535\n",
      "Score for blended models is 0.425949\n"
     ]
    }
   ],
   "source": [
    "nn_parameters = [\n",
    "    { 'input_size' :200 ,\n",
    "     'input_dim' : train_X.shape[1],\n",
    "     'input_drop_out' : 0.4 ,\n",
    "     'hidden_size' : 80 ,\n",
    "     'hidden_drop_out' :0.4},\n",
    "    { 'input_size' :100 ,\n",
    "     'input_dim' : train_X.shape[1],\n",
    "     'input_drop_out' : 0.4 ,\n",
    "     'hidden_size' : 30 ,\n",
    "     'hidden_drop_out' :0.4}\n",
    "\n",
    "]\n",
    "\n",
    "(train_blend_x_medium , test_blend_x_medium , blend_scores,best_round) = nn_blend_data(nn_parameters,train_df_nn, \n",
    "                                                                                       y_medium , \n",
    "                                                                                       test_df_nn,\n",
    "                                                         10,\n",
    "                                                         5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42636395  0.42553463]\n",
      "[ 64.  64.]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_Keras_0331_ovr_medium_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend = '../output/test_blend_Keras_0331_ovr_medium_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores,axis=0))\n",
    "print (np.mean(best_round,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_medium, delimiter=\",\")\n",
    "np.savetxt(name_test_blend,test_blend_x_medium, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3839\n"
     ]
    }
   ],
   "source": [
    "y_high =[]\n",
    "for i in range(train_X.shape[0]):\n",
    "    y_high.append(1 if train_y[i] == 2 else 0)\n",
    "    \n",
    "y_high = np.array(y_high)  \n",
    "print np.sum(y_high)\n",
    "y_high = to_categorical(y_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df_nn, y_high, train_size=.80, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 2 estimators for 10 folds\n",
      "Model 1: {'input_size': 200, 'input_drop_out': 0.4, 'hidden_drop_out': 0.4, 'hidden_size': 80, 'input_dim': 412}\n",
      "Model 1 fold 1\n",
      "best round 64\n",
      "('Score: ', 0.17049442023116387)\n",
      "Model 1 fold 1 fitting finished in 434.581s\n",
      "Model 1 fold 2\n",
      "best round 64\n",
      "('Score: ', 0.17302170162217112)\n",
      "Model 1 fold 2 fitting finished in 433.833s\n",
      "Model 1 fold 3\n",
      "best round 64\n",
      "('Score: ', 0.1820879041929036)\n",
      "Model 1 fold 3 fitting finished in 433.848s\n",
      "Model 1 fold 4\n",
      "best round 64\n",
      "('Score: ', 0.16819531986422559)\n",
      "Model 1 fold 4 fitting finished in 435.834s\n",
      "Model 1 fold 5\n",
      "best round 64\n",
      "('Score: ', 0.19059734687505989)\n",
      "Model 1 fold 5 fitting finished in 432.931s\n",
      "Model 1 fold 6\n",
      "best round 64\n",
      "('Score: ', 0.17243870005728451)\n",
      "Model 1 fold 6 fitting finished in 435.523s\n",
      "Model 1 fold 7\n",
      "best round 64\n",
      "('Score: ', 0.17667642113197501)\n",
      "Model 1 fold 7 fitting finished in 433.020s\n",
      "Model 1 fold 8\n",
      "best round 64\n",
      "('Score: ', 0.19013913734430607)\n",
      "Model 1 fold 8 fitting finished in 434.752s\n",
      "Model 1 fold 9\n",
      "best round 64\n",
      "('Score: ', 0.17714745536253623)\n",
      "Model 1 fold 9 fitting finished in 434.625s\n",
      "Model 1 fold 10\n",
      "best round 64\n",
      "('Score: ', 0.16990083612741513)\n",
      "Model 1 fold 10 fitting finished in 434.107s\n",
      "Score for model 1 is 0.177070\n",
      "Model 2: {'input_size': 100, 'input_drop_out': 0.4, 'hidden_drop_out': 0.4, 'hidden_size': 30, 'input_dim': 412}\n",
      "Model 2 fold 1\n",
      "best round 64\n",
      "('Score: ', 0.16981952436051242)\n",
      "Model 2 fold 1 fitting finished in 260.587s\n",
      "Model 2 fold 2\n",
      "best round 64\n",
      "('Score: ', 0.17329482425814174)\n",
      "Model 2 fold 2 fitting finished in 259.263s\n",
      "Model 2 fold 3\n",
      "best round 64\n",
      "('Score: ', 0.18222155784850155)\n",
      "Model 2 fold 3 fitting finished in 260.403s\n",
      "Model 2 fold 4\n",
      "best round 64\n",
      "('Score: ', 0.16698288502600792)\n",
      "Model 2 fold 4 fitting finished in 260.525s\n",
      "Model 2 fold 5\n",
      "best round 64\n",
      "('Score: ', 0.18863760198859189)\n",
      "Model 2 fold 5 fitting finished in 260.580s\n",
      "Model 2 fold 6\n",
      "best round 64\n",
      "('Score: ', 0.17087049607432017)\n",
      "Model 2 fold 6 fitting finished in 260.380s\n",
      "Model 2 fold 7\n",
      "best round 64\n",
      "('Score: ', 0.17586713978049878)\n",
      "Model 2 fold 7 fitting finished in 261.454s\n",
      "Model 2 fold 8\n",
      "best round 64\n",
      "('Score: ', 0.18857509191953131)\n",
      "Model 2 fold 8 fitting finished in 259.437s\n",
      "Model 2 fold 9\n",
      "best round 64\n",
      "('Score: ', 0.17823797081673934)\n",
      "Model 2 fold 9 fitting finished in 260.119s\n",
      "Model 2 fold 10\n",
      "best round 64\n",
      "('Score: ', 0.17159582682927957)\n",
      "Model 2 fold 10 fitting finished in 260.444s\n",
      "Score for model 2 is 0.176610\n",
      "Score for blended models is 0.176840\n"
     ]
    }
   ],
   "source": [
    "nn_parameters = [\n",
    "    { 'input_size' :200 ,\n",
    "     'input_dim' : train_X.shape[1],\n",
    "     'input_drop_out' : 0.4 ,\n",
    "     'hidden_size' : 80 ,\n",
    "     'hidden_drop_out' :0.4},\n",
    "    { 'input_size' :100 ,\n",
    "     'input_dim' : train_X.shape[1],\n",
    "     'input_drop_out' : 0.4 ,\n",
    "     'hidden_size' : 30 ,\n",
    "     'hidden_drop_out' :0.4}\n",
    "\n",
    "]\n",
    "\n",
    "(train_blend_x_hihg, test_blend_x_hihg, blend_scores,best_round) = nn_blend_data(nn_parameters,train_df_nn, \n",
    "                                                                                       y_high , \n",
    "                                                                                       test_df_nn,\n",
    "                                                         10,\n",
    "                                                         5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17706992  0.17661029]\n",
      "[ 64.  64.]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_Keras_0331_ovr_high_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend = '../output/test_blend_Keras_0331_ovr_high_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores,axis=0))\n",
    "print (np.mean(best_round,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_hihg, delimiter=\",\")\n",
    "np.savetxt(name_test_blend,test_blend_x_hihg, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46456146,  0.53543854,  0.55918074,  0.44081929],\n",
       "       [ 0.65307534,  0.34692469,  0.64788789,  0.35211208],\n",
       "       [ 0.298702  ,  0.701298  ,  0.31918669,  0.68081331],\n",
       "       [ 0.0652181 ,  0.93478191,  0.11783206,  0.88216794],\n",
       "       [ 0.01999347,  0.98000652,  0.02754674,  0.97245324],\n",
       "       [ 0.286787  ,  0.71321297,  0.37462229,  0.62537771],\n",
       "       [ 0.30486089,  0.69513911,  0.39302596,  0.60697407],\n",
       "       [ 0.77407664,  0.22592336,  0.76265699,  0.23734303],\n",
       "       [ 0.04599821,  0.95400178,  0.04560963,  0.95439035],\n",
       "       [ 0.04567733,  0.95432264,  0.08780251,  0.91219747]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_blend_x_low[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44033614,  0.55966389,  0.48364738,  0.51635259],\n",
       "       [ 0.56981212,  0.43018788,  0.5069834 ,  0.4930166 ],\n",
       "       [ 0.71032268,  0.28967732,  0.71398932,  0.28601068],\n",
       "       [ 0.79661608,  0.20338391,  0.82728297,  0.17271705],\n",
       "       [ 0.97628778,  0.02371221,  0.97221869,  0.02778132],\n",
       "       [ 0.72416741,  0.27583256,  0.77770293,  0.22229706],\n",
       "       [ 0.68811274,  0.31188726,  0.72412932,  0.27587068],\n",
       "       [ 0.56539565,  0.43460438,  0.57953453,  0.42046544],\n",
       "       [ 0.95258194,  0.04741804,  0.97551912,  0.02448091],\n",
       "       [ 0.93746662,  0.06253336,  0.91640061,  0.0835994 ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_blend_x_medium[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.48133171e-01,   5.18668257e-02,   9.56971407e-01,\n",
       "          4.30286191e-02],\n",
       "       [  9.07860279e-01,   9.21396986e-02,   9.03508782e-01,\n",
       "          9.64911953e-02],\n",
       "       [  9.92276788e-01,   7.72319501e-03,   9.86826658e-01,\n",
       "          1.31733138e-02],\n",
       "       [  9.99772906e-01,   2.27101613e-04,   9.99815583e-01,\n",
       "          1.84422839e-04],\n",
       "       [  9.99597371e-01,   4.02599951e-04,   9.98769820e-01,\n",
       "          1.23019773e-03],\n",
       "       [  9.92041230e-01,   7.95879401e-03,   9.85059083e-01,\n",
       "          1.49408951e-02],\n",
       "       [  9.93075550e-01,   6.92442246e-03,   9.90770400e-01,\n",
       "          9.22962371e-03],\n",
       "       [  5.62102914e-01,   4.37897086e-01,   5.53607643e-01,\n",
       "          4.46392328e-01],\n",
       "       [  9.97734606e-01,   2.26539746e-03,   9.96763468e-01,\n",
       "          3.23651708e-03],\n",
       "       [  9.98655975e-01,   1.34401838e-03,   9.98934984e-01,\n",
       "          1.06500229e-03]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_blend_x_hihg[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_blend_x = np.hstack([train_blend_x_low[:,[1,3]],train_blend_x_medium[:,[1,3]],train_blend_x_hihg[:,[1,3]]])\n",
    "train_blend_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53543854,  0.44081929,  0.55966389,  0.51635259,  0.05186683,\n",
       "         0.04302862],\n",
       "       [ 0.34692469,  0.35211208,  0.43018788,  0.4930166 ,  0.0921397 ,\n",
       "         0.0964912 ],\n",
       "       [ 0.701298  ,  0.68081331,  0.28967732,  0.28601068,  0.0077232 ,\n",
       "         0.01317331],\n",
       "       ..., \n",
       "       [ 0.24082758,  0.40614626,  0.61263579,  0.53841865,  0.17041728,\n",
       "         0.15469342],\n",
       "       [ 0.61600149,  0.66993582,  0.37558073,  0.34411123,  0.02602372,\n",
       "         0.03474894],\n",
       "       [ 0.170774  ,  0.13867518,  0.5747925 ,  0.52559209,  0.37286255,\n",
       "         0.20092012]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_blend_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 6)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_mean = np.hstack([test_blend_x_low[:,[1,3]],test_blend_x_medium[:,[1,3]],test_blend_x_hihg[:,[1,3]]])\n",
    "test_blend_x_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.45016491e-01,   4.42961633e-01,   4.96813539e-01,\n",
       "          5.02928707e-01,   4.73185966e-02,   4.74120317e-02],\n",
       "       [  9.89467651e-01,   9.91195834e-01,   1.93006209e-02,\n",
       "          1.22408562e-02,   9.66879284e-03,   7.65174278e-03],\n",
       "       [  9.72961313e-01,   9.74756777e-01,   6.58714678e-02,\n",
       "          6.76788870e-02,   8.12055035e-03,   1.01542623e-02],\n",
       "       ..., \n",
       "       [  9.92661548e-01,   9.90405649e-01,   1.40206488e-02,\n",
       "          1.15989062e-02,   1.32738879e-03,   1.26324503e-03],\n",
       "       [  9.83876938e-01,   9.89677304e-01,   1.01579200e-02,\n",
       "          8.76117819e-03,   2.72480752e-04,   3.60779543e-04],\n",
       "       [  5.93080962e-01,   6.36519444e-01,   3.77584869e-01,\n",
       "          3.54368082e-01,   1.71170815e-02,   2.06032272e-02]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_train_blend = '../output/train_blend_Keras_ovr_BM_0331_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_Keras_ovr_BM_0331_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "# print (np.mean(blend_scores_xgb,axis=0))\n",
    "# print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_mean, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
