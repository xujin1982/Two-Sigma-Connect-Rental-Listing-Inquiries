{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "# from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from scipy.stats import skew, boxcox\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((49352, 229), (74659, 229))\n"
     ]
    }
   ],
   "source": [
    "train_X = pd.read_pickle('../input/' + 'train_X_2017-02-16-20-51.pkl')\n",
    "test_X = pd.read_pickle('../input/' + 'test_X_2017-02-16-20-51.pkl')\n",
    "test_listing = pd.read_pickle('../input/' + 'listing_id.pkl')\n",
    "\n",
    "train_y = pd.read_pickle('../input/' + 'y_2017-02-16-20-51.pkl') \n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb.LGBMClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8   0.533950251891\n",
      "15   0.534017695883\n",
      "31   0.533337457941\n",
      "63   0.535837989584\n",
      "127   0.538235118996\n",
      "255   0.546729607409\n"
     ]
    }
   ],
   "source": [
    "for x in [8,15,31,63,127,255]:\n",
    "    rgr = lgb.LGBMClassifier(objective = 'multiclass',\n",
    "                             learning_rate=0.1,\n",
    "                             n_estimators=100000,\n",
    "                             num_leaves=x)\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "\n",
    "    print rgr.num_leaves, ' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_leaves = 31\n",
    "# 8 0.533950251891\n",
    "# 15 0.534017695883\n",
    "# 31 0.533337457941\n",
    "# 63 0.535837989584\n",
    "# 127 0.538235118996\n",
    "# 255 0.546729607409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160   0.532305066204\n",
      "170   0.533234947845\n",
      "180   0.53306705402\n",
      "190   0.533105412017\n",
      "200   0.531902339787\n",
      "210   0.534220217084\n"
     ]
    }
   ],
   "source": [
    "for x in [160,170,180,190,200,210]:\n",
    "    rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "                             n_estimators=100000,\n",
    "                             num_leaves=num_leaves,\n",
    "                             min_child_samples = x)\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "    print rgr.min_child_samples, ' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]\n",
    "#     print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_child_samples = 100\n",
    "# 10   0.533337457941\n",
    "# 20   0.533263247468\n",
    "# 30   0.535289720244\n",
    "# 40   0.533228908358\n",
    "# 50   0.534171528081\n",
    "# 60   0.533426694633\n",
    "# 70   0.532820041162\n",
    "# 80   0.532902415753\n",
    "# 90   0.531844072176\n",
    "# 100   0.53178303038\n",
    "# 110   0.533220584562\n",
    "# 120   0.533929718659\n",
    "# 130   0.532662257772\n",
    "# 140   0.532125059541\n",
    "# 150   0.532639213339\n",
    "# 160   0.532305066204\n",
    "# 170   0.533234947845\n",
    "# 180   0.53306705402\n",
    "# 190   0.533105412017\n",
    "# 200   0.531902339787\n",
    "# 210   0.534220217084\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3   0.534473187429\n",
      "0.4   0.532180375183\n",
      "0.5   0.531460371729\n",
      "0.6   0.52982761516\n",
      "0.7   0.530897962036\n",
      "0.8   0.531948878135\n",
      "0.9   0.532586875189\n"
     ]
    }
   ],
   "source": [
    "for x in [0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "                             n_estimators=100000,\n",
    "                             num_leaves=num_leaves,\n",
    "                             min_child_samples = min_child_samples,\n",
    "                             colsample_bytree = x)\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "    # print 'best_round: ', rgr.best_iteration\n",
    "    print rgr.colsample_bytree, ' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colsample_bytree = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5   0.537526883916\n",
      "0.6   0.535739141308\n",
      "0.7   0.533475341743\n",
      "0.8   0.532631951484\n",
      "0.9   0.531377832399\n"
     ]
    }
   ],
   "source": [
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "                             n_estimators=100000,\n",
    "                             num_leaves=num_leaves,\n",
    "                             min_child_samples = min_child_samples,\n",
    "                             colsample_bytree = colsample_bytree,\n",
    "                             subsample = x,\n",
    "                             subsample_freq=1)\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "    # print 'best_round: ', rgr.best_iteration\n",
    "    print rgr.subsample, ' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subsample = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15   0.539288189734\n",
      "31   0.535639813978\n",
      "63   0.533283444874\n",
      "127   0.532144055737\n",
      "255   0.531377832399\n",
      "511   0.531200059402\n",
      "1023   0.532617672046\n",
      "2047   0.532119589388\n"
     ]
    }
   ],
   "source": [
    "for x in [15,31,63, 127, 255, 511, 1023, 2047]:\n",
    "    rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "                             n_estimators=100000,\n",
    "                             num_leaves=num_leaves,\n",
    "                             min_child_samples = min_child_samples,\n",
    "                             colsample_bytree = colsample_bytree,\n",
    "                             subsample = subsample,\n",
    "                             subsample_freq=1,\n",
    "                             max_bin = x )\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "\n",
    "    # print 'best_round: ', rgr.best_iteration\n",
    "    print rgr.max_bin,' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_bin = 511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "    1 | 02m50s | \u001b[35m  -0.53476\u001b[0m | \u001b[32m            0.9494\u001b[0m | \u001b[32m 206.0155\u001b[0m | \u001b[32m           111.6937\u001b[0m | \u001b[32m     53.0017\u001b[0m | \u001b[32m     0.9958\u001b[0m | \n",
      "    2 | 02m11s | \u001b[35m  -0.53134\u001b[0m | \u001b[32m            0.9097\u001b[0m | \u001b[32m 710.0274\u001b[0m | \u001b[32m            99.8716\u001b[0m | \u001b[32m     25.7253\u001b[0m | \u001b[32m     0.8223\u001b[0m | \n",
      "    3 | 01m12s |   -0.53298 |             0.5736 |  508.9968 |            144.0163 |      28.6098 |      0.9377 | \n",
      "    4 | 01m24s |   -0.53490 |             0.8441 |  683.6996 |             99.5012 |      60.9060 |      0.9267 | \n",
      "    5 | 01m06s |   -0.53391 |             0.5226 |  508.3731 |             85.1011 |      36.6520 |      0.8504 | \n",
      "    6 | 01m02s |   -0.53513 |             0.6736 |  319.5854 |            124.2871 |      61.2123 |      0.8560 | \n",
      "    7 | 01m09s |   -0.53263 |             0.6901 |  470.4126 |            136.2148 |      37.3028 |      0.8218 | \n",
      "    8 | 01m13s |   -0.53334 |             0.9346 |  352.0016 |            147.4805 |      39.1799 |      0.9080 | \n",
      "    9 | 01m34s |   -0.53230 |             0.7673 |  347.2218 |            151.3890 |      29.7680 |      0.8735 | \n",
      "   10 | 01m59s |   -0.53209 |             0.8957 |  386.8950 |            133.4809 |      30.6284 |      0.8357 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/bayes_opt/helpers.py:95: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = (mean - y_max - xi)/std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00035908]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 01m42s |   -0.53312 |             0.5305 |  797.2248 |             92.6381 |      25.8138 |      0.8091 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.49498158e-05]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 01m42s | \u001b[35m  -0.53122\u001b[0m | \u001b[32m            0.7626\u001b[0m | \u001b[32m 290.6732\u001b[0m | \u001b[32m           116.4943\u001b[0m | \u001b[32m     15.3131\u001b[0m | \u001b[32m     0.8439\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00023937]), 'nit': 6, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 01m44s |   -0.53166 |             0.7140 |  431.8401 |             98.0688 |      16.3717 |      0.8915 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.00377147e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.20073208e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 03m18s |   -0.53323 |             0.9458 |  704.1814 |            123.2425 |      17.8612 |      0.9948 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.65901365e-05]), 'nit': 3, 'funcalls': 46}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00016809]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 01m51s |   -0.53307 |             0.7208 |  773.9992 |             81.2863 |      21.2061 |      0.9746 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.66505998e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 01m56s |   -0.53220 |             0.8672 |  661.9549 |             90.8773 |      17.9356 |      0.9945 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.77417712e-05]), 'nit': 4, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 01m44s |   -0.53238 |             0.9901 |  209.5177 |            154.7229 |      22.2663 |      0.9860 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.45074409e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 01m44s |   -0.53176 |             0.9354 |  275.2759 |            133.4616 |      15.6176 |      0.9118 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00075529]), 'nit': 5, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 02m19s |   -0.53238 |             0.6194 |  423.0654 |            156.2254 |      19.2615 |      0.9731 | \n",
      "   20 | 01m43s |   -0.53149 |             0.8494 |  333.8046 |            124.6656 |      18.1923 |      0.9127 | \n",
      "   21 | 01m41s |   -0.53127 |             0.7548 |  327.3567 |            158.6803 |      18.6545 |      0.9304 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00114462]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.0008617]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 01m44s |   -0.53188 |             0.6976 |  367.2999 |             95.5699 |      16.6479 |      0.9259 | \n",
      "   23 | 01m44s |   -0.53178 |             0.6097 |  712.2395 |             91.5011 |      21.4893 |      0.9545 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00115603]), 'nit': 5, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 01m41s |   -0.53123 |             0.8706 |  202.2066 |             80.8088 |      16.6911 |      0.8613 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00040309]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -8.14082450e-05]), 'nit': 6, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 01m55s |   -0.53153 |             0.7534 |  308.8735 |            101.4059 |      15.0581 |      0.9337 | \n",
      "   26 | 01m58s |   -0.53224 |             0.8008 |  387.4367 |            126.0620 |      16.2544 |      0.9734 | \n",
      "   27 | 01m44s |   -0.53484 |             0.7328 |  789.5658 |            141.8161 |      52.6390 |      0.9155 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00021941]), 'nit': 3, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 01m31s |   -0.53446 |             0.6520 |  431.9204 |             96.2836 |      47.7710 |      0.8855 | \n",
      "   29 | 02m26s |   -0.53192 |             0.5354 |  242.3317 |            100.4000 |      15.9467 |      0.9749 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -4.30197000e-05]), 'nit': 7, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00013341]), 'nit': 4, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 01m36s |   -0.53204 |             0.6275 |  573.4928 |             87.5118 |      24.2194 |      0.8411 | \n",
      "   31 | 02m25s | \u001b[35m  -0.53102\u001b[0m | \u001b[32m            0.8426\u001b[0m | \u001b[32m 478.6974\u001b[0m | \u001b[32m           117.6221\u001b[0m | \u001b[32m     16.4580\u001b[0m | \u001b[32m     0.8206\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.26833237e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 02m03s |   -0.53494 |             0.7151 |  770.4839 |             99.8584 |      62.7594 |      0.8415 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00010201]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 01m34s |   -0.53188 |             0.5727 |  616.0457 |            110.8740 |      21.0601 |      0.9422 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.09879189e-05]), 'nit': 8, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 02m07s |   -0.53309 |             0.9948 |  547.5036 |             88.5593 |      17.0859 |      0.9977 | \n",
      "   35 | 01m25s |   -0.53168 |             0.5229 |  204.3560 |            135.1914 |      15.3167 |      0.8876 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00010035]), 'nit': 6, 'funcalls': 56}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00018057]), 'nit': 5, 'funcalls': 56}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 01m35s |   -0.53194 |             0.5922 |  611.8562 |             86.9664 |      22.1675 |      0.9013 | \n",
      "   37 | 01m40s |   -0.53183 |             0.8796 |  453.9247 |            127.4825 |      23.3588 |      0.8768 | \n",
      "   38 | 01m46s |   -0.53152 |             0.8095 |  578.5334 |            115.9199 |      22.4066 |      0.9495 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.0001312]), 'nit': 6, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 01m43s |   -0.53222 |             0.6637 |  588.7522 |            159.7344 |      17.8775 |      0.9793 | \n",
      "   40 | 01m34s |   -0.53259 |             0.5042 |  320.8941 |            150.5419 |      16.5171 |      0.8000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  2.37601344e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00062186]), 'nit': 6, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 01m36s |   -0.53352 |             0.8728 |  602.1469 |            148.9227 |      42.3492 |      0.8142 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.25386391e-05]), 'nit': 4, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 02m04s |   -0.53225 |             0.9996 |  339.5156 |            157.0639 |      15.0079 |      0.9203 | \n",
      "   43 | 01m34s |   -0.53223 |             0.6486 |  265.7415 |             87.4480 |      18.3331 |      0.8010 | \n",
      "   44 | 01m34s |   -0.53255 |             0.6474 |  286.1596 |            159.6759 |      27.0409 |      0.9674 | \n",
      "   45 | 01m55s |   -0.53185 |             0.7595 |  764.2768 |            116.4333 |      24.4025 |      0.9210 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00079656]), 'nit': 4, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 | 01m55s |   -0.53223 |             0.7986 |  790.9825 |            139.1079 |      17.6317 |      0.8300 | \n",
      "   47 | 01m38s |   -0.53181 |             0.5268 |  468.2110 |            100.4549 |      20.0324 |      0.8654 | \n",
      "   48 | 01m55s |   -0.53173 |             0.7773 |  460.9678 |            157.3346 |      15.2557 |      0.9048 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.0005743]), 'nit': 6, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 01m42s |   -0.53184 |             0.5113 |  260.9516 |            113.5624 |      15.8408 |      0.8203 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00112517]), 'nit': 3, 'funcalls': 46}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 01m40s |   -0.53239 |             0.7990 |  340.5197 |            105.1115 |      28.4028 |      0.9560 | \n"
     ]
    }
   ],
   "source": [
    "def lgbm_cv(max_bin, num_leaves, min_child_samples, colsample_bytree, subsample, learning_rate=0.1):\n",
    "    skf = list(KFold(len(train_y), 5))\n",
    "    scores=[]\n",
    "    for i, (train, val) in enumerate(skf):\n",
    "        est=lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                               max_bin=int(max_bin),\n",
    "                               num_leaves=int(num_leaves),\n",
    "                               min_child_samples=int(min_child_samples),\n",
    "                               colsample_bytree=colsample_bytree,\n",
    "                               subsample=subsample,\n",
    "                               subsample_freq = 1\n",
    "                              )\n",
    " \n",
    "        train_x_fold = train_X[train]\n",
    "        train_y_fold = train_y[train]\n",
    "        val_x_fold = train_X[val]\n",
    "        val_y_fold = train_y[val]\n",
    "        est.set_params( n_estimators=100000)\n",
    "        est.fit(train_x_fold,\n",
    "                train_y_fold,\n",
    "                eval_set=[(val_x_fold, val_y_fold)],\n",
    "                eval_metric='multi_logloss',\n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False\n",
    "               )\n",
    "        val_y_predict_fold = est.predict_proba(val_x_fold)\n",
    "        score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "        scores.append(score)\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "lgbm_BO = BayesianOptimization(lgbm_cv, \n",
    "                               {\n",
    "                                'max_bin': (200,800),\n",
    "                                'num_leaves': (15,63),\n",
    "                                'min_child_samples' :(80,160),\n",
    "                                'colsample_bytree': (0.5,1),\n",
    "                                'subsample' : (0.8,1)})\n",
    "\n",
    "lgbm_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lgbm_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    print (\"Blend %d estimators for %d folds\" % (len(estimators), fold))\n",
    "    skf = list(KFold(len(train_y), fold))\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*len(estimators)))\n",
    "    test_blend_x = np.zeros((test_x.shape[0], N_class*len(estimators)))\n",
    "    scores = np.zeros ((len(skf),len(estimators)))\n",
    "    best_rounds = np.zeros ((len(skf),len(estimators)))\n",
    "    \n",
    "\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*len(skf)))\n",
    "        for i, (train, val) in enumerate(skf):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x[train]\n",
    "            train_y_fold = train_y[train]\n",
    "            val_x_fold = train_x[val]\n",
    "            val_y_fold = train_y[val]\n",
    "            if early_stopping_rounds==0: # without early stopping\n",
    "                est.fit(train_x_fold, train_y_fold)\n",
    "                best_rounds[i,j]=est.n_estimators\n",
    "                val_y_predict_fold = est.predict_proba(val_x_fold)\n",
    "                score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "                print (\"Score: \", score)\n",
    "                scores[i,j]=score\n",
    "                train_blend_x[val, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "                test_blend_x_j[:,i] = est.predict_proba(test_x)\n",
    "                print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            else:                        # early stopping\n",
    "                est.set_params( n_estimators=100000)\n",
    "                est.fit(train_x_fold,\n",
    "                        train_y_fold,\n",
    "                        eval_set=[(val_x_fold, val_y_fold)],\n",
    "                        eval_metric='multi_logloss',\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose=False\n",
    "                       )\n",
    "                best_round=est.best_iteration\n",
    "                best_rounds[i,j]=best_round\n",
    "                print (\"best round %d\" % (best_round))\n",
    "                val_y_predict_fold = est.predict_proba(val_x_fold,num_iteration=best_round)\n",
    "                score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "                print (\"Score: \", score)\n",
    "                scores[i,j]=score\n",
    "                train_blend_x[val, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "                test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,num_iteration=best_round)\n",
    "                print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "       \n",
    "        test_blend_x_j = pd.DataFrame(test_blend_x_j)\n",
    "        for N in range(N_class):\n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x, scores,best_rounds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>max_bin</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.458039</td>\n",
       "      <td>117.622103</td>\n",
       "      <td>478.697403</td>\n",
       "      <td>0.842639</td>\n",
       "      <td>0.820588</td>\n",
       "      <td>-0.531018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.313144</td>\n",
       "      <td>116.494344</td>\n",
       "      <td>290.673175</td>\n",
       "      <td>0.762613</td>\n",
       "      <td>0.843922</td>\n",
       "      <td>-0.531225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.691140</td>\n",
       "      <td>80.808810</td>\n",
       "      <td>202.206598</td>\n",
       "      <td>0.870567</td>\n",
       "      <td>0.861266</td>\n",
       "      <td>-0.531231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.654455</td>\n",
       "      <td>158.680310</td>\n",
       "      <td>327.356657</td>\n",
       "      <td>0.754814</td>\n",
       "      <td>0.930391</td>\n",
       "      <td>-0.531267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.192282</td>\n",
       "      <td>124.665623</td>\n",
       "      <td>333.804592</td>\n",
       "      <td>0.849373</td>\n",
       "      <td>0.912663</td>\n",
       "      <td>-0.531491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  min_child_samples     max_bin  colsample_bytree  subsample  \\\n",
       "20   16.458039         117.622103  478.697403          0.842639   0.820588   \n",
       "1    15.313144         116.494344  290.673175          0.762613   0.843922   \n",
       "13   16.691140          80.808810  202.206598          0.870567   0.861266   \n",
       "10   18.654455         158.680310  327.356657          0.754814   0.930391   \n",
       "9    18.192282         124.665623  333.804592          0.849373   0.912663   \n",
       "\n",
       "       score  \n",
       "20 -0.531018  \n",
       "1  -0.531225  \n",
       "13 -0.531231  \n",
       "10 -0.531267  \n",
       "9  -0.531491  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_bo_scores = pd.DataFrame([[s[0]['num_leaves'],\n",
    "                               s[0]['min_child_samples'],\n",
    "                               s[0]['max_bin'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[1]] for s in zip(lgbm_BO.res['all']['params'],lgbm_BO.res['all']['values'])],\n",
    "                            columns = ['num_leaves',\n",
    "                                       'min_child_samples',\n",
    "                                       'max_bin',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'score'])\n",
    "gbm_bo_scores=gbm_bo_scores.sort_values('score',ascending=False)\n",
    "gbm_bo_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 5 estimators for 5 folds\n",
      "Model 1: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.842639, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=478, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=117, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=16,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.820588, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 1 fold 1\n",
      "best round 5753\n",
      "('Score: ', 0.53784225704008859)\n",
      "Model 1 fold 1 fitting finished in 274.031s\n",
      "Model 1 fold 2\n",
      "best round 5187\n",
      "('Score: ', 0.52171515148042436)\n",
      "Model 1 fold 2 fitting finished in 241.103s\n",
      "Model 1 fold 3\n",
      "best round 4922\n",
      "('Score: ', 0.52046110692644332)\n",
      "Model 1 fold 3 fitting finished in 237.563s\n",
      "Model 1 fold 4\n",
      "best round 4465\n",
      "('Score: ', 0.5278600588979343)\n",
      "Model 1 fold 4 fitting finished in 211.716s\n",
      "Model 1 fold 5\n",
      "best round 5081\n",
      "('Score: ', 0.53806928668114651)\n",
      "Model 1 fold 5 fitting finished in 249.759s\n",
      "Score for model 1 is 0.529190\n",
      "Model 2: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.762613, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=290, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=116, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=15,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.843922, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 2 fold 1\n",
      "best round 5758\n",
      "('Score: ', 0.53719534060112029)\n",
      "Model 2 fold 1 fitting finished in 238.662s\n",
      "Model 2 fold 2\n",
      "best round 5699\n",
      "('Score: ', 0.52196213143152481)\n",
      "Model 2 fold 2 fitting finished in 253.955s\n",
      "Model 2 fold 3\n",
      "best round 5794\n",
      "('Score: ', 0.51989645091023096)\n",
      "Model 2 fold 3 fitting finished in 240.563s\n",
      "Model 2 fold 4\n",
      "best round 4888\n",
      "('Score: ', 0.5278438613107016)\n",
      "Model 2 fold 4 fitting finished in 206.141s\n",
      "Model 2 fold 5\n",
      "best round 5280\n",
      "('Score: ', 0.53869844995493443)\n",
      "Model 2 fold 5 fitting finished in 223.068s\n",
      "Score for model 2 is 0.529119\n",
      "Model 3: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.870567, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=202, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=80, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=16,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.861266, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 3 fold 1\n",
      "best round 5232\n",
      "('Score: ', 0.53735341613449628)\n",
      "Model 3 fold 1 fitting finished in 231.596s\n",
      "Model 3 fold 2\n",
      "best round 5705\n",
      "('Score: ', 0.5218664368726057)\n",
      "Model 3 fold 2 fitting finished in 245.874s\n",
      "Model 3 fold 3\n",
      "best round 5423\n",
      "('Score: ', 0.52045246150142288)\n",
      "Model 3 fold 3 fitting finished in 251.721s\n",
      "Model 3 fold 4\n",
      "best round 4340\n",
      "('Score: ', 0.52725544016994375)\n",
      "Model 3 fold 4 fitting finished in 200.229s\n",
      "Model 3 fold 5\n",
      "best round 5567\n",
      "('Score: ', 0.53719341483844196)\n",
      "Model 3 fold 5 fitting finished in 244.960s\n",
      "Score for model 3 is 0.528824\n",
      "Model 4: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.754814, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=327, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=158, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=18,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.930391, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 4 fold 1\n",
      "best round 5068\n",
      "('Score: ', 0.53872590492840111)\n",
      "Model 4 fold 1 fitting finished in 239.652s\n",
      "Model 4 fold 2\n",
      "best round 4876\n",
      "('Score: ', 0.52224376244234227)\n",
      "Model 4 fold 2 fitting finished in 226.817s\n",
      "Model 4 fold 3\n",
      "best round 4775\n",
      "('Score: ', 0.52067625020010477)\n",
      "Model 4 fold 3 fitting finished in 227.534s\n",
      "Model 4 fold 4\n",
      "best round 3890\n",
      "('Score: ', 0.5284071955663463)\n",
      "Model 4 fold 4 fitting finished in 188.189s\n",
      "Model 4 fold 5\n",
      "best round 4930\n",
      "('Score: ', 0.53789009631815743)\n",
      "Model 4 fold 5 fitting finished in 233.943s\n",
      "Score for model 4 is 0.529589\n",
      "Model 5: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.849373, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=333, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=124, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=18,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.912663, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 5 fold 1\n",
      "best round 5013\n",
      "('Score: ', 0.53821884038705992)\n",
      "Model 5 fold 1 fitting finished in 245.876s\n",
      "Model 5 fold 2\n",
      "best round 4548\n",
      "('Score: ', 0.522198238818675)\n",
      "Model 5 fold 2 fitting finished in 224.806s\n",
      "Model 5 fold 3\n",
      "best round 4933\n",
      "('Score: ', 0.52079652950815436)\n",
      "Model 5 fold 3 fitting finished in 245.741s\n",
      "Model 5 fold 4\n",
      "best round 4041\n",
      "('Score: ', 0.52827128604341478)\n",
      "Model 5 fold 4 fitting finished in 219.562s\n",
      "Model 5 fold 5\n",
      "best round 4669\n",
      "('Score: ', 0.53796523902911508)\n",
      "Model 5 fold 5 fitting finished in 242.485s\n",
      "Score for model 5 is 0.529490\n",
      "Score for blended models is 0.529242\n"
     ]
    }
   ],
   "source": [
    "estimators = [lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=478,\n",
    "                     num_leaves=16,\n",
    "                     min_child_samples=117,\n",
    "                     colsample_bytree=0.842639,\n",
    "                     subsample=0.820588,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531018\n",
    "              lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=290,\n",
    "                     num_leaves=15,\n",
    "                     min_child_samples=116,\n",
    "                     colsample_bytree=0.762613,\n",
    "                     subsample=0.843922,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531225\n",
    "              lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=202,\n",
    "                     num_leaves=16,\n",
    "                     min_child_samples=80,\n",
    "                     colsample_bytree=0.870567,\n",
    "                     subsample=0.861266,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531231\n",
    "              lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=327,\n",
    "                     num_leaves=18,\n",
    "                     min_child_samples=158,\n",
    "                     colsample_bytree=0.754814,\n",
    "                     subsample=0.930391,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531267\n",
    "              lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=333,\n",
    "                     num_leaves=18,\n",
    "                     min_child_samples=124,\n",
    "                     colsample_bytree=0.849373,\n",
    "                     subsample=0.912663,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531491              \n",
    "        ]\n",
    "\n",
    "(train_blend_x_gbm,\n",
    " test_blend_x_gbm,\n",
    " blend_scores_gbm,\n",
    " best_rounds_gbm) = lgbm_blend(estimators, train_X, train_y, test_X,\n",
    "                                 5,\n",
    "                                 500) #as the learning rate decreases the number of stopping rounds need to be increased\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52918957  0.52911925  0.52882423  0.52958864  0.52949003]\n",
      "[ 5081.6  5483.8  5253.4  4707.8  4640.8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend = '../output/test_blend_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_gbm,axis=0))\n",
    "print (np.mean(best_rounds_gbm,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_gbm, delimiter=\",\")\n",
    "np.savetxt(name_test_blend,test_blend_x_gbm, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "df = pd.read_json(open(\"../input/test.json\", \"r\"))\n",
    "labels2idx ={'high': 0, 'low': 2, 'medium': 1}\n",
    "sub_name = '../output/sub_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = df[\"listing_id\"]\n",
    "\n",
    "y_test = np.zeros((df.shape[0], 3))\n",
    "\n",
    "for N in range(3):\n",
    "    y_test[:,N] = pd.DataFrame(test_blend_x_gbm).iloc[:,[x for x in range(test_blend_x_gbm.shape[1]) if x%3 == N]].mean(axis=1)\n",
    "    \n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_test[:, labels2idx[label]]\n",
    "sub.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
