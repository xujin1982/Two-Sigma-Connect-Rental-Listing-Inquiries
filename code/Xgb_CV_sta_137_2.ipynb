{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.stats.mstats import gmean\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import skew, boxcox,boxcox_normmax\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 137) (74659, 137) (49352,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_CV_statistics1.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_CV_statistics1.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'train_y_CV_statistics.csv',header=None))\n",
    "sub_id = test_X.listing_id.astype('int32').values\n",
    "\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 137)\n",
      "(9871, 137)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "# xgtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rgr = xgb.XGBClassifier(objective = 'multi:softprob',\n",
    "#                        learning_rate = 0.1,\n",
    "#                        n_estimators = 10000,\n",
    "#                        nthread = -1,\n",
    "#                        max_depth=10)\n",
    "\n",
    "# rgr.fit(X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "# #         num_class = 3,\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=25\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pred_y = rgr.predict_proba(test_X, ntree_limit = rgr.best_iteration)\n",
    "# pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tune XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t0.531135 621\n",
      "4 \t0.528788 436\n",
      "5 \t0.528401 334\n",
      "6 \t0.529342 216\n",
      "7 \t0.532007 141\n",
      "8 \t0.532342 134\n",
      "9 \t0.536764 97\n",
      "10 \t0.538813 76\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "best_score = 1000\n",
    "train_param = 0\n",
    "for x in [3,4,5,6,7,8,9,10]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= x,\n",
    "        nthread = -1,\n",
    "        silent = False\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "max_depth = train_param\n",
    "print max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t0.527937 309\n",
      "4 \t0.528707 243\n",
      "8 \t0.529375 381\n",
      "12 \t0.528663 316\n",
      "16 \t0.528997 323\n",
      "20 \t0.52832 333\n",
      "24 \t0.528435 398\n",
      "28 \t0.528545 315\n",
      "32 \t0.528707 339\n",
      "40 \t0.527865 337\n",
      "48 \t0.529024 336\n",
      "64 \t0.528953 376\n",
      "128 \t0.531708 381\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [2,4,8,12,16,20,24,28,32,40,48,64,128]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 \t0.527787 391\n",
      "75 \t0.528922 367\n",
      "80 \t0.529824 473\n",
      "100 \t0.530926 383\n",
      "120 \t0.531655 449\n",
      "140 \t0.530849 445\n",
      "160 \t0.531763 498\n",
      "200 \t0.533395 648\n"
     ]
    }
   ],
   "source": [
    "for x in [50,75,80,100,120,140,160,200]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "min_child_weight = train_param\n",
    "print min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 \t0.533177 678\n",
      "0.1 \t0.528575 489\n",
      "0.2 \t0.527417 305\n",
      "0.3 \t0.527616 336\n",
      "0.4 \t0.527998 362\n",
      "0.5 \t0.526321 366\n",
      "0.6 \t0.527867 387\n",
      "0.7 \t0.52753 435\n",
      "0.8 \t0.527293 383\n",
      "0.9 \t0.529772 324\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = train_param\n",
    "print colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 \t0.532237 396\n",
      "0.6 \t0.52943 395\n",
      "0.7 \t0.528151 379\n",
      "0.8 \t0.528136 420\n",
      "0.9 \t0.52825 357\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        subsample = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "subsample = train_param\n",
    "print subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 \t0.527882 329\n",
      "0.6 \t0.527404 389\n",
      "0.9 \t0.528133 318\n",
      "1.2 \t0.526418 497\n",
      "1.5 \t0.528352 345\n",
      "1.8 \t0.528509 354\n",
      "2.1 \t0.527858 409\n",
      "2.4 \t0.52787 549\n",
      "2.7 \t0.525604 525\n",
      "3.0 \t0.527605 393\n"
     ]
    }
   ],
   "source": [
    "train_param = 0\n",
    "for x in [0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3.0]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        subsample = subsample,\n",
    "        gamma = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7\n"
     ]
    }
   ],
   "source": [
    "gamma = train_param\n",
    "print gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.3 \t0.52431 436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[800]\ttrain-mlogloss:0.359776+0.00266422\ttest-mlogloss:0.524082+0.00630427\n",
      "\n",
      "    1 | 14m49s | \u001b[35m  -0.52408\u001b[0m | \u001b[32m            0.3699\u001b[0m | \u001b[32m   2.7645\u001b[0m | \u001b[32m     5.2078\u001b[0m | \u001b[32m           45.4868\u001b[0m | \u001b[32m     0.8879\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[285]\ttrain-mlogloss:0.325537+0.0016814\ttest-mlogloss:0.524654+0.00677044\n",
      "\n",
      "    2 | 14m57s |   -0.52465 |             0.6851 |    2.4539 |      8.3154 |            45.7695 |      0.7657 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[551]\ttrain-mlogloss:0.339858+0.00319843\ttest-mlogloss:0.524485+0.00638942\n",
      "\n",
      "    3 | 13m06s |   -0.52448 |             0.4012 |    2.0265 |      6.6715 |            66.1248 |      0.9127 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[378]\ttrain-mlogloss:0.358955+0.0019046\ttest-mlogloss:0.525668+0.00705407\n",
      "\n",
      "    4 | 16m34s |   -0.52567 |             0.6038 |    2.8094 |      8.4318 |            97.0481 |      0.8596 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[525]\ttrain-mlogloss:0.342282+0.00196847\ttest-mlogloss:0.524124+0.00757812\n",
      "\n",
      "    5 | 13m30s |   -0.52412 |             0.3605 |    2.8978 |      7.1435 |            53.8190 |      0.8468 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[782]\ttrain-mlogloss:0.351144+0.00161723\ttest-mlogloss:0.524529+0.00639481\n",
      "\n",
      "    6 | 15m21s |   -0.52453 |             0.3991 |    2.4316 |      5.0829 |            57.9487 |      0.8338 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[314]\ttrain-mlogloss:0.3425+0.00196518\ttest-mlogloss:0.526062+0.00626777\n",
      "\n",
      "    7 | 10m58s |   -0.52606 |             0.4355 |    2.4102 |      8.7372 |            56.8017 |      0.7136 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[306]\ttrain-mlogloss:0.345179+0.00184774\ttest-mlogloss:0.525209+0.00630689\n",
      "\n",
      "    8 | 11m46s |   -0.52521 |             0.4772 |    2.5824 |      8.0178 |            57.0593 |      0.8172 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[316]\ttrain-mlogloss:0.313947+0.00197842\ttest-mlogloss:0.523528+0.00573488\n",
      "\n",
      "    9 | 13m36s | \u001b[35m  -0.52353\u001b[0m | \u001b[32m            0.5539\u001b[0m | \u001b[32m   2.0509\u001b[0m | \u001b[32m     8.4740\u001b[0m | \u001b[32m           50.0463\u001b[0m | \u001b[32m     0.9698\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[542]\ttrain-mlogloss:0.346406+0.00224511\ttest-mlogloss:0.525039+0.00622661\n",
      "\n",
      "   10 | 18m33s |   -0.52504 |             0.6295 |    2.1406 |      6.1119 |            87.9358 |      0.8766 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[971]\ttrain-mlogloss:0.374173+0.00182065\ttest-mlogloss:0.524782+0.00653497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 26m10s |   -0.52478 |             0.7417 |    2.8924 |      4.6909 |            30.0294 |      0.9526 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1019]\ttrain-mlogloss:0.403717+0.00185238\ttest-mlogloss:0.526458+0.00635421\n",
      "\n",
      "   12 | 21m50s |   -0.52646 |             0.5782 |    2.8339 |      4.0838 |            99.9071 |      0.9376 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1056]\ttrain-mlogloss:0.409918+0.00266758\ttest-mlogloss:0.52689+0.00596366\n",
      "\n",
      "   13 | 27m46s |   -0.52689 |             0.7657 |    2.9047 |      4.3252 |            75.1984 |      0.9944 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[316]\ttrain-mlogloss:0.296025+0.00157446\ttest-mlogloss:0.523184+0.00707509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.71315229e-05]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00051215]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00011172]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 11m22s | \u001b[35m  -0.52318\u001b[0m | \u001b[32m            0.3500\u001b[0m | \u001b[32m   2.4217\u001b[0m | \u001b[32m     9.9616\u001b[0m | \u001b[32m           30.0457\u001b[0m | \u001b[32m     0.9948\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[407]\ttrain-mlogloss:0.319775+0.00179118\ttest-mlogloss:0.52196+0.00636937\n",
      "\n",
      "   15 | 13m48s | \u001b[35m  -0.52196\u001b[0m | \u001b[32m            0.3431\u001b[0m | \u001b[32m   2.9852\u001b[0m | \u001b[32m     9.8936\u001b[0m | \u001b[32m           38.6922\u001b[0m | \u001b[32m     0.9886\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[527]\ttrain-mlogloss:0.325852+0.00169995\ttest-mlogloss:0.523349+0.00587314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00076742]), 'nit': 3, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 15m21s |   -0.52335 |             0.3117 |    2.5705 |      9.8625 |            83.4601 |      0.9881 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[243]\ttrain-mlogloss:0.288896+0.00319662\ttest-mlogloss:0.523907+0.00612811\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.58001912e-05]), 'nit': 7, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 17m09s |   -0.52391 |             0.7668 |    2.0165 |      9.3644 |            36.4631 |      0.9824 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[388]\ttrain-mlogloss:0.282784+0.00140062\ttest-mlogloss:0.523435+0.00518146\n",
      "\n",
      "   18 | 12m26s |   -0.52343 |             0.3160 |    2.0538 |      9.9078 |            42.3049 |      0.9979 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[443]\ttrain-mlogloss:0.347299+0.000955969\ttest-mlogloss:0.523667+0.00616503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00011712]), 'nit': 7, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 17m23s |   -0.52367 |             0.4510 |    2.9674 |      9.6916 |            89.0906 |      0.9825 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[415]\ttrain-mlogloss:0.314453+0.00197418\ttest-mlogloss:0.522546+0.00639241\n",
      "\n",
      "   20 | 13m38s |   -0.52255 |             0.3289 |    2.9662 |      9.4430 |            33.0534 |      0.9911 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[417]\ttrain-mlogloss:0.334694+0.00199873\ttest-mlogloss:0.523154+0.00626636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00160544]), 'nit': 3, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 17m51s |   -0.52315 |             0.4872 |    2.9812 |      9.9585 |            70.2075 |      0.9688 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[390]\ttrain-mlogloss:0.325184+0.00175253\ttest-mlogloss:0.522479+0.00583294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00016806]), 'nit': 7, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 13m26s |   -0.52248 |             0.3550 |    2.8788 |      9.7572 |            47.8806 |      0.9858 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1111]\ttrain-mlogloss:0.392529+0.00268541\ttest-mlogloss:0.525521+0.00659181\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00022543]), 'nit': 6, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 | 26m05s |   -0.52552 |             0.6639 |    2.9345 |      4.1309 |            51.0818 |      0.9879 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1384]\ttrain-mlogloss:0.401367+0.00477641\ttest-mlogloss:0.525243+0.00638665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00098198]), 'nit': 3, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00050873]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 18m30s |   -0.52524 |             0.3105 |    2.9130 |      4.5316 |            38.7214 |      0.9996 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1250]\ttrain-mlogloss:0.419666+0.00303129\ttest-mlogloss:0.526337+0.00621042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00082169]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 16m49s |   -0.52634 |             0.3076 |    2.8708 |      4.0273 |            93.2869 |      0.9934 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[430]\ttrain-mlogloss:0.325488+0.00255702\ttest-mlogloss:0.523205+0.00662472\n",
      "\n",
      "   26 | 16m00s |   -0.52320 |             0.4217 |    2.1147 |      9.5000 |            99.9846 |      0.9990 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[404]\ttrain-mlogloss:0.311997+0.002719\ttest-mlogloss:0.523532+0.00662383\n",
      "\n",
      "   27 | 13m03s |   -0.52353 |             0.3322 |    2.0162 |      9.7306 |            76.0949 |      0.9801 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[480]\ttrain-mlogloss:0.300542+0.00238513\ttest-mlogloss:0.522665+0.00687734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00020576]), 'nit': 3, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 14m42s |   -0.52266 |             0.3077 |    2.7993 |      9.9480 |            35.9872 |      0.9760 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[395]\ttrain-mlogloss:0.332722+0.00233335\ttest-mlogloss:0.523675+0.00629095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00062535]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 13m05s |   -0.52368 |             0.3406 |    2.7163 |      9.9466 |            63.6880 |      0.9916 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[424]\ttrain-mlogloss:0.321994+0.0016189\ttest-mlogloss:0.523886+0.00600027\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.0001597]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00029559]), 'nit': 5, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 14m00s |   -0.52389 |             0.3525 |    2.0270 |      9.9218 |            93.3794 |      0.9899 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[499]\ttrain-mlogloss:0.322601+0.00186049\ttest-mlogloss:0.522958+0.00598764\n",
      "\n",
      "   31 | 15m14s |   -0.52296 |             0.3203 |    2.9330 |      9.2927 |            51.2480 |      0.9928 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[396]\ttrain-mlogloss:0.32169+0.00280418\ttest-mlogloss:0.522762+0.00677553\n",
      "\n",
      "   32 | 14m25s |   -0.52276 |             0.3757 |    2.9831 |      9.3205 |            40.7963 |      0.9942 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[528]\ttrain-mlogloss:0.33185+0.00227839\ttest-mlogloss:0.522142+0.00630805\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00149224]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 14m36s |   -0.52214 |             0.3036 |    2.9123 |      8.0124 |            47.3447 |      0.9935 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[563]\ttrain-mlogloss:0.329555+0.00272212\ttest-mlogloss:0.523007+0.00633885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00057485]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 15m06s |   -0.52301 |             0.3080 |    2.9096 |      8.2670 |            49.2890 |      0.9955 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[271]\ttrain-mlogloss:0.331888+0.00343583\ttest-mlogloss:0.523843+0.00606784\n",
      "\n",
      "   35 | 12m00s |   -0.52384 |             0.4469 |    2.0094 |      9.7599 |            68.5086 |      0.9940 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1248]\ttrain-mlogloss:0.408691+0.0032489\ttest-mlogloss:0.525518+0.00615553\n",
      "\n",
      "   36 | 18m16s |   -0.52552 |             0.3439 |    2.9296 |      4.1428 |            63.8607 |      0.9949 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[680]\ttrain-mlogloss:0.328734+0.00150574\ttest-mlogloss:0.522417+0.00681082\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00236639]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 15m53s |   -0.52242 |             0.3050 |    2.9975 |      7.4795 |            30.6884 |      0.9898 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[455]\ttrain-mlogloss:0.32923+0.00185983\ttest-mlogloss:0.522154+0.00654895\n",
      "\n",
      "   38 | 12m38s |   -0.52215 |             0.3041 |    2.8941 |      8.7357 |            37.7799 |      0.9874 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[529]\ttrain-mlogloss:0.332931+0.00176829\ttest-mlogloss:0.523188+0.00578049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00010286]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00011302]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 15m45s |   -0.52319 |             0.3103 |    2.8375 |      9.6975 |            72.8310 |      0.9928 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[913]\ttrain-mlogloss:0.380035+0.00234085\ttest-mlogloss:0.524865+0.0066144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.28581421e-05]), 'nit': 7, 'funcalls': 61}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.76151077e-05]), 'nit': 6, 'funcalls': 62}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 | 17m47s |   -0.52486 |             0.4831 |    2.5172 |      4.7847 |            45.3399 |      0.9268 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[875]\ttrain-mlogloss:0.398898+0.00195013\ttest-mlogloss:0.524852+0.00578102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -9.01061867e-05]), 'nit': 7, 'funcalls': 61}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00040987]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 14m45s |   -0.52485 |             0.3042 |    2.9897 |      5.7696 |            81.2279 |      0.9923 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[546]\ttrain-mlogloss:0.340599+0.0023427\ttest-mlogloss:0.523179+0.00643942\n",
      "\n",
      "   42 | 12m13s |   -0.52318 |             0.3284 |    2.4206 |      6.9817 |            33.0168 |      0.9909 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[495]\ttrain-mlogloss:0.33266+0.00159504\ttest-mlogloss:0.522333+0.00656059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  6.18415797e-05]), 'nit': 5, 'funcalls': 90}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 13m35s |   -0.52233 |             0.3018 |    2.8663 |      8.0424 |            46.9486 |      0.9958 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[311]\ttrain-mlogloss:0.329929+0.00202065\ttest-mlogloss:0.523588+0.00648347\n",
      "\n",
      "   44 | 11m02s |   -0.52359 |             0.3237 |    2.8720 |      9.9537 |            38.2804 |      0.9071 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[337]\ttrain-mlogloss:0.343478+0.00299261\ttest-mlogloss:0.524647+0.00534775\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00092394]), 'nit': 4, 'funcalls': 57}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 21m18s |   -0.52465 |             0.7460 |    2.9599 |      9.5553 |            79.9405 |      0.9984 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[528]\ttrain-mlogloss:0.344857+0.00165415\ttest-mlogloss:0.524154+0.00757224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00138208]), 'nit': 3, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 | 22m45s |   -0.52415 |             0.7843 |    2.9799 |      6.0434 |            34.6694 |      0.9908 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[288]\ttrain-mlogloss:0.332665+0.00313116\ttest-mlogloss:0.524482+0.0062659\n",
      "\n",
      "   47 | 19m37s |   -0.52448 |             0.7885 |    2.0738 |      9.4162 |            86.3951 |      0.9749 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[452]\ttrain-mlogloss:0.355489+0.00215729\ttest-mlogloss:0.523887+0.00647073\n",
      "\n",
      "   48 | 15m32s |   -0.52389 |             0.3705 |    2.9251 |      9.9386 |            99.9056 |      0.9590 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[428]\ttrain-mlogloss:0.339964+0.00199377\ttest-mlogloss:0.524351+0.006255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.0018803]), 'nit': 4, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.0016431]), 'nit': 3, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 20m27s |   -0.52435 |             0.7165 |    2.9591 |      7.7461 |            44.1374 |      0.9968 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[848]\ttrain-mlogloss:0.366512+0.00208806\ttest-mlogloss:0.52401+0.00637071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00026417]), 'nit': 4, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 16m46s |   -0.52401 |             0.3021 |    2.9954 |      6.0283 |            69.7415 |      0.9776 | \n"
     ]
    }
   ],
   "source": [
    "xgtrain = xgb.DMatrix(train_X, label=train_y) \n",
    "\n",
    "def xgb_evaluate(min_child_weight, colsample_bytree, max_depth, subsample, gamma):\n",
    "    params = dict()\n",
    "    params['objective']='multi:softprob'\n",
    "    params['eval_metric']='mlogloss',\n",
    "    params['num_class']=3\n",
    "    params['silent']=1\n",
    "    params['eta'] = 0.1\n",
    "    params['verbose_eval'] = True\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    \n",
    "    cv_result = xgb.cv(\n",
    "        params, xgtrain, \n",
    "        num_boost_round=10000, nfold=5,\n",
    "        metrics = 'mlogloss',\n",
    "        seed=seed,callbacks=[xgb.callback.early_stop(50)]\n",
    "    )\n",
    "    \n",
    "    return -cv_result['test-mlogloss-mean'].values[-1]\n",
    "\n",
    "\n",
    "xgb_BO = BayesianOptimization(\n",
    "    xgb_evaluate, \n",
    "    {\n",
    "        'max_depth': (4,10),\n",
    "        'min_child_weight': (30,100),\n",
    "        'colsample_bytree': (0.3,0.8),\n",
    "        'subsample': (0.7,1),\n",
    "        'gamma': (2,3)\n",
    "    }\n",
    ")\n",
    "\n",
    "xgb_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>gamma</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.893582</td>\n",
       "      <td>38.692208</td>\n",
       "      <td>0.343099</td>\n",
       "      <td>0.988641</td>\n",
       "      <td>2.985231</td>\n",
       "      <td>-0.521960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.012421</td>\n",
       "      <td>47.344712</td>\n",
       "      <td>0.303623</td>\n",
       "      <td>0.993480</td>\n",
       "      <td>2.912287</td>\n",
       "      <td>-0.522142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.735716</td>\n",
       "      <td>37.779927</td>\n",
       "      <td>0.304125</td>\n",
       "      <td>0.987374</td>\n",
       "      <td>2.894111</td>\n",
       "      <td>-0.522154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.042435</td>\n",
       "      <td>46.948556</td>\n",
       "      <td>0.301839</td>\n",
       "      <td>0.995753</td>\n",
       "      <td>2.866326</td>\n",
       "      <td>-0.522333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.479458</td>\n",
       "      <td>30.688415</td>\n",
       "      <td>0.305018</td>\n",
       "      <td>0.989820</td>\n",
       "      <td>2.997530</td>\n",
       "      <td>-0.522417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.757235</td>\n",
       "      <td>47.880630</td>\n",
       "      <td>0.355007</td>\n",
       "      <td>0.985846</td>\n",
       "      <td>2.878814</td>\n",
       "      <td>-0.522479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.442971</td>\n",
       "      <td>33.053379</td>\n",
       "      <td>0.328882</td>\n",
       "      <td>0.991066</td>\n",
       "      <td>2.966176</td>\n",
       "      <td>-0.522546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.947977</td>\n",
       "      <td>35.987158</td>\n",
       "      <td>0.307668</td>\n",
       "      <td>0.976048</td>\n",
       "      <td>2.799263</td>\n",
       "      <td>-0.522665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.320539</td>\n",
       "      <td>40.796274</td>\n",
       "      <td>0.375652</td>\n",
       "      <td>0.994171</td>\n",
       "      <td>2.983123</td>\n",
       "      <td>-0.522762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.292661</td>\n",
       "      <td>51.247953</td>\n",
       "      <td>0.320341</td>\n",
       "      <td>0.992831</td>\n",
       "      <td>2.933025</td>\n",
       "      <td>-0.522958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  colsample_bytree  subsample     gamma  \\\n",
       "4    9.893582         38.692208          0.343099   0.988641  2.985231   \n",
       "22   8.012421         47.344712          0.303623   0.993480  2.912287   \n",
       "27   8.735716         37.779927          0.304125   0.987374  2.894111   \n",
       "32   8.042435         46.948556          0.301839   0.995753  2.866326   \n",
       "26   7.479458         30.688415          0.305018   0.989820  2.997530   \n",
       "11   9.757235         47.880630          0.355007   0.985846  2.878814   \n",
       "9    9.442971         33.053379          0.328882   0.991066  2.966176   \n",
       "17   9.947977         35.987158          0.307668   0.976048  2.799263   \n",
       "21   9.320539         40.796274          0.375652   0.994171  2.983123   \n",
       "20   9.292661         51.247953          0.320341   0.992831  2.933025   \n",
       "\n",
       "       score  \n",
       "4  -0.521960  \n",
       "22 -0.522142  \n",
       "27 -0.522154  \n",
       "32 -0.522333  \n",
       "26 -0.522417  \n",
       "11 -0.522479  \n",
       "9  -0.522546  \n",
       "17 -0.522665  \n",
       "21 -0.522762  \n",
       "20 -0.522958  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bo_scores = pd.DataFrame([[s[0]['max_depth'],\n",
    "                               s[0]['min_child_weight'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[0]['gamma'],\n",
    "                               s[1]] for s in zip(xgb_BO.res['all']['params'],xgb_BO.res['all']['values'])],\n",
    "                            columns = ['max_depth',\n",
    "                                       'min_child_weight',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'gamma',\n",
    "                                       'score'])\n",
    "xgb_bo_scores=xgb_bo_scores.sort_values('score',ascending=False)\n",
    "xgb_bo_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = test_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_loc_price_diff</th>\n",
       "      <th>num_price</th>\n",
       "      <th>num_loc_median_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>-49.5</td>\n",
       "      <td>2600</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>-500.0</td>\n",
       "      <td>2750</td>\n",
       "      <td>3250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>5700.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>7200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>-1555.0</td>\n",
       "      <td>4195</td>\n",
       "      <td>5750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>4200</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>-3464.0</td>\n",
       "      <td>2300</td>\n",
       "      <td>5764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>4200.0</td>\n",
       "      <td>6500</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>3275.0</td>\n",
       "      <td>6200</td>\n",
       "      <td>2925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>-1169.0</td>\n",
       "      <td>4595</td>\n",
       "      <td>5764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>-955.0</td>\n",
       "      <td>3995</td>\n",
       "      <td>4950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8096</th>\n",
       "      <td>4825.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8401</th>\n",
       "      <td>-350.0</td>\n",
       "      <td>3650</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8585</th>\n",
       "      <td>-1237.5</td>\n",
       "      <td>2700</td>\n",
       "      <td>3937.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8746</th>\n",
       "      <td>720.0</td>\n",
       "      <td>5895</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9409</th>\n",
       "      <td>-449.0</td>\n",
       "      <td>2250</td>\n",
       "      <td>2699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037</th>\n",
       "      <td>-1250.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>3850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>-198.0</td>\n",
       "      <td>4977</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10307</th>\n",
       "      <td>-250.0</td>\n",
       "      <td>3750</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11706</th>\n",
       "      <td>-1400.0</td>\n",
       "      <td>4325</td>\n",
       "      <td>5725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12982</th>\n",
       "      <td>-575.0</td>\n",
       "      <td>4600</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13114</th>\n",
       "      <td>950.0</td>\n",
       "      <td>3700</td>\n",
       "      <td>2750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>-49.5</td>\n",
       "      <td>2600</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14186</th>\n",
       "      <td>-455.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>2450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14525</th>\n",
       "      <td>-250.0</td>\n",
       "      <td>3750</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15371</th>\n",
       "      <td>-837.5</td>\n",
       "      <td>3100</td>\n",
       "      <td>3937.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>-2000.0</td>\n",
       "      <td>5200</td>\n",
       "      <td>7200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15634</th>\n",
       "      <td>-437.5</td>\n",
       "      <td>3500</td>\n",
       "      <td>3937.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16095</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2850</td>\n",
       "      <td>2750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250</th>\n",
       "      <td>795.0</td>\n",
       "      <td>2995</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45851</th>\n",
       "      <td>-255.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>2750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46268</th>\n",
       "      <td>-154.5</td>\n",
       "      <td>2495</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47001</th>\n",
       "      <td>110.0</td>\n",
       "      <td>2410</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48562</th>\n",
       "      <td>-449.0</td>\n",
       "      <td>2250</td>\n",
       "      <td>2699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49191</th>\n",
       "      <td>1767.0</td>\n",
       "      <td>6942</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50883</th>\n",
       "      <td>-105.0</td>\n",
       "      <td>2095</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51757</th>\n",
       "      <td>-254.5</td>\n",
       "      <td>2395</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52355</th>\n",
       "      <td>1152.5</td>\n",
       "      <td>4500</td>\n",
       "      <td>3347.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53231</th>\n",
       "      <td>805.0</td>\n",
       "      <td>4400</td>\n",
       "      <td>3595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54106</th>\n",
       "      <td>-254.5</td>\n",
       "      <td>2395</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55155</th>\n",
       "      <td>105.0</td>\n",
       "      <td>5800</td>\n",
       "      <td>5695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55392</th>\n",
       "      <td>-1037.5</td>\n",
       "      <td>2900</td>\n",
       "      <td>3937.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55403</th>\n",
       "      <td>-901.0</td>\n",
       "      <td>3208</td>\n",
       "      <td>4109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55608</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>7200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56876</th>\n",
       "      <td>-6205.0</td>\n",
       "      <td>3795</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56881</th>\n",
       "      <td>270.0</td>\n",
       "      <td>2970</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57071</th>\n",
       "      <td>452.5</td>\n",
       "      <td>3800</td>\n",
       "      <td>3347.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58290</th>\n",
       "      <td>-105.0</td>\n",
       "      <td>2095</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59732</th>\n",
       "      <td>3725.0</td>\n",
       "      <td>7000</td>\n",
       "      <td>3275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61119</th>\n",
       "      <td>5651.5</td>\n",
       "      <td>8999</td>\n",
       "      <td>3347.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61426</th>\n",
       "      <td>300.0</td>\n",
       "      <td>3025</td>\n",
       "      <td>2725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65689</th>\n",
       "      <td>276.0</td>\n",
       "      <td>2950</td>\n",
       "      <td>2674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66961</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2300</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67319</th>\n",
       "      <td>-198.0</td>\n",
       "      <td>4977</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67678</th>\n",
       "      <td>-254.5</td>\n",
       "      <td>2395</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67683</th>\n",
       "      <td>3720.0</td>\n",
       "      <td>6995</td>\n",
       "      <td>3275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68048</th>\n",
       "      <td>-608.0</td>\n",
       "      <td>2292</td>\n",
       "      <td>2900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70205</th>\n",
       "      <td>1650.0</td>\n",
       "      <td>7150</td>\n",
       "      <td>5500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70245</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>7200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71754</th>\n",
       "      <td>600.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_loc_price_diff  num_price  num_loc_median_price\n",
       "710                 -49.5       2600                2649.5\n",
       "779                -500.0       2750                3250.0\n",
       "988                5700.0       8000                2300.0\n",
       "1542               2800.0      10000                7200.0\n",
       "2099              -1555.0       4195                5750.0\n",
       "3447               -200.0       4200                4400.0\n",
       "3697              -3464.0       2300                5764.0\n",
       "4662               4200.0       6500                2300.0\n",
       "4669               3275.0       6200                2925.0\n",
       "4689              -1169.0       4595                5764.0\n",
       "7145               -955.0       3995                4950.0\n",
       "8096               4825.0      10000                5175.0\n",
       "8401               -350.0       3650                4000.0\n",
       "8585              -1237.5       2700                3937.5\n",
       "8746                720.0       5895                5175.0\n",
       "9409               -449.0       2250                2699.0\n",
       "10037             -1250.0       2600                3850.0\n",
       "10160              -198.0       4977                5175.0\n",
       "10307              -250.0       3750                4000.0\n",
       "11706             -1400.0       4325                5725.0\n",
       "12982              -575.0       4600                5175.0\n",
       "13114               950.0       3700                2750.0\n",
       "13144               -49.5       2600                2649.5\n",
       "14186              -455.0       1995                2450.0\n",
       "14525              -250.0       3750                4000.0\n",
       "15371              -837.5       3100                3937.5\n",
       "15451             -2000.0       5200                7200.0\n",
       "15634              -437.5       3500                3937.5\n",
       "16095               100.0       2850                2750.0\n",
       "16250               795.0       2995                2200.0\n",
       "...                   ...        ...                   ...\n",
       "45851              -255.0       2495                2750.0\n",
       "46268              -154.5       2495                2649.5\n",
       "47001               110.0       2410                2300.0\n",
       "48562              -449.0       2250                2699.0\n",
       "49191              1767.0       6942                5175.0\n",
       "50883              -105.0       2095                2200.0\n",
       "51757              -254.5       2395                2649.5\n",
       "52355              1152.5       4500                3347.5\n",
       "53231               805.0       4400                3595.0\n",
       "54106              -254.5       2395                2649.5\n",
       "55155               105.0       5800                5695.0\n",
       "55392             -1037.5       2900                3937.5\n",
       "55403              -901.0       3208                4109.0\n",
       "55608              2800.0      10000                7200.0\n",
       "56876             -6205.0       3795               10000.0\n",
       "56881               270.0       2970                2700.0\n",
       "57071               452.5       3800                3347.5\n",
       "58290              -105.0       2095                2200.0\n",
       "59732              3725.0       7000                3275.0\n",
       "61119              5651.5       8999                3347.5\n",
       "61426               300.0       3025                2725.0\n",
       "65689               276.0       2950                2674.0\n",
       "66961               305.0       2300                1995.0\n",
       "67319              -198.0       4977                5175.0\n",
       "67678              -254.5       2395                2649.5\n",
       "67683              3720.0       6995                3275.0\n",
       "68048              -608.0       2292                2900.0\n",
       "70205              1650.0       7150                5500.0\n",
       "70245              2800.0      10000                7200.0\n",
       "71754               600.0       5000                4400.0\n",
       "\n",
       "[115 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_ind = test_X.num_loc_price_diff.isnull()\n",
    "test_X['num_loc_price_diff'] = test_X['num_price'] - test_X['num_loc_median_price']\n",
    "test_X[null_ind][['num_loc_price_diff','num_price','num_loc_median_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgb_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,random_state=5555)\n",
    "    N_class = len(set(train_y))\n",
    "        \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(objective = 'multi:softprob')\n",
    "        est.set_params(silent = False)\n",
    "        est.set_params(learning_rate = 0.02)\n",
    "        est.set_params(n_estimators=100000)\n",
    "        \n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "    \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]      \n",
    "\n",
    "            est.fit(train_x_fold,train_y_fold,\n",
    "                    eval_set = [(val_x_fold, val_y_fold)],\n",
    "                    eval_metric = 'mlogloss',\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose=False)\n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,ntree_limit=best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score\n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,ntree_limit=best_round)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 5 folds\n",
      "Model 1: XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.304125,\n",
      "       gamma=2.894111, learning_rate=0.02, max_delta_step=0, max_depth=8,\n",
      "       min_child_weight=37, missing=None, n_estimators=100000, nthread=-1,\n",
      "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=False, subsample=0.987374)\n",
      "Model 1 fold 1\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "#             xgb.XGBClassifier(max_depth = 7,\n",
    "#                               min_child_weight = 5,\n",
    "#                               colsample_bytree = 0.293906 ,\n",
    "#                               subsample = 0.947733 ,\n",
    "#                               gamma = 2.983057),\n",
    "#              xgb.XGBClassifier(max_depth = 6,\n",
    "#                               min_child_weight = 2,\n",
    "#                               colsample_bytree = 0.200079,\n",
    "#                               subsample = 0.976483,\n",
    "#                               gamma = 2.872736),\n",
    "#              xgb.XGBClassifier(max_depth = 6,\n",
    "#                               min_child_weight = 25,\n",
    "#                               colsample_bytree = 0.273249,\n",
    "#                               subsample = 0.983080,\n",
    "#                               gamma = 2.978747),         \n",
    "#              xgb.XGBClassifier(max_depth = 7,\n",
    "#                               min_child_weight = 4,\n",
    "#                               colsample_bytree = 0.219052,\n",
    "#                               subsample = 0.741765,\n",
    "#                               gamma = 2.649557),  \n",
    "             xgb.XGBClassifier(max_depth = 8,\n",
    "                              min_child_weight = 37,\n",
    "                              colsample_bytree = 0.304125,\n",
    "                              subsample = 0.987374,\n",
    "                              gamma = 2.894111)              \n",
    "             ]\n",
    "\n",
    "#  \t \tmax_depth \tmin_child_weight \tcolsample_bytree \tsubsample \tgamma \tscore\n",
    "# 4 \t9.893582 \t38.692208 \t0.343099 \t0.988641 \t2.985231 \t-0.521960  52041029\n",
    "# 22 \t8.012421 \t47.344712 \t0.303623 \t0.993480 \t2.912287 \t-0.522142  52057958\n",
    "# 27 \t8.735716 \t37.779927 \t0.304125 \t0.987374 \t2.894111 \t-0.522154\n",
    "(train_blend_x_xgb,\n",
    " test_blend_x_xgb_mean,\n",
    " test_blend_x_xgb_gmean,\n",
    " blend_scores_xgb,\n",
    " best_rounds_xgb) = xgb_blend(estimators,\n",
    "                              train_X,train_y,\n",
    "                              test_X,\n",
    "                              5,\n",
    "                              500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52041029]\n",
      "[ 2541.4]\n"
     ]
    }
   ],
   "source": [
    "# # now = datetime.now()\n",
    "\n",
    "# name_train_blend = '../output/train_blend_xgb_cv137_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "# name_test_blend_mean = '../output/test_blend_xgb_mean_cv137_5blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "# name_test_blend_gmean = '../output/test_blend_xgb_gmean_cv137_5blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "# print (np.mean(blend_scores_xgb,axis=0))\n",
    "# print (np.mean(best_rounds_xgb,axis=0))\n",
    "# np.savetxt(name_train_blend,train_blend_x_xgb, delimiter=\",\")\n",
    "# np.savetxt(name_test_blend_mean,test_blend_x_xgb_mean, delimiter=\",\")\n",
    "# np.savetxt(name_test_blend_gmean,test_blend_x_xgb_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data 0322\n",
    "# [ 0.52385999  0.52420308  0.52429754  0.52366222  0.52450185]\n",
    "# [ 2866.7  3979.7  3102.9  2783.1  4450.5]\n",
    "\n",
    "# data 0331 seed = 2017\n",
    "# [ 0.5161796   0.51727863  0.51867825  0.517129    0.51732854]\n",
    "# [ 4857.5  6379.5  5516.4  3337.9  1674.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.938200</td>\n",
       "      <td>0.058592</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>7211212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.993766</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>7150865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391082</td>\n",
       "      <td>0.443861</td>\n",
       "      <td>0.165057</td>\n",
       "      <td>6887163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954680</td>\n",
       "      <td>0.042502</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>6888711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.994358</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>6934781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        low    medium      high  listing_id\n",
       "0  0.938200  0.058592  0.003208     7211212\n",
       "1  0.993766  0.005808  0.000426     7150865\n",
       "2  0.391082  0.443861  0.165057     6887163\n",
       "3  0.954680  0.042502  0.002818     6888711\n",
       "4  0.994358  0.005169  0.000473     6934781"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_blend_x_xgb = pd.DataFrame(train_blend_x_xgb[:,:3])\n",
    "train_blend_x_xgb.columns = [\"low\", \"medium\", \"high\"]\n",
    "train_blend_x_xgb[\"listing_id\"] = train_X.listing_id.values\n",
    "\n",
    "train_blend_x_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401541</td>\n",
       "      <td>0.525831</td>\n",
       "      <td>0.072628</td>\n",
       "      <td>7142618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.986221</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>7210040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.668526</td>\n",
       "      <td>0.283461</td>\n",
       "      <td>0.048012</td>\n",
       "      <td>7103890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.496940</td>\n",
       "      <td>0.472054</td>\n",
       "      <td>0.031006</td>\n",
       "      <td>7143442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.742120</td>\n",
       "      <td>0.234169</td>\n",
       "      <td>0.023711</td>\n",
       "      <td>6860601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        low    medium      high  listing_id\n",
       "0  0.401541  0.525831  0.072628     7142618\n",
       "1  0.986221  0.009393  0.004387     7210040\n",
       "2  0.668526  0.283461  0.048012     7103890\n",
       "3  0.496940  0.472054  0.031006     7143442\n",
       "4  0.742120  0.234169  0.023711     6860601"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_mean = pd.DataFrame(test_blend_x_xgb_mean[:,:3])\n",
    "test_blend_x_xgb_mean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_blend_x_xgb_mean[\"listing_id\"] = test_X.listing_id.values\n",
    "\n",
    "test_blend_x_xgb_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.398646</td>\n",
       "      <td>0.524051</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>7142618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.986218</td>\n",
       "      <td>0.009124</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>7210040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666860</td>\n",
       "      <td>0.280832</td>\n",
       "      <td>0.045953</td>\n",
       "      <td>7103890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.496360</td>\n",
       "      <td>0.471526</td>\n",
       "      <td>0.030715</td>\n",
       "      <td>7143442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.741411</td>\n",
       "      <td>0.231883</td>\n",
       "      <td>0.023414</td>\n",
       "      <td>6860601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        low    medium      high  listing_id\n",
       "0  0.398646  0.524051  0.072400     7142618\n",
       "1  0.986218  0.009124  0.004201     7210040\n",
       "2  0.666860  0.280832  0.045953     7103890\n",
       "3  0.496360  0.471526  0.030715     7143442\n",
       "4  0.741411  0.231883  0.023414     6860601"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_gmean = pd.DataFrame(test_blend_x_xgb_gmean[:,:3])\n",
    "test_blend_x_xgb_gmean.columns = [\"low\", \"medium\", \"high\"]\n",
    "test_blend_x_xgb_gmean[\"listing_id\"] = test_X.listing_id.values\n",
    "\n",
    "test_blend_x_xgb_gmean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 412) (74659, 412) (49352,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X_BM = pd.read_csv(data_path + 'train_BM_0331.csv')\n",
    "test_X_BM = pd.read_csv(data_path + 'test_BM_0331.csv')\n",
    "\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X_BM.shape, test_X_BM.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_train = train_X_BM[['listing_id']].merge(train_blend_x_xgb,on = 'listing_id', \n",
    "                                             how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_mean = test_X_BM[['listing_id']].merge(test_blend_x_xgb_mean,on = 'listing_id', \n",
    "                                                how = 'left')[[\"low\", \"medium\", \"high\"]].values\n",
    "tmp_test_gmean = test_X_BM[['listing_id']].merge(test_blend_x_xgb_gmean,on = 'listing_id', \n",
    "                                                 how = 'left')[[\"low\", \"medium\", \"high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.45454741e-01,   4.35612619e-01,   1.89326406e-02],\n",
       "       [  2.38422796e-01,   7.03407645e-01,   5.81695400e-02],\n",
       "       [  7.36379206e-01,   2.52045274e-01,   1.15755545e-02],\n",
       "       [  9.38200235e-01,   5.85920289e-02,   3.20768380e-03],\n",
       "       [  9.71339464e-01,   2.82589309e-02,   4.01635072e-04],\n",
       "       [  8.02813649e-01,   1.44351289e-01,   5.28350845e-02],\n",
       "       [  8.38758707e-01,   1.45681798e-01,   1.55594582e-02],\n",
       "       [  2.11300716e-01,   2.94703752e-01,   4.93995577e-01],\n",
       "       [  9.66512680e-01,   2.57101785e-02,   7.77717493e-03],\n",
       "       [  9.55001295e-01,   4.42494452e-02,   7.49233819e-04]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52057958]\n",
      "[ 3222.6]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_xgb_cv137_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_mean_cv137_5blend_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../output/test_blend_xgb_gmean_cv137_5blend_BM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb,axis=0))\n",
    "print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,tmp_train, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,tmp_test_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,tmp_test_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "sub_name = '../output/sub_XGB_mean_BM_cv137_5blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(tmp_test_mean[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X_BM.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39300703,  0.5333155 ,  0.06647976],\n",
       "       [ 0.98636611,  0.00922575,  0.00406247],\n",
       "       [ 0.65414999,  0.29349853,  0.04406867],\n",
       "       ..., \n",
       "       [ 0.51356489,  0.42521578,  0.04422116],\n",
       "       [ 0.21262641,  0.46016629,  0.31441058],\n",
       "       [ 0.96598009,  0.03009712,  0.00326856]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_gmean[[\"low\", \"medium\", \"high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
