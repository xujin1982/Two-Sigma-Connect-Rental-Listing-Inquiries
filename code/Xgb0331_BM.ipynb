{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.stats.mstats import gmean\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import skew, boxcox,boxcox_normmax\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 412) (74659, 412) (49352,)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_X = pd.read_csv(data_path + 'train_BM_0331.csv')\n",
    "test_X = pd.read_csv(data_path + 'test_BM_0331.csv')\n",
    "train_y = np.ravel(pd.read_csv(data_path + 'labels_BrandenMurray.csv'))\n",
    "sub_id = test_X.listing_id.astype('int32').values\n",
    "# all_features = features_to_use + desc_sparse_cols + feat_sparse_cols\n",
    "print train_X.shape, test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39481, 412)\n",
      "(9871, 412)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "# xgtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rgr = xgb.XGBClassifier(objective = 'multi:softprob',\n",
    "#                        learning_rate = 0.1,\n",
    "#                        n_estimators = 10000,\n",
    "#                        nthread = -1,\n",
    "#                        max_depth=10)\n",
    "\n",
    "# rgr.fit(X_train,y_train,\n",
    "#         eval_set=[(X_val,y_val)],\n",
    "#         eval_metric='mlogloss',\n",
    "# #         num_class = 3,\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose=25\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pred_y = rgr.predict_proba(test_X, ntree_limit = rgr.best_iteration)\n",
    "# pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tune XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t0.53415 1712\n",
      "3 \t0.533524 757\n",
      "4 \t0.534241 466\n",
      "5 \t0.53388 367\n",
      "6 \t0.533953 271\n",
      "7 \t0.535565 189\n",
      "8 \t0.538649 153\n",
      "9 \t0.541866 125\n",
      "10 \t0.548011 76\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "best_score = 1000\n",
    "train_param = 0\n",
    "for x in [2,3,4,5,6,7,8,9,10]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= x,\n",
    "        nthread = -1,\n",
    "        silent = False\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# max_depth = train_param\n",
    "max_depth = 6\n",
    "print max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t0.53235 282\n",
      "4 \t0.532919 288\n",
      "8 \t0.53183 305\n",
      "12 \t0.531764 320\n",
      "16 \t0.532015 323\n",
      "20 \t0.531898 353\n",
      "24 \t0.532541 383\n",
      "28 \t0.533103 328\n",
      "32 \t0.53122 318\n",
      "40 \t0.532665 371\n",
      "48 \t0.531682 422\n",
      "64 \t0.530637 492\n",
      "128 \t0.532116 480\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [2,4,8,12,16,20,24,28,32,40,48,64,128]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 \t0.532236 423\n",
      "80 \t0.531871 301\n",
      "100 \t0.532396 484\n",
      "120 \t0.532189 424\n",
      "140 \t0.53347 487\n",
      "160 \t0.533486 528\n",
      "200 \t0.5388 490\n"
     ]
    }
   ],
   "source": [
    "train_param = 64\n",
    "for x in [75,80,100,120,140,160,200]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "min_child_weight = train_param\n",
    "print min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 \t0.533157 871\n",
      "0.1 \t0.530213 621\n",
      "0.2 \t0.526989 589\n",
      "0.3 \t0.527614 604\n",
      "0.4 \t0.52638 567\n",
      "0.5 \t0.528794 399\n",
      "0.6 \t0.529739 392\n",
      "0.7 \t0.528932 440\n",
      "0.8 \t0.530149 469\n",
      "0.9 \t0.530505 418\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = train_param\n",
    "print colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 \t0.535153 344\n",
      "0.6 \t0.533371 357\n",
      "0.7 \t0.532252 469\n",
      "0.8 \t0.531656 333\n",
      "0.9 \t0.530366 319\n"
     ]
    }
   ],
   "source": [
    "train_param = 1\n",
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        subsample = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "subsample = train_param\n",
    "print subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 \t0.527861 404\n",
      "0.6 \t0.528877 450\n",
      "0.9 \t0.527787 475\n",
      "1.2 \t0.529479 487\n",
      "1.5 \t0.528439 606\n",
      "1.8 \t0.528744 403\n",
      "2.1 \t0.52782 477\n",
      "2.4 \t0.529459 492\n",
      "2.7 \t0.528578 621\n",
      "3.0 \t0.530566 482\n"
     ]
    }
   ],
   "source": [
    "train_param = 0\n",
    "for x in [0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3.0]:\n",
    "    rgr = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        seed = 1234, # use a fixed seed during tuning so we can reproduce the results\n",
    "        learning_rate = learning_rate,\n",
    "        n_estimators = 10000,\n",
    "        max_depth= max_depth,\n",
    "        nthread = -1,\n",
    "        silent = False,\n",
    "        min_child_weight = min_child_weight,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        subsample = subsample,\n",
    "        gamma = x\n",
    "    )\n",
    "    rgr.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if rgr.best_score < best_score:\n",
    "        best_score = rgr.best_score\n",
    "        train_param = x\n",
    "        \n",
    "\n",
    "    print x, '\\t', rgr.best_score, rgr.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "gamma = train_param\n",
    "print gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.3 \t0.52431 436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[491]\ttrain-mlogloss:0.369143+0.00141556\ttest-mlogloss:0.524025+0.00535169\n",
      "\n",
      "    1 | 19m03s | \u001b[35m  -0.52402\u001b[0m | \u001b[32m            0.2598\u001b[0m | \u001b[32m   2.6639\u001b[0m | \u001b[32m     8.4837\u001b[0m | \u001b[32m           54.9284\u001b[0m | \u001b[32m     0.9771\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[299]\ttrain-mlogloss:0.319295+0.00100848\ttest-mlogloss:0.523601+0.00596716\n",
      "\n",
      "    2 | 13m47s | \u001b[35m  -0.52360\u001b[0m | \u001b[32m            0.3543\u001b[0m | \u001b[32m   0.9319\u001b[0m | \u001b[32m     7.3296\u001b[0m | \u001b[32m           12.3184\u001b[0m | \u001b[32m     0.9373\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[508]\ttrain-mlogloss:0.37262+0.00120878\ttest-mlogloss:0.52406+0.0051568\n",
      "\n",
      "    3 | 14m46s |   -0.52406 |             0.2567 |    1.8882 |      6.3925 |            42.6240 |      0.9534 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[547]\ttrain-mlogloss:0.345123+0.000651869\ttest-mlogloss:0.523982+0.00521109\n",
      "\n",
      "    4 | 13m20s |   -0.52398 |             0.2064 |    0.0926 |      5.6778 |             3.2073 |      0.8839 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[335]\ttrain-mlogloss:0.355865+0.00205579\ttest-mlogloss:0.526756+0.00584492\n",
      "\n",
      "    5 | 26m08s |   -0.52676 |             0.6514 |    0.9707 |      7.3048 |            52.4184 |      0.8504 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[406]\ttrain-mlogloss:0.38387+0.000759057\ttest-mlogloss:0.527834+0.00597442\n",
      "\n",
      "    6 | 36m04s |   -0.52783 |             0.7861 |    2.7741 |      7.8744 |            80.9856 |      0.7938 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[508]\ttrain-mlogloss:0.37036+0.00163233\ttest-mlogloss:0.525472+0.0052648\n",
      "\n",
      "    7 | 25m58s |   -0.52547 |             0.5172 |    0.5114 |      6.1878 |            79.4465 |      0.9286 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[332]\ttrain-mlogloss:0.353653+0.00155633\ttest-mlogloss:0.524804+0.00503928\n",
      "\n",
      "    8 | 16m51s |   -0.52480 |             0.3986 |    0.4585 |      7.2518 |            42.5487 |      0.8160 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[463]\ttrain-mlogloss:0.36961+0.00180028\ttest-mlogloss:0.525962+0.00534669\n",
      "\n",
      "    9 | 21m30s |   -0.52596 |             0.4487 |    1.8464 |      6.5127 |            50.4482 |      0.8735 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[565]\ttrain-mlogloss:0.397732+0.00134052\ttest-mlogloss:0.526315+0.00568737\n",
      "\n",
      "   10 | 32m59s |   -0.52631 |             0.7244 |    2.3952 |      5.0356 |            66.9681 |      0.8275 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1044]\ttrain-mlogloss:0.409964+0.00131725\ttest-mlogloss:0.527282+0.00553843\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00010951]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 19m48s |   -0.52728 |             0.2192 |    0.3522 |      4.0512 |            99.9218 |      0.9976 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[376]\ttrain-mlogloss:0.297039+0.00132814\ttest-mlogloss:0.523402+0.00485786\n",
      "\n",
      "   12 | 17m26s | \u001b[35m  -0.52340\u001b[0m | \u001b[32m            0.2558\u001b[0m | \u001b[32m   2.7017\u001b[0m | \u001b[32m     9.6630\u001b[0m | \u001b[32m            1.4767\u001b[0m | \u001b[32m     0.8498\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[412]\ttrain-mlogloss:0.356789+0.00118658\ttest-mlogloss:0.524028+0.0059227\n",
      "\n",
      "   13 | 15m51s |   -0.52403 |             0.2068 |    2.9092 |      9.9406 |            29.4807 |      0.8315 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[347]\ttrain-mlogloss:0.339617+0.00177375\ttest-mlogloss:0.525596+0.00534454\n",
      "\n",
      "   14 | 14m22s |   -0.52560 |             0.2324 |    0.4804 |      9.9278 |            71.0388 |      0.9296 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[934]\ttrain-mlogloss:0.40916+0.000588615\ttest-mlogloss:0.525345+0.00535134\n",
      "\n",
      "   15 | 20m41s |   -0.52534 |             0.2665 |    2.9725 |      4.0219 |             9.0597 |      0.7892 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[227]\ttrain-mlogloss:0.256531+0.00179822\ttest-mlogloss:0.526977+0.00613597\n",
      "\n",
      "   16 | 09m50s |   -0.52698 |             0.2064 |    0.0041 |      9.9893 |             9.8211 |      0.8819 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[803]\ttrain-mlogloss:0.392438+0.00154986\ttest-mlogloss:0.525328+0.00590749\n",
      "\n",
      "   17 | 15m33s |   -0.52533 |             0.2281 |    0.1376 |      4.2059 |            22.7611 |      0.9851 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[400]\ttrain-mlogloss:0.347816+0.00104789\ttest-mlogloss:0.526883+0.00536669\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -6.56931938e-05]), 'nit': 6, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 19m40s |   -0.52688 |             0.3053 |    0.0029 |      9.8138 |            98.5699 |      0.9853 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[332]\ttrain-mlogloss:0.343878+0.00116347\ttest-mlogloss:0.525954+0.00522726\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00043826]), 'nit': 6, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 36m37s |   -0.52595 |             0.7514 |    2.9370 |      9.9507 |            43.4940 |      0.9653 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[424]\ttrain-mlogloss:0.354516+0.00142327\ttest-mlogloss:0.524079+0.00535335\n",
      "\n",
      "   20 | 15m50s |   -0.52408 |             0.2414 |    2.8622 |      8.8889 |            18.1170 |      0.9892 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[699]\ttrain-mlogloss:0.435319+0.00117557\ttest-mlogloss:0.528053+0.00611008\n",
      "\n",
      "   21 | 13m08s |   -0.52805 |             0.2108 |    0.0327 |      4.9744 |            89.0565 |      0.9509 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[910]\ttrain-mlogloss:0.386042+0.000849827\ttest-mlogloss:0.524707+0.00502798\n",
      "\n",
      "   22 | 41m40s |   -0.52471 |             0.7300 |    2.6772 |      4.6909 |             1.0416 |      0.9526 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1277]\ttrain-mlogloss:0.41324+0.000726861\ttest-mlogloss:0.525421+0.00563471\n",
      "\n",
      "   23 | 24m25s |   -0.52542 |             0.2333 |    2.8300 |      4.1328 |            35.3088 |      0.9208 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[753]\ttrain-mlogloss:0.415752+0.00192638\ttest-mlogloss:0.526272+0.00529835\n",
      "\n",
      "   24 | 16m28s |   -0.52627 |             0.2766 |    0.1104 |      4.0162 |            59.5708 |      0.9937 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1116]\ttrain-mlogloss:0.432091+0.00124384\ttest-mlogloss:0.527147+0.00626104\n",
      "\n",
      "   25 | 22m38s |   -0.52715 |             0.2469 |    2.7598 |      4.1105 |            75.7769 |      0.8898 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[798]\ttrain-mlogloss:0.386941+0.000941617\ttest-mlogloss:0.525108+0.00553479\n",
      "\n",
      "   26 | 16m01s |   -0.52511 |             0.2418 |    0.1786 |      4.2562 |            14.7240 |      0.9844 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[580]\ttrain-mlogloss:0.36709+0.00086661\ttest-mlogloss:0.52509+0.00536862\n",
      "\n",
      "   27 | 22m28s |   -0.52509 |             0.2330 |    2.9389 |      9.8010 |            60.7356 |      0.9514 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[262]\ttrain-mlogloss:0.309578+0.00109071\ttest-mlogloss:0.524086+0.00523673\n",
      "\n",
      "   28 | 12m38s |   -0.52409 |             0.2627 |    0.1863 |      9.4721 |            33.9439 |      0.9803 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[203]\ttrain-mlogloss:0.26458+0.0024065\ttest-mlogloss:0.528026+0.00487423\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00014857]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 08m25s |   -0.52803 |             0.2196 |    0.1880 |      8.9031 |             1.0870 |      0.9877 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[562]\ttrain-mlogloss:0.339802+0.000969745\ttest-mlogloss:0.522373+0.00486769\n",
      "\n",
      "   30 | 21m19s | \u001b[35m  -0.52237\u001b[0m | \u001b[32m            0.2939\u001b[0m | \u001b[32m   2.9831\u001b[0m | \u001b[32m     7.3638\u001b[0m | \u001b[32m            5.2056\u001b[0m | \u001b[32m     0.9477\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[239]\ttrain-mlogloss:0.303319+0.000729387\ttest-mlogloss:0.525761+0.00488401\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00011646]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00014114]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 12m10s |   -0.52576 |             0.2635 |    0.0687 |      9.7298 |            23.5484 |      0.7600 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[443]\ttrain-mlogloss:0.379603+0.00106819\ttest-mlogloss:0.5258+0.00542867\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00017104]), 'nit': 5, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 15m31s |   -0.52580 |             0.2110 |    2.9076 |      8.9744 |            38.1256 |      0.7151 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[755]\ttrain-mlogloss:0.36593+0.00161783\ttest-mlogloss:0.526411+0.00510749\n",
      "\n",
      "   33 | 33m16s |   -0.52641 |             0.2847 |    2.7754 |      9.9386 |            99.8665 |      0.9590 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1049]\ttrain-mlogloss:0.347335+0.000984919\ttest-mlogloss:0.523264+0.00510022\n",
      "\n",
      "   34 | 25m06s |   -0.52326 |             0.2001 |    2.8727 |      6.8038 |             2.3888 |      0.9765 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[366]\ttrain-mlogloss:0.284038+0.00155563\ttest-mlogloss:0.5255+0.00490584\n",
      "\n",
      "   35 | 41m53s |   -0.52550 |             0.7868 |    2.9047 |      9.0844 |             3.7275 |      0.9691 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[783]\ttrain-mlogloss:0.398939+0.00105041\ttest-mlogloss:0.525543+0.00544005\n",
      "\n",
      "   36 | 15m48s |   -0.52554 |             0.2252 |    0.0727 |      4.2193 |            31.3365 |      0.8237 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[383]\ttrain-mlogloss:0.332347+0.000715384\ttest-mlogloss:0.524707+0.00584703\n",
      "\n",
      "   37 | 16m31s |   -0.52471 |             0.2322 |    2.9566 |      9.3483 |            11.9199 |      0.7973 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[341]\ttrain-mlogloss:0.348877+0.0011782\ttest-mlogloss:0.525871+0.0059912\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00033516]), 'nit': 6, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   38 | 14m26s |   -0.52587 |             0.2309 |    0.0019 |      9.9000 |            78.4521 |      0.9415 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[293]\ttrain-mlogloss:0.330222+0.00111667\ttest-mlogloss:0.525889+0.00588314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  6.44573593e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 12m02s |   -0.52589 |             0.2041 |    0.3891 |      9.8814 |            47.7581 |      0.8912 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1337]\ttrain-mlogloss:0.39829+0.000434908\ttest-mlogloss:0.524267+0.0053944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00083471]), 'nit': 3, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 | 23m44s |   -0.52427 |             0.2051 |    2.9612 |      4.0368 |             4.6387 |      0.8971 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1181]\ttrain-mlogloss:0.423+0.00120629\ttest-mlogloss:0.526558+0.00549919\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00044713]), 'nit': 3, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 22m37s |   -0.52656 |             0.2235 |    2.9391 |      4.0231 |            46.5912 |      0.7962 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[623]\ttrain-mlogloss:0.388245+0.00132764\ttest-mlogloss:0.523853+0.00510554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00049408]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00054218]), 'nit': 6, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 19m14s |   -0.52385 |             0.2732 |    2.9787 |      6.1874 |            25.2938 |      0.9831 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[919]\ttrain-mlogloss:0.406833+0.00171946\ttest-mlogloss:0.526366+0.00536774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00068085]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 | 17m00s |   -0.52637 |             0.2148 |    0.0822 |      4.3978 |            67.2873 |      0.9938 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[854]\ttrain-mlogloss:0.374183+0.00122259\ttest-mlogloss:0.524666+0.00570887\n",
      "\n",
      "   44 | 15m26s |   -0.52467 |             0.2012 |    0.0196 |      4.8042 |             7.7232 |      0.9656 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[835]\ttrain-mlogloss:0.395393+0.00129872\ttest-mlogloss:0.524719+0.00562002\n",
      "\n",
      "   45 | 19m34s |   -0.52472 |             0.2124 |    2.9960 |      5.7975 |            19.2861 |      0.7872 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[521]\ttrain-mlogloss:0.34812+0.000909827\ttest-mlogloss:0.523912+0.0061609\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00048139]), 'nit': 7, 'funcalls': 59}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 | 16m05s |   -0.52391 |             0.2089 |    2.8316 |      7.7883 |             8.0460 |      0.8411 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1274]\ttrain-mlogloss:0.389239+0.00207845\ttest-mlogloss:0.524654+0.00553646\n",
      "\n",
      "   47 | 29m47s |   -0.52465 |             0.2025 |    2.9862 |      6.0283 |            57.2058 |      0.9776 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[760]\ttrain-mlogloss:0.403392+0.00220186\ttest-mlogloss:0.5259+0.00552248\n",
      "\n",
      "   48 | 18m24s |   -0.52590 |             0.3094 |    0.2867 |      4.1067 |            40.2533 |      0.9836 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[478]\ttrain-mlogloss:0.334041+0.000844325\ttest-mlogloss:0.523989+0.00539789\n",
      "\n",
      "   49 | 15m36s |   -0.52399 |             0.2191 |    2.6496 |      7.2954 |             4.7286 |      0.7418 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[713]\ttrain-mlogloss:0.373496+0.000476789\ttest-mlogloss:0.52575+0.00572418\n",
      "\n",
      "   50 | 29m11s |   -0.52575 |             0.2598 |    2.8163 |      9.7388 |            90.5959 |      0.9998 | \n"
     ]
    }
   ],
   "source": [
    "xgtrain = xgb.DMatrix(train_X, label=train_y) \n",
    "\n",
    "def xgb_evaluate(min_child_weight, colsample_bytree, max_depth, subsample, gamma):\n",
    "    params = dict()\n",
    "    params['objective']='multi:softprob'\n",
    "    params['eval_metric']='mlogloss',\n",
    "    params['num_class']=3\n",
    "    params['silent']=1\n",
    "    params['eta'] = 0.1\n",
    "    params['verbose_eval'] = True\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    \n",
    "    cv_result = xgb.cv(\n",
    "        params, xgtrain, \n",
    "        num_boost_round=10000, nfold=5,\n",
    "        metrics = 'mlogloss',\n",
    "        seed=seed,callbacks=[xgb.callback.early_stop(50)]\n",
    "    )\n",
    "    \n",
    "    return -cv_result['test-mlogloss-mean'].values[-1]\n",
    "\n",
    "\n",
    "xgb_BO = BayesianOptimization(\n",
    "    xgb_evaluate, \n",
    "    {\n",
    "        'max_depth': (4,10),\n",
    "        'min_child_weight': (1,100),\n",
    "        'colsample_bytree': (0.2,0.8),\n",
    "        'subsample': (0.7,1),\n",
    "        'gamma': (0,3)\n",
    "    }\n",
    ")\n",
    "\n",
    "xgb_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>gamma</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.363771</td>\n",
       "      <td>5.205648</td>\n",
       "      <td>0.293906</td>\n",
       "      <td>0.947733</td>\n",
       "      <td>2.983057</td>\n",
       "      <td>-0.522373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.803827</td>\n",
       "      <td>2.388761</td>\n",
       "      <td>0.200079</td>\n",
       "      <td>0.976483</td>\n",
       "      <td>2.872736</td>\n",
       "      <td>-0.523264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.663005</td>\n",
       "      <td>1.476686</td>\n",
       "      <td>0.255750</td>\n",
       "      <td>0.849778</td>\n",
       "      <td>2.701710</td>\n",
       "      <td>-0.523402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.187359</td>\n",
       "      <td>25.293805</td>\n",
       "      <td>0.273249</td>\n",
       "      <td>0.983080</td>\n",
       "      <td>2.978747</td>\n",
       "      <td>-0.523853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7.788349</td>\n",
       "      <td>8.046040</td>\n",
       "      <td>0.208883</td>\n",
       "      <td>0.841063</td>\n",
       "      <td>2.831562</td>\n",
       "      <td>-0.523912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7.295389</td>\n",
       "      <td>4.728571</td>\n",
       "      <td>0.219052</td>\n",
       "      <td>0.741765</td>\n",
       "      <td>2.649557</td>\n",
       "      <td>-0.523989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.940602</td>\n",
       "      <td>29.480668</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.831500</td>\n",
       "      <td>2.909245</td>\n",
       "      <td>-0.524028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.888892</td>\n",
       "      <td>18.117018</td>\n",
       "      <td>0.241398</td>\n",
       "      <td>0.989176</td>\n",
       "      <td>2.862189</td>\n",
       "      <td>-0.524079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.472113</td>\n",
       "      <td>33.943859</td>\n",
       "      <td>0.262672</td>\n",
       "      <td>0.980347</td>\n",
       "      <td>0.186261</td>\n",
       "      <td>-0.524086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.036754</td>\n",
       "      <td>4.638651</td>\n",
       "      <td>0.205099</td>\n",
       "      <td>0.897103</td>\n",
       "      <td>2.961195</td>\n",
       "      <td>-0.524267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  colsample_bytree  subsample     gamma  \\\n",
       "19   7.363771          5.205648          0.293906   0.947733  2.983057   \n",
       "23   6.803827          2.388761          0.200079   0.976483  2.872736   \n",
       "1    9.663005          1.476686          0.255750   0.849778  2.701710   \n",
       "31   6.187359         25.293805          0.273249   0.983080  2.978747   \n",
       "35   7.788349          8.046040          0.208883   0.841063  2.831562   \n",
       "38   7.295389          4.728571          0.219052   0.741765  2.649557   \n",
       "2    9.940602         29.480668          0.206800   0.831500  2.909245   \n",
       "9    8.888892         18.117018          0.241398   0.989176  2.862189   \n",
       "17   9.472113         33.943859          0.262672   0.980347  0.186261   \n",
       "29   4.036754          4.638651          0.205099   0.897103  2.961195   \n",
       "\n",
       "       score  \n",
       "19 -0.522373  \n",
       "23 -0.523264  \n",
       "1  -0.523402  \n",
       "31 -0.523853  \n",
       "35 -0.523912  \n",
       "38 -0.523989  \n",
       "2  -0.524028  \n",
       "9  -0.524079  \n",
       "17 -0.524086  \n",
       "29 -0.524267  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bo_scores = pd.DataFrame([[s[0]['max_depth'],\n",
    "                               s[0]['min_child_weight'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[0]['gamma'],\n",
    "                               s[1]] for s in zip(xgb_BO.res['all']['params'],xgb_BO.res['all']['values'])],\n",
    "                            columns = ['max_depth',\n",
    "                                       'min_child_weight',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'gamma',\n",
    "                                       'score'])\n",
    "xgb_bo_scores=xgb_bo_scores.sort_values('score',ascending=False)\n",
    "xgb_bo_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = test_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_loc_price_diff</th>\n",
       "      <th>num_price</th>\n",
       "      <th>num_loc_median_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>-49.5</td>\n",
       "      <td>2600</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>-500.0</td>\n",
       "      <td>2750</td>\n",
       "      <td>3250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>5700.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>7200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>-1555.0</td>\n",
       "      <td>4195</td>\n",
       "      <td>5750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>4200</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>-3464.0</td>\n",
       "      <td>2300</td>\n",
       "      <td>5764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>4200.0</td>\n",
       "      <td>6500</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>3275.0</td>\n",
       "      <td>6200</td>\n",
       "      <td>2925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>-1169.0</td>\n",
       "      <td>4595</td>\n",
       "      <td>5764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>-955.0</td>\n",
       "      <td>3995</td>\n",
       "      <td>4950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8096</th>\n",
       "      <td>4825.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8401</th>\n",
       "      <td>-350.0</td>\n",
       "      <td>3650</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8585</th>\n",
       "      <td>-1237.5</td>\n",
       "      <td>2700</td>\n",
       "      <td>3937.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8746</th>\n",
       "      <td>720.0</td>\n",
       "      <td>5895</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9409</th>\n",
       "      <td>-449.0</td>\n",
       "      <td>2250</td>\n",
       "      <td>2699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037</th>\n",
       "      <td>-1250.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>3850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>-198.0</td>\n",
       "      <td>4977</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10307</th>\n",
       "      <td>-250.0</td>\n",
       "      <td>3750</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11706</th>\n",
       "      <td>-1400.0</td>\n",
       "      <td>4325</td>\n",
       "      <td>5725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12982</th>\n",
       "      <td>-575.0</td>\n",
       "      <td>4600</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13114</th>\n",
       "      <td>950.0</td>\n",
       "      <td>3700</td>\n",
       "      <td>2750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>-49.5</td>\n",
       "      <td>2600</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14186</th>\n",
       "      <td>-455.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>2450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14525</th>\n",
       "      <td>-250.0</td>\n",
       "      <td>3750</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15371</th>\n",
       "      <td>-837.5</td>\n",
       "      <td>3100</td>\n",
       "      <td>3937.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>-2000.0</td>\n",
       "      <td>5200</td>\n",
       "      <td>7200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15634</th>\n",
       "      <td>-437.5</td>\n",
       "      <td>3500</td>\n",
       "      <td>3937.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16095</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2850</td>\n",
       "      <td>2750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250</th>\n",
       "      <td>795.0</td>\n",
       "      <td>2995</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45851</th>\n",
       "      <td>-255.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>2750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46268</th>\n",
       "      <td>-154.5</td>\n",
       "      <td>2495</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47001</th>\n",
       "      <td>110.0</td>\n",
       "      <td>2410</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48562</th>\n",
       "      <td>-449.0</td>\n",
       "      <td>2250</td>\n",
       "      <td>2699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49191</th>\n",
       "      <td>1767.0</td>\n",
       "      <td>6942</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50883</th>\n",
       "      <td>-105.0</td>\n",
       "      <td>2095</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51757</th>\n",
       "      <td>-254.5</td>\n",
       "      <td>2395</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52355</th>\n",
       "      <td>1152.5</td>\n",
       "      <td>4500</td>\n",
       "      <td>3347.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53231</th>\n",
       "      <td>805.0</td>\n",
       "      <td>4400</td>\n",
       "      <td>3595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54106</th>\n",
       "      <td>-254.5</td>\n",
       "      <td>2395</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55155</th>\n",
       "      <td>105.0</td>\n",
       "      <td>5800</td>\n",
       "      <td>5695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55392</th>\n",
       "      <td>-1037.5</td>\n",
       "      <td>2900</td>\n",
       "      <td>3937.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55403</th>\n",
       "      <td>-901.0</td>\n",
       "      <td>3208</td>\n",
       "      <td>4109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55608</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>7200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56876</th>\n",
       "      <td>-6205.0</td>\n",
       "      <td>3795</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56881</th>\n",
       "      <td>270.0</td>\n",
       "      <td>2970</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57071</th>\n",
       "      <td>452.5</td>\n",
       "      <td>3800</td>\n",
       "      <td>3347.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58290</th>\n",
       "      <td>-105.0</td>\n",
       "      <td>2095</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59732</th>\n",
       "      <td>3725.0</td>\n",
       "      <td>7000</td>\n",
       "      <td>3275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61119</th>\n",
       "      <td>5651.5</td>\n",
       "      <td>8999</td>\n",
       "      <td>3347.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61426</th>\n",
       "      <td>300.0</td>\n",
       "      <td>3025</td>\n",
       "      <td>2725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65689</th>\n",
       "      <td>276.0</td>\n",
       "      <td>2950</td>\n",
       "      <td>2674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66961</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2300</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67319</th>\n",
       "      <td>-198.0</td>\n",
       "      <td>4977</td>\n",
       "      <td>5175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67678</th>\n",
       "      <td>-254.5</td>\n",
       "      <td>2395</td>\n",
       "      <td>2649.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67683</th>\n",
       "      <td>3720.0</td>\n",
       "      <td>6995</td>\n",
       "      <td>3275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68048</th>\n",
       "      <td>-608.0</td>\n",
       "      <td>2292</td>\n",
       "      <td>2900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70205</th>\n",
       "      <td>1650.0</td>\n",
       "      <td>7150</td>\n",
       "      <td>5500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70245</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>7200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71754</th>\n",
       "      <td>600.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_loc_price_diff  num_price  num_loc_median_price\n",
       "710                 -49.5       2600                2649.5\n",
       "779                -500.0       2750                3250.0\n",
       "988                5700.0       8000                2300.0\n",
       "1542               2800.0      10000                7200.0\n",
       "2099              -1555.0       4195                5750.0\n",
       "3447               -200.0       4200                4400.0\n",
       "3697              -3464.0       2300                5764.0\n",
       "4662               4200.0       6500                2300.0\n",
       "4669               3275.0       6200                2925.0\n",
       "4689              -1169.0       4595                5764.0\n",
       "7145               -955.0       3995                4950.0\n",
       "8096               4825.0      10000                5175.0\n",
       "8401               -350.0       3650                4000.0\n",
       "8585              -1237.5       2700                3937.5\n",
       "8746                720.0       5895                5175.0\n",
       "9409               -449.0       2250                2699.0\n",
       "10037             -1250.0       2600                3850.0\n",
       "10160              -198.0       4977                5175.0\n",
       "10307              -250.0       3750                4000.0\n",
       "11706             -1400.0       4325                5725.0\n",
       "12982              -575.0       4600                5175.0\n",
       "13114               950.0       3700                2750.0\n",
       "13144               -49.5       2600                2649.5\n",
       "14186              -455.0       1995                2450.0\n",
       "14525              -250.0       3750                4000.0\n",
       "15371              -837.5       3100                3937.5\n",
       "15451             -2000.0       5200                7200.0\n",
       "15634              -437.5       3500                3937.5\n",
       "16095               100.0       2850                2750.0\n",
       "16250               795.0       2995                2200.0\n",
       "...                   ...        ...                   ...\n",
       "45851              -255.0       2495                2750.0\n",
       "46268              -154.5       2495                2649.5\n",
       "47001               110.0       2410                2300.0\n",
       "48562              -449.0       2250                2699.0\n",
       "49191              1767.0       6942                5175.0\n",
       "50883              -105.0       2095                2200.0\n",
       "51757              -254.5       2395                2649.5\n",
       "52355              1152.5       4500                3347.5\n",
       "53231               805.0       4400                3595.0\n",
       "54106              -254.5       2395                2649.5\n",
       "55155               105.0       5800                5695.0\n",
       "55392             -1037.5       2900                3937.5\n",
       "55403              -901.0       3208                4109.0\n",
       "55608              2800.0      10000                7200.0\n",
       "56876             -6205.0       3795               10000.0\n",
       "56881               270.0       2970                2700.0\n",
       "57071               452.5       3800                3347.5\n",
       "58290              -105.0       2095                2200.0\n",
       "59732              3725.0       7000                3275.0\n",
       "61119              5651.5       8999                3347.5\n",
       "61426               300.0       3025                2725.0\n",
       "65689               276.0       2950                2674.0\n",
       "66961               305.0       2300                1995.0\n",
       "67319              -198.0       4977                5175.0\n",
       "67678              -254.5       2395                2649.5\n",
       "67683              3720.0       6995                3275.0\n",
       "68048              -608.0       2292                2900.0\n",
       "70205              1650.0       7150                5500.0\n",
       "70245              2800.0      10000                7200.0\n",
       "71754               600.0       5000                4400.0\n",
       "\n",
       "[115 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_ind = test_X.num_loc_price_diff.isnull()\n",
    "test_X['num_loc_price_diff'] = test_X['num_price'] - test_X['num_loc_median_price']\n",
    "test_X[null_ind][['num_loc_price_diff','num_price','num_loc_median_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgb_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    N_params = len(estimators)\n",
    "    print (\"Blend %d estimators for %d folds\" % (N_params, fold))\n",
    "    skf = KFold(n_splits=fold,random_state=5555)\n",
    "    N_class = len(set(train_y))\n",
    "        \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_mean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    test_blend_x_gmean = np.zeros((test_x.shape[0], N_class*N_params))\n",
    "    scores = np.zeros ((fold,N_params))\n",
    "    best_rounds = np.zeros ((fold, N_params))\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        est.set_params(objective = 'multi:softprob')\n",
    "        est.set_params(silent = False)\n",
    "        est.set_params(learning_rate = 0.02)\n",
    "        est.set_params(n_estimators=100000)\n",
    "        \n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*fold))\n",
    "    \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train_x)):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x.iloc[train_index]\n",
    "            train_y_fold = train_y[train_index]\n",
    "            val_x_fold = train_x.iloc[val_index]\n",
    "            val_y_fold = train_y[val_index]      \n",
    "\n",
    "            est.fit(train_x_fold,train_y_fold,\n",
    "                    eval_set = [(val_x_fold, val_y_fold)],\n",
    "                    eval_metric = 'mlogloss',\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose=False)\n",
    "            best_round=est.best_iteration\n",
    "            best_rounds[i,j]=best_round\n",
    "            print (\"best round %d\" % (best_round))\n",
    "            val_y_predict_fold = est.predict_proba(val_x_fold,ntree_limit=best_round)\n",
    "            score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "            print (\"Score: \", score)\n",
    "            scores[i,j]=score\n",
    "            train_blend_x[val_index, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "            \n",
    "            test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,ntree_limit=best_round)\n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            \n",
    "        test_blend_x_mean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([test_blend_x_j[:,range(0,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(1,N_class*fold,N_class)].mean(1),\n",
    "                          test_blend_x_j[:,range(2,N_class*fold,N_class)].mean(1)]).T\n",
    "        \n",
    "        test_blend_x_gmean[:,(j*N_class):(j+1)*N_class] = \\\n",
    "                np.stack([gmean(test_blend_x_j[:,range(0,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(1,N_class*fold,N_class)], axis=1),\n",
    "                          gmean(test_blend_x_j[:,range(2,N_class*fold,N_class)], axis=1)]).T\n",
    "            \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x_mean, test_blend_x_gmean, scores,best_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 1 estimators for 30 folds\n",
      "Model 1: XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.262672,\n",
      "       gamma=0.186261, learning_rate=0.02, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=33, missing=None, n_estimators=100000, nthread=-1,\n",
      "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=False, subsample=0.980347)\n",
      "Model 1 fold 1\n",
      "best round 1710\n",
      "('Score: ', 0.52962694755729511)\n",
      "Model 1 fold 1 fitting finished in 1241.869s\n",
      "Model 1 fold 2\n",
      "best round 1391\n",
      "('Score: ', 0.50391127368957611)\n",
      "Model 1 fold 2 fitting finished in 1057.409s\n",
      "Model 1 fold 3\n",
      "best round 2524\n",
      "('Score: ', 0.47359197539021541)\n",
      "Model 1 fold 3 fitting finished in 1677.893s\n",
      "Model 1 fold 4\n",
      "best round 2337\n",
      "('Score: ', 0.492760497293112)\n",
      "Model 1 fold 4 fitting finished in 1574.285s\n",
      "Model 1 fold 5\n",
      "best round 2885\n",
      "('Score: ', 0.48593347557063327)\n",
      "Model 1 fold 5 fitting finished in 1895.388s\n",
      "Model 1 fold 6\n",
      "best round 2480\n",
      "('Score: ', 0.47724336931319367)\n",
      "Model 1 fold 6 fitting finished in 1649.978s\n",
      "Model 1 fold 7\n",
      "best round 2197\n",
      "('Score: ', 0.5174832704564678)\n",
      "Model 1 fold 7 fitting finished in 1497.076s\n",
      "Model 1 fold 8\n",
      "best round 1466\n",
      "('Score: ', 0.51170943547581604)\n",
      "Model 1 fold 8 fitting finished in 1089.575s\n",
      "Model 1 fold 9\n",
      "best round 1425\n",
      "('Score: ', 0.51336960725119696)\n",
      "Model 1 fold 9 fitting finished in 1066.811s\n",
      "Model 1 fold 10\n",
      "best round 1830\n",
      "('Score: ', 0.4746154093882069)\n",
      "Model 1 fold 10 fitting finished in 1291.665s\n",
      "Model 1 fold 11\n",
      "best round 2087\n",
      "('Score: ', 0.48764657532974248)\n",
      "Model 1 fold 11 fitting finished in 1433.431s\n",
      "Model 1 fold 12\n",
      "best round 1856\n",
      "('Score: ', 0.51660226199103276)\n",
      "Model 1 fold 12 fitting finished in 1306.845s\n",
      "Model 1 fold 13\n",
      "best round 1735\n",
      "('Score: ', 0.53030868579276502)\n",
      "Model 1 fold 13 fitting finished in 1241.206s\n",
      "Model 1 fold 14\n",
      "best round 1520\n",
      "('Score: ', 0.51065818866243162)\n",
      "Model 1 fold 14 fitting finished in 1123.487s\n",
      "Model 1 fold 15\n",
      "best round 1624\n",
      "('Score: ', 0.53908897713661807)\n",
      "Model 1 fold 15 fitting finished in 1177.293s\n",
      "Model 1 fold 16\n",
      "best round 1963\n",
      "('Score: ', 0.50365246011453435)\n",
      "Model 1 fold 16 fitting finished in 1369.861s\n",
      "Model 1 fold 17\n",
      "best round 1263\n",
      "('Score: ', 0.52222339881972923)\n",
      "Model 1 fold 17 fitting finished in 976.346s\n",
      "Model 1 fold 18\n",
      "best round 1819\n",
      "('Score: ', 0.50647430901281543)\n",
      "Model 1 fold 18 fitting finished in 1293.278s\n",
      "Model 1 fold 19\n",
      "best round 2479\n",
      "('Score: ', 0.50483915752945874)\n",
      "Model 1 fold 19 fitting finished in 1652.348s\n",
      "Model 1 fold 20\n",
      "best round 1680\n",
      "('Score: ', 0.52869502660577072)\n",
      "Model 1 fold 20 fitting finished in 1210.637s\n",
      "Model 1 fold 21\n",
      "best round 1357\n",
      "('Score: ', 0.55216817826985898)\n",
      "Model 1 fold 21 fitting finished in 1046.002s\n",
      "Model 1 fold 22\n",
      "best round 1263\n",
      "('Score: ', 0.53871609702247047)\n",
      "Model 1 fold 22 fitting finished in 977.698s\n",
      "Model 1 fold 23\n",
      "best round 2630\n",
      "('Score: ', 0.53316083379180679)\n",
      "Model 1 fold 23 fitting finished in 1740.730s\n",
      "Model 1 fold 24\n",
      "best round 2156\n",
      "('Score: ', 0.53749607309416336)\n",
      "Model 1 fold 24 fitting finished in 1483.307s\n",
      "Model 1 fold 25\n",
      "best round 3433\n",
      "('Score: ', 0.51272781786706922)\n",
      "Model 1 fold 25 fitting finished in 2176.915s\n",
      "Model 1 fold 26\n",
      "best round 1265\n",
      "('Score: ', 0.52882617081462058)\n",
      "Model 1 fold 26 fitting finished in 980.941s\n",
      "Model 1 fold 27\n",
      "best round 1329\n",
      "('Score: ', 0.54216425422829218)\n",
      "Model 1 fold 27 fitting finished in 1016.350s\n",
      "Model 1 fold 28\n",
      "best round 2775\n",
      "('Score: ', 0.51214382858326535)\n",
      "Model 1 fold 28 fitting finished in 1819.694s\n",
      "Model 1 fold 29\n",
      "best round 1914\n",
      "('Score: ', 0.50892019027233337)\n",
      "Model 1 fold 29 fitting finished in 1339.520s\n",
      "Model 1 fold 30\n",
      "best round 1517\n",
      "('Score: ', 0.53568730757431637)\n",
      "Model 1 fold 30 fitting finished in 1120.133s\n",
      "Score for model 1 is 0.514415\n",
      "Score for blended models is 0.514415\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "#             xgb.XGBClassifier(max_depth = 7,\n",
    "#                               min_child_weight = 5,\n",
    "#                               colsample_bytree = 0.293906 ,\n",
    "#                               subsample = 0.947733 ,\n",
    "#                               gamma = 2.983057),\n",
    "#              xgb.XGBClassifier(max_depth = 6,\n",
    "#                               min_child_weight = 2,\n",
    "#                               colsample_bytree = 0.200079,\n",
    "#                               subsample = 0.976483,\n",
    "#                               gamma = 2.872736),\n",
    "#              xgb.XGBClassifier(max_depth = 6,\n",
    "#                               min_child_weight = 25,\n",
    "#                               colsample_bytree = 0.273249,\n",
    "#                               subsample = 0.983080,\n",
    "#                               gamma = 2.978747),         \n",
    "#              xgb.XGBClassifier(max_depth = 7,\n",
    "#                               min_child_weight = 4,\n",
    "#                               colsample_bytree = 0.219052,\n",
    "#                               subsample = 0.741765,\n",
    "#                               gamma = 2.649557),  \n",
    "             xgb.XGBClassifier(max_depth = 9,\n",
    "                              min_child_weight = 33,\n",
    "                              colsample_bytree = 0.262672,\n",
    "                              subsample = 0.980347,\n",
    "                              gamma = 0.186261)              \n",
    "             ]\n",
    "\n",
    "#  \t \tmax_depth \tmin_child_weight \tcolsample_bytree \tsubsample \tgamma \tscore\n",
    "# 19 \t7.363771 \t5.205648 \t \t \t0.293906 \t \t \t0.947733 \t2.983057 \t-0.522373\n",
    "# 23 \t6.803827 \t2.388761 \t \t \t0.200079 \t \t \t0.976483 \t2.872736 \t-0.523264\n",
    "####### 1 \t9.663005 \t1.476686 \t \t \t0.255750 \t \t \t0.849778 \t2.701710 \t-0.523402\n",
    "# 31 \t6.187359 \t25.293805 \t \t \t0.273249 \t \t \t0.983080 \t2.978747 \t-0.523853\n",
    "####### 35 \t7.788349 \t8.046040 \t \t \t0.208883 \t \t \t0.841063 \t2.831562 \t-0.523912\n",
    "# 38 \t7.295389 \t4.728571 \t \t \t0.219052 \t \t \t0.741765 \t2.649557 \t-0.523989\n",
    "####### 2 \t9.940602 \t29.480668 \t \t \t0.206800 \t \t \t0.831500 \t2.909245 \t-0.524028\n",
    "####### 9 \t8.888892 \t18.117018 \t \t \t0.241398 \t \t \t0.989176 \t2.862189 \t-0.524079\n",
    "# 17 \t9.472113 \t33.943859 \t \t \t0.262672 \t \t \t0.980347 \t0.186261 \t-0.524086\n",
    "\n",
    "(train_blend_x_xgb,\n",
    " test_blend_x_xgb_mean,\n",
    " test_blend_x_xgb_gmean,\n",
    " blend_scores_xgb,\n",
    " best_rounds_xgb) = xgb_blend(estimators,\n",
    "                              train_X,train_y,\n",
    "                              test_X,\n",
    "                              30,\n",
    "                              500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51441484]\n",
      "[ 1930.33333333]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_xgb_BM_0331_30blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_mean = '../output/test_blend_xgb_mean_BM_0331_30blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend_gmean = '../output/test_blend_xgb_gmean_BM_0331_30blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_xgb,axis=0))\n",
    "print (np.mean(best_rounds_xgb,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_xgb, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_mean,test_blend_x_xgb_mean, delimiter=\",\")\n",
    "np.savetxt(name_test_blend_gmean,test_blend_x_xgb_gmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data 0322\n",
    "# [ 0.52385999  0.52420308  0.52429754  0.52366222  0.52450185]\n",
    "# [ 2866.7  3979.7  3102.9  2783.1  4450.5]\n",
    "\n",
    "# data 0331 seed = 2017\n",
    "# [ 0.5161796   0.51727863  0.51867825  0.517129    0.51732854]\n",
    "# [ 4857.5  6379.5  5516.4  3337.9  1674.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "sub_name = '../output/sub_XGB_mean_BM_0331_30blend_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "out_df = pd.DataFrame(test_blend_x_xgb_mean[:,:3])\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = test_X.listing_id.values\n",
    "out_df.to_csv(sub_name, index=False)\n",
    "\n",
    "\n",
    "# ypreds.columns = cols\n",
    "\n",
    "# df = pd.read_json(open(\"../input/test.json\", \"r\"))\n",
    "# ypreds['listing_id'] = df[\"listing_id\"]\n",
    "\n",
    "# ypreds.to_csv('my_preds.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.20544260e-01,   6.10888687e-01,   6.56750820e-02],\n",
       "       [  9.66028463e-01,   2.30937453e-02,   1.06505838e-02],\n",
       "       [  9.53579737e-01,   4.13955017e-02,   3.97691225e-03],\n",
       "       ..., \n",
       "       [  9.78252564e-01,   2.03241753e-02,   1.01263996e-03],\n",
       "       [  9.71474749e-01,   2.74180665e-02,   5.09567844e-04],\n",
       "       [  5.87161787e-01,   3.92164954e-01,   1.94305868e-02]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_gmean[:,9:12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.20994298e-01,   6.04517100e-01,   7.12524217e-02],\n",
       "       [  9.57150480e-01,   3.01748109e-02,   1.18646473e-02],\n",
       "       [  9.58178383e-01,   3.74607705e-02,   3.46537444e-03],\n",
       "       ..., \n",
       "       [  9.80787885e-01,   1.80516908e-02,   8.23179767e-04],\n",
       "       [  9.70638017e-01,   2.80394743e-02,   5.14503672e-04],\n",
       "       [  5.81934901e-01,   3.95535699e-01,   2.09051621e-02]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blend_x_xgb_gmean[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
