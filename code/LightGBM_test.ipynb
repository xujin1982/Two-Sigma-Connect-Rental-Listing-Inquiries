{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, KFold\n",
    "from scipy import sparse\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 45) (74659, 44)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle('../input/' + 'train_2017-02-16-20-51.pkl')\n",
    "test = pd.read_pickle('../input/' + 'test_2017-02-16-20-51.pkl')\n",
    "features_to_use = pd.read_pickle('../input/' + 'featurestouse_2017-02-16-20-51.pkl')\n",
    "# sparse_cols = pd.read_pickle('../input/' + 'sparse_2017-02-16-20-51.pkl')\n",
    "tr_sparse = pd.read_pickle('../input/' + 'tr_sparse_2017-02-16-20-51.pkl')\n",
    "te_sparse = pd.read_pickle('../input/' + 'te_sparse_2017-02-16-20-51.pkl')\n",
    "\n",
    "\n",
    "test_listing = pd.read_pickle('../input/' + 'listing_id.pkl')\n",
    "\n",
    "train_y = pd.read_pickle('../input/' + 'y_2017-02-16-20-51.pkl') \n",
    "print train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features_to_use.extend(['building_id','display_address','manager_id','street_address'])\n",
    "# for x in ['display_address_lbl', 'manager_id_lbl', 'building_id_lbl', 'street_address_lbl']:\n",
    "#     features_to_use.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = pd.concat([train[features_to_use], pd.DataFrame(tr_sparse.toarray())],axis=1)\n",
    "test_X = pd.concat([test[features_to_use], pd.DataFrame(te_sparse.toarray())],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del train,test,tr_sparse,te_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_dataset = lgb.Dataset(train_X,train_y)\n",
    "# cv_data = lgb.Dataset.create_valid(data = train_X,label = train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'max_bin':5,\n",
    "          'num_leaves':8,\n",
    "          'min_child_samples':150,\n",
    "         'objective':'multiclass',\n",
    "         'num_class':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tcv_agg's multi_logloss: 1.03643 + 0.000114533\n",
      "[2]\tcv_agg's multi_logloss: 0.984239 + 0.000178832\n",
      "[3]\tcv_agg's multi_logloss: 0.939983 + 0.000222607\n",
      "[4]\tcv_agg's multi_logloss: 0.901893 + 0.000317201\n",
      "[5]\tcv_agg's multi_logloss: 0.869156 + 0.000500942\n",
      "[6]\tcv_agg's multi_logloss: 0.84065 + 0.000562989\n",
      "[7]\tcv_agg's multi_logloss: 0.81588 + 0.000604881\n",
      "[8]\tcv_agg's multi_logloss: 0.794246 + 0.000711204\n",
      "[9]\tcv_agg's multi_logloss: 0.775291 + 0.00078676\n",
      "[10]\tcv_agg's multi_logloss: 0.758528 + 0.000867948\n",
      "[11]\tcv_agg's multi_logloss: 0.743818 + 0.000935069\n",
      "[12]\tcv_agg's multi_logloss: 0.730279 + 0.00114965\n",
      "[13]\tcv_agg's multi_logloss: 0.718329 + 0.00121912\n",
      "[14]\tcv_agg's multi_logloss: 0.707601 + 0.00124985\n",
      "[15]\tcv_agg's multi_logloss: 0.698005 + 0.00124951\n",
      "[16]\tcv_agg's multi_logloss: 0.689179 + 0.0014847\n",
      "[17]\tcv_agg's multi_logloss: 0.68134 + 0.00166939\n",
      "[18]\tcv_agg's multi_logloss: 0.67432 + 0.00168522\n",
      "[19]\tcv_agg's multi_logloss: 0.667763 + 0.00175643\n",
      "[20]\tcv_agg's multi_logloss: 0.661658 + 0.00191422\n",
      "[21]\tcv_agg's multi_logloss: 0.65622 + 0.0020384\n",
      "[22]\tcv_agg's multi_logloss: 0.651205 + 0.0020382\n",
      "[23]\tcv_agg's multi_logloss: 0.646686 + 0.00224124\n",
      "[24]\tcv_agg's multi_logloss: 0.642345 + 0.00227375\n",
      "[25]\tcv_agg's multi_logloss: 0.638487 + 0.00228346\n",
      "[26]\tcv_agg's multi_logloss: 0.634967 + 0.00225853\n",
      "[27]\tcv_agg's multi_logloss: 0.631589 + 0.00235975\n",
      "[28]\tcv_agg's multi_logloss: 0.628551 + 0.0022914\n",
      "[29]\tcv_agg's multi_logloss: 0.625703 + 0.00231006\n",
      "[30]\tcv_agg's multi_logloss: 0.62298 + 0.00241978\n",
      "[31]\tcv_agg's multi_logloss: 0.620615 + 0.00250945\n",
      "[32]\tcv_agg's multi_logloss: 0.618275 + 0.00265958\n",
      "[33]\tcv_agg's multi_logloss: 0.61607 + 0.0026696\n",
      "[34]\tcv_agg's multi_logloss: 0.614025 + 0.00268707\n",
      "[35]\tcv_agg's multi_logloss: 0.61203 + 0.00272773\n",
      "[36]\tcv_agg's multi_logloss: 0.610238 + 0.00273869\n",
      "[37]\tcv_agg's multi_logloss: 0.608461 + 0.00278807\n",
      "[38]\tcv_agg's multi_logloss: 0.606843 + 0.00283224\n",
      "[39]\tcv_agg's multi_logloss: 0.605307 + 0.00286444\n",
      "[40]\tcv_agg's multi_logloss: 0.603827 + 0.0028583\n",
      "[41]\tcv_agg's multi_logloss: 0.602438 + 0.00290372\n",
      "[42]\tcv_agg's multi_logloss: 0.601114 + 0.00291446\n",
      "[43]\tcv_agg's multi_logloss: 0.599847 + 0.00296285\n",
      "[44]\tcv_agg's multi_logloss: 0.598635 + 0.00293049\n",
      "[45]\tcv_agg's multi_logloss: 0.597457 + 0.00300083\n",
      "[46]\tcv_agg's multi_logloss: 0.596388 + 0.00303298\n",
      "[47]\tcv_agg's multi_logloss: 0.595297 + 0.00309738\n",
      "[48]\tcv_agg's multi_logloss: 0.594242 + 0.00308103\n",
      "[49]\tcv_agg's multi_logloss: 0.593253 + 0.00308257\n",
      "[50]\tcv_agg's multi_logloss: 0.592291 + 0.00313594\n",
      "[51]\tcv_agg's multi_logloss: 0.591339 + 0.0031492\n",
      "[52]\tcv_agg's multi_logloss: 0.590498 + 0.00308529\n",
      "[53]\tcv_agg's multi_logloss: 0.589709 + 0.00310847\n",
      "[54]\tcv_agg's multi_logloss: 0.588879 + 0.00306834\n",
      "[55]\tcv_agg's multi_logloss: 0.588135 + 0.00309586\n",
      "[56]\tcv_agg's multi_logloss: 0.587263 + 0.00313387\n",
      "[57]\tcv_agg's multi_logloss: 0.586537 + 0.00319758\n",
      "[58]\tcv_agg's multi_logloss: 0.58588 + 0.00321181\n",
      "[59]\tcv_agg's multi_logloss: 0.58514 + 0.00324632\n",
      "[60]\tcv_agg's multi_logloss: 0.584423 + 0.00322496\n",
      "[61]\tcv_agg's multi_logloss: 0.583802 + 0.00326471\n",
      "[62]\tcv_agg's multi_logloss: 0.583198 + 0.00332429\n",
      "[63]\tcv_agg's multi_logloss: 0.582597 + 0.00335436\n",
      "[64]\tcv_agg's multi_logloss: 0.581964 + 0.00332594\n",
      "[65]\tcv_agg's multi_logloss: 0.581441 + 0.0032999\n",
      "[66]\tcv_agg's multi_logloss: 0.58083 + 0.0032814\n",
      "[67]\tcv_agg's multi_logloss: 0.580311 + 0.00326205\n",
      "[68]\tcv_agg's multi_logloss: 0.579683 + 0.0032646\n",
      "[69]\tcv_agg's multi_logloss: 0.579148 + 0.00330088\n",
      "[70]\tcv_agg's multi_logloss: 0.578679 + 0.00325654\n",
      "[71]\tcv_agg's multi_logloss: 0.578229 + 0.00325592\n",
      "[72]\tcv_agg's multi_logloss: 0.577676 + 0.00329238\n",
      "[73]\tcv_agg's multi_logloss: 0.577138 + 0.00333268\n",
      "[74]\tcv_agg's multi_logloss: 0.576742 + 0.00330441\n",
      "[75]\tcv_agg's multi_logloss: 0.576266 + 0.00332563\n",
      "[76]\tcv_agg's multi_logloss: 0.575819 + 0.00340965\n",
      "[77]\tcv_agg's multi_logloss: 0.575406 + 0.00337637\n",
      "[78]\tcv_agg's multi_logloss: 0.575019 + 0.00338518\n",
      "[79]\tcv_agg's multi_logloss: 0.574579 + 0.00339933\n",
      "[80]\tcv_agg's multi_logloss: 0.574177 + 0.00340748\n",
      "[81]\tcv_agg's multi_logloss: 0.573774 + 0.00341404\n",
      "[82]\tcv_agg's multi_logloss: 0.573381 + 0.0034282\n",
      "[83]\tcv_agg's multi_logloss: 0.572897 + 0.00340076\n",
      "[84]\tcv_agg's multi_logloss: 0.572505 + 0.0034604\n",
      "[85]\tcv_agg's multi_logloss: 0.572104 + 0.00352081\n",
      "[86]\tcv_agg's multi_logloss: 0.571747 + 0.00349674\n",
      "[87]\tcv_agg's multi_logloss: 0.571421 + 0.00350381\n",
      "[88]\tcv_agg's multi_logloss: 0.571093 + 0.00349621\n",
      "[89]\tcv_agg's multi_logloss: 0.570761 + 0.00351337\n",
      "[90]\tcv_agg's multi_logloss: 0.570392 + 0.00343498\n",
      "[91]\tcv_agg's multi_logloss: 0.570089 + 0.00347649\n",
      "[92]\tcv_agg's multi_logloss: 0.569738 + 0.00346234\n",
      "[93]\tcv_agg's multi_logloss: 0.569433 + 0.00348989\n",
      "[94]\tcv_agg's multi_logloss: 0.569106 + 0.00349455\n",
      "[95]\tcv_agg's multi_logloss: 0.568785 + 0.00355172\n",
      "[96]\tcv_agg's multi_logloss: 0.568468 + 0.00360511\n",
      "[97]\tcv_agg's multi_logloss: 0.568164 + 0.00362673\n",
      "[98]\tcv_agg's multi_logloss: 0.567886 + 0.00359032\n",
      "[99]\tcv_agg's multi_logloss: 0.567599 + 0.00361975\n",
      "[100]\tcv_agg's multi_logloss: 0.567308 + 0.00364245\n",
      "[101]\tcv_agg's multi_logloss: 0.567031 + 0.00366059\n",
      "[102]\tcv_agg's multi_logloss: 0.566779 + 0.00368451\n",
      "[103]\tcv_agg's multi_logloss: 0.566508 + 0.00370318\n",
      "[104]\tcv_agg's multi_logloss: 0.566264 + 0.00371338\n",
      "[105]\tcv_agg's multi_logloss: 0.566001 + 0.00371582\n",
      "[106]\tcv_agg's multi_logloss: 0.565729 + 0.00373116\n",
      "[107]\tcv_agg's multi_logloss: 0.565491 + 0.00374346\n",
      "[108]\tcv_agg's multi_logloss: 0.565228 + 0.00375536\n",
      "[109]\tcv_agg's multi_logloss: 0.564949 + 0.00376294\n",
      "[110]\tcv_agg's multi_logloss: 0.564724 + 0.00380069\n",
      "[111]\tcv_agg's multi_logloss: 0.564462 + 0.00378475\n",
      "[112]\tcv_agg's multi_logloss: 0.564208 + 0.00383819\n",
      "[113]\tcv_agg's multi_logloss: 0.563978 + 0.00384845\n",
      "[114]\tcv_agg's multi_logloss: 0.563762 + 0.00387105\n",
      "[115]\tcv_agg's multi_logloss: 0.563501 + 0.00384704\n",
      "[116]\tcv_agg's multi_logloss: 0.563305 + 0.00384138\n",
      "[117]\tcv_agg's multi_logloss: 0.563117 + 0.00385059\n",
      "[118]\tcv_agg's multi_logloss: 0.562885 + 0.00385889\n",
      "[119]\tcv_agg's multi_logloss: 0.562646 + 0.00389583\n",
      "[120]\tcv_agg's multi_logloss: 0.562436 + 0.00390611\n",
      "[121]\tcv_agg's multi_logloss: 0.562238 + 0.00390243\n",
      "[122]\tcv_agg's multi_logloss: 0.561972 + 0.00394523\n",
      "[123]\tcv_agg's multi_logloss: 0.561792 + 0.00393788\n",
      "[124]\tcv_agg's multi_logloss: 0.561562 + 0.0039785\n",
      "[125]\tcv_agg's multi_logloss: 0.561349 + 0.00399649\n",
      "[126]\tcv_agg's multi_logloss: 0.561163 + 0.00400291\n",
      "[127]\tcv_agg's multi_logloss: 0.560976 + 0.00405576\n",
      "[128]\tcv_agg's multi_logloss: 0.560786 + 0.00409647\n",
      "[129]\tcv_agg's multi_logloss: 0.560648 + 0.00411783\n",
      "[130]\tcv_agg's multi_logloss: 0.560481 + 0.00410845\n",
      "[131]\tcv_agg's multi_logloss: 0.560321 + 0.00410805\n",
      "[132]\tcv_agg's multi_logloss: 0.560147 + 0.00413533\n",
      "[133]\tcv_agg's multi_logloss: 0.559984 + 0.0041167\n",
      "[134]\tcv_agg's multi_logloss: 0.559792 + 0.00415087\n",
      "[135]\tcv_agg's multi_logloss: 0.559663 + 0.00414686\n",
      "[136]\tcv_agg's multi_logloss: 0.5595 + 0.00415932\n",
      "[137]\tcv_agg's multi_logloss: 0.559323 + 0.00418511\n",
      "[138]\tcv_agg's multi_logloss: 0.559125 + 0.00418206\n",
      "[139]\tcv_agg's multi_logloss: 0.558913 + 0.00423348\n",
      "[140]\tcv_agg's multi_logloss: 0.558723 + 0.00428143\n",
      "[141]\tcv_agg's multi_logloss: 0.558567 + 0.00428774\n",
      "[142]\tcv_agg's multi_logloss: 0.558401 + 0.00433421\n",
      "[143]\tcv_agg's multi_logloss: 0.558223 + 0.00432425\n",
      "[144]\tcv_agg's multi_logloss: 0.558046 + 0.00433708\n",
      "[145]\tcv_agg's multi_logloss: 0.557903 + 0.00434328\n",
      "[146]\tcv_agg's multi_logloss: 0.557726 + 0.00436024\n",
      "[147]\tcv_agg's multi_logloss: 0.557551 + 0.00437811\n",
      "[148]\tcv_agg's multi_logloss: 0.557376 + 0.00438125\n",
      "[149]\tcv_agg's multi_logloss: 0.557192 + 0.0043391\n",
      "[150]\tcv_agg's multi_logloss: 0.557042 + 0.00430668\n",
      "[151]\tcv_agg's multi_logloss: 0.556892 + 0.00430787\n",
      "[152]\tcv_agg's multi_logloss: 0.556732 + 0.00432238\n",
      "[153]\tcv_agg's multi_logloss: 0.556591 + 0.00436598\n",
      "[154]\tcv_agg's multi_logloss: 0.556438 + 0.00434803\n",
      "[155]\tcv_agg's multi_logloss: 0.556286 + 0.00438179\n",
      "[156]\tcv_agg's multi_logloss: 0.55614 + 0.00436948\n",
      "[157]\tcv_agg's multi_logloss: 0.555993 + 0.00437091\n",
      "[158]\tcv_agg's multi_logloss: 0.555849 + 0.00438032\n",
      "[159]\tcv_agg's multi_logloss: 0.555696 + 0.00438163\n",
      "[160]\tcv_agg's multi_logloss: 0.555549 + 0.00439462\n",
      "[161]\tcv_agg's multi_logloss: 0.55541 + 0.00440815\n",
      "[162]\tcv_agg's multi_logloss: 0.555282 + 0.00433832\n",
      "[163]\tcv_agg's multi_logloss: 0.555152 + 0.00432848\n",
      "[164]\tcv_agg's multi_logloss: 0.555024 + 0.00435241\n",
      "[165]\tcv_agg's multi_logloss: 0.554919 + 0.00436802\n",
      "[166]\tcv_agg's multi_logloss: 0.554825 + 0.00441445\n",
      "[167]\tcv_agg's multi_logloss: 0.554677 + 0.0044622\n",
      "[168]\tcv_agg's multi_logloss: 0.554551 + 0.00442842\n",
      "[169]\tcv_agg's multi_logloss: 0.554415 + 0.00448174\n",
      "[170]\tcv_agg's multi_logloss: 0.554288 + 0.00451078\n",
      "[171]\tcv_agg's multi_logloss: 0.554148 + 0.00451396\n",
      "[172]\tcv_agg's multi_logloss: 0.554016 + 0.00454116\n",
      "[173]\tcv_agg's multi_logloss: 0.553879 + 0.00455246\n",
      "[174]\tcv_agg's multi_logloss: 0.553738 + 0.00459183\n",
      "[175]\tcv_agg's multi_logloss: 0.553639 + 0.0046255\n",
      "[176]\tcv_agg's multi_logloss: 0.553534 + 0.00463065\n",
      "[177]\tcv_agg's multi_logloss: 0.553401 + 0.00464555\n",
      "[178]\tcv_agg's multi_logloss: 0.553299 + 0.00464079\n",
      "[179]\tcv_agg's multi_logloss: 0.553168 + 0.00463655\n",
      "[180]\tcv_agg's multi_logloss: 0.553074 + 0.00463847\n",
      "[181]\tcv_agg's multi_logloss: 0.552988 + 0.00466428\n",
      "[182]\tcv_agg's multi_logloss: 0.552861 + 0.00468674\n",
      "[183]\tcv_agg's multi_logloss: 0.552757 + 0.00467972\n",
      "[184]\tcv_agg's multi_logloss: 0.552662 + 0.00468887\n",
      "[185]\tcv_agg's multi_logloss: 0.552562 + 0.00469868\n",
      "[186]\tcv_agg's multi_logloss: 0.552475 + 0.00469286\n",
      "[187]\tcv_agg's multi_logloss: 0.552376 + 0.00470678\n",
      "[188]\tcv_agg's multi_logloss: 0.552272 + 0.00473715\n",
      "[189]\tcv_agg's multi_logloss: 0.552147 + 0.00474264\n",
      "[190]\tcv_agg's multi_logloss: 0.55204 + 0.00475418\n",
      "[191]\tcv_agg's multi_logloss: 0.551947 + 0.00477086\n",
      "[192]\tcv_agg's multi_logloss: 0.55182 + 0.0047883\n",
      "[193]\tcv_agg's multi_logloss: 0.551712 + 0.00481411\n",
      "[194]\tcv_agg's multi_logloss: 0.551652 + 0.00480196\n",
      "[195]\tcv_agg's multi_logloss: 0.55156 + 0.00483257\n",
      "[196]\tcv_agg's multi_logloss: 0.551453 + 0.00486028\n",
      "[197]\tcv_agg's multi_logloss: 0.551394 + 0.00488854\n",
      "[198]\tcv_agg's multi_logloss: 0.551301 + 0.00491153\n",
      "[199]\tcv_agg's multi_logloss: 0.551202 + 0.0049402\n",
      "[200]\tcv_agg's multi_logloss: 0.551067 + 0.00495435\n",
      "[201]\tcv_agg's multi_logloss: 0.550997 + 0.00498282\n",
      "[202]\tcv_agg's multi_logloss: 0.550903 + 0.00497915\n",
      "[203]\tcv_agg's multi_logloss: 0.550809 + 0.00497554\n",
      "[204]\tcv_agg's multi_logloss: 0.550727 + 0.00495604\n",
      "[205]\tcv_agg's multi_logloss: 0.550638 + 0.00498112\n",
      "[206]\tcv_agg's multi_logloss: 0.55056 + 0.00500453\n",
      "[207]\tcv_agg's multi_logloss: 0.550457 + 0.00499308\n",
      "[208]\tcv_agg's multi_logloss: 0.55039 + 0.00497844\n",
      "[209]\tcv_agg's multi_logloss: 0.550329 + 0.00500153\n",
      "[210]\tcv_agg's multi_logloss: 0.550246 + 0.00499998\n",
      "[211]\tcv_agg's multi_logloss: 0.550133 + 0.00504369\n",
      "[212]\tcv_agg's multi_logloss: 0.550054 + 0.0050387\n",
      "[213]\tcv_agg's multi_logloss: 0.549989 + 0.00504085\n",
      "[214]\tcv_agg's multi_logloss: 0.549886 + 0.00505558\n",
      "[215]\tcv_agg's multi_logloss: 0.549776 + 0.00509593\n",
      "[216]\tcv_agg's multi_logloss: 0.549693 + 0.00510974\n",
      "[217]\tcv_agg's multi_logloss: 0.549589 + 0.00511203\n",
      "[218]\tcv_agg's multi_logloss: 0.549531 + 0.00508304\n",
      "[219]\tcv_agg's multi_logloss: 0.549454 + 0.00509628\n",
      "[220]\tcv_agg's multi_logloss: 0.549364 + 0.00510036\n",
      "[221]\tcv_agg's multi_logloss: 0.549291 + 0.00508711\n",
      "[222]\tcv_agg's multi_logloss: 0.549211 + 0.00510109\n",
      "[223]\tcv_agg's multi_logloss: 0.549147 + 0.00510852\n",
      "[224]\tcv_agg's multi_logloss: 0.549043 + 0.00510458\n",
      "[225]\tcv_agg's multi_logloss: 0.548948 + 0.00513239\n",
      "[226]\tcv_agg's multi_logloss: 0.548877 + 0.00514863\n",
      "[227]\tcv_agg's multi_logloss: 0.548809 + 0.00520006\n",
      "[228]\tcv_agg's multi_logloss: 0.548725 + 0.00520404\n",
      "[229]\tcv_agg's multi_logloss: 0.548645 + 0.00520666\n",
      "[230]\tcv_agg's multi_logloss: 0.548574 + 0.00521697\n",
      "[231]\tcv_agg's multi_logloss: 0.548498 + 0.00526407\n",
      "[232]\tcv_agg's multi_logloss: 0.548458 + 0.00528149\n",
      "[233]\tcv_agg's multi_logloss: 0.548395 + 0.00527273\n",
      "[234]\tcv_agg's multi_logloss: 0.54832 + 0.00529044\n",
      "[235]\tcv_agg's multi_logloss: 0.548245 + 0.00530266\n",
      "[236]\tcv_agg's multi_logloss: 0.548132 + 0.00532941\n",
      "[237]\tcv_agg's multi_logloss: 0.548055 + 0.00536131\n",
      "[238]\tcv_agg's multi_logloss: 0.547994 + 0.00536143\n",
      "[239]\tcv_agg's multi_logloss: 0.547921 + 0.0053606\n",
      "[240]\tcv_agg's multi_logloss: 0.54784 + 0.00536101\n",
      "[241]\tcv_agg's multi_logloss: 0.547779 + 0.00535214\n",
      "[242]\tcv_agg's multi_logloss: 0.547705 + 0.00534233\n",
      "[243]\tcv_agg's multi_logloss: 0.547635 + 0.00533894\n",
      "[244]\tcv_agg's multi_logloss: 0.547565 + 0.00534083\n",
      "[245]\tcv_agg's multi_logloss: 0.547511 + 0.00534129\n",
      "[246]\tcv_agg's multi_logloss: 0.547448 + 0.0053614\n",
      "[247]\tcv_agg's multi_logloss: 0.547401 + 0.00535988\n",
      "[248]\tcv_agg's multi_logloss: 0.547341 + 0.00537725\n",
      "[249]\tcv_agg's multi_logloss: 0.547272 + 0.00537886\n",
      "[250]\tcv_agg's multi_logloss: 0.547246 + 0.00538528\n",
      "[251]\tcv_agg's multi_logloss: 0.547156 + 0.00537616\n",
      "[252]\tcv_agg's multi_logloss: 0.547096 + 0.0053439\n",
      "[253]\tcv_agg's multi_logloss: 0.547035 + 0.00534853\n",
      "[254]\tcv_agg's multi_logloss: 0.546957 + 0.00534623\n",
      "[255]\tcv_agg's multi_logloss: 0.546908 + 0.00532828\n",
      "[256]\tcv_agg's multi_logloss: 0.546851 + 0.00532123\n",
      "[257]\tcv_agg's multi_logloss: 0.546806 + 0.00533467\n",
      "[258]\tcv_agg's multi_logloss: 0.546774 + 0.00534367\n",
      "[259]\tcv_agg's multi_logloss: 0.546735 + 0.00534238\n",
      "[260]\tcv_agg's multi_logloss: 0.546667 + 0.0053574\n",
      "[261]\tcv_agg's multi_logloss: 0.546592 + 0.00536579\n",
      "[262]\tcv_agg's multi_logloss: 0.546544 + 0.00538377\n",
      "[263]\tcv_agg's multi_logloss: 0.5465 + 0.00539627\n",
      "[264]\tcv_agg's multi_logloss: 0.546468 + 0.00541091\n",
      "[265]\tcv_agg's multi_logloss: 0.546424 + 0.00542129\n",
      "[266]\tcv_agg's multi_logloss: 0.546372 + 0.00543905\n",
      "[267]\tcv_agg's multi_logloss: 0.5463 + 0.00542731\n",
      "[268]\tcv_agg's multi_logloss: 0.546246 + 0.00545749\n",
      "[269]\tcv_agg's multi_logloss: 0.546207 + 0.00545577\n",
      "[270]\tcv_agg's multi_logloss: 0.546168 + 0.00545551\n",
      "[271]\tcv_agg's multi_logloss: 0.546127 + 0.00544939\n",
      "[272]\tcv_agg's multi_logloss: 0.546061 + 0.00544465\n",
      "[273]\tcv_agg's multi_logloss: 0.546038 + 0.00544638\n",
      "[274]\tcv_agg's multi_logloss: 0.545992 + 0.00545524\n",
      "[275]\tcv_agg's multi_logloss: 0.545917 + 0.00546926\n",
      "[276]\tcv_agg's multi_logloss: 0.545882 + 0.0054865\n",
      "[277]\tcv_agg's multi_logloss: 0.545849 + 0.00550346\n",
      "[278]\tcv_agg's multi_logloss: 0.545768 + 0.00550147\n",
      "[279]\tcv_agg's multi_logloss: 0.545697 + 0.00551925\n",
      "[280]\tcv_agg's multi_logloss: 0.545641 + 0.00551449\n",
      "[281]\tcv_agg's multi_logloss: 0.54559 + 0.0055224\n",
      "[282]\tcv_agg's multi_logloss: 0.54555 + 0.0055319\n",
      "[283]\tcv_agg's multi_logloss: 0.545504 + 0.00555384\n",
      "[284]\tcv_agg's multi_logloss: 0.545428 + 0.00556014\n",
      "[285]\tcv_agg's multi_logloss: 0.545363 + 0.00555976\n",
      "[286]\tcv_agg's multi_logloss: 0.545293 + 0.00558527\n",
      "[287]\tcv_agg's multi_logloss: 0.545244 + 0.00559224\n",
      "[288]\tcv_agg's multi_logloss: 0.545177 + 0.0056002\n",
      "[289]\tcv_agg's multi_logloss: 0.545102 + 0.00562904\n",
      "[290]\tcv_agg's multi_logloss: 0.545045 + 0.00564714\n",
      "[291]\tcv_agg's multi_logloss: 0.54498 + 0.00568444\n",
      "[292]\tcv_agg's multi_logloss: 0.544937 + 0.0056867\n",
      "[293]\tcv_agg's multi_logloss: 0.544898 + 0.00569467\n",
      "[294]\tcv_agg's multi_logloss: 0.544852 + 0.00570763\n",
      "[295]\tcv_agg's multi_logloss: 0.544796 + 0.00570467\n",
      "[296]\tcv_agg's multi_logloss: 0.544734 + 0.00570824\n",
      "[297]\tcv_agg's multi_logloss: 0.544678 + 0.00572632\n",
      "[298]\tcv_agg's multi_logloss: 0.544633 + 0.00574742\n",
      "[299]\tcv_agg's multi_logloss: 0.544562 + 0.00576703\n",
      "[300]\tcv_agg's multi_logloss: 0.544512 + 0.00578623\n",
      "[301]\tcv_agg's multi_logloss: 0.544482 + 0.00576785\n",
      "[302]\tcv_agg's multi_logloss: 0.544428 + 0.00578191\n",
      "[303]\tcv_agg's multi_logloss: 0.544391 + 0.00580104\n",
      "[304]\tcv_agg's multi_logloss: 0.544351 + 0.00581498\n",
      "[305]\tcv_agg's multi_logloss: 0.544306 + 0.00581741\n",
      "[306]\tcv_agg's multi_logloss: 0.54429 + 0.00582025\n",
      "[307]\tcv_agg's multi_logloss: 0.544236 + 0.00583913\n",
      "[308]\tcv_agg's multi_logloss: 0.544222 + 0.00584206\n",
      "[309]\tcv_agg's multi_logloss: 0.544172 + 0.00586946\n",
      "[310]\tcv_agg's multi_logloss: 0.544126 + 0.00590453\n",
      "[311]\tcv_agg's multi_logloss: 0.544104 + 0.00590845\n",
      "[312]\tcv_agg's multi_logloss: 0.544049 + 0.00588625\n",
      "[313]\tcv_agg's multi_logloss: 0.543996 + 0.00589886\n",
      "[314]\tcv_agg's multi_logloss: 0.543971 + 0.00590103\n",
      "[315]\tcv_agg's multi_logloss: 0.543919 + 0.00588706\n",
      "[316]\tcv_agg's multi_logloss: 0.543873 + 0.00589735\n",
      "[317]\tcv_agg's multi_logloss: 0.543849 + 0.00590685\n",
      "[318]\tcv_agg's multi_logloss: 0.543785 + 0.00591452\n",
      "[319]\tcv_agg's multi_logloss: 0.543746 + 0.00592603\n",
      "[320]\tcv_agg's multi_logloss: 0.543711 + 0.00591457\n",
      "[321]\tcv_agg's multi_logloss: 0.543648 + 0.00590443\n",
      "[322]\tcv_agg's multi_logloss: 0.543631 + 0.00592169\n",
      "[323]\tcv_agg's multi_logloss: 0.543614 + 0.00591947\n",
      "[324]\tcv_agg's multi_logloss: 0.543576 + 0.0059367\n",
      "[325]\tcv_agg's multi_logloss: 0.543564 + 0.00593545\n",
      "[326]\tcv_agg's multi_logloss: 0.54352 + 0.00594063\n",
      "[327]\tcv_agg's multi_logloss: 0.543495 + 0.00593532\n",
      "[328]\tcv_agg's multi_logloss: 0.543442 + 0.00597549\n",
      "[329]\tcv_agg's multi_logloss: 0.543414 + 0.00597847\n",
      "[330]\tcv_agg's multi_logloss: 0.543357 + 0.00595847\n",
      "[331]\tcv_agg's multi_logloss: 0.543307 + 0.00597858\n",
      "[332]\tcv_agg's multi_logloss: 0.543265 + 0.00597178\n",
      "[333]\tcv_agg's multi_logloss: 0.543231 + 0.00596209\n",
      "[334]\tcv_agg's multi_logloss: 0.543205 + 0.00595467\n",
      "[335]\tcv_agg's multi_logloss: 0.54318 + 0.00597202\n",
      "[336]\tcv_agg's multi_logloss: 0.543158 + 0.00596703\n",
      "[337]\tcv_agg's multi_logloss: 0.543108 + 0.00596137\n",
      "[338]\tcv_agg's multi_logloss: 0.543054 + 0.00594844\n",
      "[339]\tcv_agg's multi_logloss: 0.543014 + 0.00595261\n",
      "[340]\tcv_agg's multi_logloss: 0.542983 + 0.0059487\n",
      "[341]\tcv_agg's multi_logloss: 0.542956 + 0.00597022\n",
      "[342]\tcv_agg's multi_logloss: 0.542947 + 0.00597187\n",
      "[343]\tcv_agg's multi_logloss: 0.542904 + 0.00596155\n",
      "[344]\tcv_agg's multi_logloss: 0.542855 + 0.00594267\n",
      "[345]\tcv_agg's multi_logloss: 0.542819 + 0.00595602\n",
      "[346]\tcv_agg's multi_logloss: 0.542781 + 0.00594156\n",
      "[347]\tcv_agg's multi_logloss: 0.542757 + 0.00597074\n",
      "[348]\tcv_agg's multi_logloss: 0.542715 + 0.00598769\n",
      "[349]\tcv_agg's multi_logloss: 0.542699 + 0.00598779\n",
      "[350]\tcv_agg's multi_logloss: 0.542687 + 0.00602589\n",
      "[351]\tcv_agg's multi_logloss: 0.542672 + 0.00600782\n",
      "[352]\tcv_agg's multi_logloss: 0.542649 + 0.0059833\n",
      "[353]\tcv_agg's multi_logloss: 0.542616 + 0.00598122\n",
      "[354]\tcv_agg's multi_logloss: 0.542585 + 0.00600494\n",
      "[355]\tcv_agg's multi_logloss: 0.542565 + 0.00601376\n",
      "[356]\tcv_agg's multi_logloss: 0.542551 + 0.00600629\n",
      "[357]\tcv_agg's multi_logloss: 0.542528 + 0.00603715\n",
      "[358]\tcv_agg's multi_logloss: 0.542517 + 0.00605665\n",
      "[359]\tcv_agg's multi_logloss: 0.542482 + 0.00607715\n",
      "[360]\tcv_agg's multi_logloss: 0.542454 + 0.00605058\n",
      "[361]\tcv_agg's multi_logloss: 0.542427 + 0.00604679\n",
      "[362]\tcv_agg's multi_logloss: 0.542401 + 0.00604199\n",
      "[363]\tcv_agg's multi_logloss: 0.542372 + 0.0060426\n",
      "[364]\tcv_agg's multi_logloss: 0.542347 + 0.00604735\n",
      "[365]\tcv_agg's multi_logloss: 0.542334 + 0.00603228\n",
      "[366]\tcv_agg's multi_logloss: 0.542281 + 0.00604115\n",
      "[367]\tcv_agg's multi_logloss: 0.542226 + 0.00604371\n",
      "[368]\tcv_agg's multi_logloss: 0.542196 + 0.00606176\n",
      "[369]\tcv_agg's multi_logloss: 0.542184 + 0.00608264\n",
      "[370]\tcv_agg's multi_logloss: 0.542129 + 0.00609885\n",
      "[371]\tcv_agg's multi_logloss: 0.542122 + 0.0060997\n",
      "[372]\tcv_agg's multi_logloss: 0.542078 + 0.00611881\n",
      "[373]\tcv_agg's multi_logloss: 0.542052 + 0.0061181\n",
      "[374]\tcv_agg's multi_logloss: 0.542037 + 0.00613354\n",
      "[375]\tcv_agg's multi_logloss: 0.542018 + 0.00615486\n",
      "[376]\tcv_agg's multi_logloss: 0.541998 + 0.00614247\n",
      "[377]\tcv_agg's multi_logloss: 0.541976 + 0.00614146\n",
      "[378]\tcv_agg's multi_logloss: 0.541958 + 0.00614474\n",
      "[379]\tcv_agg's multi_logloss: 0.541931 + 0.00612421\n",
      "[380]\tcv_agg's multi_logloss: 0.541884 + 0.00612677\n",
      "[381]\tcv_agg's multi_logloss: 0.541847 + 0.00611264\n",
      "[382]\tcv_agg's multi_logloss: 0.541827 + 0.00611497\n",
      "[383]\tcv_agg's multi_logloss: 0.541802 + 0.0061415\n",
      "[384]\tcv_agg's multi_logloss: 0.541765 + 0.00614305\n",
      "[385]\tcv_agg's multi_logloss: 0.54174 + 0.00612669\n",
      "[386]\tcv_agg's multi_logloss: 0.541717 + 0.00613162\n",
      "[387]\tcv_agg's multi_logloss: 0.541691 + 0.00614575\n",
      "[388]\tcv_agg's multi_logloss: 0.541671 + 0.00614516\n",
      "[389]\tcv_agg's multi_logloss: 0.541605 + 0.00613982\n",
      "[390]\tcv_agg's multi_logloss: 0.541573 + 0.00613282\n",
      "[391]\tcv_agg's multi_logloss: 0.541532 + 0.00614069\n",
      "[392]\tcv_agg's multi_logloss: 0.541495 + 0.00611528\n",
      "[393]\tcv_agg's multi_logloss: 0.541475 + 0.00609065\n",
      "[394]\tcv_agg's multi_logloss: 0.541424 + 0.00608805\n",
      "[395]\tcv_agg's multi_logloss: 0.541389 + 0.00610366\n",
      "[396]\tcv_agg's multi_logloss: 0.541361 + 0.00611471\n",
      "[397]\tcv_agg's multi_logloss: 0.541319 + 0.00613276\n",
      "[398]\tcv_agg's multi_logloss: 0.541293 + 0.00611495\n",
      "[399]\tcv_agg's multi_logloss: 0.541257 + 0.00613009\n",
      "[400]\tcv_agg's multi_logloss: 0.541236 + 0.00613377\n",
      "[401]\tcv_agg's multi_logloss: 0.5412 + 0.00612552\n",
      "[402]\tcv_agg's multi_logloss: 0.541151 + 0.00612274\n",
      "[403]\tcv_agg's multi_logloss: 0.541123 + 0.00614486\n",
      "[404]\tcv_agg's multi_logloss: 0.541081 + 0.00613795\n",
      "[405]\tcv_agg's multi_logloss: 0.541071 + 0.00616846\n",
      "[406]\tcv_agg's multi_logloss: 0.541066 + 0.00615829\n",
      "[407]\tcv_agg's multi_logloss: 0.54106 + 0.00614817\n",
      "[408]\tcv_agg's multi_logloss: 0.541007 + 0.00616004\n",
      "[409]\tcv_agg's multi_logloss: 0.540987 + 0.0061605\n",
      "[410]\tcv_agg's multi_logloss: 0.540974 + 0.00616202\n",
      "[411]\tcv_agg's multi_logloss: 0.540946 + 0.00618335\n",
      "[412]\tcv_agg's multi_logloss: 0.540916 + 0.0061908\n",
      "[413]\tcv_agg's multi_logloss: 0.540891 + 0.00619841\n",
      "[414]\tcv_agg's multi_logloss: 0.540863 + 0.00621132\n",
      "[415]\tcv_agg's multi_logloss: 0.54087 + 0.00623086\n",
      "[416]\tcv_agg's multi_logloss: 0.540832 + 0.00624461\n",
      "[417]\tcv_agg's multi_logloss: 0.54082 + 0.00624145\n",
      "[418]\tcv_agg's multi_logloss: 0.540788 + 0.00625521\n",
      "[419]\tcv_agg's multi_logloss: 0.540747 + 0.0062702\n",
      "[420]\tcv_agg's multi_logloss: 0.540718 + 0.00626902\n",
      "[421]\tcv_agg's multi_logloss: 0.540721 + 0.00627655\n",
      "[422]\tcv_agg's multi_logloss: 0.540693 + 0.00627335\n",
      "[423]\tcv_agg's multi_logloss: 0.540668 + 0.00626751\n",
      "[424]\tcv_agg's multi_logloss: 0.540659 + 0.00626856\n",
      "[425]\tcv_agg's multi_logloss: 0.54067 + 0.00627094\n",
      "[426]\tcv_agg's multi_logloss: 0.540655 + 0.00625875\n",
      "[427]\tcv_agg's multi_logloss: 0.540627 + 0.00626546\n",
      "[428]\tcv_agg's multi_logloss: 0.540582 + 0.00626766\n",
      "[429]\tcv_agg's multi_logloss: 0.54055 + 0.00625518\n",
      "[430]\tcv_agg's multi_logloss: 0.540527 + 0.00625106\n",
      "[431]\tcv_agg's multi_logloss: 0.540494 + 0.00625941\n",
      "[432]\tcv_agg's multi_logloss: 0.540478 + 0.00625113\n",
      "[433]\tcv_agg's multi_logloss: 0.540466 + 0.0062388\n",
      "[434]\tcv_agg's multi_logloss: 0.540439 + 0.0062353\n",
      "[435]\tcv_agg's multi_logloss: 0.540424 + 0.00624283\n",
      "[436]\tcv_agg's multi_logloss: 0.540403 + 0.00622744\n",
      "[437]\tcv_agg's multi_logloss: 0.540377 + 0.00624506\n",
      "[438]\tcv_agg's multi_logloss: 0.540362 + 0.00624157\n",
      "[439]\tcv_agg's multi_logloss: 0.540329 + 0.00625648\n",
      "[440]\tcv_agg's multi_logloss: 0.540316 + 0.00626648\n",
      "[441]\tcv_agg's multi_logloss: 0.54029 + 0.00627737\n",
      "[442]\tcv_agg's multi_logloss: 0.540278 + 0.00627877\n",
      "[443]\tcv_agg's multi_logloss: 0.540238 + 0.0062681\n",
      "[444]\tcv_agg's multi_logloss: 0.540205 + 0.006279\n",
      "[445]\tcv_agg's multi_logloss: 0.540163 + 0.00628081\n",
      "[446]\tcv_agg's multi_logloss: 0.540139 + 0.0062942\n",
      "[447]\tcv_agg's multi_logloss: 0.54013 + 0.00629824\n",
      "[448]\tcv_agg's multi_logloss: 0.540087 + 0.00629828\n",
      "[449]\tcv_agg's multi_logloss: 0.540068 + 0.00631767\n",
      "[450]\tcv_agg's multi_logloss: 0.540054 + 0.00631369\n",
      "[451]\tcv_agg's multi_logloss: 0.540053 + 0.00632277\n",
      "[452]\tcv_agg's multi_logloss: 0.540018 + 0.00629295\n",
      "[453]\tcv_agg's multi_logloss: 0.539992 + 0.00628286\n",
      "[454]\tcv_agg's multi_logloss: 0.539983 + 0.00626189\n",
      "[455]\tcv_agg's multi_logloss: 0.539972 + 0.00625705\n",
      "[456]\tcv_agg's multi_logloss: 0.539961 + 0.00624469\n",
      "[457]\tcv_agg's multi_logloss: 0.539961 + 0.00624599\n",
      "[458]\tcv_agg's multi_logloss: 0.539959 + 0.00625303\n",
      "[459]\tcv_agg's multi_logloss: 0.539934 + 0.00624089\n",
      "[460]\tcv_agg's multi_logloss: 0.539918 + 0.00623507\n",
      "[461]\tcv_agg's multi_logloss: 0.539906 + 0.00623283\n",
      "[462]\tcv_agg's multi_logloss: 0.539871 + 0.00621826\n",
      "[463]\tcv_agg's multi_logloss: 0.539841 + 0.0062119\n",
      "[464]\tcv_agg's multi_logloss: 0.53983 + 0.00620767\n",
      "[465]\tcv_agg's multi_logloss: 0.539828 + 0.00618953\n",
      "[466]\tcv_agg's multi_logloss: 0.539799 + 0.00618991\n",
      "[467]\tcv_agg's multi_logloss: 0.539786 + 0.00618828\n",
      "[468]\tcv_agg's multi_logloss: 0.539774 + 0.00616715\n",
      "[469]\tcv_agg's multi_logloss: 0.539769 + 0.00617227\n",
      "[470]\tcv_agg's multi_logloss: 0.539769 + 0.00615355\n",
      "[471]\tcv_agg's multi_logloss: 0.539723 + 0.00616114\n",
      "[472]\tcv_agg's multi_logloss: 0.53973 + 0.00615122\n",
      "[473]\tcv_agg's multi_logloss: 0.539712 + 0.00613373\n",
      "[474]\tcv_agg's multi_logloss: 0.539705 + 0.00615863\n",
      "[475]\tcv_agg's multi_logloss: 0.539691 + 0.00615741\n",
      "[476]\tcv_agg's multi_logloss: 0.539688 + 0.00615919\n",
      "[477]\tcv_agg's multi_logloss: 0.539667 + 0.0061618\n",
      "[478]\tcv_agg's multi_logloss: 0.539644 + 0.0061585\n",
      "[479]\tcv_agg's multi_logloss: 0.539621 + 0.00614323\n",
      "[480]\tcv_agg's multi_logloss: 0.539589 + 0.00615396\n",
      "[481]\tcv_agg's multi_logloss: 0.539567 + 0.00617914\n",
      "[482]\tcv_agg's multi_logloss: 0.539554 + 0.00618291\n",
      "[483]\tcv_agg's multi_logloss: 0.53953 + 0.00619429\n",
      "[484]\tcv_agg's multi_logloss: 0.539501 + 0.00620419\n",
      "[485]\tcv_agg's multi_logloss: 0.539493 + 0.00619727\n",
      "[486]\tcv_agg's multi_logloss: 0.539458 + 0.00618683\n",
      "[487]\tcv_agg's multi_logloss: 0.539448 + 0.00619162\n",
      "[488]\tcv_agg's multi_logloss: 0.539437 + 0.00616405\n",
      "[489]\tcv_agg's multi_logloss: 0.539416 + 0.00616844\n",
      "[490]\tcv_agg's multi_logloss: 0.53937 + 0.00617743\n",
      "[491]\tcv_agg's multi_logloss: 0.539362 + 0.00616402\n",
      "[492]\tcv_agg's multi_logloss: 0.539322 + 0.0061422\n",
      "[493]\tcv_agg's multi_logloss: 0.539331 + 0.00614806\n",
      "[494]\tcv_agg's multi_logloss: 0.539319 + 0.00613317\n",
      "[495]\tcv_agg's multi_logloss: 0.539311 + 0.00614213\n",
      "[496]\tcv_agg's multi_logloss: 0.539288 + 0.00614421\n",
      "[497]\tcv_agg's multi_logloss: 0.539256 + 0.0061687\n",
      "[498]\tcv_agg's multi_logloss: 0.539249 + 0.00618972\n",
      "[499]\tcv_agg's multi_logloss: 0.539259 + 0.00619975\n",
      "[500]\tcv_agg's multi_logloss: 0.539252 + 0.00619549\n",
      "[501]\tcv_agg's multi_logloss: 0.53924 + 0.00621168\n",
      "[502]\tcv_agg's multi_logloss: 0.539224 + 0.00618743\n",
      "[503]\tcv_agg's multi_logloss: 0.539208 + 0.00617117\n",
      "[504]\tcv_agg's multi_logloss: 0.539195 + 0.00616951\n",
      "[505]\tcv_agg's multi_logloss: 0.5392 + 0.00615779\n",
      "[506]\tcv_agg's multi_logloss: 0.539193 + 0.00615727\n",
      "[507]\tcv_agg's multi_logloss: 0.53917 + 0.00616026\n",
      "[508]\tcv_agg's multi_logloss: 0.53917 + 0.00616811\n",
      "[509]\tcv_agg's multi_logloss: 0.539155 + 0.00617541\n",
      "[510]\tcv_agg's multi_logloss: 0.53915 + 0.00619372\n",
      "[511]\tcv_agg's multi_logloss: 0.539132 + 0.00619356\n",
      "[512]\tcv_agg's multi_logloss: 0.539146 + 0.0062112\n",
      "[513]\tcv_agg's multi_logloss: 0.539136 + 0.0062174\n",
      "[514]\tcv_agg's multi_logloss: 0.539124 + 0.00622882\n",
      "[515]\tcv_agg's multi_logloss: 0.53911 + 0.00624352\n",
      "[516]\tcv_agg's multi_logloss: 0.539104 + 0.0062382\n",
      "[517]\tcv_agg's multi_logloss: 0.539098 + 0.00623884\n",
      "[518]\tcv_agg's multi_logloss: 0.539097 + 0.0062469\n",
      "[519]\tcv_agg's multi_logloss: 0.539065 + 0.0062337\n",
      "[520]\tcv_agg's multi_logloss: 0.539055 + 0.00625755\n",
      "[521]\tcv_agg's multi_logloss: 0.539054 + 0.00625525\n",
      "[522]\tcv_agg's multi_logloss: 0.539034 + 0.00625331\n",
      "[523]\tcv_agg's multi_logloss: 0.539029 + 0.00626245\n",
      "[524]\tcv_agg's multi_logloss: 0.53901 + 0.00628298\n",
      "[525]\tcv_agg's multi_logloss: 0.538993 + 0.00627014\n",
      "[526]\tcv_agg's multi_logloss: 0.538986 + 0.00627563\n",
      "[527]\tcv_agg's multi_logloss: 0.538984 + 0.00627999\n",
      "[528]\tcv_agg's multi_logloss: 0.538973 + 0.00630413\n",
      "[529]\tcv_agg's multi_logloss: 0.53896 + 0.0063173\n",
      "[530]\tcv_agg's multi_logloss: 0.538953 + 0.00630032\n",
      "[531]\tcv_agg's multi_logloss: 0.538956 + 0.0063082\n",
      "[532]\tcv_agg's multi_logloss: 0.538954 + 0.00630329\n",
      "[533]\tcv_agg's multi_logloss: 0.538922 + 0.00630633\n",
      "[534]\tcv_agg's multi_logloss: 0.538906 + 0.00630438\n",
      "[535]\tcv_agg's multi_logloss: 0.538872 + 0.00630276\n",
      "[536]\tcv_agg's multi_logloss: 0.538851 + 0.00629347\n",
      "[537]\tcv_agg's multi_logloss: 0.538857 + 0.00629508\n",
      "[538]\tcv_agg's multi_logloss: 0.53885 + 0.00630027\n",
      "[539]\tcv_agg's multi_logloss: 0.538842 + 0.0063144\n",
      "[540]\tcv_agg's multi_logloss: 0.538828 + 0.00630918\n",
      "[541]\tcv_agg's multi_logloss: 0.538826 + 0.00631777\n",
      "[542]\tcv_agg's multi_logloss: 0.538809 + 0.00631439\n",
      "[543]\tcv_agg's multi_logloss: 0.53881 + 0.00632582\n",
      "[544]\tcv_agg's multi_logloss: 0.538798 + 0.00633858\n",
      "[545]\tcv_agg's multi_logloss: 0.538798 + 0.00632639\n",
      "[546]\tcv_agg's multi_logloss: 0.538767 + 0.00632185\n",
      "[547]\tcv_agg's multi_logloss: 0.53875 + 0.00632126\n",
      "[548]\tcv_agg's multi_logloss: 0.538738 + 0.00632262\n",
      "[549]\tcv_agg's multi_logloss: 0.538736 + 0.00632035\n",
      "[550]\tcv_agg's multi_logloss: 0.53873 + 0.0063043\n",
      "[551]\tcv_agg's multi_logloss: 0.538713 + 0.0063186\n",
      "[552]\tcv_agg's multi_logloss: 0.538703 + 0.00632724\n",
      "[553]\tcv_agg's multi_logloss: 0.538699 + 0.00630439\n",
      "[554]\tcv_agg's multi_logloss: 0.53867 + 0.00629576\n",
      "[555]\tcv_agg's multi_logloss: 0.538675 + 0.00628941\n",
      "[556]\tcv_agg's multi_logloss: 0.538655 + 0.00628393\n",
      "[557]\tcv_agg's multi_logloss: 0.538652 + 0.00628377\n",
      "[558]\tcv_agg's multi_logloss: 0.538641 + 0.00628174\n",
      "[559]\tcv_agg's multi_logloss: 0.538629 + 0.00629035\n",
      "[560]\tcv_agg's multi_logloss: 0.538609 + 0.00631072\n",
      "[561]\tcv_agg's multi_logloss: 0.538589 + 0.00632166\n",
      "[562]\tcv_agg's multi_logloss: 0.538567 + 0.00631562\n",
      "[563]\tcv_agg's multi_logloss: 0.538531 + 0.00630315\n",
      "[564]\tcv_agg's multi_logloss: 0.538529 + 0.00630572\n",
      "[565]\tcv_agg's multi_logloss: 0.538517 + 0.0063131\n",
      "[566]\tcv_agg's multi_logloss: 0.538503 + 0.00631977\n",
      "[567]\tcv_agg's multi_logloss: 0.538528 + 0.00632555\n",
      "[568]\tcv_agg's multi_logloss: 0.53852 + 0.00634151\n",
      "[569]\tcv_agg's multi_logloss: 0.53849 + 0.00633103\n",
      "[570]\tcv_agg's multi_logloss: 0.538502 + 0.00632124\n",
      "[571]\tcv_agg's multi_logloss: 0.538504 + 0.00632433\n",
      "[572]\tcv_agg's multi_logloss: 0.538516 + 0.00632418\n",
      "[573]\tcv_agg's multi_logloss: 0.538488 + 0.00632643\n",
      "[574]\tcv_agg's multi_logloss: 0.538478 + 0.00631393\n",
      "[575]\tcv_agg's multi_logloss: 0.538466 + 0.00631307\n",
      "[576]\tcv_agg's multi_logloss: 0.538469 + 0.0063117\n",
      "[577]\tcv_agg's multi_logloss: 0.538463 + 0.00631059\n",
      "[578]\tcv_agg's multi_logloss: 0.538452 + 0.00631215\n",
      "[579]\tcv_agg's multi_logloss: 0.538451 + 0.00628123\n",
      "[580]\tcv_agg's multi_logloss: 0.538434 + 0.00629587\n",
      "[581]\tcv_agg's multi_logloss: 0.538418 + 0.00631263\n",
      "[582]\tcv_agg's multi_logloss: 0.53841 + 0.00631564\n",
      "[583]\tcv_agg's multi_logloss: 0.538411 + 0.00630978\n",
      "[584]\tcv_agg's multi_logloss: 0.538377 + 0.00632202\n",
      "[585]\tcv_agg's multi_logloss: 0.538376 + 0.00630619\n",
      "[586]\tcv_agg's multi_logloss: 0.538363 + 0.006304\n",
      "[587]\tcv_agg's multi_logloss: 0.538352 + 0.00629659\n",
      "[588]\tcv_agg's multi_logloss: 0.538353 + 0.00628485\n",
      "[589]\tcv_agg's multi_logloss: 0.53833 + 0.00628422\n",
      "[590]\tcv_agg's multi_logloss: 0.538322 + 0.00626846\n",
      "[591]\tcv_agg's multi_logloss: 0.538303 + 0.00626669\n",
      "[592]\tcv_agg's multi_logloss: 0.538299 + 0.00627478\n",
      "[593]\tcv_agg's multi_logloss: 0.538284 + 0.00626166\n",
      "[594]\tcv_agg's multi_logloss: 0.538258 + 0.00626031\n",
      "[595]\tcv_agg's multi_logloss: 0.538256 + 0.00627492\n",
      "[596]\tcv_agg's multi_logloss: 0.538268 + 0.00629342\n",
      "[597]\tcv_agg's multi_logloss: 0.538242 + 0.00628009\n",
      "[598]\tcv_agg's multi_logloss: 0.53825 + 0.00625737\n",
      "[599]\tcv_agg's multi_logloss: 0.538222 + 0.00625686\n",
      "[600]\tcv_agg's multi_logloss: 0.538211 + 0.00629085\n",
      "[601]\tcv_agg's multi_logloss: 0.538219 + 0.00629457\n",
      "[602]\tcv_agg's multi_logloss: 0.538213 + 0.00632014\n",
      "[603]\tcv_agg's multi_logloss: 0.538207 + 0.00633775\n",
      "[604]\tcv_agg's multi_logloss: 0.538232 + 0.00634303\n",
      "[605]\tcv_agg's multi_logloss: 0.538196 + 0.00634493\n",
      "[606]\tcv_agg's multi_logloss: 0.53819 + 0.00635719\n",
      "[607]\tcv_agg's multi_logloss: 0.538195 + 0.00635525\n",
      "[608]\tcv_agg's multi_logloss: 0.538187 + 0.00637968\n",
      "[609]\tcv_agg's multi_logloss: 0.538165 + 0.00639541\n",
      "[610]\tcv_agg's multi_logloss: 0.538154 + 0.00638774\n",
      "[611]\tcv_agg's multi_logloss: 0.538135 + 0.00639809\n",
      "[612]\tcv_agg's multi_logloss: 0.538117 + 0.0064035\n",
      "[613]\tcv_agg's multi_logloss: 0.538091 + 0.00640426\n",
      "[614]\tcv_agg's multi_logloss: 0.538076 + 0.00641701\n",
      "[615]\tcv_agg's multi_logloss: 0.538045 + 0.00639616\n",
      "[616]\tcv_agg's multi_logloss: 0.538059 + 0.00640473\n",
      "[617]\tcv_agg's multi_logloss: 0.538051 + 0.00640687\n",
      "[618]\tcv_agg's multi_logloss: 0.538036 + 0.0064291\n",
      "[619]\tcv_agg's multi_logloss: 0.538014 + 0.00645308\n",
      "[620]\tcv_agg's multi_logloss: 0.538011 + 0.00645469\n",
      "[621]\tcv_agg's multi_logloss: 0.537982 + 0.00644848\n",
      "[622]\tcv_agg's multi_logloss: 0.53796 + 0.00645542\n",
      "[623]\tcv_agg's multi_logloss: 0.53796 + 0.0064729\n",
      "[624]\tcv_agg's multi_logloss: 0.537942 + 0.00646791\n",
      "[625]\tcv_agg's multi_logloss: 0.537937 + 0.00648212\n",
      "[626]\tcv_agg's multi_logloss: 0.537914 + 0.00649115\n",
      "[627]\tcv_agg's multi_logloss: 0.537904 + 0.00648561\n",
      "[628]\tcv_agg's multi_logloss: 0.537909 + 0.00649707\n",
      "[629]\tcv_agg's multi_logloss: 0.537897 + 0.00650887\n",
      "[630]\tcv_agg's multi_logloss: 0.537914 + 0.00652451\n",
      "[631]\tcv_agg's multi_logloss: 0.537917 + 0.00651665\n",
      "[632]\tcv_agg's multi_logloss: 0.537912 + 0.00651277\n",
      "[633]\tcv_agg's multi_logloss: 0.537914 + 0.00651955\n",
      "[634]\tcv_agg's multi_logloss: 0.537917 + 0.00653747\n",
      "[635]\tcv_agg's multi_logloss: 0.537895 + 0.00651857\n",
      "[636]\tcv_agg's multi_logloss: 0.537879 + 0.00651593\n",
      "[637]\tcv_agg's multi_logloss: 0.537863 + 0.00654528\n",
      "[638]\tcv_agg's multi_logloss: 0.537843 + 0.00655574\n",
      "[639]\tcv_agg's multi_logloss: 0.537847 + 0.00656214\n",
      "[640]\tcv_agg's multi_logloss: 0.537844 + 0.00656032\n",
      "[641]\tcv_agg's multi_logloss: 0.53782 + 0.00656384\n",
      "[642]\tcv_agg's multi_logloss: 0.537825 + 0.00657351\n",
      "[643]\tcv_agg's multi_logloss: 0.537816 + 0.00657749\n",
      "[644]\tcv_agg's multi_logloss: 0.537825 + 0.00659121\n",
      "[645]\tcv_agg's multi_logloss: 0.537816 + 0.00657953\n",
      "[646]\tcv_agg's multi_logloss: 0.537816 + 0.00657939\n",
      "[647]\tcv_agg's multi_logloss: 0.537801 + 0.00658288\n",
      "[648]\tcv_agg's multi_logloss: 0.537803 + 0.00658299\n",
      "[649]\tcv_agg's multi_logloss: 0.537794 + 0.00660371\n",
      "[650]\tcv_agg's multi_logloss: 0.537808 + 0.00660901\n",
      "[651]\tcv_agg's multi_logloss: 0.537812 + 0.0066085\n",
      "[652]\tcv_agg's multi_logloss: 0.537818 + 0.00661048\n",
      "[653]\tcv_agg's multi_logloss: 0.53781 + 0.00659858\n",
      "[654]\tcv_agg's multi_logloss: 0.537803 + 0.00660898\n",
      "[655]\tcv_agg's multi_logloss: 0.537799 + 0.00661162\n",
      "[656]\tcv_agg's multi_logloss: 0.537801 + 0.0066015\n",
      "[657]\tcv_agg's multi_logloss: 0.537778 + 0.00661194\n",
      "[658]\tcv_agg's multi_logloss: 0.53777 + 0.00662339\n",
      "[659]\tcv_agg's multi_logloss: 0.537767 + 0.00661668\n",
      "[660]\tcv_agg's multi_logloss: 0.53777 + 0.00661297\n",
      "[661]\tcv_agg's multi_logloss: 0.537753 + 0.00660081\n",
      "[662]\tcv_agg's multi_logloss: 0.537727 + 0.00661663\n",
      "[663]\tcv_agg's multi_logloss: 0.537712 + 0.00662662\n",
      "[664]\tcv_agg's multi_logloss: 0.537712 + 0.00662662\n",
      "[665]\tcv_agg's multi_logloss: 0.53771 + 0.00663142\n",
      "[666]\tcv_agg's multi_logloss: 0.537698 + 0.00663058\n",
      "[667]\tcv_agg's multi_logloss: 0.537681 + 0.00664268\n",
      "[668]\tcv_agg's multi_logloss: 0.537673 + 0.00664905\n",
      "[669]\tcv_agg's multi_logloss: 0.537685 + 0.006661\n",
      "[670]\tcv_agg's multi_logloss: 0.537675 + 0.00664555\n",
      "[671]\tcv_agg's multi_logloss: 0.537667 + 0.00663578\n",
      "[672]\tcv_agg's multi_logloss: 0.537646 + 0.00662371\n",
      "[673]\tcv_agg's multi_logloss: 0.537641 + 0.00664801\n",
      "[674]\tcv_agg's multi_logloss: 0.53764 + 0.00665827\n",
      "[675]\tcv_agg's multi_logloss: 0.537638 + 0.00667584\n",
      "[676]\tcv_agg's multi_logloss: 0.537633 + 0.00666489\n",
      "[677]\tcv_agg's multi_logloss: 0.537633 + 0.00668007\n",
      "[678]\tcv_agg's multi_logloss: 0.537624 + 0.00667903\n",
      "[679]\tcv_agg's multi_logloss: 0.53764 + 0.00666837\n",
      "[680]\tcv_agg's multi_logloss: 0.537638 + 0.00669258\n",
      "[681]\tcv_agg's multi_logloss: 0.537623 + 0.0066894\n",
      "[682]\tcv_agg's multi_logloss: 0.537616 + 0.00667663\n",
      "[683]\tcv_agg's multi_logloss: 0.537598 + 0.0066656\n",
      "[684]\tcv_agg's multi_logloss: 0.537587 + 0.00665611\n",
      "[685]\tcv_agg's multi_logloss: 0.537587 + 0.0066397\n",
      "[686]\tcv_agg's multi_logloss: 0.537596 + 0.00663187\n",
      "[687]\tcv_agg's multi_logloss: 0.537595 + 0.0066368\n",
      "[688]\tcv_agg's multi_logloss: 0.537598 + 0.0066412\n",
      "[689]\tcv_agg's multi_logloss: 0.537598 + 0.00663562\n",
      "[690]\tcv_agg's multi_logloss: 0.537602 + 0.00663207\n",
      "[691]\tcv_agg's multi_logloss: 0.537585 + 0.00662517\n",
      "[692]\tcv_agg's multi_logloss: 0.537583 + 0.00662145\n",
      "[693]\tcv_agg's multi_logloss: 0.5376 + 0.00659313\n",
      "[694]\tcv_agg's multi_logloss: 0.53762 + 0.00659141\n",
      "[695]\tcv_agg's multi_logloss: 0.537622 + 0.0066313\n",
      "[696]\tcv_agg's multi_logloss: 0.537629 + 0.00663021\n",
      "[697]\tcv_agg's multi_logloss: 0.537618 + 0.00662447\n",
      "[698]\tcv_agg's multi_logloss: 0.537617 + 0.00661724\n",
      "[699]\tcv_agg's multi_logloss: 0.537609 + 0.00662929\n",
      "[700]\tcv_agg's multi_logloss: 0.537609 + 0.00664283\n",
      "[701]\tcv_agg's multi_logloss: 0.537606 + 0.00664535\n",
      "[702]\tcv_agg's multi_logloss: 0.537614 + 0.00664362\n",
      "[703]\tcv_agg's multi_logloss: 0.537593 + 0.00662872\n",
      "[704]\tcv_agg's multi_logloss: 0.537605 + 0.00662282\n",
      "[705]\tcv_agg's multi_logloss: 0.537598 + 0.0066209\n",
      "[706]\tcv_agg's multi_logloss: 0.537607 + 0.00662289\n",
      "[707]\tcv_agg's multi_logloss: 0.537601 + 0.00662228\n",
      "[708]\tcv_agg's multi_logloss: 0.537606 + 0.0066214\n",
      "[709]\tcv_agg's multi_logloss: 0.537605 + 0.00660643\n",
      "[710]\tcv_agg's multi_logloss: 0.537565 + 0.00659886\n",
      "[711]\tcv_agg's multi_logloss: 0.537559 + 0.00660826\n",
      "[712]\tcv_agg's multi_logloss: 0.537553 + 0.00660868\n",
      "[713]\tcv_agg's multi_logloss: 0.537532 + 0.006616\n",
      "[714]\tcv_agg's multi_logloss: 0.537511 + 0.00660564\n",
      "[715]\tcv_agg's multi_logloss: 0.537503 + 0.00660932\n",
      "[716]\tcv_agg's multi_logloss: 0.537492 + 0.00661176\n",
      "[717]\tcv_agg's multi_logloss: 0.537493 + 0.00663477\n",
      "[718]\tcv_agg's multi_logloss: 0.537458 + 0.00664317\n",
      "[719]\tcv_agg's multi_logloss: 0.537446 + 0.00664613\n",
      "[720]\tcv_agg's multi_logloss: 0.537431 + 0.00664484\n",
      "[721]\tcv_agg's multi_logloss: 0.537426 + 0.00665964\n",
      "[722]\tcv_agg's multi_logloss: 0.537419 + 0.00667212\n",
      "[723]\tcv_agg's multi_logloss: 0.537418 + 0.0066789\n",
      "[724]\tcv_agg's multi_logloss: 0.537401 + 0.00667885\n",
      "[725]\tcv_agg's multi_logloss: 0.537375 + 0.00667024\n",
      "[726]\tcv_agg's multi_logloss: 0.537373 + 0.00668303\n",
      "[727]\tcv_agg's multi_logloss: 0.537366 + 0.00666963\n",
      "[728]\tcv_agg's multi_logloss: 0.537356 + 0.00668037\n",
      "[729]\tcv_agg's multi_logloss: 0.537363 + 0.00668142\n",
      "[730]\tcv_agg's multi_logloss: 0.537364 + 0.00668939\n",
      "[731]\tcv_agg's multi_logloss: 0.537361 + 0.00667919\n",
      "[732]\tcv_agg's multi_logloss: 0.537366 + 0.00669271\n",
      "[733]\tcv_agg's multi_logloss: 0.53736 + 0.00669335\n",
      "[734]\tcv_agg's multi_logloss: 0.537345 + 0.00669044\n",
      "[735]\tcv_agg's multi_logloss: 0.537338 + 0.00668985\n",
      "[736]\tcv_agg's multi_logloss: 0.537322 + 0.0067019\n",
      "[737]\tcv_agg's multi_logloss: 0.53732 + 0.00669857\n",
      "[738]\tcv_agg's multi_logloss: 0.537314 + 0.00671769\n",
      "[739]\tcv_agg's multi_logloss: 0.537319 + 0.00670751\n",
      "[740]\tcv_agg's multi_logloss: 0.537311 + 0.00669493\n",
      "[741]\tcv_agg's multi_logloss: 0.537307 + 0.00669516\n",
      "[742]\tcv_agg's multi_logloss: 0.537308 + 0.00670079\n",
      "[743]\tcv_agg's multi_logloss: 0.537318 + 0.00668448\n",
      "[744]\tcv_agg's multi_logloss: 0.537318 + 0.00665729\n",
      "[745]\tcv_agg's multi_logloss: 0.537297 + 0.00666369\n",
      "[746]\tcv_agg's multi_logloss: 0.537316 + 0.00666295\n",
      "[747]\tcv_agg's multi_logloss: 0.537321 + 0.00669012\n",
      "[748]\tcv_agg's multi_logloss: 0.537309 + 0.00667313\n",
      "[749]\tcv_agg's multi_logloss: 0.537299 + 0.00667099\n",
      "[750]\tcv_agg's multi_logloss: 0.537291 + 0.00666185\n",
      "[751]\tcv_agg's multi_logloss: 0.53729 + 0.00666926\n",
      "[752]\tcv_agg's multi_logloss: 0.53727 + 0.00664944\n",
      "[753]\tcv_agg's multi_logloss: 0.537256 + 0.0066691\n",
      "[754]\tcv_agg's multi_logloss: 0.537255 + 0.00667994\n",
      "[755]\tcv_agg's multi_logloss: 0.537236 + 0.0066707\n",
      "[756]\tcv_agg's multi_logloss: 0.537245 + 0.00665175\n",
      "[757]\tcv_agg's multi_logloss: 0.537228 + 0.00665096\n",
      "[758]\tcv_agg's multi_logloss: 0.537215 + 0.00664566\n",
      "[759]\tcv_agg's multi_logloss: 0.537223 + 0.00665132\n",
      "[760]\tcv_agg's multi_logloss: 0.53724 + 0.006644\n",
      "[761]\tcv_agg's multi_logloss: 0.537242 + 0.00664746\n",
      "[762]\tcv_agg's multi_logloss: 0.537211 + 0.00664529\n",
      "[763]\tcv_agg's multi_logloss: 0.537208 + 0.00666286\n",
      "[764]\tcv_agg's multi_logloss: 0.5372 + 0.00666873\n",
      "[765]\tcv_agg's multi_logloss: 0.537202 + 0.00668275\n",
      "[766]\tcv_agg's multi_logloss: 0.537193 + 0.00667293\n",
      "[767]\tcv_agg's multi_logloss: 0.537171 + 0.00666911\n",
      "[768]\tcv_agg's multi_logloss: 0.537136 + 0.00666169\n",
      "[769]\tcv_agg's multi_logloss: 0.537141 + 0.00668302\n",
      "[770]\tcv_agg's multi_logloss: 0.53714 + 0.00667868\n",
      "[771]\tcv_agg's multi_logloss: 0.537146 + 0.00667599\n",
      "[772]\tcv_agg's multi_logloss: 0.537145 + 0.00668357\n",
      "[773]\tcv_agg's multi_logloss: 0.53713 + 0.00666424\n",
      "[774]\tcv_agg's multi_logloss: 0.537125 + 0.00667313\n",
      "[775]\tcv_agg's multi_logloss: 0.537121 + 0.00667134\n",
      "[776]\tcv_agg's multi_logloss: 0.537116 + 0.00666291\n",
      "[777]\tcv_agg's multi_logloss: 0.537102 + 0.00666511\n",
      "[778]\tcv_agg's multi_logloss: 0.537099 + 0.00665996\n",
      "[779]\tcv_agg's multi_logloss: 0.537095 + 0.00664718\n",
      "[780]\tcv_agg's multi_logloss: 0.537113 + 0.00663148\n",
      "[781]\tcv_agg's multi_logloss: 0.537095 + 0.00663037\n",
      "[782]\tcv_agg's multi_logloss: 0.53708 + 0.00664227\n",
      "[783]\tcv_agg's multi_logloss: 0.537061 + 0.00664223\n",
      "[784]\tcv_agg's multi_logloss: 0.537058 + 0.0066428\n",
      "[785]\tcv_agg's multi_logloss: 0.537055 + 0.00664853\n",
      "[786]\tcv_agg's multi_logloss: 0.53707 + 0.00665251\n",
      "[787]\tcv_agg's multi_logloss: 0.537052 + 0.0066433\n",
      "[788]\tcv_agg's multi_logloss: 0.537059 + 0.00665789\n",
      "[789]\tcv_agg's multi_logloss: 0.537066 + 0.00666177\n",
      "[790]\tcv_agg's multi_logloss: 0.537075 + 0.00667012\n",
      "[791]\tcv_agg's multi_logloss: 0.537072 + 0.00666842\n",
      "[792]\tcv_agg's multi_logloss: 0.537042 + 0.00668253\n",
      "[793]\tcv_agg's multi_logloss: 0.537041 + 0.00669212\n",
      "[794]\tcv_agg's multi_logloss: 0.53706 + 0.00669393\n",
      "[795]\tcv_agg's multi_logloss: 0.537055 + 0.00668653\n",
      "[796]\tcv_agg's multi_logloss: 0.53705 + 0.00670814\n",
      "[797]\tcv_agg's multi_logloss: 0.537042 + 0.00671286\n",
      "[798]\tcv_agg's multi_logloss: 0.537023 + 0.00672222\n",
      "[799]\tcv_agg's multi_logloss: 0.537023 + 0.00672644\n",
      "[800]\tcv_agg's multi_logloss: 0.537037 + 0.00671331\n",
      "[801]\tcv_agg's multi_logloss: 0.537031 + 0.0066882\n",
      "[802]\tcv_agg's multi_logloss: 0.537033 + 0.00668814\n",
      "[803]\tcv_agg's multi_logloss: 0.537032 + 0.00668673\n",
      "[804]\tcv_agg's multi_logloss: 0.53705 + 0.00669327\n",
      "[805]\tcv_agg's multi_logloss: 0.537038 + 0.00668672\n",
      "[806]\tcv_agg's multi_logloss: 0.537059 + 0.00671897\n",
      "[807]\tcv_agg's multi_logloss: 0.537059 + 0.00671778\n",
      "[808]\tcv_agg's multi_logloss: 0.537057 + 0.00671535\n",
      "[809]\tcv_agg's multi_logloss: 0.537065 + 0.00672649\n",
      "[810]\tcv_agg's multi_logloss: 0.537074 + 0.006737\n",
      "[811]\tcv_agg's multi_logloss: 0.537068 + 0.00674606\n",
      "[812]\tcv_agg's multi_logloss: 0.537069 + 0.00671943\n",
      "[813]\tcv_agg's multi_logloss: 0.537073 + 0.00672303\n",
      "[814]\tcv_agg's multi_logloss: 0.53707 + 0.00673859\n",
      "[815]\tcv_agg's multi_logloss: 0.537051 + 0.00675789\n",
      "[816]\tcv_agg's multi_logloss: 0.537061 + 0.00674422\n",
      "[817]\tcv_agg's multi_logloss: 0.537056 + 0.00676676\n",
      "[818]\tcv_agg's multi_logloss: 0.537077 + 0.00676823\n",
      "[819]\tcv_agg's multi_logloss: 0.537078 + 0.00677958\n",
      "[820]\tcv_agg's multi_logloss: 0.537047 + 0.00679806\n",
      "[821]\tcv_agg's multi_logloss: 0.537033 + 0.00677653\n",
      "[822]\tcv_agg's multi_logloss: 0.537024 + 0.00677885\n",
      "[823]\tcv_agg's multi_logloss: 0.53703 + 0.00676641\n",
      "[824]\tcv_agg's multi_logloss: 0.537036 + 0.00676871\n",
      "[825]\tcv_agg's multi_logloss: 0.537002 + 0.00674966\n",
      "[826]\tcv_agg's multi_logloss: 0.536981 + 0.00675054\n",
      "[827]\tcv_agg's multi_logloss: 0.53698 + 0.00676943\n",
      "[828]\tcv_agg's multi_logloss: 0.536974 + 0.00678008\n",
      "[829]\tcv_agg's multi_logloss: 0.536975 + 0.00676259\n",
      "[830]\tcv_agg's multi_logloss: 0.536958 + 0.00678001\n",
      "[831]\tcv_agg's multi_logloss: 0.536965 + 0.00677279\n",
      "[832]\tcv_agg's multi_logloss: 0.53695 + 0.00677902\n",
      "[833]\tcv_agg's multi_logloss: 0.536919 + 0.00677018\n",
      "[834]\tcv_agg's multi_logloss: 0.536906 + 0.00676943\n",
      "[835]\tcv_agg's multi_logloss: 0.536893 + 0.00678296\n",
      "[836]\tcv_agg's multi_logloss: 0.536889 + 0.00678315\n",
      "[837]\tcv_agg's multi_logloss: 0.536891 + 0.00677819\n",
      "[838]\tcv_agg's multi_logloss: 0.536888 + 0.00677366\n",
      "[839]\tcv_agg's multi_logloss: 0.536883 + 0.00678107\n",
      "[840]\tcv_agg's multi_logloss: 0.536879 + 0.00677193\n",
      "[841]\tcv_agg's multi_logloss: 0.536896 + 0.00677574\n",
      "[842]\tcv_agg's multi_logloss: 0.536916 + 0.00678246\n",
      "[843]\tcv_agg's multi_logloss: 0.536905 + 0.006785\n",
      "[844]\tcv_agg's multi_logloss: 0.536903 + 0.00678954\n",
      "[845]\tcv_agg's multi_logloss: 0.536898 + 0.00679572\n",
      "[846]\tcv_agg's multi_logloss: 0.536886 + 0.00679397\n",
      "[847]\tcv_agg's multi_logloss: 0.536862 + 0.00678974\n",
      "[848]\tcv_agg's multi_logloss: 0.536863 + 0.00678699\n",
      "[849]\tcv_agg's multi_logloss: 0.536869 + 0.00677721\n",
      "[850]\tcv_agg's multi_logloss: 0.536865 + 0.00677774\n",
      "[851]\tcv_agg's multi_logloss: 0.536844 + 0.00676842\n",
      "[852]\tcv_agg's multi_logloss: 0.536857 + 0.00675528\n",
      "[853]\tcv_agg's multi_logloss: 0.536853 + 0.00677048\n",
      "[854]\tcv_agg's multi_logloss: 0.536856 + 0.0067827\n",
      "[855]\tcv_agg's multi_logloss: 0.53684 + 0.00677956\n",
      "[856]\tcv_agg's multi_logloss: 0.536853 + 0.00680581\n",
      "[857]\tcv_agg's multi_logloss: 0.536837 + 0.00680638\n",
      "[858]\tcv_agg's multi_logloss: 0.536843 + 0.00679619\n",
      "[859]\tcv_agg's multi_logloss: 0.536833 + 0.00681472\n",
      "[860]\tcv_agg's multi_logloss: 0.536824 + 0.00679979\n",
      "[861]\tcv_agg's multi_logloss: 0.536816 + 0.0067921\n",
      "[862]\tcv_agg's multi_logloss: 0.536804 + 0.00679021\n",
      "[863]\tcv_agg's multi_logloss: 0.536809 + 0.00679518\n",
      "[864]\tcv_agg's multi_logloss: 0.53681 + 0.00681458\n",
      "[865]\tcv_agg's multi_logloss: 0.536789 + 0.00680596\n",
      "[866]\tcv_agg's multi_logloss: 0.536765 + 0.0067954\n",
      "[867]\tcv_agg's multi_logloss: 0.536748 + 0.0068007\n",
      "[868]\tcv_agg's multi_logloss: 0.536748 + 0.00681107\n",
      "[869]\tcv_agg's multi_logloss: 0.536753 + 0.00681534\n",
      "[870]\tcv_agg's multi_logloss: 0.536758 + 0.00682207\n",
      "[871]\tcv_agg's multi_logloss: 0.536754 + 0.00682264\n",
      "[872]\tcv_agg's multi_logloss: 0.53674 + 0.0068342\n",
      "[873]\tcv_agg's multi_logloss: 0.536731 + 0.00682821\n",
      "[874]\tcv_agg's multi_logloss: 0.536727 + 0.0068348\n",
      "[875]\tcv_agg's multi_logloss: 0.536721 + 0.00681606\n",
      "[876]\tcv_agg's multi_logloss: 0.536727 + 0.0068301\n",
      "[877]\tcv_agg's multi_logloss: 0.536728 + 0.00684336\n",
      "[878]\tcv_agg's multi_logloss: 0.536752 + 0.00685367\n",
      "[879]\tcv_agg's multi_logloss: 0.536748 + 0.00684258\n",
      "[880]\tcv_agg's multi_logloss: 0.536751 + 0.00685268\n",
      "[881]\tcv_agg's multi_logloss: 0.53674 + 0.0068535\n",
      "[882]\tcv_agg's multi_logloss: 0.536742 + 0.00687699\n",
      "[883]\tcv_agg's multi_logloss: 0.536744 + 0.00687931\n",
      "[884]\tcv_agg's multi_logloss: 0.53674 + 0.00688441\n",
      "[885]\tcv_agg's multi_logloss: 0.536736 + 0.00688371\n",
      "[886]\tcv_agg's multi_logloss: 0.536723 + 0.00687596\n",
      "[887]\tcv_agg's multi_logloss: 0.536724 + 0.00688106\n",
      "[888]\tcv_agg's multi_logloss: 0.536737 + 0.00690134\n",
      "[889]\tcv_agg's multi_logloss: 0.536744 + 0.00691075\n",
      "[890]\tcv_agg's multi_logloss: 0.536745 + 0.00691168\n",
      "[891]\tcv_agg's multi_logloss: 0.536733 + 0.00688906\n",
      "[892]\tcv_agg's multi_logloss: 0.536729 + 0.00688188\n",
      "[893]\tcv_agg's multi_logloss: 0.536718 + 0.00686706\n",
      "[894]\tcv_agg's multi_logloss: 0.536726 + 0.00688553\n",
      "[895]\tcv_agg's multi_logloss: 0.536742 + 0.0068965\n",
      "[896]\tcv_agg's multi_logloss: 0.53671 + 0.00689629\n",
      "[897]\tcv_agg's multi_logloss: 0.536691 + 0.00689594\n",
      "[898]\tcv_agg's multi_logloss: 0.536672 + 0.00689105\n",
      "[899]\tcv_agg's multi_logloss: 0.536672 + 0.00690239\n",
      "[900]\tcv_agg's multi_logloss: 0.536671 + 0.00689068\n",
      "[901]\tcv_agg's multi_logloss: 0.536678 + 0.006895\n",
      "[902]\tcv_agg's multi_logloss: 0.536668 + 0.00689202\n",
      "[903]\tcv_agg's multi_logloss: 0.53667 + 0.00690926\n",
      "[904]\tcv_agg's multi_logloss: 0.53669 + 0.00691986\n",
      "[905]\tcv_agg's multi_logloss: 0.53669 + 0.00691587\n",
      "[906]\tcv_agg's multi_logloss: 0.536681 + 0.00689977\n",
      "[907]\tcv_agg's multi_logloss: 0.536677 + 0.00690475\n",
      "[908]\tcv_agg's multi_logloss: 0.536664 + 0.00688228\n",
      "[909]\tcv_agg's multi_logloss: 0.536667 + 0.00689274\n",
      "[910]\tcv_agg's multi_logloss: 0.536659 + 0.00688587\n",
      "[911]\tcv_agg's multi_logloss: 0.536666 + 0.0068819\n",
      "[912]\tcv_agg's multi_logloss: 0.536672 + 0.00689018\n",
      "[913]\tcv_agg's multi_logloss: 0.536659 + 0.0068958\n",
      "[914]\tcv_agg's multi_logloss: 0.536661 + 0.00690274\n",
      "[915]\tcv_agg's multi_logloss: 0.53666 + 0.006904\n",
      "[916]\tcv_agg's multi_logloss: 0.536667 + 0.0069016\n",
      "[917]\tcv_agg's multi_logloss: 0.53667 + 0.00689871\n",
      "[918]\tcv_agg's multi_logloss: 0.536689 + 0.00689918\n",
      "[919]\tcv_agg's multi_logloss: 0.536678 + 0.0069018\n",
      "[920]\tcv_agg's multi_logloss: 0.536677 + 0.00690874\n",
      "[921]\tcv_agg's multi_logloss: 0.536663 + 0.00689876\n",
      "[922]\tcv_agg's multi_logloss: 0.536665 + 0.00690842\n",
      "[923]\tcv_agg's multi_logloss: 0.536663 + 0.00689976\n",
      "[924]\tcv_agg's multi_logloss: 0.536675 + 0.00692837\n",
      "[925]\tcv_agg's multi_logloss: 0.536668 + 0.0069256\n",
      "[926]\tcv_agg's multi_logloss: 0.536686 + 0.0069195\n",
      "[927]\tcv_agg's multi_logloss: 0.536693 + 0.00691967\n",
      "[928]\tcv_agg's multi_logloss: 0.536709 + 0.00691717\n",
      "[929]\tcv_agg's multi_logloss: 0.536707 + 0.0069284\n",
      "[930]\tcv_agg's multi_logloss: 0.536718 + 0.00693388\n",
      "[931]\tcv_agg's multi_logloss: 0.536718 + 0.00694771\n",
      "[932]\tcv_agg's multi_logloss: 0.536714 + 0.00696519\n",
      "[933]\tcv_agg's multi_logloss: 0.536708 + 0.0069722\n",
      "[934]\tcv_agg's multi_logloss: 0.536707 + 0.00697551\n",
      "[935]\tcv_agg's multi_logloss: 0.536693 + 0.00697424\n",
      "[936]\tcv_agg's multi_logloss: 0.536697 + 0.0069652\n",
      "[937]\tcv_agg's multi_logloss: 0.536693 + 0.00696275\n",
      "[938]\tcv_agg's multi_logloss: 0.536694 + 0.00696709\n",
      "[939]\tcv_agg's multi_logloss: 0.536702 + 0.00697239\n",
      "[940]\tcv_agg's multi_logloss: 0.536716 + 0.00697828\n",
      "[941]\tcv_agg's multi_logloss: 0.536714 + 0.00695745\n",
      "[942]\tcv_agg's multi_logloss: 0.536714 + 0.00697201\n",
      "[943]\tcv_agg's multi_logloss: 0.53671 + 0.00696989\n"
     ]
    }
   ],
   "source": [
    "cv_reslut = lgb.cv(params, cv_dataset,\n",
    "                  num_boost_round = 1000, nfold = 5,\n",
    "                   metrics='multi_logloss',\n",
    "                   early_stopping_rounds = 30,verbose_eval = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sc_price</th>\n",
       "      <th>sc_bathrooms</th>\n",
       "      <th>sc_bedrooms</th>\n",
       "      <th>sc_longitude</th>\n",
       "      <th>sc_latitude</th>\n",
       "      <th>display_address_lbl</th>\n",
       "      <th>manager_id_lbl</th>\n",
       "      <th>building_id_lbl</th>\n",
       "      <th>street_address_lbl</th>\n",
       "      <th>created_month</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.328077</td>\n",
       "      <td>0.58025</td>\n",
       "      <td>1.312076</td>\n",
       "      <td>1.05691</td>\n",
       "      <td>-0.950246</td>\n",
       "      <td>12282</td>\n",
       "      <td>1568</td>\n",
       "      <td>3797</td>\n",
       "      <td>23484</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sc_price  sc_bathrooms  sc_bedrooms  sc_longitude  sc_latitude  \\\n",
       "0 -0.328077       0.58025     1.312076       1.05691    -0.950246   \n",
       "\n",
       "   display_address_lbl  manager_id_lbl  building_id_lbl  street_address_lbl  \\\n",
       "0                12282            1568             3797               23484   \n",
       "\n",
       "   created_month ...   190  191  192  193  194  195  196  197  198  199  \n",
       "0              6 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[1 rows x 229 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, train_size=.80, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sc_price</th>\n",
       "      <th>sc_bathrooms</th>\n",
       "      <th>sc_bedrooms</th>\n",
       "      <th>sc_longitude</th>\n",
       "      <th>sc_latitude</th>\n",
       "      <th>display_address_lbl</th>\n",
       "      <th>manager_id_lbl</th>\n",
       "      <th>building_id_lbl</th>\n",
       "      <th>street_address_lbl</th>\n",
       "      <th>created_month</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40116</th>\n",
       "      <td>-0.599280</td>\n",
       "      <td>-0.424573</td>\n",
       "      <td>-1.390344</td>\n",
       "      <td>-1.538312</td>\n",
       "      <td>-1.189751</td>\n",
       "      <td>11574</td>\n",
       "      <td>1422</td>\n",
       "      <td>810</td>\n",
       "      <td>247</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>-0.273837</td>\n",
       "      <td>-0.424573</td>\n",
       "      <td>-0.489538</td>\n",
       "      <td>-0.677940</td>\n",
       "      <td>0.518023</td>\n",
       "      <td>14348</td>\n",
       "      <td>4223</td>\n",
       "      <td>10717</td>\n",
       "      <td>21426</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>-0.585720</td>\n",
       "      <td>-0.424573</td>\n",
       "      <td>-0.489538</td>\n",
       "      <td>-1.541838</td>\n",
       "      <td>-1.153305</td>\n",
       "      <td>8631</td>\n",
       "      <td>760</td>\n",
       "      <td>4807</td>\n",
       "      <td>19056</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44468</th>\n",
       "      <td>5.095977</td>\n",
       "      <td>5.604361</td>\n",
       "      <td>3.113689</td>\n",
       "      <td>0.425735</td>\n",
       "      <td>0.710669</td>\n",
       "      <td>10118</td>\n",
       "      <td>2579</td>\n",
       "      <td>6556</td>\n",
       "      <td>15110</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42023</th>\n",
       "      <td>-0.517919</td>\n",
       "      <td>-0.424573</td>\n",
       "      <td>-1.390344</td>\n",
       "      <td>-0.110235</td>\n",
       "      <td>0.822611</td>\n",
       "      <td>15460</td>\n",
       "      <td>2845</td>\n",
       "      <td>2429</td>\n",
       "      <td>656</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sc_price  sc_bathrooms  sc_bedrooms  sc_longitude  sc_latitude  \\\n",
       "40116 -0.599280     -0.424573    -1.390344     -1.538312    -1.189751   \n",
       "774   -0.273837     -0.424573    -0.489538     -0.677940     0.518023   \n",
       "1599  -0.585720     -0.424573    -0.489538     -1.541838    -1.153305   \n",
       "44468  5.095977      5.604361     3.113689      0.425735     0.710669   \n",
       "42023 -0.517919     -0.424573    -1.390344     -0.110235     0.822611   \n",
       "\n",
       "       display_address_lbl  manager_id_lbl  building_id_lbl  \\\n",
       "40116                11574            1422              810   \n",
       "774                  14348            4223            10717   \n",
       "1599                  8631             760             4807   \n",
       "44468                10118            2579             6556   \n",
       "42023                15460            2845             2429   \n",
       "\n",
       "       street_address_lbl  created_month ...   190  191  192  193  194  195  \\\n",
       "40116                 247              5 ...     0    0    1    0    0    0   \n",
       "774                 21426              4 ...     0    0    0    0    0    0   \n",
       "1599                19056              6 ...     0    0    0    0    0    0   \n",
       "44468               15110              4 ...     0    0    1    0    0    0   \n",
       "42023                 656              4 ...     0    0    0    0    0    0   \n",
       "\n",
       "       196  197  198  199  \n",
       "40116    0    0    0    0  \n",
       "774      0    0    0    0  \n",
       "1599     0    0    0    0  \n",
       "44468    0    0    0    0  \n",
       "42023    0    0    0    0  \n",
       "\n",
       "[5 rows x 229 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgr = lgb.LGBMClassifier(objective = 'multiclass',\n",
    "                         learning_rate=0.1,\n",
    "                         n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rgr.fit(X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        categorical_feature = ['display_address_lbl', 'manager_id_lbl', 'building_id_lbl', 'street_address_lbl'],\n",
    "        eval_metric='multi_logloss',\n",
    "        early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = rgr.predict_proba(test_X,num_iteration = rgr.best_iteration/0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16035405,  0.38443535,  0.4552106 ],\n",
       "       [ 0.06430381,  0.05717463,  0.87852156],\n",
       "       [ 0.03839458,  0.34187124,  0.61973418],\n",
       "       ..., \n",
       "       [ 0.08386847,  0.39468382,  0.52144772],\n",
       "       [ 0.2322344 ,  0.63587213,  0.13189347],\n",
       "       [ 0.01420187,  0.1138008 ,  0.87199733]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "df = pd.read_json(open(\"../input/test.json\", \"r\"))\n",
    "labels2idx ={'high': 0, 'low': 1, 'medium': 2}\n",
    "sub_name = '../output/LightGBM_starter.csv'\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = df[\"listing_id\"]\n",
    "\n",
    "y_test = np.zeros((df.shape[0], 3))\n",
    "\n",
    "for N in range(3):\n",
    "    y_test[:,N] = pd.DataFrame(preds).iloc[:,[x for x in range(preds.shape[1]) if x%3 == N]].mean(axis=1)\n",
    "    \n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_test[:, labels2idx[label]]\n",
    "sub.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.74212271,  0.17109654,  0.33620017],\n",
       "       [-0.91322412, -1.06695261,  1.58006396],\n",
       "       [-1.91385035,  0.2170402 ,  0.87534819],\n",
       "       ..., \n",
       "       [-1.38161871,  0.10810954,  0.36711373],\n",
       "       [-0.46842601,  0.47846145, -0.99480119],\n",
       "       [-2.43156812, -0.32646238,  1.62422035]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'num_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7ea6507cf778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                              \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0mnum_class\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                              num_leaves=x)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     rgr.fit(X_train,y_train,\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'num_class'"
     ]
    }
   ],
   "source": [
    "for x in [8,15,31,63,127,255]:\n",
    "    rgr = lgb.LGBMClassifier(objective = 'multiclass',\n",
    "                             learning_rate=0.1,\n",
    "                             n_estimators=100000,\n",
    "                             num_class =3,\n",
    "                             num_leaves=x)\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "\n",
    "    print rgr.num_leaves, ' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_leaves = 31\n",
    "# 8 0.533950251891\n",
    "# 15 0.534017695883\n",
    "# 31 0.533337457941\n",
    "# 63 0.535837989584\n",
    "# 127 0.538235118996\n",
    "# 255 0.546729607409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160   0.532305066204\n",
      "170   0.533234947845\n",
      "180   0.53306705402\n",
      "190   0.533105412017\n",
      "200   0.531902339787\n",
      "210   0.534220217084\n"
     ]
    }
   ],
   "source": [
    "for x in [160,170,180,190,200,210]:\n",
    "    rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "                             n_estimators=100000,\n",
    "                             num_leaves=num_leaves,\n",
    "                             min_child_samples = x)\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "    print rgr.min_child_samples, ' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]\n",
    "#     print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_child_samples = 100\n",
    "# 10   0.533337457941\n",
    "# 20   0.533263247468\n",
    "# 30   0.535289720244\n",
    "# 40   0.533228908358\n",
    "# 50   0.534171528081\n",
    "# 60   0.533426694633\n",
    "# 70   0.532820041162\n",
    "# 80   0.532902415753\n",
    "# 90   0.531844072176\n",
    "# 100   0.53178303038\n",
    "# 110   0.533220584562\n",
    "# 120   0.533929718659\n",
    "# 130   0.532662257772\n",
    "# 140   0.532125059541\n",
    "# 150   0.532639213339\n",
    "# 160   0.532305066204\n",
    "# 170   0.533234947845\n",
    "# 180   0.53306705402\n",
    "# 190   0.533105412017\n",
    "# 200   0.531902339787\n",
    "# 210   0.534220217084\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3   0.534473187429\n",
      "0.4   0.532180375183\n",
      "0.5   0.531460371729\n",
      "0.6   0.52982761516\n",
      "0.7   0.530897962036\n",
      "0.8   0.531948878135\n",
      "0.9   0.532586875189\n"
     ]
    }
   ],
   "source": [
    "for x in [0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "                             n_estimators=100000,\n",
    "                             num_leaves=num_leaves,\n",
    "                             min_child_samples = min_child_samples,\n",
    "                             colsample_bytree = x)\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "    # print 'best_round: ', rgr.best_iteration\n",
    "    print rgr.colsample_bytree, ' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colsample_bytree = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5   0.537526883916\n",
      "0.6   0.535739141308\n",
      "0.7   0.533475341743\n",
      "0.8   0.532631951484\n",
      "0.9   0.531377832399\n"
     ]
    }
   ],
   "source": [
    "for x in [0.5,0.6,0.7,0.8,0.9]:\n",
    "    rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "                             n_estimators=100000,\n",
    "                             num_leaves=num_leaves,\n",
    "                             min_child_samples = min_child_samples,\n",
    "                             colsample_bytree = colsample_bytree,\n",
    "                             subsample = x,\n",
    "                             subsample_freq=1)\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "    # print 'best_round: ', rgr.best_iteration\n",
    "    print rgr.subsample, ' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subsample = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15   0.539288189734\n",
      "31   0.535639813978\n",
      "63   0.533283444874\n",
      "127   0.532144055737\n",
      "255   0.531377832399\n",
      "511   0.531200059402\n",
      "1023   0.532617672046\n",
      "2047   0.532119589388\n"
     ]
    }
   ],
   "source": [
    "for x in [15,31,63, 127, 255, 511, 1023, 2047]:\n",
    "    rgr = lgb.LGBMClassifier(learning_rate=0.1,                             \n",
    "                             n_estimators=100000,\n",
    "                             num_leaves=num_leaves,\n",
    "                             min_child_samples = min_child_samples,\n",
    "                             colsample_bytree = colsample_bytree,\n",
    "                             subsample = subsample,\n",
    "                             subsample_freq=1,\n",
    "                             max_bin = x )\n",
    "\n",
    "    rgr.fit(X_train,y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose = False)\n",
    "\n",
    "\n",
    "    # print 'best_round: ', rgr.best_iteration\n",
    "    print rgr.max_bin,' ', rgr.evals_result_.get('valid_0').get('multi_logloss')[rgr.best_iteration]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_bin = 511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n",
      "    1 | 02m50s | \u001b[35m  -0.53476\u001b[0m | \u001b[32m            0.9494\u001b[0m | \u001b[32m 206.0155\u001b[0m | \u001b[32m           111.6937\u001b[0m | \u001b[32m     53.0017\u001b[0m | \u001b[32m     0.9958\u001b[0m | \n",
      "    2 | 02m11s | \u001b[35m  -0.53134\u001b[0m | \u001b[32m            0.9097\u001b[0m | \u001b[32m 710.0274\u001b[0m | \u001b[32m            99.8716\u001b[0m | \u001b[32m     25.7253\u001b[0m | \u001b[32m     0.8223\u001b[0m | \n",
      "    3 | 01m12s |   -0.53298 |             0.5736 |  508.9968 |            144.0163 |      28.6098 |      0.9377 | \n",
      "    4 | 01m24s |   -0.53490 |             0.8441 |  683.6996 |             99.5012 |      60.9060 |      0.9267 | \n",
      "    5 | 01m06s |   -0.53391 |             0.5226 |  508.3731 |             85.1011 |      36.6520 |      0.8504 | \n",
      "    6 | 01m02s |   -0.53513 |             0.6736 |  319.5854 |            124.2871 |      61.2123 |      0.8560 | \n",
      "    7 | 01m09s |   -0.53263 |             0.6901 |  470.4126 |            136.2148 |      37.3028 |      0.8218 | \n",
      "    8 | 01m13s |   -0.53334 |             0.9346 |  352.0016 |            147.4805 |      39.1799 |      0.9080 | \n",
      "    9 | 01m34s |   -0.53230 |             0.7673 |  347.2218 |            151.3890 |      29.7680 |      0.8735 | \n",
      "   10 | 01m59s |   -0.53209 |             0.8957 |  386.8950 |            133.4809 |      30.6284 |      0.8357 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/bayes_opt/helpers.py:95: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = (mean - y_max - xi)/std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_bin |   min_child_samples |   num_leaves |   subsample | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00035908]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 01m42s |   -0.53312 |             0.5305 |  797.2248 |             92.6381 |      25.8138 |      0.8091 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.49498158e-05]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 01m42s | \u001b[35m  -0.53122\u001b[0m | \u001b[32m            0.7626\u001b[0m | \u001b[32m 290.6732\u001b[0m | \u001b[32m           116.4943\u001b[0m | \u001b[32m     15.3131\u001b[0m | \u001b[32m     0.8439\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00023937]), 'nit': 6, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 01m44s |   -0.53166 |             0.7140 |  431.8401 |             98.0688 |      16.3717 |      0.8915 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.00377147e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.20073208e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 03m18s |   -0.53323 |             0.9458 |  704.1814 |            123.2425 |      17.8612 |      0.9948 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.65901365e-05]), 'nit': 3, 'funcalls': 46}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00016809]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 01m51s |   -0.53307 |             0.7208 |  773.9992 |             81.2863 |      21.2061 |      0.9746 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.66505998e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 01m56s |   -0.53220 |             0.8672 |  661.9549 |             90.8773 |      17.9356 |      0.9945 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.77417712e-05]), 'nit': 4, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 01m44s |   -0.53238 |             0.9901 |  209.5177 |            154.7229 |      22.2663 |      0.9860 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.45074409e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 01m44s |   -0.53176 |             0.9354 |  275.2759 |            133.4616 |      15.6176 |      0.9118 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00075529]), 'nit': 5, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 02m19s |   -0.53238 |             0.6194 |  423.0654 |            156.2254 |      19.2615 |      0.9731 | \n",
      "   20 | 01m43s |   -0.53149 |             0.8494 |  333.8046 |            124.6656 |      18.1923 |      0.9127 | \n",
      "   21 | 01m41s |   -0.53127 |             0.7548 |  327.3567 |            158.6803 |      18.6545 |      0.9304 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00114462]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.0008617]), 'nit': 4, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 01m44s |   -0.53188 |             0.6976 |  367.2999 |             95.5699 |      16.6479 |      0.9259 | \n",
      "   23 | 01m44s |   -0.53178 |             0.6097 |  712.2395 |             91.5011 |      21.4893 |      0.9545 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00115603]), 'nit': 5, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 01m41s |   -0.53123 |             0.8706 |  202.2066 |             80.8088 |      16.6911 |      0.8613 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00040309]), 'nit': 4, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -8.14082450e-05]), 'nit': 6, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 01m55s |   -0.53153 |             0.7534 |  308.8735 |            101.4059 |      15.0581 |      0.9337 | \n",
      "   26 | 01m58s |   -0.53224 |             0.8008 |  387.4367 |            126.0620 |      16.2544 |      0.9734 | \n",
      "   27 | 01m44s |   -0.53484 |             0.7328 |  789.5658 |            141.8161 |      52.6390 |      0.9155 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00021941]), 'nit': 3, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 01m31s |   -0.53446 |             0.6520 |  431.9204 |             96.2836 |      47.7710 |      0.8855 | \n",
      "   29 | 02m26s |   -0.53192 |             0.5354 |  242.3317 |            100.4000 |      15.9467 |      0.9749 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -4.30197000e-05]), 'nit': 7, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00013341]), 'nit': 4, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 01m36s |   -0.53204 |             0.6275 |  573.4928 |             87.5118 |      24.2194 |      0.8411 | \n",
      "   31 | 02m25s | \u001b[35m  -0.53102\u001b[0m | \u001b[32m            0.8426\u001b[0m | \u001b[32m 478.6974\u001b[0m | \u001b[32m           117.6221\u001b[0m | \u001b[32m     16.4580\u001b[0m | \u001b[32m     0.8206\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.26833237e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 02m03s |   -0.53494 |             0.7151 |  770.4839 |             99.8584 |      62.7594 |      0.8415 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00010201]), 'nit': 5, 'funcalls': 51}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 01m34s |   -0.53188 |             0.5727 |  616.0457 |            110.8740 |      21.0601 |      0.9422 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -5.09879189e-05]), 'nit': 8, 'funcalls': 54}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 02m07s |   -0.53309 |             0.9948 |  547.5036 |             88.5593 |      17.0859 |      0.9977 | \n",
      "   35 | 01m25s |   -0.53168 |             0.5229 |  204.3560 |            135.1914 |      15.3167 |      0.8876 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00010035]), 'nit': 6, 'funcalls': 56}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00018057]), 'nit': 5, 'funcalls': 56}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 | 01m35s |   -0.53194 |             0.5922 |  611.8562 |             86.9664 |      22.1675 |      0.9013 | \n",
      "   37 | 01m40s |   -0.53183 |             0.8796 |  453.9247 |            127.4825 |      23.3588 |      0.8768 | \n",
      "   38 | 01m46s |   -0.53152 |             0.8095 |  578.5334 |            115.9199 |      22.4066 |      0.9495 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.0001312]), 'nit': 6, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 01m43s |   -0.53222 |             0.6637 |  588.7522 |            159.7344 |      17.8775 |      0.9793 | \n",
      "   40 | 01m34s |   -0.53259 |             0.5042 |  320.8941 |            150.5419 |      16.5171 |      0.8000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  2.37601344e-05]), 'nit': 5, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00062186]), 'nit': 6, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 01m36s |   -0.53352 |             0.8728 |  602.1469 |            148.9227 |      42.3492 |      0.8142 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.25386391e-05]), 'nit': 4, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 02m04s |   -0.53225 |             0.9996 |  339.5156 |            157.0639 |      15.0079 |      0.9203 | \n",
      "   43 | 01m34s |   -0.53223 |             0.6486 |  265.7415 |             87.4480 |      18.3331 |      0.8010 | \n",
      "   44 | 01m34s |   -0.53255 |             0.6474 |  286.1596 |            159.6759 |      27.0409 |      0.9674 | \n",
      "   45 | 01m55s |   -0.53185 |             0.7595 |  764.2768 |            116.4333 |      24.4025 |      0.9210 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00079656]), 'nit': 4, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 | 01m55s |   -0.53223 |             0.7986 |  790.9825 |            139.1079 |      17.6317 |      0.8300 | \n",
      "   47 | 01m38s |   -0.53181 |             0.5268 |  468.2110 |            100.4549 |      20.0324 |      0.8654 | \n",
      "   48 | 01m55s |   -0.53173 |             0.7773 |  460.9678 |            157.3346 |      15.2557 |      0.9048 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.0005743]), 'nit': 6, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 01m42s |   -0.53184 |             0.5113 |  260.9516 |            113.5624 |      15.8408 |      0.8203 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujin/AI/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00112517]), 'nit': 3, 'funcalls': 46}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 01m40s |   -0.53239 |             0.7990 |  340.5197 |            105.1115 |      28.4028 |      0.9560 | \n"
     ]
    }
   ],
   "source": [
    "def lgbm_cv(max_bin, num_leaves, min_child_samples, colsample_bytree, subsample, learning_rate=0.1):\n",
    "    skf = list(KFold(len(train_y), 5))\n",
    "    scores=[]\n",
    "    for i, (train, val) in enumerate(skf):\n",
    "        est=lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                               max_bin=int(max_bin),\n",
    "                               num_leaves=int(num_leaves),\n",
    "                               min_child_samples=int(min_child_samples),\n",
    "                               colsample_bytree=colsample_bytree,\n",
    "                               subsample=subsample,\n",
    "                               subsample_freq = 1\n",
    "                              )\n",
    " \n",
    "        train_x_fold = train_X[train]\n",
    "        train_y_fold = train_y[train]\n",
    "        val_x_fold = train_X[val]\n",
    "        val_y_fold = train_y[val]\n",
    "        est.set_params( n_estimators=100000)\n",
    "        est.fit(train_x_fold,\n",
    "                train_y_fold,\n",
    "                eval_set=[(val_x_fold, val_y_fold)],\n",
    "                eval_metric='multi_logloss',\n",
    "                early_stopping_rounds=50,\n",
    "                verbose = False\n",
    "               )\n",
    "        val_y_predict_fold = est.predict_proba(val_x_fold)\n",
    "        score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "        scores.append(score)\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "lgbm_BO = BayesianOptimization(lgbm_cv, \n",
    "                               {\n",
    "                                'max_bin': (200,800),\n",
    "                                'num_leaves': (15,63),\n",
    "                                'min_child_samples' :(80,160),\n",
    "                                'colsample_bytree': (0.5,1),\n",
    "                                'subsample' : (0.8,1)})\n",
    "\n",
    "lgbm_BO.maximize(init_points=10, n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lgbm_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    print (\"Blend %d estimators for %d folds\" % (len(estimators), fold))\n",
    "    skf = list(KFold(len(train_y), fold))\n",
    "    N_class = len(set(train_y))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], N_class*len(estimators)))\n",
    "    test_blend_x = np.zeros((test_x.shape[0], N_class*len(estimators)))\n",
    "    scores = np.zeros ((len(skf),len(estimators)))\n",
    "    best_rounds = np.zeros ((len(skf),len(estimators)))\n",
    "    \n",
    "\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], N_class*len(skf)))\n",
    "        for i, (train, val) in enumerate(skf):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x[train]\n",
    "            train_y_fold = train_y[train]\n",
    "            val_x_fold = train_x[val]\n",
    "            val_y_fold = train_y[val]\n",
    "            if early_stopping_rounds==0: # without early stopping\n",
    "                est.fit(train_x_fold, train_y_fold)\n",
    "                best_rounds[i,j]=est.n_estimators\n",
    "                val_y_predict_fold = est.predict_proba(val_x_fold)\n",
    "                score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "                print (\"Score: \", score)\n",
    "                scores[i,j]=score\n",
    "                train_blend_x[val, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "                test_blend_x_j[:,i] = est.predict_proba(test_x)\n",
    "                print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            else:                        # early stopping\n",
    "                est.set_params( n_estimators=100000)\n",
    "                est.fit(train_x_fold,\n",
    "                        train_y_fold,\n",
    "                        eval_set=[(val_x_fold, val_y_fold)],\n",
    "                        eval_metric='multi_logloss',\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose=False\n",
    "                       )\n",
    "                best_round=est.best_iteration\n",
    "                best_rounds[i,j]=best_round\n",
    "                print (\"best round %d\" % (best_round))\n",
    "                val_y_predict_fold = est.predict_proba(val_x_fold,num_iteration=best_round)\n",
    "                score = log_loss(val_y_fold, val_y_predict_fold)\n",
    "                print (\"Score: \", score)\n",
    "                scores[i,j]=score\n",
    "                train_blend_x[val, (j*N_class):(j+1)*N_class] = val_y_predict_fold\n",
    "                test_blend_x_j[:,(i*N_class):(i+1)*N_class] = est.predict_proba(test_x,num_iteration=best_round)\n",
    "                print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "       \n",
    "        test_blend_x_j = pd.DataFrame(test_blend_x_j)\n",
    "        for N in range(N_class):\n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x, scores,best_rounds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>max_bin</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.458039</td>\n",
       "      <td>117.622103</td>\n",
       "      <td>478.697403</td>\n",
       "      <td>0.842639</td>\n",
       "      <td>0.820588</td>\n",
       "      <td>-0.531018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.313144</td>\n",
       "      <td>116.494344</td>\n",
       "      <td>290.673175</td>\n",
       "      <td>0.762613</td>\n",
       "      <td>0.843922</td>\n",
       "      <td>-0.531225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.691140</td>\n",
       "      <td>80.808810</td>\n",
       "      <td>202.206598</td>\n",
       "      <td>0.870567</td>\n",
       "      <td>0.861266</td>\n",
       "      <td>-0.531231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.654455</td>\n",
       "      <td>158.680310</td>\n",
       "      <td>327.356657</td>\n",
       "      <td>0.754814</td>\n",
       "      <td>0.930391</td>\n",
       "      <td>-0.531267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.192282</td>\n",
       "      <td>124.665623</td>\n",
       "      <td>333.804592</td>\n",
       "      <td>0.849373</td>\n",
       "      <td>0.912663</td>\n",
       "      <td>-0.531491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  min_child_samples     max_bin  colsample_bytree  subsample  \\\n",
       "20   16.458039         117.622103  478.697403          0.842639   0.820588   \n",
       "1    15.313144         116.494344  290.673175          0.762613   0.843922   \n",
       "13   16.691140          80.808810  202.206598          0.870567   0.861266   \n",
       "10   18.654455         158.680310  327.356657          0.754814   0.930391   \n",
       "9    18.192282         124.665623  333.804592          0.849373   0.912663   \n",
       "\n",
       "       score  \n",
       "20 -0.531018  \n",
       "1  -0.531225  \n",
       "13 -0.531231  \n",
       "10 -0.531267  \n",
       "9  -0.531491  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_bo_scores = pd.DataFrame([[s[0]['num_leaves'],\n",
    "                               s[0]['min_child_samples'],\n",
    "                               s[0]['max_bin'],\n",
    "                               s[0]['colsample_bytree'],\n",
    "                               s[0]['subsample'],\n",
    "                               s[1]] for s in zip(lgbm_BO.res['all']['params'],lgbm_BO.res['all']['values'])],\n",
    "                            columns = ['num_leaves',\n",
    "                                       'min_child_samples',\n",
    "                                       'max_bin',\n",
    "                                       'colsample_bytree',\n",
    "                                       'subsample',\n",
    "                                       'score'])\n",
    "gbm_bo_scores=gbm_bo_scores.sort_values('score',ascending=False)\n",
    "gbm_bo_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend 5 estimators for 5 folds\n",
      "Model 1: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.842639, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=478, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=117, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=16,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.820588, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 1 fold 1\n",
      "best round 5753\n",
      "('Score: ', 0.53784225704008859)\n",
      "Model 1 fold 1 fitting finished in 274.031s\n",
      "Model 1 fold 2\n",
      "best round 5187\n",
      "('Score: ', 0.52171515148042436)\n",
      "Model 1 fold 2 fitting finished in 241.103s\n",
      "Model 1 fold 3\n",
      "best round 4922\n",
      "('Score: ', 0.52046110692644332)\n",
      "Model 1 fold 3 fitting finished in 237.563s\n",
      "Model 1 fold 4\n",
      "best round 4465\n",
      "('Score: ', 0.5278600588979343)\n",
      "Model 1 fold 4 fitting finished in 211.716s\n",
      "Model 1 fold 5\n",
      "best round 5081\n",
      "('Score: ', 0.53806928668114651)\n",
      "Model 1 fold 5 fitting finished in 249.759s\n",
      "Score for model 1 is 0.529190\n",
      "Model 2: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.762613, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=290, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=116, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=15,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.843922, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 2 fold 1\n",
      "best round 5758\n",
      "('Score: ', 0.53719534060112029)\n",
      "Model 2 fold 1 fitting finished in 238.662s\n",
      "Model 2 fold 2\n",
      "best round 5699\n",
      "('Score: ', 0.52196213143152481)\n",
      "Model 2 fold 2 fitting finished in 253.955s\n",
      "Model 2 fold 3\n",
      "best round 5794\n",
      "('Score: ', 0.51989645091023096)\n",
      "Model 2 fold 3 fitting finished in 240.563s\n",
      "Model 2 fold 4\n",
      "best round 4888\n",
      "('Score: ', 0.5278438613107016)\n",
      "Model 2 fold 4 fitting finished in 206.141s\n",
      "Model 2 fold 5\n",
      "best round 5280\n",
      "('Score: ', 0.53869844995493443)\n",
      "Model 2 fold 5 fitting finished in 223.068s\n",
      "Score for model 2 is 0.529119\n",
      "Model 3: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.870567, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=202, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=80, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=16,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.861266, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 3 fold 1\n",
      "best round 5232\n",
      "('Score: ', 0.53735341613449628)\n",
      "Model 3 fold 1 fitting finished in 231.596s\n",
      "Model 3 fold 2\n",
      "best round 5705\n",
      "('Score: ', 0.5218664368726057)\n",
      "Model 3 fold 2 fitting finished in 245.874s\n",
      "Model 3 fold 3\n",
      "best round 5423\n",
      "('Score: ', 0.52045246150142288)\n",
      "Model 3 fold 3 fitting finished in 251.721s\n",
      "Model 3 fold 4\n",
      "best round 4340\n",
      "('Score: ', 0.52725544016994375)\n",
      "Model 3 fold 4 fitting finished in 200.229s\n",
      "Model 3 fold 5\n",
      "best round 5567\n",
      "('Score: ', 0.53719341483844196)\n",
      "Model 3 fold 5 fitting finished in 244.960s\n",
      "Score for model 3 is 0.528824\n",
      "Model 4: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.754814, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=327, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=158, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=18,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.930391, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 4 fold 1\n",
      "best round 5068\n",
      "('Score: ', 0.53872590492840111)\n",
      "Model 4 fold 1 fitting finished in 239.652s\n",
      "Model 4 fold 2\n",
      "best round 4876\n",
      "('Score: ', 0.52224376244234227)\n",
      "Model 4 fold 2 fitting finished in 226.817s\n",
      "Model 4 fold 3\n",
      "best round 4775\n",
      "('Score: ', 0.52067625020010477)\n",
      "Model 4 fold 3 fitting finished in 227.534s\n",
      "Model 4 fold 4\n",
      "best round 3890\n",
      "('Score: ', 0.5284071955663463)\n",
      "Model 4 fold 4 fitting finished in 188.189s\n",
      "Model 4 fold 5\n",
      "best round 4930\n",
      "('Score: ', 0.53789009631815743)\n",
      "Model 4 fold 5 fitting finished in 233.943s\n",
      "Score for model 4 is 0.529589\n",
      "Model 5: LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.849373, drop_rate=0.1,\n",
      "        is_unbalance=False, learning_rate=0.01, max_bin=333, max_depth=-1,\n",
      "        max_drop=50, min_child_samples=124, min_child_weight=5,\n",
      "        min_split_gain=0, n_estimators=100000, nthread=-1, num_leaves=18,\n",
      "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5,\n",
      "        subsample=0.912663, subsample_for_bin=50000, subsample_freq=1,\n",
      "        uniform_drop=False, xgboost_dart_mode=False)\n",
      "Model 5 fold 1\n",
      "best round 5013\n",
      "('Score: ', 0.53821884038705992)\n",
      "Model 5 fold 1 fitting finished in 245.876s\n",
      "Model 5 fold 2\n",
      "best round 4548\n",
      "('Score: ', 0.522198238818675)\n",
      "Model 5 fold 2 fitting finished in 224.806s\n",
      "Model 5 fold 3\n",
      "best round 4933\n",
      "('Score: ', 0.52079652950815436)\n",
      "Model 5 fold 3 fitting finished in 245.741s\n",
      "Model 5 fold 4\n",
      "best round 4041\n",
      "('Score: ', 0.52827128604341478)\n",
      "Model 5 fold 4 fitting finished in 219.562s\n",
      "Model 5 fold 5\n",
      "best round 4669\n",
      "('Score: ', 0.53796523902911508)\n",
      "Model 5 fold 5 fitting finished in 242.485s\n",
      "Score for model 5 is 0.529490\n",
      "Score for blended models is 0.529242\n"
     ]
    }
   ],
   "source": [
    "estimators = [lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=478,\n",
    "                     num_leaves=16,\n",
    "                     min_child_samples=117,\n",
    "                     colsample_bytree=0.842639,\n",
    "                     subsample=0.820588,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531018\n",
    "              lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=290,\n",
    "                     num_leaves=15,\n",
    "                     min_child_samples=116,\n",
    "                     colsample_bytree=0.762613,\n",
    "                     subsample=0.843922,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531225\n",
    "              lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=202,\n",
    "                     num_leaves=16,\n",
    "                     min_child_samples=80,\n",
    "                     colsample_bytree=0.870567,\n",
    "                     subsample=0.861266,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531231\n",
    "              lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=327,\n",
    "                     num_leaves=18,\n",
    "                     min_child_samples=158,\n",
    "                     colsample_bytree=0.754814,\n",
    "                     subsample=0.930391,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531267\n",
    "              lgb.LGBMClassifier(\n",
    "                     learning_rate=0.01, ## use smaller learning rate for better accuracies\n",
    "                     n_estimators=100000,\n",
    "                     max_bin=333,\n",
    "                     num_leaves=18,\n",
    "                     min_child_samples=124,\n",
    "                     colsample_bytree=0.849373,\n",
    "                     subsample=0.912663,\n",
    "                     subsample_freq=1),\n",
    "#               score -0.531491              \n",
    "        ]\n",
    "\n",
    "(train_blend_x_gbm,\n",
    " test_blend_x_gbm,\n",
    " blend_scores_gbm,\n",
    " best_rounds_gbm) = lgbm_blend(estimators, train_X, train_y, test_X,\n",
    "                                 5,\n",
    "                                 500) #as the learning rate decreases the number of stopping rounds need to be increased\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52918957  0.52911925  0.52882423  0.52958864  0.52949003]\n",
      "[ 5081.6  5483.8  5253.4  4707.8  4640.8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "now = datetime.now()\n",
    "\n",
    "name_train_blend = '../output/train_blend_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "name_test_blend = '../output/test_blend_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "print (np.mean(blend_scores_gbm,axis=0))\n",
    "print (np.mean(best_rounds_gbm,axis=0))\n",
    "np.savetxt(name_train_blend,train_blend_x_gbm, delimiter=\",\")\n",
    "np.savetxt(name_test_blend,test_blend_x_gbm, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "df = pd.read_json(open(\"../input/test.json\", \"r\"))\n",
    "labels2idx ={'high': 0, 'low': 1, 'medium': 2}\n",
    "sub_name = '../output/sub_LightGBM_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = df[\"listing_id\"]\n",
    "\n",
    "y_test = np.zeros((df.shape[0], 3))\n",
    "\n",
    "for N in range(3):\n",
    "    y_test[:,N] = pd.DataFrame(test_blend_x_gbm).iloc[:,[x for x in range(test_blend_x_gbm.shape[1]) if x%3 == N]].mean(axis=1)\n",
    "    \n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_test[:, labels2idx[label]]\n",
    "sub.to_csv(sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
